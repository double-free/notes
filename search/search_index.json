{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Ye's Notes Notes for my random readings. There's no explicit goal, but I'd love to keep my brain busy. The notes can be roughly split to 3 topics, they are related to my work to varying degrees: Trading Computer science Mathematics Again, I'm not an expert in any of these areas, sorry for any error or incompleteness, and appreciate if you can point them out. Trading WIP Computer Science WIP Mathematics WIP","title":"Ye's Notes"},{"location":"#yes-notes","text":"Notes for my random readings. There's no explicit goal, but I'd love to keep my brain busy. The notes can be roughly split to 3 topics, they are related to my work to varying degrees: Trading Computer science Mathematics Again, I'm not an expert in any of these areas, sorry for any error or incompleteness, and appreciate if you can point them out.","title":"Ye's Notes"},{"location":"#trading","text":"WIP","title":"Trading"},{"location":"#computer-science","text":"WIP","title":"Computer Science"},{"location":"#mathematics","text":"WIP","title":"Mathematics"},{"location":"computer-science/algorithm/swiss_map/","text":"Hash Table in Rust: SwissTable \u5728\u770b Rust \u7684\u6587\u6863\u7684\u65f6\u5019\u770b\u5230\u4e86\u8fd9\u4e48\u4e00\u53e5\uff1a The hash table implementation is a Rust port of Google\u2019s SwissTable. The original C++ version of SwissTable can be found here, and this CppCon talk gives an overview of how the algorithm works. SwissTable \u4e3b\u8981\u5e0c\u671b\u89e3\u51b3 cpp \u6807\u51c6\u5e93\u4e2d std::unordered_map , std::unordered_set \u7684\u4e00\u4e9b\u75db\u70b9\uff0c\u5305\u62ec\uff1a \u7531\u4e8e\u4f7f\u7528\u94fe\u8868\u89e3\u51b3\u54c8\u5e0c\u51b2\u7a81\uff0c\u5bf9 cpu \u7f13\u5b58\u4e0d\u53cb\u597d \u5bf9\u4e8e\u6bcf\u4e2a\u503c\uff0c\u9700\u8981\u5b58\u50a8 hash value\uff0c\u5bfc\u81f4\u989d\u5916\u7684\u5185\u5b58\u4f7f\u7528 \u6bcf\u6b21 find \u64cd\u4f5c\u90fd\u9700\u8981 3 \u6b65\uff0c\u5373\uff1a1) \u627e\u5230 bucket\uff0c2) \u8df3\u8fc7\u94fe\u8868\u7684 dummy head \u8282\u70b9\uff0c3) \u5f00\u59cb\u904d\u5386\u94fe\u8868\uff0c\u5176\u4e2d\u7b2c\u4e8c\u6b65\u662f\u53ef\u4ee5\u4f18\u5316\u7684\uff08flat map\uff09 \u51fa\u4e8e\u597d\u5947\uff0c\u4e86\u89e3\u4e86\u4e0b SwissTable \u548c cpp \u6807\u51c6\u5e93\u7684 HashTable \u5b9e\u73b0\u6709\u4ec0\u4e48\u533a\u522b\u3002 1 HashTable in cpp standard library \u5982\u56fe\u6240\u793a\uff1a \u6807\u51c6\u5e93 HashTable \u4f7f\u7528\u94fe\u5730\u5740\u6cd5\u89e3\u51b3\u51b2\u7a81\uff0c\u5373 bucket + linked list\u3002 \u5bf9\u4e8e\u6bcf\u4e2a\u503c\uff0c\u5728\u94fe\u8868\u91cc\u5b58\u50a8\u5b83\u7684 hash value \u548c pointer\uff0c\u4e00\u5171 16 \u5b57\u8282\uff0c\u8fd8\u6709\u94fe\u8868\u8282\u70b9\u6307\u9488\u7684\u989d\u5916\u5f00\u9500 8 \u5b57\u8282\u3002 \u503c\u5f97\u6ce8\u610f\u7684\u662f\uff1a \u5bf9\u4e8e\u6bcf\u4e2a bucket \u7684 linked list\uff0c\u90fd\u6709\u4e00\u4e2a dummy head\uff08\u4e3a\u4e86\u63d2\u5165\u65b0\u7684\u5143\u7d20\u65b9\u4fbf\uff09 \u5728\u6807\u51c6\u5e93\u7684\u5b9e\u73b0\u91cc\uff0c\u628a\u6240\u6709\u7684 value \u8fde\u63a5\u6210\u4e86\u4e00\u4e2a\u5927\u7684 linked list\uff0c\u8fd9\u662f\u4e3a\u4e86\u4f18\u5316\u8fed\u4ee3\u6027\u80fd\uff08\u8df3\u8fc7\u7a7a\u7684 bucket\uff09 \u5728 2 \u7684\u524d\u63d0\u4e0b\uff0cdummy head \u88ab\u8bbe\u7f6e\u4e3a\u4e0a\u4e00\u4e2a bucket \u7684\u6700\u540e\u4e00\u4e2a\u5143\u7d20 2 SwissTable High level concepts to keep in mind: - open-addressing - searches in parallel using SIMD - first-come-first-serve collision resolution - chunked (SIMD) triangular (quadratic-ish) probing - tombstones to avoid backshifts \u76f8\u5bf9\u4e8e\u6807\u51c6\u5e93\u7684\u5b9e\u73b0\uff0cSwissTable \u505a\u4e86\u4e00\u4e9b\u4fee\u6539\u3002 # Modification What we gain What we lose 1 \u53bb\u6389 dummy head find \u65f6\u51cf\u5c11\u4e00\u6b21\u94fe\u8868\u8282\u70b9\u64cd\u4f5c \u8fed\u4ee3\u6574\u4e2a\u5bb9\u5668\u9700\u8981\u904d\u5386\u6240\u6709\u7a7a\u6876 2 \u53bb\u6389 hash value payload \u4ece 16 \u5b57\u8282\u51cf\u5c11\u5230 8 \u5b57\u8282 rehash \u7684\u65f6\u5019\u9700\u8981\u91cd\u65b0\u8ba1\u7b97 hash value\uff0c\u4f46\u662f\u7528\u6237\u4e5f\u53ef\u4ee5\u9009\u62e9\u81ea\u5df1\u5b58\u5728\u7ed3\u6784\u4f53\u91cc 3 \u4e0d\u518d\u4f7f\u7528\u94fe\u5730\u5740\u6cd5\uff0c\u8f6c\u800c\u4f7f\u7528\u5f00\u653e\u5730\u5740\u6cd5\u89e3\u51b3\u51b2\u7a81 \u53bb\u6389\u4e86\u94fe\u8868\u8282\u70b9\u6307\u9488\u7684\u5f00\u9500 8 \u5b57\u8282\uff0c\u5e76\u4e14\u5bf9\u7f13\u5b58\u53cb\u597d \u9700\u8981\u8bb0\u5f55\u5143\u7d20\u72b6\u6001\uff0cload factor \u5931\u6548 4 \u76f4\u63a5\u628a\u503c\u653e\u5230 bucket \u91cc \u7701\u53bb\u4ece bucket \u8df3\u8f6c\u5177\u4f53\u503c\u7684\u8fc7\u7a0b \u9700\u8981\u54e8\u5175\uff0c\u4e14\u5143\u7d20\u8d8a\u591a\u6027\u80fd\u8d8a\u5dee 5 \u5c06\u54e8\u5175\u6362\u6210 meta data \u6027\u80fd\u66f4\u4f18 \u5b9e\u73b0\u590d\u6742 \u5bf9\u4e8e 5\uff0cmeta data \u9700\u8981\u8868\u793a\u6bcf\u4e00\u4e2a\u5751\u4f4d\u5904\u4e8e\u54ea\u4e00\u79cd\u72b6\u6001\uff1a empty full deleted \u56e0\u4e3a\u6709 3 \u4e2a\u72b6\u6001\uff0c\u6ca1\u529e\u6cd5\u7528\u4e00\u4e2a bit \u8868\u793a\u4e00\u4e2a\u5751\u4f4d\uff0c\u8fd9\u5c31\u975e\u5e38\u86cb\u75bc\u4e86\u3002 2.1 Control Bytes and Hashes SwissTable \u901a\u8fc7 \u4e24\u7ea7\u7684 hash value \u89e3\u51b3\u4e86\u8fd9\u4e2a\u95ee\u9898\uff0c\u5206\u522b\u662f 57 bits \u7684 H1 \u548c 7 bits \u7684 H2\u3002 \u5176\u4e2d\uff0cmeta data \u7531\u4e00\u4e2a bit \u4ee5\u53ca H2 \u7ec4\u6210\uff0c\u4e00\u5171 1 \u4e2a\u5b57\u8282\u3002\u5b83\u53ef\u80fd\u8868\u793a\uff1a 0b11111111 , empty 0b10000000 , deleted 0b0xxxxxxx , full, and the lower 7 bits is H2 \u6ce8\u610f\uff0c meta data \u662f\u5355\u72ec\u5b58\u653e\u7684 \uff0c\u5373 H2 \u5e76\u4e0d\u548c hash value \u5171\u7528\u3002\u5e76\u4e14 SwissTable \u4e2d\u7684\u503c\u672c\u6765\u4e5f\u4e0d\u4fdd\u5b58\u5176 hash value\u3002 2.2 Searching and Probing Here's the pseudo code: // higher 57 bits size_t H1 ( size_t hash ) { return hash >> 7 ;} // lower 7 bits size_t H2 ( size_t hash ) { return hash & 0x7f ;} iterator find ( const K & key , size_t hash ) const { size_t pos = H1 ( hash ) % size_ ; while ( true ) { // H1, H2 and key match if ( H2 ( hash ) == ctrl_ [ pos ] && key == slots_ [ pos ]) { return iterator_at ( pos ); } // note that \"kEmpty\" (but not \"kDeleted\") indicates the ends of elements under H1 if ( ctrl_ [ pos ] == kEmpty ) { return end (); } // H1 matches, H2 or key does not match, try next element with the same H1 pos = ( pos + 1 ) % size_ ; } } find \u64cd\u4f5c\u7684\u57fa\u672c\u6b65\u9aa4\uff1a \u6c42\u5f97 key \u7684 hash value\uff0c\u5f97\u5230 H1 \u548c H2 \u901a\u8fc7 H1 \u53d6\u4f59\u627e\u5230\u5bf9\u5e94\u7684 bucket index ( pos ) \u5bf9\u6bd4 H2 \u548c pos \u5bf9\u5e94\u7684 meta data\uff0c\u5982\u679c\u5339\u914d\uff0c\u518d\u6bd4\u8f83 key\uff0c\u82e5\u5339\u914d\uff0c\u8fd4\u56de\u627e\u5230\u7684\u5143\u7d20 \u82e5\u6ca1\u627e\u5230\uff0c\u79fb\u52a8\u5230 pos + 1 \u7ee7\u7eed\u6bd4\u8f83\uff0c\u76f4\u81f3\u627e\u5230 meta data \u662f EMPTY \u4f18\u52bf\uff1a extremely cache friendly. \u6211\u4eec\u5bf9\u6bd4\u7684 meta data ( ctrl_ ) \u53ea\u6709\u4e00\u4e2a\u5b57\u8282\u5927\u5c0f\uff0c64kB \u7684 L1 cache \u53ef\u4ee5\u5b58 64*1024 \u4e2a\u3002 2.3 SIMD optimization \u4e0a\u9762\u7684\u7b97\u6cd5\u770b\u8d77\u6765\u5df2\u7ecf\u975e\u5e38\u5b8c\u7f8e\u4e86\uff0c\u4f46\u662f\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 SIMD(Single Instruction Multiple Data) \u8fdb\u4e00\u6b65\u4f18\u5316 meta data \u7684\u6bd4\u8f83\u3002\u8fd9\u4e9b\u6307\u4ee4\u53ef\u4ee5\u540c\u65f6\u64cd\u4f5c 16 \u5b57\u8282\u7684\u6570\u636e\uff0c\u5e26\u6765\u6781\u5927\u7684\u6548\u7387\u63d0\u5347\u3002\u4f46\u662f\u4ed6\u4eec\u53ea\u4f5c\u7528\u4e8e Intel \u800c\u975e ARM \u7684\u82af\u7247\uff0c\u56e0\u4e3a ARM \u91c7\u7528\u7cbe\u7b80\u6307\u4ee4\u96c6\uff08sorry\uff0c Apple M1/M2)\u3002 \u7528\u5230\u7684\u6307\u4ee4\uff1a _mm_set1_epi8 \u4ee4 16 bytes \u7684\u6570\u636e\u7b49\u4e8e\u67d0\u4e2a\u76f8\u540c\u7684\u503c _mm_cmpeq_epi8 byte-wise \u5730\u5bf9\u6bd4\u4e24\u4e2a 16 bytes \u7684\u6570\u636e _mm_movemask_epi8 \u5c06\u6bcf\u4e2a byte \u7684\u6700\u9ad8\u4f4d\u53d6\u51fa\uff0c16 bytes \u7684\u6570\u636e\u53d8\u4e3a\u4e86 16 bits \u7ec4\u5408\u8d77\u6765\uff1a BitMask < uint32_t > Match ( h2_t hash ) const { auto match = _mm_set1_epi8 ( hash ); return BitMask < uint32_t > ( _mm_movemask_epi8 ( _mm_cmpeq_epi8 ( match , ctrl ))); } \u56e0\u4e3a\u53ef\u4ee5\u5e76\u884c\u5904\u7406 16 \u4e2a meta data\uff0c\u6211\u4eec\u53ef\u4ee5\u628a\u6bcf 16 \u4e2a\u5143\u7d20\u7684 meta data \u548c slots \u6346\u7ed1\u6210\u4e00\u4e2a Group\uff0c\u5e76\u4ee5 Group \u4e3a\u5355\u4f4d\u5b9e\u73b0 find \u64cd\u4f5c\u3002 iterator find ( const K & key , size_t hash ) const { // pos of a group size_t pos = H1 ( hash ) % num_groups_ ; while ( true ) { Group g { ctrl_ + pos * 16 }; // use SIMD function above to group-wise compare and find matched buckets for ( int i : g . Match ( H2 ( hash ))) { if ( key == slots_ [ pos + i ]) { return iterator_at ( pos * 16 + i ); } } if ( g . MatchEmpty ()) { return end (); } // next Group, instead of bucket pos = ( pos + 1 ) % num_groups_ ; } } Real Code in Rust hashbrown \u4f7f\u7528 Rust \u5b9e\u73b0\u4e86 SwissTable\uff0c\u5b83\u7684 find \u5b9e\u73b0\u5982\u4e0b\uff1a #[inline] fn probe_seq ( & self , hash : u64 ) -> ProbeSeq { ProbeSeq { pos : h1 ( hash ) & self . bucket_mask , stride : 0 , } } /// Searches for an element in the table. This uses dynamic dispatch to reduce the amount of /// code generated, but it is eliminated by LLVM optimizations. #[inline] fn find_inner ( & self , hash : u64 , eq : & mut dyn FnMut ( usize ) -> bool ) -> Option < usize > { let h2_hash = h2 ( hash ); let mut probe_seq = self . probe_seq ( hash ); loop { let group = unsafe { Group :: load ( self . ctrl ( probe_seq . pos )) }; for bit in group . match_byte ( h2_hash ) { let index = ( probe_seq . pos + bit ) & self . bucket_mask ; if likely ( eq ( index )) { return Some ( index ); } } if likely ( group . match_empty (). any_bit_set ()) { return None ; } probe_seq . move_next ( self . bucket_mask ); } } \u53ef\u4ee5\u770b\u51fa\u57fa\u672c\u548c\u4e0a\u6587\u63cf\u8ff0\u4e00\u81f4\uff0c\u4f46\u662f\u5b83\u4f7f\u7528\u4e86\u4e09\u89d2\u6570\u7ec4\u6765\u9009\u62e9\u4e0b\u4e00\u4e2a\u63a2\u6d4b\u4f4d\u7f6e\u3002 Reference Designing a Fast, Efficient, Cache-friendly Hash Table, Step by Step hashbrown hashbrown notes","title":"Hash Table in Rust: SwissTable"},{"location":"computer-science/algorithm/swiss_map/#hash-table-in-rust-swisstable","text":"\u5728\u770b Rust \u7684\u6587\u6863\u7684\u65f6\u5019\u770b\u5230\u4e86\u8fd9\u4e48\u4e00\u53e5\uff1a The hash table implementation is a Rust port of Google\u2019s SwissTable. The original C++ version of SwissTable can be found here, and this CppCon talk gives an overview of how the algorithm works. SwissTable \u4e3b\u8981\u5e0c\u671b\u89e3\u51b3 cpp \u6807\u51c6\u5e93\u4e2d std::unordered_map , std::unordered_set \u7684\u4e00\u4e9b\u75db\u70b9\uff0c\u5305\u62ec\uff1a \u7531\u4e8e\u4f7f\u7528\u94fe\u8868\u89e3\u51b3\u54c8\u5e0c\u51b2\u7a81\uff0c\u5bf9 cpu \u7f13\u5b58\u4e0d\u53cb\u597d \u5bf9\u4e8e\u6bcf\u4e2a\u503c\uff0c\u9700\u8981\u5b58\u50a8 hash value\uff0c\u5bfc\u81f4\u989d\u5916\u7684\u5185\u5b58\u4f7f\u7528 \u6bcf\u6b21 find \u64cd\u4f5c\u90fd\u9700\u8981 3 \u6b65\uff0c\u5373\uff1a1) \u627e\u5230 bucket\uff0c2) \u8df3\u8fc7\u94fe\u8868\u7684 dummy head \u8282\u70b9\uff0c3) \u5f00\u59cb\u904d\u5386\u94fe\u8868\uff0c\u5176\u4e2d\u7b2c\u4e8c\u6b65\u662f\u53ef\u4ee5\u4f18\u5316\u7684\uff08flat map\uff09 \u51fa\u4e8e\u597d\u5947\uff0c\u4e86\u89e3\u4e86\u4e0b SwissTable \u548c cpp \u6807\u51c6\u5e93\u7684 HashTable \u5b9e\u73b0\u6709\u4ec0\u4e48\u533a\u522b\u3002","title":"Hash Table in Rust: SwissTable"},{"location":"computer-science/algorithm/swiss_map/#1-hashtable-in-cpp-standard-library","text":"\u5982\u56fe\u6240\u793a\uff1a \u6807\u51c6\u5e93 HashTable \u4f7f\u7528\u94fe\u5730\u5740\u6cd5\u89e3\u51b3\u51b2\u7a81\uff0c\u5373 bucket + linked list\u3002 \u5bf9\u4e8e\u6bcf\u4e2a\u503c\uff0c\u5728\u94fe\u8868\u91cc\u5b58\u50a8\u5b83\u7684 hash value \u548c pointer\uff0c\u4e00\u5171 16 \u5b57\u8282\uff0c\u8fd8\u6709\u94fe\u8868\u8282\u70b9\u6307\u9488\u7684\u989d\u5916\u5f00\u9500 8 \u5b57\u8282\u3002 \u503c\u5f97\u6ce8\u610f\u7684\u662f\uff1a \u5bf9\u4e8e\u6bcf\u4e2a bucket \u7684 linked list\uff0c\u90fd\u6709\u4e00\u4e2a dummy head\uff08\u4e3a\u4e86\u63d2\u5165\u65b0\u7684\u5143\u7d20\u65b9\u4fbf\uff09 \u5728\u6807\u51c6\u5e93\u7684\u5b9e\u73b0\u91cc\uff0c\u628a\u6240\u6709\u7684 value \u8fde\u63a5\u6210\u4e86\u4e00\u4e2a\u5927\u7684 linked list\uff0c\u8fd9\u662f\u4e3a\u4e86\u4f18\u5316\u8fed\u4ee3\u6027\u80fd\uff08\u8df3\u8fc7\u7a7a\u7684 bucket\uff09 \u5728 2 \u7684\u524d\u63d0\u4e0b\uff0cdummy head \u88ab\u8bbe\u7f6e\u4e3a\u4e0a\u4e00\u4e2a bucket \u7684\u6700\u540e\u4e00\u4e2a\u5143\u7d20","title":"1 HashTable in cpp standard library"},{"location":"computer-science/algorithm/swiss_map/#2-swisstable","text":"High level concepts to keep in mind: - open-addressing - searches in parallel using SIMD - first-come-first-serve collision resolution - chunked (SIMD) triangular (quadratic-ish) probing - tombstones to avoid backshifts \u76f8\u5bf9\u4e8e\u6807\u51c6\u5e93\u7684\u5b9e\u73b0\uff0cSwissTable \u505a\u4e86\u4e00\u4e9b\u4fee\u6539\u3002 # Modification What we gain What we lose 1 \u53bb\u6389 dummy head find \u65f6\u51cf\u5c11\u4e00\u6b21\u94fe\u8868\u8282\u70b9\u64cd\u4f5c \u8fed\u4ee3\u6574\u4e2a\u5bb9\u5668\u9700\u8981\u904d\u5386\u6240\u6709\u7a7a\u6876 2 \u53bb\u6389 hash value payload \u4ece 16 \u5b57\u8282\u51cf\u5c11\u5230 8 \u5b57\u8282 rehash \u7684\u65f6\u5019\u9700\u8981\u91cd\u65b0\u8ba1\u7b97 hash value\uff0c\u4f46\u662f\u7528\u6237\u4e5f\u53ef\u4ee5\u9009\u62e9\u81ea\u5df1\u5b58\u5728\u7ed3\u6784\u4f53\u91cc 3 \u4e0d\u518d\u4f7f\u7528\u94fe\u5730\u5740\u6cd5\uff0c\u8f6c\u800c\u4f7f\u7528\u5f00\u653e\u5730\u5740\u6cd5\u89e3\u51b3\u51b2\u7a81 \u53bb\u6389\u4e86\u94fe\u8868\u8282\u70b9\u6307\u9488\u7684\u5f00\u9500 8 \u5b57\u8282\uff0c\u5e76\u4e14\u5bf9\u7f13\u5b58\u53cb\u597d \u9700\u8981\u8bb0\u5f55\u5143\u7d20\u72b6\u6001\uff0cload factor \u5931\u6548 4 \u76f4\u63a5\u628a\u503c\u653e\u5230 bucket \u91cc \u7701\u53bb\u4ece bucket \u8df3\u8f6c\u5177\u4f53\u503c\u7684\u8fc7\u7a0b \u9700\u8981\u54e8\u5175\uff0c\u4e14\u5143\u7d20\u8d8a\u591a\u6027\u80fd\u8d8a\u5dee 5 \u5c06\u54e8\u5175\u6362\u6210 meta data \u6027\u80fd\u66f4\u4f18 \u5b9e\u73b0\u590d\u6742 \u5bf9\u4e8e 5\uff0cmeta data \u9700\u8981\u8868\u793a\u6bcf\u4e00\u4e2a\u5751\u4f4d\u5904\u4e8e\u54ea\u4e00\u79cd\u72b6\u6001\uff1a empty full deleted \u56e0\u4e3a\u6709 3 \u4e2a\u72b6\u6001\uff0c\u6ca1\u529e\u6cd5\u7528\u4e00\u4e2a bit \u8868\u793a\u4e00\u4e2a\u5751\u4f4d\uff0c\u8fd9\u5c31\u975e\u5e38\u86cb\u75bc\u4e86\u3002","title":"2 SwissTable"},{"location":"computer-science/algorithm/swiss_map/#21-control-bytes-and-hashes","text":"SwissTable \u901a\u8fc7 \u4e24\u7ea7\u7684 hash value \u89e3\u51b3\u4e86\u8fd9\u4e2a\u95ee\u9898\uff0c\u5206\u522b\u662f 57 bits \u7684 H1 \u548c 7 bits \u7684 H2\u3002 \u5176\u4e2d\uff0cmeta data \u7531\u4e00\u4e2a bit \u4ee5\u53ca H2 \u7ec4\u6210\uff0c\u4e00\u5171 1 \u4e2a\u5b57\u8282\u3002\u5b83\u53ef\u80fd\u8868\u793a\uff1a 0b11111111 , empty 0b10000000 , deleted 0b0xxxxxxx , full, and the lower 7 bits is H2 \u6ce8\u610f\uff0c meta data \u662f\u5355\u72ec\u5b58\u653e\u7684 \uff0c\u5373 H2 \u5e76\u4e0d\u548c hash value \u5171\u7528\u3002\u5e76\u4e14 SwissTable \u4e2d\u7684\u503c\u672c\u6765\u4e5f\u4e0d\u4fdd\u5b58\u5176 hash value\u3002","title":"2.1 Control Bytes and Hashes"},{"location":"computer-science/algorithm/swiss_map/#22-searching-and-probing","text":"Here's the pseudo code: // higher 57 bits size_t H1 ( size_t hash ) { return hash >> 7 ;} // lower 7 bits size_t H2 ( size_t hash ) { return hash & 0x7f ;} iterator find ( const K & key , size_t hash ) const { size_t pos = H1 ( hash ) % size_ ; while ( true ) { // H1, H2 and key match if ( H2 ( hash ) == ctrl_ [ pos ] && key == slots_ [ pos ]) { return iterator_at ( pos ); } // note that \"kEmpty\" (but not \"kDeleted\") indicates the ends of elements under H1 if ( ctrl_ [ pos ] == kEmpty ) { return end (); } // H1 matches, H2 or key does not match, try next element with the same H1 pos = ( pos + 1 ) % size_ ; } } find \u64cd\u4f5c\u7684\u57fa\u672c\u6b65\u9aa4\uff1a \u6c42\u5f97 key \u7684 hash value\uff0c\u5f97\u5230 H1 \u548c H2 \u901a\u8fc7 H1 \u53d6\u4f59\u627e\u5230\u5bf9\u5e94\u7684 bucket index ( pos ) \u5bf9\u6bd4 H2 \u548c pos \u5bf9\u5e94\u7684 meta data\uff0c\u5982\u679c\u5339\u914d\uff0c\u518d\u6bd4\u8f83 key\uff0c\u82e5\u5339\u914d\uff0c\u8fd4\u56de\u627e\u5230\u7684\u5143\u7d20 \u82e5\u6ca1\u627e\u5230\uff0c\u79fb\u52a8\u5230 pos + 1 \u7ee7\u7eed\u6bd4\u8f83\uff0c\u76f4\u81f3\u627e\u5230 meta data \u662f EMPTY \u4f18\u52bf\uff1a extremely cache friendly. \u6211\u4eec\u5bf9\u6bd4\u7684 meta data ( ctrl_ ) \u53ea\u6709\u4e00\u4e2a\u5b57\u8282\u5927\u5c0f\uff0c64kB \u7684 L1 cache \u53ef\u4ee5\u5b58 64*1024 \u4e2a\u3002","title":"2.2 Searching and Probing"},{"location":"computer-science/algorithm/swiss_map/#23-simd-optimization","text":"\u4e0a\u9762\u7684\u7b97\u6cd5\u770b\u8d77\u6765\u5df2\u7ecf\u975e\u5e38\u5b8c\u7f8e\u4e86\uff0c\u4f46\u662f\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 SIMD(Single Instruction Multiple Data) \u8fdb\u4e00\u6b65\u4f18\u5316 meta data \u7684\u6bd4\u8f83\u3002\u8fd9\u4e9b\u6307\u4ee4\u53ef\u4ee5\u540c\u65f6\u64cd\u4f5c 16 \u5b57\u8282\u7684\u6570\u636e\uff0c\u5e26\u6765\u6781\u5927\u7684\u6548\u7387\u63d0\u5347\u3002\u4f46\u662f\u4ed6\u4eec\u53ea\u4f5c\u7528\u4e8e Intel \u800c\u975e ARM \u7684\u82af\u7247\uff0c\u56e0\u4e3a ARM \u91c7\u7528\u7cbe\u7b80\u6307\u4ee4\u96c6\uff08sorry\uff0c Apple M1/M2)\u3002 \u7528\u5230\u7684\u6307\u4ee4\uff1a _mm_set1_epi8 \u4ee4 16 bytes \u7684\u6570\u636e\u7b49\u4e8e\u67d0\u4e2a\u76f8\u540c\u7684\u503c _mm_cmpeq_epi8 byte-wise \u5730\u5bf9\u6bd4\u4e24\u4e2a 16 bytes \u7684\u6570\u636e _mm_movemask_epi8 \u5c06\u6bcf\u4e2a byte \u7684\u6700\u9ad8\u4f4d\u53d6\u51fa\uff0c16 bytes \u7684\u6570\u636e\u53d8\u4e3a\u4e86 16 bits \u7ec4\u5408\u8d77\u6765\uff1a BitMask < uint32_t > Match ( h2_t hash ) const { auto match = _mm_set1_epi8 ( hash ); return BitMask < uint32_t > ( _mm_movemask_epi8 ( _mm_cmpeq_epi8 ( match , ctrl ))); } \u56e0\u4e3a\u53ef\u4ee5\u5e76\u884c\u5904\u7406 16 \u4e2a meta data\uff0c\u6211\u4eec\u53ef\u4ee5\u628a\u6bcf 16 \u4e2a\u5143\u7d20\u7684 meta data \u548c slots \u6346\u7ed1\u6210\u4e00\u4e2a Group\uff0c\u5e76\u4ee5 Group \u4e3a\u5355\u4f4d\u5b9e\u73b0 find \u64cd\u4f5c\u3002 iterator find ( const K & key , size_t hash ) const { // pos of a group size_t pos = H1 ( hash ) % num_groups_ ; while ( true ) { Group g { ctrl_ + pos * 16 }; // use SIMD function above to group-wise compare and find matched buckets for ( int i : g . Match ( H2 ( hash ))) { if ( key == slots_ [ pos + i ]) { return iterator_at ( pos * 16 + i ); } } if ( g . MatchEmpty ()) { return end (); } // next Group, instead of bucket pos = ( pos + 1 ) % num_groups_ ; } }","title":"2.3 SIMD optimization"},{"location":"computer-science/algorithm/swiss_map/#real-code-in-rust","text":"hashbrown \u4f7f\u7528 Rust \u5b9e\u73b0\u4e86 SwissTable\uff0c\u5b83\u7684 find \u5b9e\u73b0\u5982\u4e0b\uff1a #[inline] fn probe_seq ( & self , hash : u64 ) -> ProbeSeq { ProbeSeq { pos : h1 ( hash ) & self . bucket_mask , stride : 0 , } } /// Searches for an element in the table. This uses dynamic dispatch to reduce the amount of /// code generated, but it is eliminated by LLVM optimizations. #[inline] fn find_inner ( & self , hash : u64 , eq : & mut dyn FnMut ( usize ) -> bool ) -> Option < usize > { let h2_hash = h2 ( hash ); let mut probe_seq = self . probe_seq ( hash ); loop { let group = unsafe { Group :: load ( self . ctrl ( probe_seq . pos )) }; for bit in group . match_byte ( h2_hash ) { let index = ( probe_seq . pos + bit ) & self . bucket_mask ; if likely ( eq ( index )) { return Some ( index ); } } if likely ( group . match_empty (). any_bit_set ()) { return None ; } probe_seq . move_next ( self . bucket_mask ); } } \u53ef\u4ee5\u770b\u51fa\u57fa\u672c\u548c\u4e0a\u6587\u63cf\u8ff0\u4e00\u81f4\uff0c\u4f46\u662f\u5b83\u4f7f\u7528\u4e86\u4e09\u89d2\u6570\u7ec4\u6765\u9009\u62e9\u4e0b\u4e00\u4e2a\u63a2\u6d4b\u4f4d\u7f6e\u3002","title":"Real Code in Rust"},{"location":"computer-science/algorithm/swiss_map/#reference","text":"Designing a Fast, Efficient, Cache-friendly Hash Table, Step by Step hashbrown hashbrown notes","title":"Reference"},{"location":"computer-science/lgbm/LgbmL1AndL2/","text":"LightGBM \u53c2\u6570\u4e2d\u7684 lambda_l1 \u548c lambda_l2 LightGBM \u7684\u53c2\u6570\u5927\u90e8\u5206\u610f\u4e49\u90fd\u80fd\u901a\u8fc7\u540d\u5b57\u731c\u51fa\u6765\uff0c\u4f8b\u5982 num_leaves \uff0c early_stopping \u7b49\u3002\u4f46\u662f\u6709\u4e24\u4e2a\u5e38\u7528\u53c2\u6570\u662f\u4e2a\u5f02\u7c7b\uff1a lambda_l1 lambda_l2 \u987a\u5e26\u4e0e\u4ed6\u4eec\u76f8\u5173\u7684\u8fd8\u6709\u4e00\u4e2a min_gain_to_split \u8981\u8c03\u8282\u8fd9\u4e9b\u53c2\u6570\u9700\u8981\u7406\u89e3\u4ed6\u4eec\u80cc\u540e\u7684\u542b\u4e49\u3002\u4f46\u662f\uff0clightGBM \u5230\u5e95\u662f\u5982\u4f55\u5b9a\u4e49\u7f51\u4e0a\u4f3c\u4e4e\u6ca1\u627e\u5230\u628a\u8fd9\u4e2a\u8bf4\u6e05\u695a\u7684\u3002\u5b98\u7f51\u53ea\u662f\u975e\u5e38\u7b80\u5355\u5730\u63d0\u4e86\u4e00\u4e0b\u8fd9\u4e9b\u662f\u4e3a\u4e86\u6b63\u5219\u5316\u3002 \u6240\u8c13\u6b63\u5219\u5316\uff08Regularization\uff09\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u4e00\u79cd\u5e38\u7528\u7684\u6280\u672f\uff0c\u5176\u4e3b\u8981\u76ee\u7684\u662f\u63a7\u5236\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u51cf\u5c0f\u8fc7\u62df\u5408\u3002\u6700\u57fa\u672c\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u662f\u5728\u539f\u76ee\u6807\uff08\u4ee3\u4ef7\uff09\u51fd\u6570 \u4e2d\u6dfb\u52a0\u60e9\u7f5a\u9879\uff0c\u5bf9\u590d\u6742\u5ea6\u9ad8\u7684\u6a21\u578b\u8fdb\u884c\u201c\u60e9\u7f5a\u201d\u3002 \u56e0\u6b64\u5bf9\u4e8e LightGBM \u6765\u8bb2\u8fd9\u51e0\u4e2a\u53c2\u6570\u80af\u5b9a\u662f\u7528\u4e8e\u63a7\u5236\u6811\u8282\u70b9\u5206\u88c2\u7684\u3002\u4f46\u662f\u4f3c\u4e4e\u4e5f\u6ca1\u627e\u5230\u7279\u5730\u9488\u5bf9 LightGBM \u5982\u4f55\u6b63\u5219\u5316\u7684\u4ecb\u7ecd\uff0c\u4e8e\u662f\u6211\u81ea\u5df1\u770b\u4e86\u4e0b\u6e90\u7801\u3002 1 \u7ed3\u8bba lambda_l1 , lambda_l2 \u548c min_gain_to_split \u90fd\u662f\u7528\u4e8e\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u907f\u514d\u8fc7\u62df\u5408\u7684\u3002 \u4ed6\u4eec\u4f5c\u7528\u4e8e\u6bcf\u4e2a\u8282\u70b9\u7684 gain\u3002gain \u5728 LightGBM \u4e2d\u7528\u4e8e\u63cf\u8ff0\u8282\u70b9\u4e0a\u6240\u6709\u6837\u672c\u7684\u8bad\u7ec3\u7a0b\u5ea6\u3002gain \u8d8a\u5c0f\u8bf4\u660e\u8bad\u7ec3\u8d8a\u5145\u5206\uff0c\u5206\u88c2\u4ef7\u503c\u8d8a\u4f4e\u3002 gain \u7684\u8ba1\u7b97\u65b9\u5f0f\u4e3a\uff1a \\[ \\frac{[\\text{Thresh}(\u68af\u5ea6\u548c, \\lambda_{L1})]^2}{\u4e8c\u9636\u5bfc\u6570\u548c + \\lambda_{L2}} \\] \u5bf9\u4e8e\u56de\u5f52\u95ee\u9898\uff0c\u4e8c\u9636\u5bfc\u6570\u4e3a1\uff0c\u5176\u548c\u4e3a\u8282\u70b9\u6837\u672c\u6570\u3002 lambda_l1 \u548c lambda_l2 \u90fd\u7528\u4e8e\u52a0\u901f gain \u7684\u51cf\u5c0f\u3002 lambda_l1 \uff1a\u8bbe\u7f6e\u4e00\u4e2a threshold\uff0cgain \u5c0f\u4e8e\u8fd9\u4e2a threshold \u76f4\u63a5\u8ba4\u4e3a\u662f 0\uff0c\u4e0d\u518d\u5206\u88c2\u3002 lambda_l2 \uff1a\u4e3a gain \u7684\u5206\u6bcd\uff08\u5373\u8282\u70b9\u6837\u672c\u6570\uff09\u589e\u52a0\u4e00\u4e2a\u5e38\u6570\u9879\uff0c\u4f5c\u7528\u4e8e\u5168\u7a0b\uff0c\u5728\u8282\u70b9\u6837\u672c\u6570\u5df2\u7ecf\u5f88\u5c0f\u7684\u65f6\u5019\uff0c\u80fd\u663e\u8457\u51cf\u5c0f gain \u907f\u514d\u5206\u88c2\u3002 min_gain_to_split \u7684\u4f5c\u7528\u53ef\u4ee5\u901a\u8fc7\u540d\u5b57\u731c\u51fa\u3002\u5c31\u662f\u5982\u679c\u4e00\u4e2a\u8282\u70b9\u7684 gain \u4f4e\u4e8e\u8fd9\u4e2a\u6570\uff0c\u4e0d\u518d\u5206\u88c2\u3002 2 \u6e90\u7801\u89e3\u8bfb Boosting \u7684\u6bcf\u4e00\u6b21\u8fed\u4ee3\u90fd\u4f1a\u751f\u6210\u4e00\u68f5\u6811\u3002\u5728\u751f\u6210\u6811\u7684\u65f6\u5019\uff0c\u6211\u4eec\u9700\u8981\u5bfb\u627e\u6bcf\u4e2a\u7279\u5f81\u7684\u6700\u4f73\u5206\u5272\u70b9\u3002 2.1 \u7528 gain \u6765\u51b3\u5b9a\u662f\u5426\u5206\u5272 \u5728 feature_histogram.hpp \u7528\u4e8e\u5bfb\u627e\u6700\u4f73\u5206\u5272\u70b9\u7684 FindBestThresholdSequentially() \u65b9\u6cd5\u4e2d\uff0c\u6709\u5982\u4e0b\u4ee3\u7801\u7528\u4e8e\u51b3\u5b9a\u662f\u5426\u5206\u5272\uff1a // current split gain double current_gain = GetSplitGains < USE_MC , USE_L1 , USE_MAX_OUTPUT , USE_SMOOTHING > ( sum_left_gradient , sum_left_hessian , sum_right_gradient , sum_right_hessian , meta_ -> config -> lambda_l1 , meta_ -> config -> lambda_l2 , meta_ -> config -> max_delta_step , constraints , meta_ -> monotone_type , meta_ -> config -> path_smooth , left_count , right_count , parent_output ); // gain with split is worse than without split if ( current_gain <= min_gain_shift ) { continue ; } // mark as able to be split is_splittable_ = true ; \u5176\u4e2d min_gain_shift \u7531\u4ee5\u4e0b\u51fd\u6570\u8ba1\u7b97\uff08\u7528\u5230\u4e86 min_gain_to_split \uff09\uff1a template < bool USE_RAND , bool USE_L1 , bool USE_MAX_OUTPUT , bool USE_SMOOTHING > double BeforeNumercal ( double sum_gradient , double sum_hessian , double parent_output , data_size_t num_data , SplitInfo * output , int * rand_threshold ) { is_splittable_ = false ; output -> monotone_type = meta_ -> monotone_type ; double gain_shift = GetLeafGain < USE_L1 , USE_MAX_OUTPUT , USE_SMOOTHING > ( sum_gradient , sum_hessian , meta_ -> config -> lambda_l1 , meta_ -> config -> lambda_l2 , meta_ -> config -> max_delta_step , meta_ -> config -> path_smooth , num_data , parent_output ); * rand_threshold = 0 ; if ( USE_RAND ) { if ( meta_ -> num_bin - 2 > 0 ) { * rand_threshold = meta_ -> rand . NextInt ( 0 , meta_ -> num_bin - 2 ); } } return gain_shift + meta_ -> config -> min_gain_to_split ; } \u53ef\u4ee5\u770b\u51fa min_gain_shift \u7531\u4e24\u90e8\u5206\u6784\u6210\uff1a \u672a\u5206\u5272\u8282\u70b9\u7684 gain\uff0c\u7531 GetLeafGain() \u8ba1\u7b97 \u914d\u7f6e\u7684 min_gain_to_split \u4e0e\u4e4b\u76f8\u6bd4\u8f83\u7684 current_gain \u5219\u662f\u8c03\u7528\u4e86 GetSplitGains() \uff1a template < bool USE_MC , bool USE_L1 , bool USE_MAX_OUTPUT , bool USE_SMOOTHING > static double GetSplitGains ( double sum_left_gradients , double sum_left_hessians , double sum_right_gradients , double sum_right_hessians , double l1 , double l2 , double max_delta_step , const FeatureConstraint * constraints , int8_t monotone_constraint , double smoothing , data_size_t left_count , data_size_t right_count , double parent_output ) { if ( ! USE_MC ) { return GetLeafGain < USE_L1 , USE_MAX_OUTPUT , USE_SMOOTHING > ( sum_left_gradients , sum_left_hessians , l1 , l2 , max_delta_step , smoothing , left_count , parent_output ) + GetLeafGain < USE_L1 , USE_MAX_OUTPUT , USE_SMOOTHING > ( sum_right_gradients , sum_right_hessians , l1 , l2 , max_delta_step , smoothing , right_count , parent_output ); } // omitted... } \u53ef\u4ee5\u770b\u51fa\uff0c GetSplitGains() \u5b9e\u9645\u5c31\u662f\u5bf9\u5206\u5272\u540e\u7684\u4e24\u4e2a\u5b50\u8282\u70b9\u5206\u522b\u8c03\u7528 GetLeafGain() \uff0c\u518d\u5c06 gains \u76f8\u52a0\u3002 \u6240\u4ee5\u672c\u8d28\u4e0a\u8fd9\u4e2a\u6bd4\u8f83\u7684\u610f\u4e49\u662f\uff0c\u5982\u679c\u5206\u5272\u540e\u7684 gain \u5c0f\u4e8e\u5206\u5272\u524d gain \u5916\u52a0 min_gain_to_split \uff0c\u5c31\u4e0d\u4f5c\u8fdb\u4e00\u6b65\u5206\u5272\u3002 \u73b0\u5728\u6211\u4eec\u660e\u767d\u4e86 min_gain_to_split \u7684\u539f\u7406\u4e86\uff0c lambda_l1 \u548c lambda_l2 \u5462\uff1f 2.2 \u5982\u4f55\u8ba1\u7b97 gain \u8ba1\u7b97 gain \u5c31\u9700\u8981\u7528\u5230 lambda_l1 \u548c lambda_l2 \u4e86\u3002 template < bool USE_L1 , bool USE_MAX_OUTPUT , bool USE_SMOOTHING > static double GetLeafGain ( double sum_gradients , double sum_hessians , double l1 , double l2 , double max_delta_step , double smoothing , data_size_t num_data , double parent_output ) { if ( ! USE_MAX_OUTPUT && ! USE_SMOOTHING ) { if ( USE_L1 ) { const double sg_l1 = ThresholdL1 ( sum_gradients , l1 ); return ( sg_l1 * sg_l1 ) / ( sum_hessians + l2 ); } else { return ( sum_gradients * sum_gradients ) / ( sum_hessians + l2 ); } } else { double output = CalculateSplittedLeafOutput < USE_L1 , USE_MAX_OUTPUT , USE_SMOOTHING > ( sum_gradients , sum_hessians , l1 , l2 , max_delta_step , smoothing , num_data , parent_output ); return GetLeafGainGivenOutput < USE_L1 > ( sum_gradients , sum_hessians , l1 , l2 , output ); } } gain \u7684\u8ba1\u7b97\u65b9\u6cd5\u5c31\u662f\uff1a \\[ \\frac{[\\text{Thresh}(\u68af\u5ea6\u548c, \\lambda_{L1})]^2}{\u4e8c\u9636\u5bfc\u6570\u548c + \\lambda_{L2}} \\] Thresh \u7684\u7b97\u6cd5\u5f88\u7b80\u5355\uff0c\u5c31\u662f\u5f53\u68af\u5ea6\u548c\u5728 \\([-\\lambda_{L1}, +\\lambda_{L1}]\\) \u533a\u95f4\u65f6\uff0c\u53d6 0\uff1b\u5176\u4f59\u60c5\u51b5\u4e0d\u53d8\u3002 static double ThresholdL1 ( double s , double l1 ) { const double reg_s = std :: max ( 0.0 , std :: fabs ( s ) - l1 ); return Common :: Sign ( s ) * reg_s ; } \u4e8c\u9636\u5bfc\u6570\u548c\u9700\u8981\u7ee7\u7eed\u9605\u8bfb\u4ee3\u7801\u3002\u5bf9\u4e8e regression \u95ee\u9898\uff0c\u68af\u5ea6\u548c\u4e8c\u9636\u5bfc\u6570\u4e3a\uff1a void GetGradients ( const double * score , score_t * gradients , score_t * hessians ) const override { if ( weights_ == nullptr ) { #pragma omp parallel for schedule(static) for ( data_size_t i = 0 ; i < num_data_ ; ++ i ) { gradients [ i ] = static_cast < score_t > ( score [ i ] - label_ [ i ]); hessians [ i ] = 1.0f ; } } else { #pragma omp parallel for schedule(static) for ( data_size_t i = 0 ; i < num_data_ ; ++ i ) { gradients [ i ] = static_cast < score_t > (( score [ i ] - label_ [ i ]) * weights_ [ i ]); hessians [ i ] = static_cast < score_t > ( weights_ [ i ]); } } } \u8fd9\u662f\u975e\u5e38\u5bb9\u6613\u7406\u89e3\u7684\uff0c\u56e0\u4e3a\u5728 regression \u4efb\u52a1\u4e2d\uff0cLightGBM \u91c7\u7528\u7684\u76ee\u6807\u51fd\u6570\u662f\u5e73\u65b9\u8bef\u5dee\uff1a \\[ 0.5(y -\\hat{y})^2 \\] \u5c06\u5176\u5bf9 y \u6c42\u5bfc\uff0c\u4e00\u9636\u5bfc\u6570\uff08\u68af\u5ea6\uff09\u5c31\u662f\u76f4\u63a5\u4f5c\u5dee\uff0c\u4e8c\u9636\u5bfc\u6570\u662f1\uff0c \u4e8c\u9636\u5bfc\u6570\u548c\u5c31\u662f\u8be5\u8282\u70b9\u6837\u672c\u6570\u91cf \u3002 \u90a3\u4e48\u5bf9\u4e8e regression \u95ee\u9898\uff0cgain \u7684\u542b\u4e49\u5c31\u6e05\u695a\u4e86\u3002\u5b83\u662f\u7528\u4e8e\u63cf\u8ff0\u4e00\u4e2a\u8282\u70b9\u5206\u88c2\u7684\u201c\u4ef7\u503c\u201d\u3002\u4e00\u4e2a\u8282\u70b9\u4e2d\u7684\u6837\u672c\u8bad\u7ec3\u8d8a\u5145\u5206\uff0cgain \u5c31\u8d8a\u5c0f\uff0c\u56e0\u4e3a\u68af\u5ea6\u548c\u5c0f \u3002 \u540c\u65f6\uff0c lambda_l1 , lambda_l2 \u7684\u4f5c\u7528\u4e5f\u6e05\u695a\u4e86\uff0c \u4ed6\u4eec\u90fd\u7528\u4e8e\u52a0\u901f gain \u51cf\u5c0f\u7684\u8fc7\u7a0b \u3002 lambda_l1 \uff1a\u8bbe\u7f6e\u4e00\u4e2a threshold\uff0cgain \u5c0f\u4e8e\u8fd9\u4e2a threshold \u76f4\u63a5\u8ba4\u4e3a\u662f 0\uff0c\u4e0d\u518d\u5206\u88c2\u3002 lambda_l2 \uff1a\u4e3a gain \u7684\u5206\u6bcd\uff08\u5373\u8282\u70b9\u6837\u672c\u6570\uff09\u589e\u52a0\u4e00\u4e2a\u5e38\u6570\u9879\uff0c\u4f5c\u7528\u4e8e\u5168\u7a0b\uff0c\u5728\u8282\u70b9\u6837\u672c\u6570\u5df2\u7ecf\u5f88\u5c0f\u7684\u65f6\u5019\uff0c\u80fd\u663e\u8457\u51cf\u5c0f gain \u907f\u514d\u5206\u88c2\u3002","title":"LightGBM \u53c2\u6570\u4e2d\u7684 lambda_l1 \u548c lambda_l2"},{"location":"computer-science/lgbm/LgbmL1AndL2/#lightgbm-lambda_l1-lambda_l2","text":"LightGBM \u7684\u53c2\u6570\u5927\u90e8\u5206\u610f\u4e49\u90fd\u80fd\u901a\u8fc7\u540d\u5b57\u731c\u51fa\u6765\uff0c\u4f8b\u5982 num_leaves \uff0c early_stopping \u7b49\u3002\u4f46\u662f\u6709\u4e24\u4e2a\u5e38\u7528\u53c2\u6570\u662f\u4e2a\u5f02\u7c7b\uff1a lambda_l1 lambda_l2 \u987a\u5e26\u4e0e\u4ed6\u4eec\u76f8\u5173\u7684\u8fd8\u6709\u4e00\u4e2a min_gain_to_split \u8981\u8c03\u8282\u8fd9\u4e9b\u53c2\u6570\u9700\u8981\u7406\u89e3\u4ed6\u4eec\u80cc\u540e\u7684\u542b\u4e49\u3002\u4f46\u662f\uff0clightGBM \u5230\u5e95\u662f\u5982\u4f55\u5b9a\u4e49\u7f51\u4e0a\u4f3c\u4e4e\u6ca1\u627e\u5230\u628a\u8fd9\u4e2a\u8bf4\u6e05\u695a\u7684\u3002\u5b98\u7f51\u53ea\u662f\u975e\u5e38\u7b80\u5355\u5730\u63d0\u4e86\u4e00\u4e0b\u8fd9\u4e9b\u662f\u4e3a\u4e86\u6b63\u5219\u5316\u3002 \u6240\u8c13\u6b63\u5219\u5316\uff08Regularization\uff09\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u4e00\u79cd\u5e38\u7528\u7684\u6280\u672f\uff0c\u5176\u4e3b\u8981\u76ee\u7684\u662f\u63a7\u5236\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u51cf\u5c0f\u8fc7\u62df\u5408\u3002\u6700\u57fa\u672c\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u662f\u5728\u539f\u76ee\u6807\uff08\u4ee3\u4ef7\uff09\u51fd\u6570 \u4e2d\u6dfb\u52a0\u60e9\u7f5a\u9879\uff0c\u5bf9\u590d\u6742\u5ea6\u9ad8\u7684\u6a21\u578b\u8fdb\u884c\u201c\u60e9\u7f5a\u201d\u3002 \u56e0\u6b64\u5bf9\u4e8e LightGBM \u6765\u8bb2\u8fd9\u51e0\u4e2a\u53c2\u6570\u80af\u5b9a\u662f\u7528\u4e8e\u63a7\u5236\u6811\u8282\u70b9\u5206\u88c2\u7684\u3002\u4f46\u662f\u4f3c\u4e4e\u4e5f\u6ca1\u627e\u5230\u7279\u5730\u9488\u5bf9 LightGBM \u5982\u4f55\u6b63\u5219\u5316\u7684\u4ecb\u7ecd\uff0c\u4e8e\u662f\u6211\u81ea\u5df1\u770b\u4e86\u4e0b\u6e90\u7801\u3002","title":"LightGBM \u53c2\u6570\u4e2d\u7684 lambda_l1 \u548c lambda_l2"},{"location":"computer-science/lgbm/LgbmL1AndL2/#1","text":"lambda_l1 , lambda_l2 \u548c min_gain_to_split \u90fd\u662f\u7528\u4e8e\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u907f\u514d\u8fc7\u62df\u5408\u7684\u3002 \u4ed6\u4eec\u4f5c\u7528\u4e8e\u6bcf\u4e2a\u8282\u70b9\u7684 gain\u3002gain \u5728 LightGBM \u4e2d\u7528\u4e8e\u63cf\u8ff0\u8282\u70b9\u4e0a\u6240\u6709\u6837\u672c\u7684\u8bad\u7ec3\u7a0b\u5ea6\u3002gain \u8d8a\u5c0f\u8bf4\u660e\u8bad\u7ec3\u8d8a\u5145\u5206\uff0c\u5206\u88c2\u4ef7\u503c\u8d8a\u4f4e\u3002 gain \u7684\u8ba1\u7b97\u65b9\u5f0f\u4e3a\uff1a \\[ \\frac{[\\text{Thresh}(\u68af\u5ea6\u548c, \\lambda_{L1})]^2}{\u4e8c\u9636\u5bfc\u6570\u548c + \\lambda_{L2}} \\] \u5bf9\u4e8e\u56de\u5f52\u95ee\u9898\uff0c\u4e8c\u9636\u5bfc\u6570\u4e3a1\uff0c\u5176\u548c\u4e3a\u8282\u70b9\u6837\u672c\u6570\u3002 lambda_l1 \u548c lambda_l2 \u90fd\u7528\u4e8e\u52a0\u901f gain \u7684\u51cf\u5c0f\u3002 lambda_l1 \uff1a\u8bbe\u7f6e\u4e00\u4e2a threshold\uff0cgain \u5c0f\u4e8e\u8fd9\u4e2a threshold \u76f4\u63a5\u8ba4\u4e3a\u662f 0\uff0c\u4e0d\u518d\u5206\u88c2\u3002 lambda_l2 \uff1a\u4e3a gain \u7684\u5206\u6bcd\uff08\u5373\u8282\u70b9\u6837\u672c\u6570\uff09\u589e\u52a0\u4e00\u4e2a\u5e38\u6570\u9879\uff0c\u4f5c\u7528\u4e8e\u5168\u7a0b\uff0c\u5728\u8282\u70b9\u6837\u672c\u6570\u5df2\u7ecf\u5f88\u5c0f\u7684\u65f6\u5019\uff0c\u80fd\u663e\u8457\u51cf\u5c0f gain \u907f\u514d\u5206\u88c2\u3002 min_gain_to_split \u7684\u4f5c\u7528\u53ef\u4ee5\u901a\u8fc7\u540d\u5b57\u731c\u51fa\u3002\u5c31\u662f\u5982\u679c\u4e00\u4e2a\u8282\u70b9\u7684 gain \u4f4e\u4e8e\u8fd9\u4e2a\u6570\uff0c\u4e0d\u518d\u5206\u88c2\u3002","title":"1 \u7ed3\u8bba"},{"location":"computer-science/lgbm/LgbmL1AndL2/#2","text":"Boosting \u7684\u6bcf\u4e00\u6b21\u8fed\u4ee3\u90fd\u4f1a\u751f\u6210\u4e00\u68f5\u6811\u3002\u5728\u751f\u6210\u6811\u7684\u65f6\u5019\uff0c\u6211\u4eec\u9700\u8981\u5bfb\u627e\u6bcf\u4e2a\u7279\u5f81\u7684\u6700\u4f73\u5206\u5272\u70b9\u3002","title":"2 \u6e90\u7801\u89e3\u8bfb"},{"location":"computer-science/lgbm/LgbmL1AndL2/#21-gain","text":"\u5728 feature_histogram.hpp \u7528\u4e8e\u5bfb\u627e\u6700\u4f73\u5206\u5272\u70b9\u7684 FindBestThresholdSequentially() \u65b9\u6cd5\u4e2d\uff0c\u6709\u5982\u4e0b\u4ee3\u7801\u7528\u4e8e\u51b3\u5b9a\u662f\u5426\u5206\u5272\uff1a // current split gain double current_gain = GetSplitGains < USE_MC , USE_L1 , USE_MAX_OUTPUT , USE_SMOOTHING > ( sum_left_gradient , sum_left_hessian , sum_right_gradient , sum_right_hessian , meta_ -> config -> lambda_l1 , meta_ -> config -> lambda_l2 , meta_ -> config -> max_delta_step , constraints , meta_ -> monotone_type , meta_ -> config -> path_smooth , left_count , right_count , parent_output ); // gain with split is worse than without split if ( current_gain <= min_gain_shift ) { continue ; } // mark as able to be split is_splittable_ = true ; \u5176\u4e2d min_gain_shift \u7531\u4ee5\u4e0b\u51fd\u6570\u8ba1\u7b97\uff08\u7528\u5230\u4e86 min_gain_to_split \uff09\uff1a template < bool USE_RAND , bool USE_L1 , bool USE_MAX_OUTPUT , bool USE_SMOOTHING > double BeforeNumercal ( double sum_gradient , double sum_hessian , double parent_output , data_size_t num_data , SplitInfo * output , int * rand_threshold ) { is_splittable_ = false ; output -> monotone_type = meta_ -> monotone_type ; double gain_shift = GetLeafGain < USE_L1 , USE_MAX_OUTPUT , USE_SMOOTHING > ( sum_gradient , sum_hessian , meta_ -> config -> lambda_l1 , meta_ -> config -> lambda_l2 , meta_ -> config -> max_delta_step , meta_ -> config -> path_smooth , num_data , parent_output ); * rand_threshold = 0 ; if ( USE_RAND ) { if ( meta_ -> num_bin - 2 > 0 ) { * rand_threshold = meta_ -> rand . NextInt ( 0 , meta_ -> num_bin - 2 ); } } return gain_shift + meta_ -> config -> min_gain_to_split ; } \u53ef\u4ee5\u770b\u51fa min_gain_shift \u7531\u4e24\u90e8\u5206\u6784\u6210\uff1a \u672a\u5206\u5272\u8282\u70b9\u7684 gain\uff0c\u7531 GetLeafGain() \u8ba1\u7b97 \u914d\u7f6e\u7684 min_gain_to_split \u4e0e\u4e4b\u76f8\u6bd4\u8f83\u7684 current_gain \u5219\u662f\u8c03\u7528\u4e86 GetSplitGains() \uff1a template < bool USE_MC , bool USE_L1 , bool USE_MAX_OUTPUT , bool USE_SMOOTHING > static double GetSplitGains ( double sum_left_gradients , double sum_left_hessians , double sum_right_gradients , double sum_right_hessians , double l1 , double l2 , double max_delta_step , const FeatureConstraint * constraints , int8_t monotone_constraint , double smoothing , data_size_t left_count , data_size_t right_count , double parent_output ) { if ( ! USE_MC ) { return GetLeafGain < USE_L1 , USE_MAX_OUTPUT , USE_SMOOTHING > ( sum_left_gradients , sum_left_hessians , l1 , l2 , max_delta_step , smoothing , left_count , parent_output ) + GetLeafGain < USE_L1 , USE_MAX_OUTPUT , USE_SMOOTHING > ( sum_right_gradients , sum_right_hessians , l1 , l2 , max_delta_step , smoothing , right_count , parent_output ); } // omitted... } \u53ef\u4ee5\u770b\u51fa\uff0c GetSplitGains() \u5b9e\u9645\u5c31\u662f\u5bf9\u5206\u5272\u540e\u7684\u4e24\u4e2a\u5b50\u8282\u70b9\u5206\u522b\u8c03\u7528 GetLeafGain() \uff0c\u518d\u5c06 gains \u76f8\u52a0\u3002 \u6240\u4ee5\u672c\u8d28\u4e0a\u8fd9\u4e2a\u6bd4\u8f83\u7684\u610f\u4e49\u662f\uff0c\u5982\u679c\u5206\u5272\u540e\u7684 gain \u5c0f\u4e8e\u5206\u5272\u524d gain \u5916\u52a0 min_gain_to_split \uff0c\u5c31\u4e0d\u4f5c\u8fdb\u4e00\u6b65\u5206\u5272\u3002 \u73b0\u5728\u6211\u4eec\u660e\u767d\u4e86 min_gain_to_split \u7684\u539f\u7406\u4e86\uff0c lambda_l1 \u548c lambda_l2 \u5462\uff1f","title":"2.1 \u7528 gain \u6765\u51b3\u5b9a\u662f\u5426\u5206\u5272"},{"location":"computer-science/lgbm/LgbmL1AndL2/#22-gain","text":"\u8ba1\u7b97 gain \u5c31\u9700\u8981\u7528\u5230 lambda_l1 \u548c lambda_l2 \u4e86\u3002 template < bool USE_L1 , bool USE_MAX_OUTPUT , bool USE_SMOOTHING > static double GetLeafGain ( double sum_gradients , double sum_hessians , double l1 , double l2 , double max_delta_step , double smoothing , data_size_t num_data , double parent_output ) { if ( ! USE_MAX_OUTPUT && ! USE_SMOOTHING ) { if ( USE_L1 ) { const double sg_l1 = ThresholdL1 ( sum_gradients , l1 ); return ( sg_l1 * sg_l1 ) / ( sum_hessians + l2 ); } else { return ( sum_gradients * sum_gradients ) / ( sum_hessians + l2 ); } } else { double output = CalculateSplittedLeafOutput < USE_L1 , USE_MAX_OUTPUT , USE_SMOOTHING > ( sum_gradients , sum_hessians , l1 , l2 , max_delta_step , smoothing , num_data , parent_output ); return GetLeafGainGivenOutput < USE_L1 > ( sum_gradients , sum_hessians , l1 , l2 , output ); } } gain \u7684\u8ba1\u7b97\u65b9\u6cd5\u5c31\u662f\uff1a \\[ \\frac{[\\text{Thresh}(\u68af\u5ea6\u548c, \\lambda_{L1})]^2}{\u4e8c\u9636\u5bfc\u6570\u548c + \\lambda_{L2}} \\] Thresh \u7684\u7b97\u6cd5\u5f88\u7b80\u5355\uff0c\u5c31\u662f\u5f53\u68af\u5ea6\u548c\u5728 \\([-\\lambda_{L1}, +\\lambda_{L1}]\\) \u533a\u95f4\u65f6\uff0c\u53d6 0\uff1b\u5176\u4f59\u60c5\u51b5\u4e0d\u53d8\u3002 static double ThresholdL1 ( double s , double l1 ) { const double reg_s = std :: max ( 0.0 , std :: fabs ( s ) - l1 ); return Common :: Sign ( s ) * reg_s ; } \u4e8c\u9636\u5bfc\u6570\u548c\u9700\u8981\u7ee7\u7eed\u9605\u8bfb\u4ee3\u7801\u3002\u5bf9\u4e8e regression \u95ee\u9898\uff0c\u68af\u5ea6\u548c\u4e8c\u9636\u5bfc\u6570\u4e3a\uff1a void GetGradients ( const double * score , score_t * gradients , score_t * hessians ) const override { if ( weights_ == nullptr ) { #pragma omp parallel for schedule(static) for ( data_size_t i = 0 ; i < num_data_ ; ++ i ) { gradients [ i ] = static_cast < score_t > ( score [ i ] - label_ [ i ]); hessians [ i ] = 1.0f ; } } else { #pragma omp parallel for schedule(static) for ( data_size_t i = 0 ; i < num_data_ ; ++ i ) { gradients [ i ] = static_cast < score_t > (( score [ i ] - label_ [ i ]) * weights_ [ i ]); hessians [ i ] = static_cast < score_t > ( weights_ [ i ]); } } } \u8fd9\u662f\u975e\u5e38\u5bb9\u6613\u7406\u89e3\u7684\uff0c\u56e0\u4e3a\u5728 regression \u4efb\u52a1\u4e2d\uff0cLightGBM \u91c7\u7528\u7684\u76ee\u6807\u51fd\u6570\u662f\u5e73\u65b9\u8bef\u5dee\uff1a \\[ 0.5(y -\\hat{y})^2 \\] \u5c06\u5176\u5bf9 y \u6c42\u5bfc\uff0c\u4e00\u9636\u5bfc\u6570\uff08\u68af\u5ea6\uff09\u5c31\u662f\u76f4\u63a5\u4f5c\u5dee\uff0c\u4e8c\u9636\u5bfc\u6570\u662f1\uff0c \u4e8c\u9636\u5bfc\u6570\u548c\u5c31\u662f\u8be5\u8282\u70b9\u6837\u672c\u6570\u91cf \u3002 \u90a3\u4e48\u5bf9\u4e8e regression \u95ee\u9898\uff0cgain \u7684\u542b\u4e49\u5c31\u6e05\u695a\u4e86\u3002\u5b83\u662f\u7528\u4e8e\u63cf\u8ff0\u4e00\u4e2a\u8282\u70b9\u5206\u88c2\u7684\u201c\u4ef7\u503c\u201d\u3002\u4e00\u4e2a\u8282\u70b9\u4e2d\u7684\u6837\u672c\u8bad\u7ec3\u8d8a\u5145\u5206\uff0cgain \u5c31\u8d8a\u5c0f\uff0c\u56e0\u4e3a\u68af\u5ea6\u548c\u5c0f \u3002 \u540c\u65f6\uff0c lambda_l1 , lambda_l2 \u7684\u4f5c\u7528\u4e5f\u6e05\u695a\u4e86\uff0c \u4ed6\u4eec\u90fd\u7528\u4e8e\u52a0\u901f gain \u51cf\u5c0f\u7684\u8fc7\u7a0b \u3002 lambda_l1 \uff1a\u8bbe\u7f6e\u4e00\u4e2a threshold\uff0cgain \u5c0f\u4e8e\u8fd9\u4e2a threshold \u76f4\u63a5\u8ba4\u4e3a\u662f 0\uff0c\u4e0d\u518d\u5206\u88c2\u3002 lambda_l2 \uff1a\u4e3a gain \u7684\u5206\u6bcd\uff08\u5373\u8282\u70b9\u6837\u672c\u6570\uff09\u589e\u52a0\u4e00\u4e2a\u5e38\u6570\u9879\uff0c\u4f5c\u7528\u4e8e\u5168\u7a0b\uff0c\u5728\u8282\u70b9\u6837\u672c\u6570\u5df2\u7ecf\u5f88\u5c0f\u7684\u65f6\u5019\uff0c\u80fd\u663e\u8457\u51cf\u5c0f gain \u907f\u514d\u5206\u88c2\u3002","title":"2.2 \u5982\u4f55\u8ba1\u7b97 gain"},{"location":"computer-science/lgbm/LgbmVol1/","text":"LightGBM \u5b9e\u6218\uff1a\u6ce2\u52a8\u7387\u9884\u6d4b(1) \u8fd9\u662f Kaggle \u4e0a\u7684\u4e00\u4e2a\u6bd4\u8d5b\uff1a Optiver Realized Volatility Prediction \u3002 \u76ee\u7684\u662f\u901a\u8fc7\u80a1\u7968\u7684\u5386\u53f2 order book \u548c trade \u6765\u9884\u6d4b\u5b83\u63a5\u4e0b\u6765\u5341\u5206\u949f\u7684volatility\u3002\u57fa\u672c\u91d1\u878d\u6982\u5ff5\u5c31\u4e0d\u8d58\u8ff0\u4e86\u3002 1. Data overview \u8be5\u6bd4\u8d5b\u7ed9\u51fa\u7684\u8bad\u7ec3\u6570\u636e\u5305\u542b 112 \u652f\u80a1\u7968\u3002\u6bcf\u652f\u80a1\u7968\u4ee5 10 \u5206\u949f\u4e3a\u91c7\u6837\u65f6\u95f4\uff08time_id\uff09\uff0c\u8bb0\u5f55\u4e86 order book \u548c trade \u7684\u8be6\u7ec6\u6570\u636e\u3002 1.1 Order book time_id: \u6bcf\u5341\u5206\u949f\u4e3a\u4e00\u4e2a bucket\uff0ctime_id \u4e5f\u662f bucket \u7684 id seconds_in_bucket: 10\u5206\u949f=600\u79d2\uff0c\u6bcf\u4e2a bucket \u91cd\u7f6e price: \u5f52\u4e00\u5316\u540e\u7684\u4ef7\u683c\uff0c\u4e5f\u79f0\u4e3a\u56de\u62a5\u7387\u3002\u4ee5\u7b2c\u4e00\u6761\u8bb0\u5f55\u4e3a\u57fa\u51c6\u503c 1.00 size: \u5728\u8fd9\u4e2a\u4ef7\u683c\u4e0a\u9762\u62a5\u4ef7\u7684\u8ba2\u5355\u6570\u91cf 1.2 Trade 2. Benchmark \u4e3a\u4e86\u8861\u91cf\u6211\u4eec\u9884\u6d4b\u7684\u6548\u679c\uff0c\u9700\u8981\u4e00\u4e2a\u7b80\u5355\u7684\u9884\u6d4b\u4f5c\u4e3a benchmark\uff0c\u4f4e\u4e8e\u8fd9\u4e2a benchmark \u8bf4\u660e\u6a21\u578b\u662f\u65e0\u6548\u7684\u3002 \u6700\u7b80\u5355\u7684\u9884\u6d4b\u5c31\u662f\u76f4\u63a5\u7528\u8fc7\u53bb 10 \u5206\u949f\u7684 volatility \u6765\u9884\u6d4b\u672a\u6765 10 \u5206\u949f \u7684\u3002\u5982\u679c\u6211\u4eec\u9009\u53d6\u5747\u65b9\u6839\u767e\u5206\u6bd4\u8bef\u5dee\uff08RMSPE\uff09\u4f5c\u4e3a\u8bc4\u5206\u6807\u51c6\uff0c\u5219\u5176\u8bef\u5dee\u4e3a 0.341\uff0c\u537334.10%\u3002 RMSPE \u8ba1\u7b97\u65b9\u5f0f\u4e3a\uff1a \\( \\(\\text{RMSPE} = \\sqrt{ \\frac{ 1 }{ N } \\sum_{i=1}^N (\\frac{y_i - \\hat{y}_i}{y_i})^2 }\\) \\) 2.1 Benchmark code \u53ef\u4ee5\u7528\u4ee5\u4e0b\u4ee3\u7801\u8ba1\u7b97 benchmark\uff0c\u8ba1\u7b97 volatility \u548c RMSPE \u7684\u65b9\u6cd5\u4e0e\u4e4b\u540e LightGBM \u4e2d\u662f\u4e00\u81f4\u7684\u3002 vol = get_histocal_volatility ( 'data/book_train.parquet/' ) print_score ( vol ) 2.1.1 Volatility calculation import pandas as pd import numpy as np import glob import multiprocessing as mp def vwap(row): return (row.bid_price1 * row.ask_size1 + row.ask_price1 * row.bid_size1) / (row.ask_size1 + row.bid_size1) def calculate_realized_volatility(frame): # theo_price = frame.apply(vwap, axis=1) theo_price = vwap(frame) log_return = np.log(theo_price).diff().dropna() return np.sqrt(np.sum(log_return**2)) def get_stock_volatility(path): book = pd.read_parquet(path) vol = book.groupby('time_id').apply(calculate_realized_volatility).reset_index(name='volatility') vol['stock_id'] = int(path.split('=')[1]) return vol.reindex(['stock_id', 'time_id', 'volatility'], axis=1) def get_histocal_volatility(train_dir): paths = glob.glob(f'{train_dir}/*') with mp.Pool(4) as p: results = p.map(get_stock_volatility, paths) return pd.concat(results) 2.1.2 RMSPE calculation def convert_to_submit_format(vol): row_id = pd.Series(vol.stock_id.astype(str) + '-' + vol.time_id.astype(str), name='row_id') return pd.concat([row_id, vol.iloc[:,2]], axis=1) def print_score(vol): train = convert_to_submit_format(pd.read_csv('data/train.csv')) pred = convert_to_submit_format(vol) from sklearn.metrics import r2_score def rmspe(y_true, y_pred): return (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))) joined = pd.merge(pred, train, on='row_id') R2 = round(r2_score(y_true = joined.target, y_pred = joined.volatility),3) RMSPE = round(rmspe(y_true = joined.target, y_pred = joined.volatility),3) print(f'Performance of the naive prediction: R2 score: {R2}, RMSPE: {RMSPE}') 3. \u7528 LightGBM \u9884\u6d4b volatility \u672c\u8282\u5c06\u7b80\u5355\u5e94\u7528 LightGBM \u9884\u6d4b volatility\uff0c\u6682\u65f6\u4e0d\u6d89\u53ca\u4efb\u4f55\u8c03\u53c2\u4ee5\u53ca\u7279\u5f81\u5de5\u7a0b\u7684\u4f18\u5316\u3002\u4ec5\u4ec5\u9a8c\u8bc1 LightGBM \u5728\u9ed8\u8ba4\u53c2\u6570\u4e0b\u3001\u5229\u7528\u7b80\u5355\u7684\u7279\u5f81\u5373\u53ef\u83b7\u5f97\u8d85\u8fc7 benchmark \u7684\u9884\u6d4b\u6548\u679c\uff0c\u91cd\u70b9\u9610\u8ff0\u5982\u4f55\u8c03\u5305 :)\u3002 3.1 \u7279\u5f81\u63d0\u53d6 \u5bf9\u4e8e book \u548c trade\uff0c\u6211\u4eec\u90fd\u9700\u8981\u505a\u4e00\u4e9b\u7b80\u5355\u7684\u8ba1\u7b97\u6765\u5c06\u539f\u59cb\u6570\u636e\u7a0d\u4f5c\u52a0\u5de5\u3002 \u5f52\u6839\u5230\u5e95\uff0c\u6ce2\u52a8\u7387\u53cd\u5e94\u7684\u662f\u4ef7\u683c\u53d8\u5316\u5267\u70c8\u7a0b\u5ea6\u3002\u7406\u8bba\u4e0a\uff0c\u5f53\u67d0\u4e2a\u80a1\u7968\u6d41\u52a8\u6027\u4e0d\u4f73\uff08\u5373\u4e70\u5356\u4ef7\u5dee\u5927\u3001\u6302\u5355\u6570\u91cf\u5c11\uff09\u65f6\uff0c\u5b83\u7684\u6ce2\u52a8\u7387\u4f1a\u663e\u8457\u4e0a\u5347\u3002\u6b64\u5916\uff0c\u5982\u679c\u67d0\u4e2a\u80a1\u7968\u4ea4\u6613\u91cf\u76f8\u5bf9\u5176\u6302\u5355\u91cf\u8f83\u5927\uff0c\u4e5f\u4f1a\u6709\u8f83\u5927\u7684\u6ce2\u52a8\u7387\u3002 \u53e6\u5916\uff0c\u7531\u4e8e\u6bcf\u4e2a time_id \u6709 10 \u5206\u949f\u7684\u6570\u636e\uff0c\u76f4\u89c9\u4e0a\uff0c\u8fd9\u4e9b\u6570\u636e\u5bf9\u672a\u6765\u4ea4\u6613\u7684\u5f71\u54cd\u5e94\u8be5\u662f\u4f1a decay \u7684\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u6839\u636e\u65f6\u95f4\u5c06\u5176\u5206\u4e3a\u591a\u4e2a batch\u3002 3.1.1 book features book \u65b9\u9762\uff0c\u7531\u4e8e volatility \u662f\u57fa\u4e8e vwap \u7684\uff0c\u6211\u8ba1\u7b97\u4e86\u591a\u79cd vwap\uff0c\u7528\u4e8e\u8868\u73b0\u67d0\u4e00\u4e2a level \u88ab\u5168\u90e8 take \u7684\u60c5\u51b5\u3002\u6b64\u5916\uff0c\u4e70\u5356\u4ef7\u5dee\u3001\u4e70 1 \u548c\u4e70 2 \u4ef7\u5dee\u3001\u5356 1 \u548c \u5356 2 \u7684\u4ef7\u5dee\u90fd\u53ef\u4ee5\u7eb3\u5165\u8003\u8651\u3002 def vwap(row, bid_idx, ask_idx): # TODO: multi-level return (row[f'bid_price{bid_idx}'] * row[f'ask_size{ask_idx}'] + row[f'ask_price{ask_idx}'] * row[f'bid_size{bid_idx}']) / ( row[f'ask_size{ask_idx}'] + row[f'bid_size{bid_idx}']) def get_book(stock_id): book = pd.read_parquet(f\"data/book_train.parquet/stock_id={stock_id}\") # VWAPs # level 0 price does not change book['vwap11'] = vwap(book, 1, 1) # ask level 0 is fully traded book['vwap12'] = vwap(book, 1, 2) # bid level 0 is fully traded book['vwap21'] = vwap(book, 2, 1) # bid and ask level 0 is fully traded book['vwap22'] = vwap(book, 2, 2) book['bid_ask_spread'] = book.ask_price1 - book.bid_price1 book['bid_gap'] = book.bid_price1 - book.bid_price2 book['ask_gap'] = book.ask_price2 - book.ask_price1 book['bid_imbalance'] = book.bid_size1 / book.bid_size2 book['ask_imbalance'] = book.ask_size1 / book.ask_size2 return book def get_book_features(book, window): book['batch_id'] = cut_by_time(book, window) feature_dict = { 'vwap11': ['mean', 'std', 'max', calculate_realized_volatility], 'vwap12': ['mean', 'std', 'max', calculate_realized_volatility], 'vwap21': ['mean', 'std', 'max', calculate_realized_volatility], 'vwap22': ['mean', 'std', 'max', calculate_realized_volatility], 'bid_gap': ['mean', 'std', 'max'], 'ask_gap': ['mean', 'std', 'max'], 'bid_ask_spread': ['mean', 'std', 'max'], 'bid_size1': ['mean', 'std', 'max', 'sum'], 'ask_size1': ['mean', 'std', 'max', 'sum'], 'bid_imbalance': ['mean', 'std', 'max'], 'ask_imbalance': ['mean', 'std', 'max'], } return get_features(book, feature_dict) 3.1.2 trade features \u968f\u4fbf\u63d0\u53d6\u4e86\u51e0\u4e2a trade \u7684\u7279\u5f81\uff0c\u4f8b\u5982\u4ea4\u6613\u6570\u91cf\u3001\u4ea4\u6613\u91d1\u989d\u7b49\u7b49\u3002 def get_trade ( stock_id ): trade = pd . read_parquet ( f \"data/trade_train.parquet/stock_id= { stock_id } \" ) . rename ({ 'size' : 'trade_volume' }, axis = 1 ) trade [ 'trade_amount' ] = trade . price * trade . trade_volume trade [ 'per_trade_quantity' ] = trade . trade_volume / trade . order_count return trade def get_trade_features ( trade , window ): trade [ 'batch_id' ] = cut_by_time ( trade , window ) feature_dict = { 'trade_volume' : [ 'mean' , 'std' , 'max' , 'sum' ], 'trade_amount' : [ 'mean' , 'std' , 'max' ], 'per_trade_quantity' : [ 'mean' , 'std' , 'max' ] } return get_features ( trade , feature_dict ) def get_all_features ( stock_id , window ): book = get_book ( stock_id ) book_features = get_book_features ( book , window ) trade = get_trade ( stock_id ) trade_features = get_trade_features ( trade , window ) merged = pd . merge ( book_features , trade_features , on = [ 'time_id_' ]) return merged def get_train_data ( stocks , window ): df = [] for stock in stocks : features = get_all_features ( stock , window ) features [ 'stock_id_' ] = stock df . append ( features ) return pd . concat ( df ) . reset_index ( drop = True ) 3.2 \u5e94\u7528 LightGBM \u6211\u4eec\u5df2\u7ecf\u5728 3.1 \u4e2d\u5f97\u5230\u4e86\u4e00\u5806\u7279\u5f81\u4e86\uff08294\u7ef4\uff09\uff0c\u73b0\u5728\u53ef\u4ee5\u5c06\u5b83\u4eec feed \u5230 LightGBM \u4e2d\u8fdb\u884c\u8bad\u7ec3\u4e86\u3002\u539f\u59cb\u6570\u636e\u96c6\u4e2d\u63d0\u4f9b\u4e86 train.csv \u7528\u4e8e\u8bad\u7ec3\u3002\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u4f7f\u7528\u7ecf\u5178\u7684\u4ea4\u53c9\u9a8c\u8bc1\u6765\u8bad\u7ec3\u6a21\u578b\u3002\u5c06\u539f\u59cb\u6570\u636e\u968f\u673a\u5206\u4e3a 5 \u4efd\uff0c\u5176\u4e2d 4 \u4efd\u7528\u4e8e\u8bad\u7ec3\uff0c1 \u4efd\u7528\u4e8e\u9a8c\u8bc1\u3002 from sklearn.model_selection import KFold import lightgbm # root mean squared percentage error def rmspe(y_true, y_pred): return np.sqrt(np.mean(np.square((y_true - y_pred)/y_true))) def feval_rmspe(y_pred, lgb_train): y_true = lgb_train.get_label() return 'RMSPE', rmspe(y_true, y_pred), False result = pd.read_csv('data/train.csv') selected_y = result[result.stock_id.isin([stock_id])].target.reset_index(drop=True) kf = KFold(n_splits = 5, random_state = 2021, shuffle = True) train_features = train_data.drop('time_id_', axis=1) for train_index, test_index in kf.split(train_features): # print(\"TRAIN:\", train_index, \"TEST:\", test_index) X_train, X_test = train_features.loc[train_index], train_features.loc[test_index] y_train, y_test = selected_y.loc[train_index], selected_y.loc[test_index] train_dataset = lightgbm.Dataset(X_train, y_train, weight=1/np.square(y_train)) validation_dataset = lightgbm.Dataset(X_test, y_test, weight=1/np.square(y_test)) model = lightgbm.train(params={}, train_set = train_dataset, valid_sets = [train_dataset, validation_dataset], early_stopping_rounds=50, feval = feval_rmspe, verbose_eval = 20, num_boost_round=1000) # get prediction score y_pred = model.predict(X_test) print(\"RMSPE = \", rmspe(y_test, y_pred)) lightgbm.plot_importance(model, max_num_features=20) \u6ce8\u610f\uff0c time_id \u5e76\u4e0d\u5c5e\u4e8e\u7279\u5f81\uff0c\u5728\u8fd9\u91cc\u9700\u8981\u53bb\u6389\u4ee5\u514d\u5bf9\u8bad\u7ec3\u9020\u6210\u8d1f\u9762\u5f71\u54cd\u3002 3.2.1 LightGBM \u6b65\u9aa4 \u5206\u4e3a 3 \u6b65\uff1a \u5efa\u7acb\u6570\u636e\u96c6\uff08 train_dataset = lightgbm.Dataset(...) \uff09 \u8bad\u7ec3\u6a21\u578b ( model = lightgbm.train(...) ) \u9884\u6d4b ( model.predict(X_test) ) \u7740\u91cd\u8bb2\u4e0b\u7b2c 2 \u6b65\u7684\u53c2\u6570\uff0c\u5b83\u6700\u4e3a\u590d\u6742\u3002 model = lightgbm . train ( params = {}, train_set = train_dataset , valid_sets = [ train_dataset , validation_dataset ], early_stopping_rounds = 50 , feval = feval_rmspe , verbose_eval = 20 , num_boost_round = 1000 ) - params={} \u8bf4\u660e\u6211\u4eec\u4f7f\u7528\u9ed8\u8ba4\u53c2\u6570\u3002\u7531\u4e8e\u7bc7\u5e45\u6240\u9650\uff0c\u53c2\u6570\u542b\u4e49\u548c\u8c03\u4f18\u653e\u5728\u4e0b\u4e00\u7bc7\u6587\u7ae0\u3002 valid_set , early_stopping_rounds , feval \uff1a\u8fd9\u4e09\u4e2a\u53c2\u6570\u662f\u53ef\u9009\u53c2\u6570\uff0c\u4ed6\u4eec\u662f\u6709\u5173\u8054\u7684\u3002\u76ee\u7684\u662f\u907f\u514d\u8fc7\u62df\u5408\u3002\u5229\u7528 feval \u6765\u8bc4\u4ef7\u9a8c\u8bc1\u96c6\u5728\u8fd9\u4e2a\u6a21\u578b\u4e0b\u7684\u51c6\u786e\u5ea6\uff0c\u5982\u679c\u8d85\u8fc7 early_stopping_rounds \u90fd\u6ca1\u6709\u63d0\u9ad8\uff0c\u5c31\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3\uff0c\u8fd4\u56de\u5c40\u90e8\u6700\u4f18\u7684\u6a21\u578b num_boost_round \u7528\u4e8e\u63a7\u5236 boost \u8fc7\u7a0b\u7684\u6700\u5927\u5faa\u73af\u6b21\u6570\uff0c\u6bcf\u4e00\u6b21\u5faa\u73af\u4f1a\u751f\u6210\u4e00\u68f5\u6811\u6765\u62df\u5408\u6b8b\u5dee\uff0c\u5982\u679c early_stopping_rounds \u751f\u6548\uff0c\u5c31\u4e0d\u5fc5\u8fd0\u884c\u5230\u6700\u540e\u3002 3.2.2 \u7279\u5f81\u91cd\u8981\u6027 \u8fd9\u4e5f\u662f\u4e00\u4e2a\u6709\u8da3\u7684\u6982\u5ff5\uff0c\u5728\u6211\u4eec\u7684\u6a21\u578b\u4e2d\uff0c\u7279\u5f81\u91cd\u8981\u6027\u5982\u4e0b\u6240\u793a\uff1a 3.2.2.1 \u7279\u5f81\u91cd\u8981\u6027\u7684\u8ba1\u7b97 \u5bf9\u4e8e\u6811\u65b9\u6cd5\u6765\u8bf4\uff08LightGBM\uff0cXGBoost\uff0cGBDT\uff09\uff0c\u4ed6\u4eec\u7684\u8ba1\u7b97\u65b9\u6cd5\u90fd\u662f\u7c7b\u4f3c\u7684\uff0c\u5373\u5728\u67d0\u4e2a\u8282\u70b9\u5206\u88c2\u524d\u540e\uff0c\u6bd4\u8f83\u5176\u201d\u4e0d\u7eaf\u5ea6\u201c\uff0c\u4e0d\u7eaf\u5ea6\u4e0b\u964d\u8d8a\u591a\uff0c\u8bf4\u660e\u6548\u679c\u8d8a\u597d\u3002 \\[ \\text{importance} = \\frac{ n }{ N } ( \\rho - \\frac{n_l}{n} \\rho_l - \\frac{n_r}{n} \\rho_r ) \\] \u5176\u4e2d: \\(n\\) - \u67d0\u8282\u70b9\u6837\u672c\u6570 \\(N\\) - \u603b\u6837\u672c\u6570 \\(\\rho\\) - \u4e0d\u7eaf\u5ea6 \u4e0b\u6807 l, r \u5206\u522b\u8868\u793a\u5206\u88c2\u540e\u7684\u5de6\u53f3\u5b50\u8282\u70b9\u3002 \u56e0\u6b64\uff0c\u5176\u542b\u4e49\u4e5f\u662f\u660e\u663e\u7684\u3002\u9996\u5148\u4ee5\u8be5\u8282\u70b9\u6837\u672c\u6570\u5360\u603b\u6837\u672c\u6570\u4e3a\u6743\u91cd\uff0c\u4e58\u4ee5\u5206\u88c2\u540e\u964d\u4f4e\u7684\u4e0d\u7eaf\u5ea6\uff0c\u5f97\u5230\u8be5\u8282\u70b9\u5206\u88c2\u7684\u201c\u8d21\u732e\u201d\uff0c\u5373\u91cd\u8981\u6027\u3002 3.2.3 \u9884\u6d4b\u7ed3\u679c \u6211\u4eec\u975e\u5e38\u8f7b\u677e\u5730\u5c06\u9884\u6d4b\u8bef\u5dee RMSPE \u4ece 0.34 \u964d\u4f4e\u5230\u4e86 0.22~0.25 \u3002\u7531\u4e8e\u672c\u4eba\u7535\u8111\u6e23\uff0c\u53ea\u968f\u673a\u9009\u7528\u4e86\u51e0\u4e2a\u80a1\u7968\u7684\u6570\u636e\uff0c\u4f46\u662f\u4ece\u7edf\u8ba1\u610f\u4e49\u4e0a\u8bb2\u5e94\u8be5\u548c\u8bad\u7ec3\u6240\u6709\u6570\u636e\u8bef\u5dee\u7c7b\u4f3c\u3002\u56e0\u6b64\u867d\u4e0d\u4e25\u8c28\u4e5f\u8db3\u591f\u8bf4\u660e LightGBM \u786e\u5b9e\u662f\u975e\u5e38\u6709\u6548\u7684\u3002 \u5f53\u7136\uff0c\u8fd9\u662f\u4e00\u4e2a\u5f88\u83dc\u7684\u6210\u7ee9\uff0c\u5728\u8fd9\u4e2a\u6bd4\u8d5b\u4e2d\uff0c\u524d\u51e0\u540d\u5df2\u7ecf\u5c06\u8bef\u5dee\u964d\u4f4e\u5230\u4e86 0.18 \u4ee5\u5185\u3002\u8fd9\u662f\u56e0\u4e3a\u6211\u4eec\u8fd8\u6ca1\u6709\u8fdb\u884c\u4efb\u4f55\u53c2\u6570\u8c03\u4f18\uff0c\u7279\u5f81\u4e5f\u662f\u968f\u624b\u9009\u7684\u3002\u6211\u4eec\u5c06\u5728\u4e0b\u4e00\u7bc7\u4e2d\u8be6\u7ec6\u4ecb\u7ecd\u5982\u4f55\u4f18\u5316\u53c2\u6570\uff0c\u4ee5\u53ca\u63d0\u9ad8\u7279\u5f81\u7684\u8d28\u91cf\u3002 [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007232 seconds. You can set `force_col_wise=true` to remove the overhead. [LightGBM] [Info] Total Bins 74970 [LightGBM] [Info] Number of data points in the train set: 3064, number of used features: 294 [LightGBM] [Info] Start training from score 0.003745 Training until validation scores don't improve for 50 rounds [20] training's RMSPE: 0.185026 valid_1's RMSPE: 0.249763 [40] training's RMSPE: 0.141187 valid_1's RMSPE: 0.238492 [60] training's RMSPE: 0.117718 valid_1's RMSPE: 0.240709 [80] training's RMSPE: 0.100988 valid_1's RMSPE: 0.244922 Early stopping, best iteration is: [34] training's RMSPE: 0.150671 valid_1's RMSPE: 0.237703 RMSPE = 0.2377028864491903 [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009398 seconds. You can set `force_col_wise=true` to remove the overhead. [LightGBM] [Info] Total Bins 74970 [LightGBM] [Info] Number of data points in the train set: 3064, number of used features: 294 [LightGBM] [Info] Start training from score 0.003736 Training until validation scores don't improve for 50 rounds [20] training's RMSPE: 0.182278 valid_1's RMSPE: 0.244471 [40] training's RMSPE: 0.139054 valid_1's RMSPE: 0.242755 [60] training's RMSPE: 0.116214 valid_1's RMSPE: 0.249089 Early stopping, best iteration is: [26] training's RMSPE: 0.164368 valid_1's RMSPE: 0.240414 RMSPE = 0.24041392797196037 [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007414 seconds. You can set `force_col_wise=true` to remove the overhead. [LightGBM] [Info] Total Bins 74968 [LightGBM] [Info] Number of data points in the train set: 3064, number of used features: 294 [LightGBM] [Info] Start training from score 0.003772 Training until validation scores don't improve for 50 rounds [20] training's RMSPE: 0.183314 valid_1's RMSPE: 0.263333 [40] training's RMSPE: 0.140241 valid_1's RMSPE: 0.254926 [60] training's RMSPE: 0.116984 valid_1's RMSPE: 0.256409 [80] training's RMSPE: 0.0994774 valid_1's RMSPE: 0.261615 Early stopping, best iteration is: [38] training's RMSPE: 0.143255 valid_1's RMSPE: 0.253827 RMSPE = 0.2538268499911712 [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007743 seconds. You can set `force_col_wise=true` to remove the overhead. [LightGBM] [Info] Total Bins 74970 [LightGBM] [Info] Number of data points in the train set: 3064, number of used features: 294 [LightGBM] [Info] Start training from score 0.003678 Training until validation scores don't improve for 50 rounds [20] training's RMSPE: 0.185122 valid_1's RMSPE: 0.224511 [40] training's RMSPE: 0.141241 valid_1's RMSPE: 0.220552 [60] training's RMSPE: 0.11815 valid_1's RMSPE: 0.22418 [80] training's RMSPE: 0.101414 valid_1's RMSPE: 0.227895 Early stopping, best iteration is: [32] training's RMSPE: 0.154159 valid_1's RMSPE: 0.219429 RMSPE = 0.2194288855505451 [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004243 seconds. You can set `force_col_wise=true` to remove the overhead. [LightGBM] [Info] Total Bins 74969 [LightGBM] [Info] Number of data points in the train set: 3064, number of used features: 294 [LightGBM] [Info] Start training from score 0.003703 Training until validation scores don't improve for 50 rounds [20] training's RMSPE: 0.184329 valid_1's RMSPE: 0.238253 [40] training's RMSPE: 0.141179 valid_1's RMSPE: 0.232793 [60] training's RMSPE: 0.118668 valid_1's RMSPE: 0.235608 Early stopping, best iteration is: [28] training's RMSPE: 0.161778 valid_1's RMSPE: 0.232168 RMSPE = 0.23216812618489302 4. LightGBM \u53c2\u6570\u8c03\u6574\u53ca\u7279\u5f81\u4f18\u5316 \u89c1\u4e0b\u4e00\u7bc7 LightGBM \u5b9e\u6218\uff1a\u6ce2\u52a8\u7387\u9884\u6d4b(2) \u3002 5. Appendix Useful tool functions, especially the get_features . It uses pandas.pivot to create \"flatten\" features based on trunks separated by time. def calculate_realized_volatility(price): log_return = np.log(price).diff().dropna() return np.sqrt(np.sum(log_return**2)) def cut_by_time(df, window_seconds): batch_id = df.groupby('time_id', group_keys=False).apply( lambda g: (g.seconds_in_bucket / window_seconds).astype(int)) return batch_id def get_features(df, feature_dict): features = df.groupby(['time_id', 'batch_id'], group_keys=False ).agg(feature_dict).reset_index() # concat multi-level column features.columns = ['_'.join(col) for col in features.columns] # now each time id has several rows of features for different time window # use pandas.pivot to flat these rows flat_features = features.pivot(index='time_id_', columns='batch_id_') flat_features.columns = [f'{col[0]}_{col[1]}' for col in flat_features.columns] return flat_features.reset_index() 6. Reference Optiver Realized Volatility Prediction lightGBM Baseline for \"Optiver Realized Volatility Prediction\"","title":"LightGBM \u5b9e\u6218\uff1a\u6ce2\u52a8\u7387\u9884\u6d4b(1)"},{"location":"computer-science/lgbm/LgbmVol1/#lightgbm-1","text":"\u8fd9\u662f Kaggle \u4e0a\u7684\u4e00\u4e2a\u6bd4\u8d5b\uff1a Optiver Realized Volatility Prediction \u3002 \u76ee\u7684\u662f\u901a\u8fc7\u80a1\u7968\u7684\u5386\u53f2 order book \u548c trade \u6765\u9884\u6d4b\u5b83\u63a5\u4e0b\u6765\u5341\u5206\u949f\u7684volatility\u3002\u57fa\u672c\u91d1\u878d\u6982\u5ff5\u5c31\u4e0d\u8d58\u8ff0\u4e86\u3002","title":"LightGBM \u5b9e\u6218\uff1a\u6ce2\u52a8\u7387\u9884\u6d4b(1)"},{"location":"computer-science/lgbm/LgbmVol1/#1-data-overview","text":"\u8be5\u6bd4\u8d5b\u7ed9\u51fa\u7684\u8bad\u7ec3\u6570\u636e\u5305\u542b 112 \u652f\u80a1\u7968\u3002\u6bcf\u652f\u80a1\u7968\u4ee5 10 \u5206\u949f\u4e3a\u91c7\u6837\u65f6\u95f4\uff08time_id\uff09\uff0c\u8bb0\u5f55\u4e86 order book \u548c trade \u7684\u8be6\u7ec6\u6570\u636e\u3002","title":"1. Data overview"},{"location":"computer-science/lgbm/LgbmVol1/#11-order-book","text":"time_id: \u6bcf\u5341\u5206\u949f\u4e3a\u4e00\u4e2a bucket\uff0ctime_id \u4e5f\u662f bucket \u7684 id seconds_in_bucket: 10\u5206\u949f=600\u79d2\uff0c\u6bcf\u4e2a bucket \u91cd\u7f6e price: \u5f52\u4e00\u5316\u540e\u7684\u4ef7\u683c\uff0c\u4e5f\u79f0\u4e3a\u56de\u62a5\u7387\u3002\u4ee5\u7b2c\u4e00\u6761\u8bb0\u5f55\u4e3a\u57fa\u51c6\u503c 1.00 size: \u5728\u8fd9\u4e2a\u4ef7\u683c\u4e0a\u9762\u62a5\u4ef7\u7684\u8ba2\u5355\u6570\u91cf","title":"1.1 Order book"},{"location":"computer-science/lgbm/LgbmVol1/#12-trade","text":"","title":"1.2 Trade"},{"location":"computer-science/lgbm/LgbmVol1/#2-benchmark","text":"\u4e3a\u4e86\u8861\u91cf\u6211\u4eec\u9884\u6d4b\u7684\u6548\u679c\uff0c\u9700\u8981\u4e00\u4e2a\u7b80\u5355\u7684\u9884\u6d4b\u4f5c\u4e3a benchmark\uff0c\u4f4e\u4e8e\u8fd9\u4e2a benchmark \u8bf4\u660e\u6a21\u578b\u662f\u65e0\u6548\u7684\u3002 \u6700\u7b80\u5355\u7684\u9884\u6d4b\u5c31\u662f\u76f4\u63a5\u7528\u8fc7\u53bb 10 \u5206\u949f\u7684 volatility \u6765\u9884\u6d4b\u672a\u6765 10 \u5206\u949f \u7684\u3002\u5982\u679c\u6211\u4eec\u9009\u53d6\u5747\u65b9\u6839\u767e\u5206\u6bd4\u8bef\u5dee\uff08RMSPE\uff09\u4f5c\u4e3a\u8bc4\u5206\u6807\u51c6\uff0c\u5219\u5176\u8bef\u5dee\u4e3a 0.341\uff0c\u537334.10%\u3002 RMSPE \u8ba1\u7b97\u65b9\u5f0f\u4e3a\uff1a \\( \\(\\text{RMSPE} = \\sqrt{ \\frac{ 1 }{ N } \\sum_{i=1}^N (\\frac{y_i - \\hat{y}_i}{y_i})^2 }\\) \\)","title":"2. Benchmark"},{"location":"computer-science/lgbm/LgbmVol1/#21-benchmark-code","text":"\u53ef\u4ee5\u7528\u4ee5\u4e0b\u4ee3\u7801\u8ba1\u7b97 benchmark\uff0c\u8ba1\u7b97 volatility \u548c RMSPE \u7684\u65b9\u6cd5\u4e0e\u4e4b\u540e LightGBM \u4e2d\u662f\u4e00\u81f4\u7684\u3002 vol = get_histocal_volatility ( 'data/book_train.parquet/' ) print_score ( vol )","title":"2.1 Benchmark code"},{"location":"computer-science/lgbm/LgbmVol1/#211-volatility-calculation","text":"import pandas as pd import numpy as np import glob import multiprocessing as mp def vwap(row): return (row.bid_price1 * row.ask_size1 + row.ask_price1 * row.bid_size1) / (row.ask_size1 + row.bid_size1) def calculate_realized_volatility(frame): # theo_price = frame.apply(vwap, axis=1) theo_price = vwap(frame) log_return = np.log(theo_price).diff().dropna() return np.sqrt(np.sum(log_return**2)) def get_stock_volatility(path): book = pd.read_parquet(path) vol = book.groupby('time_id').apply(calculate_realized_volatility).reset_index(name='volatility') vol['stock_id'] = int(path.split('=')[1]) return vol.reindex(['stock_id', 'time_id', 'volatility'], axis=1) def get_histocal_volatility(train_dir): paths = glob.glob(f'{train_dir}/*') with mp.Pool(4) as p: results = p.map(get_stock_volatility, paths) return pd.concat(results)","title":"2.1.1 Volatility calculation"},{"location":"computer-science/lgbm/LgbmVol1/#212-rmspe-calculation","text":"def convert_to_submit_format(vol): row_id = pd.Series(vol.stock_id.astype(str) + '-' + vol.time_id.astype(str), name='row_id') return pd.concat([row_id, vol.iloc[:,2]], axis=1) def print_score(vol): train = convert_to_submit_format(pd.read_csv('data/train.csv')) pred = convert_to_submit_format(vol) from sklearn.metrics import r2_score def rmspe(y_true, y_pred): return (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))) joined = pd.merge(pred, train, on='row_id') R2 = round(r2_score(y_true = joined.target, y_pred = joined.volatility),3) RMSPE = round(rmspe(y_true = joined.target, y_pred = joined.volatility),3) print(f'Performance of the naive prediction: R2 score: {R2}, RMSPE: {RMSPE}')","title":"2.1.2 RMSPE calculation"},{"location":"computer-science/lgbm/LgbmVol1/#3-lightgbm-volatility","text":"\u672c\u8282\u5c06\u7b80\u5355\u5e94\u7528 LightGBM \u9884\u6d4b volatility\uff0c\u6682\u65f6\u4e0d\u6d89\u53ca\u4efb\u4f55\u8c03\u53c2\u4ee5\u53ca\u7279\u5f81\u5de5\u7a0b\u7684\u4f18\u5316\u3002\u4ec5\u4ec5\u9a8c\u8bc1 LightGBM \u5728\u9ed8\u8ba4\u53c2\u6570\u4e0b\u3001\u5229\u7528\u7b80\u5355\u7684\u7279\u5f81\u5373\u53ef\u83b7\u5f97\u8d85\u8fc7 benchmark \u7684\u9884\u6d4b\u6548\u679c\uff0c\u91cd\u70b9\u9610\u8ff0\u5982\u4f55\u8c03\u5305 :)\u3002","title":"3. \u7528 LightGBM \u9884\u6d4b volatility"},{"location":"computer-science/lgbm/LgbmVol1/#31","text":"\u5bf9\u4e8e book \u548c trade\uff0c\u6211\u4eec\u90fd\u9700\u8981\u505a\u4e00\u4e9b\u7b80\u5355\u7684\u8ba1\u7b97\u6765\u5c06\u539f\u59cb\u6570\u636e\u7a0d\u4f5c\u52a0\u5de5\u3002 \u5f52\u6839\u5230\u5e95\uff0c\u6ce2\u52a8\u7387\u53cd\u5e94\u7684\u662f\u4ef7\u683c\u53d8\u5316\u5267\u70c8\u7a0b\u5ea6\u3002\u7406\u8bba\u4e0a\uff0c\u5f53\u67d0\u4e2a\u80a1\u7968\u6d41\u52a8\u6027\u4e0d\u4f73\uff08\u5373\u4e70\u5356\u4ef7\u5dee\u5927\u3001\u6302\u5355\u6570\u91cf\u5c11\uff09\u65f6\uff0c\u5b83\u7684\u6ce2\u52a8\u7387\u4f1a\u663e\u8457\u4e0a\u5347\u3002\u6b64\u5916\uff0c\u5982\u679c\u67d0\u4e2a\u80a1\u7968\u4ea4\u6613\u91cf\u76f8\u5bf9\u5176\u6302\u5355\u91cf\u8f83\u5927\uff0c\u4e5f\u4f1a\u6709\u8f83\u5927\u7684\u6ce2\u52a8\u7387\u3002 \u53e6\u5916\uff0c\u7531\u4e8e\u6bcf\u4e2a time_id \u6709 10 \u5206\u949f\u7684\u6570\u636e\uff0c\u76f4\u89c9\u4e0a\uff0c\u8fd9\u4e9b\u6570\u636e\u5bf9\u672a\u6765\u4ea4\u6613\u7684\u5f71\u54cd\u5e94\u8be5\u662f\u4f1a decay \u7684\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u6839\u636e\u65f6\u95f4\u5c06\u5176\u5206\u4e3a\u591a\u4e2a batch\u3002","title":"3.1 \u7279\u5f81\u63d0\u53d6"},{"location":"computer-science/lgbm/LgbmVol1/#311-book-features","text":"book \u65b9\u9762\uff0c\u7531\u4e8e volatility \u662f\u57fa\u4e8e vwap \u7684\uff0c\u6211\u8ba1\u7b97\u4e86\u591a\u79cd vwap\uff0c\u7528\u4e8e\u8868\u73b0\u67d0\u4e00\u4e2a level \u88ab\u5168\u90e8 take \u7684\u60c5\u51b5\u3002\u6b64\u5916\uff0c\u4e70\u5356\u4ef7\u5dee\u3001\u4e70 1 \u548c\u4e70 2 \u4ef7\u5dee\u3001\u5356 1 \u548c \u5356 2 \u7684\u4ef7\u5dee\u90fd\u53ef\u4ee5\u7eb3\u5165\u8003\u8651\u3002 def vwap(row, bid_idx, ask_idx): # TODO: multi-level return (row[f'bid_price{bid_idx}'] * row[f'ask_size{ask_idx}'] + row[f'ask_price{ask_idx}'] * row[f'bid_size{bid_idx}']) / ( row[f'ask_size{ask_idx}'] + row[f'bid_size{bid_idx}']) def get_book(stock_id): book = pd.read_parquet(f\"data/book_train.parquet/stock_id={stock_id}\") # VWAPs # level 0 price does not change book['vwap11'] = vwap(book, 1, 1) # ask level 0 is fully traded book['vwap12'] = vwap(book, 1, 2) # bid level 0 is fully traded book['vwap21'] = vwap(book, 2, 1) # bid and ask level 0 is fully traded book['vwap22'] = vwap(book, 2, 2) book['bid_ask_spread'] = book.ask_price1 - book.bid_price1 book['bid_gap'] = book.bid_price1 - book.bid_price2 book['ask_gap'] = book.ask_price2 - book.ask_price1 book['bid_imbalance'] = book.bid_size1 / book.bid_size2 book['ask_imbalance'] = book.ask_size1 / book.ask_size2 return book def get_book_features(book, window): book['batch_id'] = cut_by_time(book, window) feature_dict = { 'vwap11': ['mean', 'std', 'max', calculate_realized_volatility], 'vwap12': ['mean', 'std', 'max', calculate_realized_volatility], 'vwap21': ['mean', 'std', 'max', calculate_realized_volatility], 'vwap22': ['mean', 'std', 'max', calculate_realized_volatility], 'bid_gap': ['mean', 'std', 'max'], 'ask_gap': ['mean', 'std', 'max'], 'bid_ask_spread': ['mean', 'std', 'max'], 'bid_size1': ['mean', 'std', 'max', 'sum'], 'ask_size1': ['mean', 'std', 'max', 'sum'], 'bid_imbalance': ['mean', 'std', 'max'], 'ask_imbalance': ['mean', 'std', 'max'], } return get_features(book, feature_dict)","title":"3.1.1 book features"},{"location":"computer-science/lgbm/LgbmVol1/#312-trade-features","text":"\u968f\u4fbf\u63d0\u53d6\u4e86\u51e0\u4e2a trade \u7684\u7279\u5f81\uff0c\u4f8b\u5982\u4ea4\u6613\u6570\u91cf\u3001\u4ea4\u6613\u91d1\u989d\u7b49\u7b49\u3002 def get_trade ( stock_id ): trade = pd . read_parquet ( f \"data/trade_train.parquet/stock_id= { stock_id } \" ) . rename ({ 'size' : 'trade_volume' }, axis = 1 ) trade [ 'trade_amount' ] = trade . price * trade . trade_volume trade [ 'per_trade_quantity' ] = trade . trade_volume / trade . order_count return trade def get_trade_features ( trade , window ): trade [ 'batch_id' ] = cut_by_time ( trade , window ) feature_dict = { 'trade_volume' : [ 'mean' , 'std' , 'max' , 'sum' ], 'trade_amount' : [ 'mean' , 'std' , 'max' ], 'per_trade_quantity' : [ 'mean' , 'std' , 'max' ] } return get_features ( trade , feature_dict ) def get_all_features ( stock_id , window ): book = get_book ( stock_id ) book_features = get_book_features ( book , window ) trade = get_trade ( stock_id ) trade_features = get_trade_features ( trade , window ) merged = pd . merge ( book_features , trade_features , on = [ 'time_id_' ]) return merged def get_train_data ( stocks , window ): df = [] for stock in stocks : features = get_all_features ( stock , window ) features [ 'stock_id_' ] = stock df . append ( features ) return pd . concat ( df ) . reset_index ( drop = True )","title":"3.1.2 trade features"},{"location":"computer-science/lgbm/LgbmVol1/#32-lightgbm","text":"\u6211\u4eec\u5df2\u7ecf\u5728 3.1 \u4e2d\u5f97\u5230\u4e86\u4e00\u5806\u7279\u5f81\u4e86\uff08294\u7ef4\uff09\uff0c\u73b0\u5728\u53ef\u4ee5\u5c06\u5b83\u4eec feed \u5230 LightGBM \u4e2d\u8fdb\u884c\u8bad\u7ec3\u4e86\u3002\u539f\u59cb\u6570\u636e\u96c6\u4e2d\u63d0\u4f9b\u4e86 train.csv \u7528\u4e8e\u8bad\u7ec3\u3002\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u4f7f\u7528\u7ecf\u5178\u7684\u4ea4\u53c9\u9a8c\u8bc1\u6765\u8bad\u7ec3\u6a21\u578b\u3002\u5c06\u539f\u59cb\u6570\u636e\u968f\u673a\u5206\u4e3a 5 \u4efd\uff0c\u5176\u4e2d 4 \u4efd\u7528\u4e8e\u8bad\u7ec3\uff0c1 \u4efd\u7528\u4e8e\u9a8c\u8bc1\u3002 from sklearn.model_selection import KFold import lightgbm # root mean squared percentage error def rmspe(y_true, y_pred): return np.sqrt(np.mean(np.square((y_true - y_pred)/y_true))) def feval_rmspe(y_pred, lgb_train): y_true = lgb_train.get_label() return 'RMSPE', rmspe(y_true, y_pred), False result = pd.read_csv('data/train.csv') selected_y = result[result.stock_id.isin([stock_id])].target.reset_index(drop=True) kf = KFold(n_splits = 5, random_state = 2021, shuffle = True) train_features = train_data.drop('time_id_', axis=1) for train_index, test_index in kf.split(train_features): # print(\"TRAIN:\", train_index, \"TEST:\", test_index) X_train, X_test = train_features.loc[train_index], train_features.loc[test_index] y_train, y_test = selected_y.loc[train_index], selected_y.loc[test_index] train_dataset = lightgbm.Dataset(X_train, y_train, weight=1/np.square(y_train)) validation_dataset = lightgbm.Dataset(X_test, y_test, weight=1/np.square(y_test)) model = lightgbm.train(params={}, train_set = train_dataset, valid_sets = [train_dataset, validation_dataset], early_stopping_rounds=50, feval = feval_rmspe, verbose_eval = 20, num_boost_round=1000) # get prediction score y_pred = model.predict(X_test) print(\"RMSPE = \", rmspe(y_test, y_pred)) lightgbm.plot_importance(model, max_num_features=20) \u6ce8\u610f\uff0c time_id \u5e76\u4e0d\u5c5e\u4e8e\u7279\u5f81\uff0c\u5728\u8fd9\u91cc\u9700\u8981\u53bb\u6389\u4ee5\u514d\u5bf9\u8bad\u7ec3\u9020\u6210\u8d1f\u9762\u5f71\u54cd\u3002","title":"3.2 \u5e94\u7528 LightGBM"},{"location":"computer-science/lgbm/LgbmVol1/#321-lightgbm","text":"\u5206\u4e3a 3 \u6b65\uff1a \u5efa\u7acb\u6570\u636e\u96c6\uff08 train_dataset = lightgbm.Dataset(...) \uff09 \u8bad\u7ec3\u6a21\u578b ( model = lightgbm.train(...) ) \u9884\u6d4b ( model.predict(X_test) ) \u7740\u91cd\u8bb2\u4e0b\u7b2c 2 \u6b65\u7684\u53c2\u6570\uff0c\u5b83\u6700\u4e3a\u590d\u6742\u3002 model = lightgbm . train ( params = {}, train_set = train_dataset , valid_sets = [ train_dataset , validation_dataset ], early_stopping_rounds = 50 , feval = feval_rmspe , verbose_eval = 20 , num_boost_round = 1000 ) - params={} \u8bf4\u660e\u6211\u4eec\u4f7f\u7528\u9ed8\u8ba4\u53c2\u6570\u3002\u7531\u4e8e\u7bc7\u5e45\u6240\u9650\uff0c\u53c2\u6570\u542b\u4e49\u548c\u8c03\u4f18\u653e\u5728\u4e0b\u4e00\u7bc7\u6587\u7ae0\u3002 valid_set , early_stopping_rounds , feval \uff1a\u8fd9\u4e09\u4e2a\u53c2\u6570\u662f\u53ef\u9009\u53c2\u6570\uff0c\u4ed6\u4eec\u662f\u6709\u5173\u8054\u7684\u3002\u76ee\u7684\u662f\u907f\u514d\u8fc7\u62df\u5408\u3002\u5229\u7528 feval \u6765\u8bc4\u4ef7\u9a8c\u8bc1\u96c6\u5728\u8fd9\u4e2a\u6a21\u578b\u4e0b\u7684\u51c6\u786e\u5ea6\uff0c\u5982\u679c\u8d85\u8fc7 early_stopping_rounds \u90fd\u6ca1\u6709\u63d0\u9ad8\uff0c\u5c31\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3\uff0c\u8fd4\u56de\u5c40\u90e8\u6700\u4f18\u7684\u6a21\u578b num_boost_round \u7528\u4e8e\u63a7\u5236 boost \u8fc7\u7a0b\u7684\u6700\u5927\u5faa\u73af\u6b21\u6570\uff0c\u6bcf\u4e00\u6b21\u5faa\u73af\u4f1a\u751f\u6210\u4e00\u68f5\u6811\u6765\u62df\u5408\u6b8b\u5dee\uff0c\u5982\u679c early_stopping_rounds \u751f\u6548\uff0c\u5c31\u4e0d\u5fc5\u8fd0\u884c\u5230\u6700\u540e\u3002","title":"3.2.1 LightGBM \u6b65\u9aa4"},{"location":"computer-science/lgbm/LgbmVol1/#322","text":"\u8fd9\u4e5f\u662f\u4e00\u4e2a\u6709\u8da3\u7684\u6982\u5ff5\uff0c\u5728\u6211\u4eec\u7684\u6a21\u578b\u4e2d\uff0c\u7279\u5f81\u91cd\u8981\u6027\u5982\u4e0b\u6240\u793a\uff1a","title":"3.2.2 \u7279\u5f81\u91cd\u8981\u6027"},{"location":"computer-science/lgbm/LgbmVol1/#3221","text":"\u5bf9\u4e8e\u6811\u65b9\u6cd5\u6765\u8bf4\uff08LightGBM\uff0cXGBoost\uff0cGBDT\uff09\uff0c\u4ed6\u4eec\u7684\u8ba1\u7b97\u65b9\u6cd5\u90fd\u662f\u7c7b\u4f3c\u7684\uff0c\u5373\u5728\u67d0\u4e2a\u8282\u70b9\u5206\u88c2\u524d\u540e\uff0c\u6bd4\u8f83\u5176\u201d\u4e0d\u7eaf\u5ea6\u201c\uff0c\u4e0d\u7eaf\u5ea6\u4e0b\u964d\u8d8a\u591a\uff0c\u8bf4\u660e\u6548\u679c\u8d8a\u597d\u3002 \\[ \\text{importance} = \\frac{ n }{ N } ( \\rho - \\frac{n_l}{n} \\rho_l - \\frac{n_r}{n} \\rho_r ) \\] \u5176\u4e2d: \\(n\\) - \u67d0\u8282\u70b9\u6837\u672c\u6570 \\(N\\) - \u603b\u6837\u672c\u6570 \\(\\rho\\) - \u4e0d\u7eaf\u5ea6 \u4e0b\u6807 l, r \u5206\u522b\u8868\u793a\u5206\u88c2\u540e\u7684\u5de6\u53f3\u5b50\u8282\u70b9\u3002 \u56e0\u6b64\uff0c\u5176\u542b\u4e49\u4e5f\u662f\u660e\u663e\u7684\u3002\u9996\u5148\u4ee5\u8be5\u8282\u70b9\u6837\u672c\u6570\u5360\u603b\u6837\u672c\u6570\u4e3a\u6743\u91cd\uff0c\u4e58\u4ee5\u5206\u88c2\u540e\u964d\u4f4e\u7684\u4e0d\u7eaf\u5ea6\uff0c\u5f97\u5230\u8be5\u8282\u70b9\u5206\u88c2\u7684\u201c\u8d21\u732e\u201d\uff0c\u5373\u91cd\u8981\u6027\u3002","title":"3.2.2.1 \u7279\u5f81\u91cd\u8981\u6027\u7684\u8ba1\u7b97"},{"location":"computer-science/lgbm/LgbmVol1/#323","text":"\u6211\u4eec\u975e\u5e38\u8f7b\u677e\u5730\u5c06\u9884\u6d4b\u8bef\u5dee RMSPE \u4ece 0.34 \u964d\u4f4e\u5230\u4e86 0.22~0.25 \u3002\u7531\u4e8e\u672c\u4eba\u7535\u8111\u6e23\uff0c\u53ea\u968f\u673a\u9009\u7528\u4e86\u51e0\u4e2a\u80a1\u7968\u7684\u6570\u636e\uff0c\u4f46\u662f\u4ece\u7edf\u8ba1\u610f\u4e49\u4e0a\u8bb2\u5e94\u8be5\u548c\u8bad\u7ec3\u6240\u6709\u6570\u636e\u8bef\u5dee\u7c7b\u4f3c\u3002\u56e0\u6b64\u867d\u4e0d\u4e25\u8c28\u4e5f\u8db3\u591f\u8bf4\u660e LightGBM \u786e\u5b9e\u662f\u975e\u5e38\u6709\u6548\u7684\u3002 \u5f53\u7136\uff0c\u8fd9\u662f\u4e00\u4e2a\u5f88\u83dc\u7684\u6210\u7ee9\uff0c\u5728\u8fd9\u4e2a\u6bd4\u8d5b\u4e2d\uff0c\u524d\u51e0\u540d\u5df2\u7ecf\u5c06\u8bef\u5dee\u964d\u4f4e\u5230\u4e86 0.18 \u4ee5\u5185\u3002\u8fd9\u662f\u56e0\u4e3a\u6211\u4eec\u8fd8\u6ca1\u6709\u8fdb\u884c\u4efb\u4f55\u53c2\u6570\u8c03\u4f18\uff0c\u7279\u5f81\u4e5f\u662f\u968f\u624b\u9009\u7684\u3002\u6211\u4eec\u5c06\u5728\u4e0b\u4e00\u7bc7\u4e2d\u8be6\u7ec6\u4ecb\u7ecd\u5982\u4f55\u4f18\u5316\u53c2\u6570\uff0c\u4ee5\u53ca\u63d0\u9ad8\u7279\u5f81\u7684\u8d28\u91cf\u3002 [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007232 seconds. You can set `force_col_wise=true` to remove the overhead. [LightGBM] [Info] Total Bins 74970 [LightGBM] [Info] Number of data points in the train set: 3064, number of used features: 294 [LightGBM] [Info] Start training from score 0.003745 Training until validation scores don't improve for 50 rounds [20] training's RMSPE: 0.185026 valid_1's RMSPE: 0.249763 [40] training's RMSPE: 0.141187 valid_1's RMSPE: 0.238492 [60] training's RMSPE: 0.117718 valid_1's RMSPE: 0.240709 [80] training's RMSPE: 0.100988 valid_1's RMSPE: 0.244922 Early stopping, best iteration is: [34] training's RMSPE: 0.150671 valid_1's RMSPE: 0.237703 RMSPE = 0.2377028864491903 [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009398 seconds. You can set `force_col_wise=true` to remove the overhead. [LightGBM] [Info] Total Bins 74970 [LightGBM] [Info] Number of data points in the train set: 3064, number of used features: 294 [LightGBM] [Info] Start training from score 0.003736 Training until validation scores don't improve for 50 rounds [20] training's RMSPE: 0.182278 valid_1's RMSPE: 0.244471 [40] training's RMSPE: 0.139054 valid_1's RMSPE: 0.242755 [60] training's RMSPE: 0.116214 valid_1's RMSPE: 0.249089 Early stopping, best iteration is: [26] training's RMSPE: 0.164368 valid_1's RMSPE: 0.240414 RMSPE = 0.24041392797196037 [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007414 seconds. You can set `force_col_wise=true` to remove the overhead. [LightGBM] [Info] Total Bins 74968 [LightGBM] [Info] Number of data points in the train set: 3064, number of used features: 294 [LightGBM] [Info] Start training from score 0.003772 Training until validation scores don't improve for 50 rounds [20] training's RMSPE: 0.183314 valid_1's RMSPE: 0.263333 [40] training's RMSPE: 0.140241 valid_1's RMSPE: 0.254926 [60] training's RMSPE: 0.116984 valid_1's RMSPE: 0.256409 [80] training's RMSPE: 0.0994774 valid_1's RMSPE: 0.261615 Early stopping, best iteration is: [38] training's RMSPE: 0.143255 valid_1's RMSPE: 0.253827 RMSPE = 0.2538268499911712 [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007743 seconds. You can set `force_col_wise=true` to remove the overhead. [LightGBM] [Info] Total Bins 74970 [LightGBM] [Info] Number of data points in the train set: 3064, number of used features: 294 [LightGBM] [Info] Start training from score 0.003678 Training until validation scores don't improve for 50 rounds [20] training's RMSPE: 0.185122 valid_1's RMSPE: 0.224511 [40] training's RMSPE: 0.141241 valid_1's RMSPE: 0.220552 [60] training's RMSPE: 0.11815 valid_1's RMSPE: 0.22418 [80] training's RMSPE: 0.101414 valid_1's RMSPE: 0.227895 Early stopping, best iteration is: [32] training's RMSPE: 0.154159 valid_1's RMSPE: 0.219429 RMSPE = 0.2194288855505451 [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004243 seconds. You can set `force_col_wise=true` to remove the overhead. [LightGBM] [Info] Total Bins 74969 [LightGBM] [Info] Number of data points in the train set: 3064, number of used features: 294 [LightGBM] [Info] Start training from score 0.003703 Training until validation scores don't improve for 50 rounds [20] training's RMSPE: 0.184329 valid_1's RMSPE: 0.238253 [40] training's RMSPE: 0.141179 valid_1's RMSPE: 0.232793 [60] training's RMSPE: 0.118668 valid_1's RMSPE: 0.235608 Early stopping, best iteration is: [28] training's RMSPE: 0.161778 valid_1's RMSPE: 0.232168 RMSPE = 0.23216812618489302","title":"3.2.3 \u9884\u6d4b\u7ed3\u679c"},{"location":"computer-science/lgbm/LgbmVol1/#4-lightgbm","text":"\u89c1\u4e0b\u4e00\u7bc7 LightGBM \u5b9e\u6218\uff1a\u6ce2\u52a8\u7387\u9884\u6d4b(2) \u3002","title":"4. LightGBM \u53c2\u6570\u8c03\u6574\u53ca\u7279\u5f81\u4f18\u5316"},{"location":"computer-science/lgbm/LgbmVol1/#5-appendix","text":"Useful tool functions, especially the get_features . It uses pandas.pivot to create \"flatten\" features based on trunks separated by time. def calculate_realized_volatility(price): log_return = np.log(price).diff().dropna() return np.sqrt(np.sum(log_return**2)) def cut_by_time(df, window_seconds): batch_id = df.groupby('time_id', group_keys=False).apply( lambda g: (g.seconds_in_bucket / window_seconds).astype(int)) return batch_id def get_features(df, feature_dict): features = df.groupby(['time_id', 'batch_id'], group_keys=False ).agg(feature_dict).reset_index() # concat multi-level column features.columns = ['_'.join(col) for col in features.columns] # now each time id has several rows of features for different time window # use pandas.pivot to flat these rows flat_features = features.pivot(index='time_id_', columns='batch_id_') flat_features.columns = [f'{col[0]}_{col[1]}' for col in flat_features.columns] return flat_features.reset_index()","title":"5. Appendix"},{"location":"computer-science/lgbm/LgbmVol1/#6-reference","text":"Optiver Realized Volatility Prediction lightGBM Baseline for \"Optiver Realized Volatility Prediction\"","title":"6. Reference"},{"location":"computer-science/lgbm/LgbmVol2/","text":"LightGBM \u5b9e\u6218\uff1a\u6ce2\u52a8\u7387\u9884\u6d4b(2) \u5728\u4e0a\u4e00\u7bc7\u6587\u7ae0 LightGBM \u5b9e\u6218\uff1a\u6ce2\u52a8\u7387\u9884\u6d4b(1) \u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86 LightGBM \u7684\u57fa\u672c\u7528\u6cd5\u3002\u672c\u7bc7\u5c06\u4fa7\u91cd\u4ece\u4e24\u4e2a\u65b9\u9762\u4ecb\u7ecd\u8fdb\u9636\u65b9\u6cd5\uff1a \u5982\u4f55\u63d0\u53d6\u66f4\u597d\u7684\u7279\u5f81 \u5982\u4f55\u8c03\u8282 LightGBM \u53c2\u6570 \u6700\u7ec8\u7ed3\u679c\u662f\u5c06\u9884\u6d4b\u8bef\u5dee\u4ece 0.24 \u964d\u4f4e\u5230\u4e86 0.19\u3002\u8fd9\u53ea\u662f KFold \u9a8c\u8bc1\u96c6\u7684\u7ed3\u679c\uff0c\u56e0\u4e3a\u6bd4\u8d5b\u5df2\u7ed3\u675f\uff0c\u6ca1\u529e\u6cd5\u63d0\u4ea4\u770b\u770b\u4e86\uff0c\u6392\u540d\u7b2c\u4e00\u7684\u4f3c\u4e4e\u53ef\u4ee5\u505a\u5230 0.18 \u4ee5\u5185\u3002 \u672c\u9879\u76ee\u4ee3\u7801\u5df2\u4e0a\u4f20 GitHub\uff1a LightGBM-Volatility-Predict . 1 \u66f4\u597d\u7684\u7279\u5f81 \u5b9e\u8d28\u4e0a\u8fd9\u662f\u4e00\u79cd\u6839\u636e\u5bf9\u4e1a\u52a1\u7684\u7406\u89e3\uff0c\u4e0d\u65ad\u5c1d\u8bd5\u7ec4\u5408\u57fa\u7840\u4fe1\u606f\u7684\u8fc7\u7a0b\u3002\u5bf9\u4e8e\u65b0\u6784\u5efa\u7684\u7279\u5f81\uff0c\u53ef\u4ee5\u901a\u8fc7\u8bad\u7ec3\u7ed3\u679c\u662f\u5426\u6709\u63d0\u5347\u3001\u201c\u7279\u5f81\u91cd\u8981\u5ea6\u201c\u662f\u5426\u8f83\u9ad8\u6765\u5224\u65ad\u662f\u4e0d\u662f\u4e00\u4e2a\u597d\u7684\u7279\u5f81\u3002 1.1 \u5355\u4e2a stock \u7684\u7279\u5f81 \u6211\u4eec\u7684\u76ee\u6807\u662f\u9884\u6d4b\u672a\u6765 10 \u5206\u949f\u7684\u6ce2\u52a8\u7387\uff0c\u90a3\u4e48\u54ea\u4e9b\u7279\u5f81\u662f\u597d\u7279\u5f81\u5462\uff1f\u6ce2\u52a8\u7387\u53cd\u5e94\u7684\u662f\u4ef7\u683c\u53d8\u5316\u5267\u70c8\u7a0b\u5ea6\u3002\u7406\u8bba\u4e0a\uff0c\u5f53\u67d0\u4e2a\u80a1\u7968\u6d41\u52a8\u6027\u4e0d\u4f73\uff08\u5373\u4e70\u5356\u4ef7\u5dee\u5927\u3001\u6302\u5355\u6570\u91cf\u5c11\uff09\u65f6\uff0c\u5b83\u7684\u6ce2\u52a8\u7387\u4f1a\u663e\u8457\u4e0a\u5347\u3002\u6b64\u5916\uff0c\u6210\u4ea4\u9891\u7387\u3001\u6302\u5355\u64a4\u5355\u9891\u7387\u7b49\u4e5f\u53ef\u4ee5\u7eb3\u5165\u8003\u8651\u3002 1.1.1 \u65f6\u95f4\u7a97\u53e3\u7edf\u8ba1\u7279\u5f81 \u73b0\u5b9e\u4e2d\u7684\u80a1\u7968\u4ef7\u683c\u53d8\u5316\u5e76\u4e0d\u662f\u4e00\u4e2a Markov \u8fc7\u7a0b\u3002\u4f46\u662f\uff0c\u663e\u7136\u8ddd\u79bb\u8f83\u8fd1\u7684\u4e8b\u4ef6\u5bf9\u9884\u6d4b\u5f71\u54cd\u8f83\u5927\u3002\u56e0\u6b64\uff0c\u5bf9\u4e8e\u8bad\u7ec3\u6570\u636e\uff0c\u7531\u4e8e\u662f\u4ee5 10 \u5206\u949f\u4e3a\u4e00\u4e2a time_id\uff0c\u6211\u4eec\u53ef\u4ee5\u8003\u8651\u5c06\u5176\u66f4\u8fdb\u4e00\u6b65\u7ec6\u5206\uff0c\u4f8b\u5982\uff0c100 \u79d2\u4e3a\u4e00\u4e2a batch\u3002\u5c06\u539f\u672c\u7684 stock_id-time_id \u4e24\u5c42\u7ed3\u6784\u7ec6\u5206\u4e3a\u4e09\u5c42\uff1astock_id-time_id-batch_id\u3002 \u5728\u751f\u6210\u8bad\u7ec3\u6570\u636e\u65f6\uff0c\u6bcf\u4e2a time_id \u4e0b\u591a\u4e2a batch_id \u4e4b\u95f4\u662f\u5e73\u884c\u7684\u7279\u5f81\uff0c\u4f8b\u5982\uff1a 1.1.2 \u6700\u540e\u65f6\u523b\u7279\u5f81 \u5982\u679c\u53ea\u6709\u4e00\u4e9b\u7c7b\u4f3c\u4e8e\u5747\u503c\u7684\u7edf\u8ba1\u7279\u5f81\uff0c\u6211\u4eec\u4f1a\u5ffd\u7565\u4e00\u4e2a\u91cd\u8981\u7684\u4fe1\u606f\uff1a\u5728\u8981\u9884\u6d4b\u7684\u63a5\u4e0b\u6765\u7684 10 \u5206\u949f\uff0c\u521d\u59cb\u72b6\u6001\u662f\u600e\u6837\u7684\uff1f \u56e0\u6b64\uff0c\u6211\u4eec\u6709\u5fc5\u8981\u4fdd\u7559 book \u6bcf\u4e2a time_id \u7684\u6700\u540e\u4e00\u6761\uff0c\u5728\u8fd9\u91cc\u6211\u8bb0\u5f55\u4e86 book \u7684\u4e70\u5356\u5dee\u4ef7\u4ee5\u53ca\u6bcf\u4e2a level \u7684\u603b\u6302\u5355\u91cf\uff1a # last book state last_state = raw_book . drop_duplicates ([ \"time_id\" ], keep = \"last\" ) . reset_index ( drop = True ) book_features [ \"last_total_volume_lv1\" ] = last_state . bid_size1 + last_state . ask_size1 book_features [ \"last_total_volume_lv12\" ] = ( book_features . last_total_volume_lv1 + last_state . bid_size2 + last_state . ask_size2 ) book_features [ \"last_bid_ask_spread\" ] = last_state . ask_price1 - last_state . bid_price1 return book_features 1.1.3 \u4e00\u4e9b\u590d\u6742\u7684\u7279\u5f81 \u6211\u4eec\u53ef\u4ee5\u5c06 book \u548c trade \u8054\u5408\u8d77\u6765\u89c2\u5bdf\uff0c\u4f8b\u5982\uff0c\u4f7f\u7528 pd.merge_asof \u53ef\u4ee5\u77e5\u9053\u6bcf\u4e2a trade \u53d1\u751f\u65f6\u7684 book \u60c5\u51b5\u3002\u76f8\u6bd4\u4e8e\u5355\u7eaf\u7684 trade \u6570\u91cf\uff0c trade/book \u7684\u6bd4\u4f8b\u66f4\u80fd\u63cf\u8ff0\u5230\u5e95\u4ea4\u6613\u8005\u6709\u591a\u6fc0\u8fdb\u3002 merged = pd . merge_asof ( trade , raw_book [ [ \"time_id\" , \"time_seconds\" , \"bid_size1\" , \"ask_size1\" , \"bid_size2\" , \"ask_size2\" , ] ], by = \"time_id\" , on = \"time_seconds\" , ) merged [ \"trade_ratio_lv1\" ] = merged . trade_volume / ( merged . bid_size1 + merged . ask_size1 ) merged [ \"trade_ratio_lv12\" ] = merged . trade_volume / ( merged . bid_size1 + merged . ask_size1 + merged . bid_size2 + merged . ask_size2 ) \u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u80fd\u8bb0\u5f55 book \u53d1\u751f\u4e86\u591a\u5c11\u6b21 \u201cflip\u201d\uff0c\u5373\u4ea4\u6613\u4e00\u6574\u4e2a level \u7684\u60c5\u51b5\u3002 1.2 \u5168\u5c40\u7279\u5f81 \u6211\u4eec\u76ee\u524d\u4e3a\u6b62\u90fd\u53ea\u6839\u636e\u4e00\u4e2a\u80a1\u7968\u7684\u4fe1\u606f\u505a\u9884\u6d4b\u3002\u5b9e\u9645\u4e0a\uff0c\u4e0d\u540c\u80a1\u7968\u4e4b\u95f4\u80af\u5b9a\u5b58\u5728\u5173\u8054\u7684\u3002\u4f8b\u5982\uff0c\u540c\u4e00\u677f\u5757\u3001\u540c\u4e00\u4e2a\u884c\u4e1a\u6216\u662f\u540c\u4e00\u4e2aETF\u7684\u80a1\u7968\u6ce2\u52a8\u7387\u663e\u7136\u662f\u76f8\u5173\u7684\u3002\u56e0\u6b64\uff0c\u5982\u679c\u80fd\u52a0\u5165\u4e00\u4e9b\u201d\u5168\u5c40\u201c\u7684\uff0c\u7c7b\u4f3c\u4e8e\u5927\u76d8\u4fe1\u606f\u7684\u7279\u5f81\uff0c\u5e94\u8be5\u4f1a\u5bf9\u9884\u6d4b\u7ed3\u679c\u6709\u5e2e\u52a9\u3002 1.2.1 \u5c06\u80a1\u7968\u5206\u7ec4\uff08Kmeans\uff09 \u6211\u4eec\u9700\u8981\u628a\u80a1\u7968\u5927\u81f4\u5206\u7ec4\uff0c\u5e76\u6bcf\u4e2a\u7ec4\u5206\u522b\u7edf\u8ba1\u4e00\u4e9b\u7279\u5f81\uff0c\u4f5c\u4e3a\u8be5\u65f6\u6bb5\u7684\u5168\u5c40\u4fe1\u606f\u52a0\u5165\u8bad\u7ec3\u7279\u5f81\u4e2d\u3002 \u6211\u4eec\u5229\u7528 KMeans \u4f9d\u636e\u5386\u53f2\u6570\u636e\u7684\u6ce2\u52a8\u7387\u53d8\u5316\uff08\u800c\u975e\u6ce2\u52a8\u7387\uff09\u8fdb\u884c\u5206\u7ec4\u3002\u6211\u968f\u4fbf\u5c1d\u8bd5\u4e86\u4e0b KMeans \u548c DBSCAN\uff0c\u53d1\u73b0\u8fd9\u4e2a\u6570\u636e\u66f4\u9002\u5408\u7528 KMeans \u5206\uff0c\u5f53\u7136\u4e5f\u53ef\u4ee5\u4f7f\u7528\u66f4\u9ad8\u7ea7\u7684\u7b97\u6cd5\uff0c\u4e0d\u8fc7\u8fd9\u5e76\u4e0d\u662f\u91cd\u70b9\u3002 \u4e0d\u76f4\u63a5\u4f7f\u7528\u6ce2\u52a8\u7387\u662f\u56e0\u4e3a\u4e0d\u540c\u80a1\u7968\u4e4b\u95f4\u5b58\u5728\u57fa\u672c\u6ce2\u52a8\u7387\u7684\u5dee\u5f02\u3002\u4f46\u662f\u5982\u679c\u662f\u76f8\u5173\u7684\u80a1\u7968\uff08\u4f8b\u5982\u540c\u4e00\u4e2a\u884c\u4e1a\u7684\uff09\uff0c\u90a3\u4e48\u4ed6\u4eec\u6ce2\u52a8\u7387\u7684\u53d8\u52a8\u8d8b\u52bf\u5e94\u8be5\u662f\u7c7b\u4f3c\u7684\u3002 \u5206\u7ec4\u6b65\u9aa4\u5927\u6982\u662f\uff1a 1. \u83b7\u53d6\u6240\u6709\u80a1\u7968\u7684\u5386\u53f2\u6ce2\u52a8\u7387 (\u5728 train.csv \u4e2d\uff09 2. \u6839\u636e time_id \u5206\u7ec4\uff0c\u5e76\u6c42\u6bcf\u4e2a\u80a1\u7968\u7684\u76f8\u5173\u5ea6\u77e9\u9635 3. \u6839\u636e\u76f8\u5173\u5ea6\u77e9\u9635\u8fdb\u884c\u5206\u7ec4 def get_correlation ( y_path ): vol_true = pd . read_csv ( y_path ) . pivot ( index = \"time_id\" , columns = \"stock_id\" , values = \"target\" ) # correlation is based on the \"change rate\" of volatility # instead of the raw volatility, I think it is comparable between stocks return ( vol_true / vol_true . shift ( 1 )) . corr () \u4f8b\u5982\u6211\u4eec\u5c06\u5176\u5206\u4e3a 5 \u4e2a\u7ec4\uff0c\u6bcf\u4e2a\u7ec4\u7684\u80a1\u7968\u4e2a\u6570\u662f\uff1a group_id 0 41 1 14 2 25 3 28 4 4 dtype: int64 \u6700\u5927\u7684\u7ec4\uff0c\u7ec4 0 \u5185\u7684\u5143\u7d20\u662f\uff1a 2, 7, 13, 14, 15, 17, 19, 20, 23, 26, 28, 32, 34, 35, 39, 41, 42, 43, 46, 47, 48, 51, 52, 53, 59, 64, 67, 68, 70, 93, 95, 102, 104, 105, 107, 114, 118, 119, 120, 123, 125 1.2.2 \u83b7\u53d6\u6bcf\u4e2a\u7ec4\u7684\u7edf\u8ba1\u7279\u5f81 \u5bf9\u4e8e\u4e0d\u540c stock \u6bd4\u8f83 reasonable \u7684\u7edf\u8ba1\u6570\u636e\u5c31\u662f\u5747\u503c\u4e86\u3002\u6211\u4eec\u9700\u8981\u5728\u6bcf\u4e2a time_id\uff0c\u5bf9\u6bcf\u4e2a\u7ec4\u7edf\u8ba1\u6240\u9700\u7279\u5f81\u7684\u5747\u503c\u3002\u5b9e\u73b0\u5982\u4e0b\uff1a def get_stock_group_features ( train_features , corr , selected_features ): copied_corr = corr . copy () from sklearn.cluster import KMeans # clustering = DBSCAN(eps=0.4, min_samples=2).fit(corr.values) clustering = KMeans ( n_clusters = 5 , random_state = 0 ) . fit ( copied_corr ) copied_corr [ \"group_id\" ] = clustering . labels_ merged = train_features . merge ( copied_corr [[ \"group_id\" ]], on = \"stock_id\" ) group_features = ( merged . groupby ([ \"time_id_\" , \"group_id\" ]) . mean () . reindex ( selected_features , axis = 1 ) . reset_index () . pivot ( index = \"time_id_\" , columns = \"group_id\" ) ) group_features . columns = [ f \" { col [ 0 ] } _group { col [ 1 ] } \" for col in group_features . columns ] return group_features . reset_index () \u6700\u540e\u53ef\u4ee5\u5f97\u5230\u7c7b\u4f3c\u4e8e\u8fd9\u6837\u7684\u7279\u5f81\uff0c\u9644\u52a0\u5728\u6bcf\u4e2a stock \u81ea\u8eab\u7684\u7279\u5f81\u540e\u9762\uff1a 1.3 \u5229\u7528\u7279\u5f81\u91cd\u8981\u5ea6\u7b5b\u9009\u7279\u5f81 \u5728\u4e0a\u4e00\u7bc7\u6587\u7ae0 LightGBM \u5b9e\u6218\uff1a\u6ce2\u52a8\u7387\u9884\u6d4b(1) \u4e2d\uff0c\u5df2\u7ecf\u7b80\u5355\u4ecb\u7ecd\u4e86\u7279\u5f81\u91cd\u8981\u5ea6\u7684\u8ba1\u7b97\u65b9\u6cd5\u548c\u542b\u4e49\u3002\u8fd9\u91cc\uff0c\u6211\u4eec\u53ef\u4ee5\u5c1d\u8bd5\u4f7f\u7528\u5b83\u6765\u53bb\u6389\u5783\u573e\u7279\u5f81\uff0c\u4fdd\u7559\u4f18\u79c0\u7684\u7279\u5f81\u3002\u8fd9\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\uff0c\u907f\u514d\u8fc7\u62df\u5408\u3002 \u5728\u5f97\u5230\u6a21\u578b\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u753b\u51fa\u6bcf\u4e2a\u7279\u5f81\u91cd\u8981\u6027\uff1a lightgbm.plot_importance(model, max_num_features=20) \u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u4e0b\u9762\u7684\u51fd\u6570\u5f97\u5230\u4e00\u4e2a DataFrame\uff1a def get_feature_importance ( model ): return pd . DataFrame ( { \"feature\" : model . feature_name (), \"importance\" : model . feature_importance ()} ) . sort_values ( by = \"importance\" , ascending = False ) \u6574\u4f53\u770b\u6765\uff0c\u91cd\u8981\u7684\u7279\u5f81\u8fd8\u662f\u6bd4\u8f83\u7b26\u5408\u76f4\u89c9\u7684\u3002\u5c24\u5176\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5168\u5c40\u7279\u5f81\u6392\u540d\u975e\u5e38\u9760\u524d\u3002\u8fd9\u8bf4\u660e\u6211\u4eec\u5728 1.2 \u4e2d\u52a0\u5165\u5168\u5c40\u7279\u5f81\u662f\u975e\u5e38\u6709\u610f\u4e49\u7684\u3002 1.4 \u7279\u5f81\u4f18\u5316\u7ed3\u679c \u4e0a\u8ff0\u7279\u5f81\u5e76\u6ca1\u6709\u5b8c\u5168\u5229\u7528\u8d77\u6765\uff0c\u56e0\u4e3a\u6211\u7535\u8111\u5b9e\u5728\u592a\u70c2\u4e86\uff0c\u7279\u5f81\u8d85\u8fc7 400 \u5c31\u5df2\u7ecf\u5185\u5b58\u4e0d\u8db3\u65e0\u6cd5\u8fd0\u884c\u4e86\uff0c\u56e0\u6b64\u5bf9\u4e8e group \u7684\u7279\u5f81\uff0c\u6211\u4ec5\u9009\u62e9\u4e86\u4e00\u90e8\u5206\uff1a selected_features = [] selected_features . extend ([ col for col in train_data . columns if 'trade_volume_mean' in col ]) selected_features . extend ([ col for col in train_data . columns if 'last' in col ]) selected_features . extend ([ col for col in train_data . columns if 'vwap11_realized_volatility' in col ]) # selected_features.extend([col for col in train_data.columns if 'gap' in col]) # selected_features.extend([col for col in train_data.columns if 'spread' in col]) selected_features . extend ([ col for col in train_data . columns if 'flip' in col ]) selected_features . extend ([ col for col in train_data . columns if 'count' in col ]) selected_features . extend ([ col for col in train_data . columns if 'trade_ratio_lv1_' in col ]) selected_features = set ( selected_features ) \u4f46\u662f\u7ed3\u679c\u5df2\u7ecf\u76f8\u5f53\u597d\u4e86\uff0c\u8f7b\u677e\u4ece\u4e4b\u524d\u7684 0.22~0.25 \u4f18\u5316\u5230\u4e86 0.19~0.20\uff08\u9ed8\u8ba4 LGBM \u53c2\u6570\u4e0b\uff09\u3002 Early stopping, best iteration is: [548] training's l2: 1.41377e-07 training's RMSPE: 0.173893 valid_1's l2: 1.79515e-07 valid_1's RMSPE: 0.196654 RMSPE = 0.19665403611036217 Early stopping, best iteration is: [744] training's l2: 1.3117e-07 training's RMSPE: 0.167791 valid_1's l2: 1.75072e-07 valid_1's RMSPE: 0.192851 RMSPE = 0.19285066677735865 Early stopping, best iteration is: [389] training's l2: 1.5088e-07 training's RMSPE: 0.179636 valid_1's l2: 2.03518e-07 valid_1's RMSPE: 0.209418 RMSPE = 0.20941792466116485 Early stopping, best iteration is: [764] training's l2: 1.30281e-07 training's RMSPE: 0.167222 valid_1's l2: 1.86109e-07 valid_1's RMSPE: 0.198835 RMSPE = 0.19883534222771257 Early stopping, best iteration is: [672] training's l2: 1.35331e-07 training's RMSPE: 0.170158 valid_1's l2: 1.79225e-07 valid_1's RMSPE: 0.196387 RMSPE = 0.19638739751965206 2 Light GBM \u53c2\u6570\u8c03\u8282 \u7279\u5f81\u786e\u5b9a\u540e\uff0c\u53c2\u6570\u8c03\u8282\u5f88\u96be\u518d\u5927\u5e45\u63d0\u9ad8\u7cbe\u5ea6\u4e86\uff0c\u6ca1\u6709\u5f88\u4e13\u4e1a\u7684\u8c03\u8282\uff0c\u56e0\u4e3a\u8fd9\u4e2a\u8fc7\u7a0b\u672c\u8eab\u6ca1\u4ec0\u4e48\u610f\u601d\uff0c\u6700\u7ec8\u8bef\u5dee\u7387\u5982\u4e0b\uff1a Did not meet early stopping. Best iteration is: [1000] training's l2: 1.29986e-07 training's RMSPE: 0.16674 valid_1's l2: 1.73911e-07 valid_1's RMSPE: 0.19356 RMSPE = 0.19355980904948505 Did not meet early stopping. Best iteration is: [1000] training's l2: 1.29211e-07 training's RMSPE: 0.166533 valid_1's l2: 1.69505e-07 valid_1's RMSPE: 0.18976 RMSPE = 0.18975971408050601 Early stopping, best iteration is: [467] training's l2: 1.51157e-07 training's RMSPE: 0.1798 valid_1's l2: 1.96557e-07 valid_1's RMSPE: 0.205806 RMSPE = 0.20580561455113955 Did not meet early stopping. Best iteration is: [1000] training's l2: 1.29565e-07 training's RMSPE: 0.166761 valid_1's l2: 1.78346e-07 valid_1's RMSPE: 0.194644 RMSPE = 0.19464427237056287 Did not meet early stopping. Best iteration is: [1000] training's l2: 1.30119e-07 training's RMSPE: 0.166848 valid_1's l2: 1.74124e-07 valid_1's RMSPE: 0.193572 RMSPE = 0.19357219429054603 \u8d21\u732e\u6700\u5927\u7684\u53c2\u6570\u5c31\u662f categorical_colum \u3002\u5c06 stock id \u6307\u5b9a\u4e3a\u7c7b\u522b\u7279\u5f81\u540e\uff0c\u6709\u660e\u663e\u7684\u63d0\u9ad8\u3002\u5176\u4f59\u53c2\u6570\u6211\u611f\u89c9\u5dee\u5f02\u4e0d\u5927\u3002\u6700\u7ec8\u4f7f\u7528\u7684\u53c2\u6570\u4e3a\uff1a params = { 'learning_rate' : 0.06 , 'bagging_fraction' : 0.72 , 'bagging_freq' : 4 , 'feature_fraction' : 0.6 , 'lambda_l1' : 0.5 , 'lambda_l2' : 1.0 , 'categorical_column' :[ 0 ]} model = lightgbm . train ( params = lgbm_params , train_set = train_dataset , valid_sets = [ train_dataset , validation_dataset ], feval = feval_rmspe , num_boost_round = 1000 , callbacks = [ lightgbm . early_stopping ( 200 ), lightgbm . log_evaluation ( 50 )], ) 2.1 \u63d0\u9ad8\u7cbe\u5ea6 \u80fd\u63d0\u9ad8\u7cbe\u5ea6\u7684\u53c2\u6570\u5e76\u4e0d\u662f\u975e\u5e38\u591a\uff0c\u6211\u53ea\u627e\u5230\u4e24\u4e2a\u3002\u4e2a\u4eba\u611f\u89c9\u53c2\u6570\u8c03\u8282\u66f4\u591a\u662f\u4e3a\u4e86\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u4ee5\u53ca\u907f\u514d\u8fc7\u62df\u5408\u3002 2.1.1 \u6307\u5b9a categorical feature \u57fa\u4e8e\u6811\u7684\u65b9\u6cd5\u6709\u4e00\u4e2a\u4f18\u70b9\u662f\u80fd\u591f\u975e\u5e38\u597d\u7684\u5904\u7406\u7c7b\u522b\u7279\u5f81\uff08categorical feature\uff09\u3002\u5728\u8fd9\u4e2a\u9879\u76ee\u4e2d\uff0cstock_id \u5c31\u662f\u4e00\u4e2a\u7c7b\u522b\u7279\u5f81\uff0c\u5b83\u7684\u5927\u5c0f\u6ca1\u6709\u610f\u4e49\uff0c\u53ea\u662f\u8868\u660e\u7c7b\u578b\u3002 \u6211\u4eec\u53ef\u4ee5\u660e\u786e\u544a\u8bc9 LGBM stock_id \u662f categorical feature\uff0c\u8fd9\u6837\u505a\u6ca1\u6709\u4efb\u4f55\u526f\u4f5c\u7528\uff1a params = { 'categorical_column' :[ 0 ] } models = lgbm_train . train ( train_features . drop ( 'time_id_' , axis = 1 ), train_y . target , 5 , params ) \u4ec5\u4e00\u6761\u914d\u7f6e\u5c31\u80fd\u83b7\u5f97\u660e\u663e\u7684\u4f18\u5316 (\u8bef\u5dee\u4ece 0.196 \u4e0b\u964d\u5230 0.192)\uff0c\u5e76\u4e14 stock_id \u7684\u91cd\u8981\u6027\u663e\u8457\u63d0\u5347\uff0c\u66f4\u7b26\u5408\u76f4\u89c9\u3002 Early stopping, best iteration is: [824] training's l2: 1.16958e-07 training's RMSPE: 0.158164 valid_1's l2: 1.71789e-07 valid_1's RMSPE: 0.192376 RMSPE = 0.19237567863942145 Early stopping, best iteration is: [796] training's l2: 1.17188e-07 training's RMSPE: 0.158596 valid_1's l2: 1.71186e-07 valid_1's RMSPE: 0.190699 RMSPE = 0.19069872260565224 Early stopping, best iteration is: [550] training's l2: 1.29443e-07 training's RMSPE: 0.166386 valid_1's l2: 1.98206e-07 valid_1's RMSPE: 0.206667 RMSPE = 0.20666692821450117 Early stopping, best iteration is: [574] training's l2: 1.28093e-07 training's RMSPE: 0.165812 valid_1's l2: 1.79801e-07 valid_1's RMSPE: 0.195436 RMSPE = 0.19543642931738184 Early stopping, best iteration is: [393] training's l2: 1.40621e-07 training's RMSPE: 0.173451 valid_1's l2: 1.77851e-07 valid_1's RMSPE: 0.195633 RMSPE = 0.19563316948191248 2.1.2 \u8bbe\u7f6e\u66f4\u5c0f\u7684 learning rate \u6700\u7b80\u5355\u7c97\u66b4\u7684\u63d0\u9ad8\u7cbe\u5ea6\u65b9\u6cd5\uff0c\u4f46\u662f\u968f\u4e4b\u800c\u6765\u662f\u8bad\u7ec3\u65f6\u95f4\u7684\u589e\u52a0\uff0c\u4e00\u822c\u914d\u5408\u4e0b\u9762\u7ae0\u8282\u4e2d\u7684\u63d0\u9ad8\u8bad\u7ec3\u901f\u5ea6\u7684\u53c2\u6570\u4f7f\u7528\u3002 'learning_rate': 0.06, 2.2 \u9632\u6b62\u8fc7\u62df\u5408 & \u63d0\u9ad8\u8bad\u7ec3\u901f\u5ea6 2.2.1 \u8bbe\u7f6e early stopping early stopping \u9700\u8981\u5728\u8bad\u7ec3\u65f6\u989d\u5916\u63d0\u4f9b\u4e00\u4e2a\u9a8c\u8bc1\u6570\u636e\u96c6\uff0c\u5982\u679c\u9a8c\u8bc1\u6570\u636e\u96c6\u4e0a\u7684\u9884\u6d4b\u6548\u679c\u5728 N \u6b21\u8fed\u4ee3\u4e2d\u6ca1\u529e\u6cd5\u518d\u63d0\u9ad8\uff0c\u5c31\u63d0\u524d\u505c\u6b62\u3002\u6d89\u53ca\u5230 2 \u4e2a\u53c2\u6570\uff1a valid_sets \u4f7f\u7528 KFold \u5206\u7684\u9a8c\u8bc1\u96c6\u3002 callbacks=[lightgbm.early_stopping(100)] 100 \u6b21\u8fed\u4ee3\u6ca1\u6709\u63d0\u9ad8\uff0c\u5219\u8fd4\u56de\u5f53\u524d\u6700\u4f18\u6a21\u578b model = lightgbm . train ( params = lgbm_params , train_set = train_dataset , valid_sets = [ train_dataset , validation_dataset ], feval = feval_rmspe , num_boost_round = 1000 , callbacks = [ lightgbm . early_stopping ( 100 ), lightgbm . log_evaluation ( 50 )], ) \u5177\u4f53\u6548\u679c\u5c31\u662f\u6709\u65f6\u5019\u6ca1\u6709\u8bad\u7ec3\u5230 num_boost_round \u5c31\u63d0\u524d\u7ec8\u6b62\u4e86\uff1a Early stopping, best iteration is: [393] training's l2: 1.40621e-07 training's RMSPE: 0.173451 valid_1's l2: 1.77851e-07 valid_1's RMSPE: 0.195633 RMSPE = 0.19563316948191248 2.2.2 Subsampling \u901a\u8fc7\u968f\u673a\u4e22\u5f03\u4e00\u90e8\u5206\u6837\u672c\u6216\u8005\u7279\u5f81\uff0c\u52a0\u5feb\u8bad\u7ec3\u901f\u5ea6\uff0c\u907f\u514d\u8fc7\u62df\u5408\u3002 \u5206\u4e3a\u4e24\u79cd\uff0c\u4e00\u79cd\u662f\u5bf9\u6837\u672c\uff08\u5373 rows\uff09\uff1a 'bagging_fraction': 0.72, 'bagging_freq': 4, \u8fd9\u4e24\u4e2a\u5fc5\u987b\u4e00\u8d77\u4f7f\u7528\uff0c bagging_fraction \u8868\u793a\u4fdd\u7559\u591a\u5c11\u6837\u672c\uff0c bagging_freq \u8868\u793a\u6bcf\u9694\u591a\u5c11\u8f6e\u751f\u6548\u4e00\u6b21\uff0c\u8bbe\u7f6e\u4e3a 0 \u5219\u4e0d\u4f1a\u751f\u6548\u3002 \u8fd8\u6709\u4e00\u79cd\u662f\u5bf9\u7279\u5f81\uff08\u5373 columns\uff09\uff1a 'feature_fraction': 0.6, 2.2.3 \u63a7\u5236\u6a21\u578b\u590d\u6742\u5ea6 \u6211\u4eec\u77e5\u9053 lightgbm \u751f\u6210\u7684\u6a21\u578b\u5176\u5b9e\u662f\u4e00\u5806\u6811\u7684\u7ec4\u5408\u3002\u90a3\u4e48\u5c31\u53ef\u4ee5\u4ece\u4e24\u4e2a\u65b9\u5411\u63a7\u5236\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u907f\u514d\u8fc7\u62df\u5408\uff1a \u63a7\u5236\u6811\u7684\u603b\u6570 num_boost_round \u63a7\u5236\u6bcf\u68f5\u6811\u7684\u590d\u6742\u5ea6 min_data_in_leaf num_leaves max_depth 2.2.4 Regularization \u6b63\u5219\u5316\uff08Regularization\uff09\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u4e00\u79cd\u5e38\u7528\u7684\u6280\u672f\uff0c\u5176\u4e3b\u8981\u76ee\u7684\u662f\u63a7\u5236\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u51cf\u5c0f\u8fc7\u62df\u5408\u3002\u6700\u57fa\u672c\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u662f\u5728\u539f\u76ee\u6807\uff08\u4ee3\u4ef7\uff09\u51fd\u6570 \u4e2d\u6dfb\u52a0\u60e9\u7f5a\u9879\uff0c\u5bf9\u590d\u6742\u5ea6\u9ad8\u7684\u6a21\u578b\u8fdb\u884c\u201c\u60e9\u7f5a\u201d\u3002 \u6d89\u53ca 3 \u4e2a\u53c2\u6570\uff1a lambda_l1 \u8bbe\u7f6e\u4e00\u4e2a threshold\uff0cgain \u5c0f\u4e8e\u8fd9\u4e2a threshold \u76f4\u63a5\u8ba4\u4e3a\u662f 0\uff0c\u4e0d\u518d\u5206\u88c2\u3002 lambda_l2 \u4e3a gain \u7684\u5206\u6bcd\uff08\u5373\u8282\u70b9\u6837\u672c\u6570\uff09\u589e\u52a0\u4e00\u4e2a\u5e38\u6570\u9879\uff0c\u4f5c\u7528\u4e8e\u5168\u7a0b\uff0c\u5728\u8282\u70b9\u6837\u672c\u6570\u5df2\u7ecf\u5f88\u5c0f\u7684\u65f6\u5019\uff0c\u80fd\u663e\u8457\u51cf\u5c0f gain \u907f\u514d\u5206\u88c2\u3002 min_gain_to_split \u5982\u679c\u4e00\u4e2a\u8282\u70b9\u7684 gain \u4f4e\u4e8e\u8fd9\u4e2a\u6570\uff0c\u4e0d\u518d\u5206\u88c2\u3002 \u5728\u6211\u53e6\u4e00\u7bc7\u6587\u7ae0 LightGBM \u53c2\u6570\u4e2d\u7684 lambda_l1 \u548c lambda_l2 \u4e2d\u6709\u8be6\u7ec6\u7684\u4ecb\u7ecd\u3002 \u53c2\u8003 clustering methods Understanding LightGBM Parameters (and How to Tune Them) - neptune.ai An Overview of LightGBM (avanwyk.com) \u6df1\u5165\u7406\u89e3L1\u3001L2\u6b63\u5219\u5316","title":"LightGBM \u5b9e\u6218\uff1a\u6ce2\u52a8\u7387\u9884\u6d4b(2)"},{"location":"computer-science/lgbm/LgbmVol2/#lightgbm-2","text":"\u5728\u4e0a\u4e00\u7bc7\u6587\u7ae0 LightGBM \u5b9e\u6218\uff1a\u6ce2\u52a8\u7387\u9884\u6d4b(1) \u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86 LightGBM \u7684\u57fa\u672c\u7528\u6cd5\u3002\u672c\u7bc7\u5c06\u4fa7\u91cd\u4ece\u4e24\u4e2a\u65b9\u9762\u4ecb\u7ecd\u8fdb\u9636\u65b9\u6cd5\uff1a \u5982\u4f55\u63d0\u53d6\u66f4\u597d\u7684\u7279\u5f81 \u5982\u4f55\u8c03\u8282 LightGBM \u53c2\u6570 \u6700\u7ec8\u7ed3\u679c\u662f\u5c06\u9884\u6d4b\u8bef\u5dee\u4ece 0.24 \u964d\u4f4e\u5230\u4e86 0.19\u3002\u8fd9\u53ea\u662f KFold \u9a8c\u8bc1\u96c6\u7684\u7ed3\u679c\uff0c\u56e0\u4e3a\u6bd4\u8d5b\u5df2\u7ed3\u675f\uff0c\u6ca1\u529e\u6cd5\u63d0\u4ea4\u770b\u770b\u4e86\uff0c\u6392\u540d\u7b2c\u4e00\u7684\u4f3c\u4e4e\u53ef\u4ee5\u505a\u5230 0.18 \u4ee5\u5185\u3002 \u672c\u9879\u76ee\u4ee3\u7801\u5df2\u4e0a\u4f20 GitHub\uff1a LightGBM-Volatility-Predict .","title":"LightGBM \u5b9e\u6218\uff1a\u6ce2\u52a8\u7387\u9884\u6d4b(2)"},{"location":"computer-science/lgbm/LgbmVol2/#1","text":"\u5b9e\u8d28\u4e0a\u8fd9\u662f\u4e00\u79cd\u6839\u636e\u5bf9\u4e1a\u52a1\u7684\u7406\u89e3\uff0c\u4e0d\u65ad\u5c1d\u8bd5\u7ec4\u5408\u57fa\u7840\u4fe1\u606f\u7684\u8fc7\u7a0b\u3002\u5bf9\u4e8e\u65b0\u6784\u5efa\u7684\u7279\u5f81\uff0c\u53ef\u4ee5\u901a\u8fc7\u8bad\u7ec3\u7ed3\u679c\u662f\u5426\u6709\u63d0\u5347\u3001\u201c\u7279\u5f81\u91cd\u8981\u5ea6\u201c\u662f\u5426\u8f83\u9ad8\u6765\u5224\u65ad\u662f\u4e0d\u662f\u4e00\u4e2a\u597d\u7684\u7279\u5f81\u3002","title":"1 \u66f4\u597d\u7684\u7279\u5f81"},{"location":"computer-science/lgbm/LgbmVol2/#11-stock","text":"\u6211\u4eec\u7684\u76ee\u6807\u662f\u9884\u6d4b\u672a\u6765 10 \u5206\u949f\u7684\u6ce2\u52a8\u7387\uff0c\u90a3\u4e48\u54ea\u4e9b\u7279\u5f81\u662f\u597d\u7279\u5f81\u5462\uff1f\u6ce2\u52a8\u7387\u53cd\u5e94\u7684\u662f\u4ef7\u683c\u53d8\u5316\u5267\u70c8\u7a0b\u5ea6\u3002\u7406\u8bba\u4e0a\uff0c\u5f53\u67d0\u4e2a\u80a1\u7968\u6d41\u52a8\u6027\u4e0d\u4f73\uff08\u5373\u4e70\u5356\u4ef7\u5dee\u5927\u3001\u6302\u5355\u6570\u91cf\u5c11\uff09\u65f6\uff0c\u5b83\u7684\u6ce2\u52a8\u7387\u4f1a\u663e\u8457\u4e0a\u5347\u3002\u6b64\u5916\uff0c\u6210\u4ea4\u9891\u7387\u3001\u6302\u5355\u64a4\u5355\u9891\u7387\u7b49\u4e5f\u53ef\u4ee5\u7eb3\u5165\u8003\u8651\u3002","title":"1.1 \u5355\u4e2a stock \u7684\u7279\u5f81"},{"location":"computer-science/lgbm/LgbmVol2/#111","text":"\u73b0\u5b9e\u4e2d\u7684\u80a1\u7968\u4ef7\u683c\u53d8\u5316\u5e76\u4e0d\u662f\u4e00\u4e2a Markov \u8fc7\u7a0b\u3002\u4f46\u662f\uff0c\u663e\u7136\u8ddd\u79bb\u8f83\u8fd1\u7684\u4e8b\u4ef6\u5bf9\u9884\u6d4b\u5f71\u54cd\u8f83\u5927\u3002\u56e0\u6b64\uff0c\u5bf9\u4e8e\u8bad\u7ec3\u6570\u636e\uff0c\u7531\u4e8e\u662f\u4ee5 10 \u5206\u949f\u4e3a\u4e00\u4e2a time_id\uff0c\u6211\u4eec\u53ef\u4ee5\u8003\u8651\u5c06\u5176\u66f4\u8fdb\u4e00\u6b65\u7ec6\u5206\uff0c\u4f8b\u5982\uff0c100 \u79d2\u4e3a\u4e00\u4e2a batch\u3002\u5c06\u539f\u672c\u7684 stock_id-time_id \u4e24\u5c42\u7ed3\u6784\u7ec6\u5206\u4e3a\u4e09\u5c42\uff1astock_id-time_id-batch_id\u3002 \u5728\u751f\u6210\u8bad\u7ec3\u6570\u636e\u65f6\uff0c\u6bcf\u4e2a time_id \u4e0b\u591a\u4e2a batch_id \u4e4b\u95f4\u662f\u5e73\u884c\u7684\u7279\u5f81\uff0c\u4f8b\u5982\uff1a","title":"1.1.1 \u65f6\u95f4\u7a97\u53e3\u7edf\u8ba1\u7279\u5f81"},{"location":"computer-science/lgbm/LgbmVol2/#112","text":"\u5982\u679c\u53ea\u6709\u4e00\u4e9b\u7c7b\u4f3c\u4e8e\u5747\u503c\u7684\u7edf\u8ba1\u7279\u5f81\uff0c\u6211\u4eec\u4f1a\u5ffd\u7565\u4e00\u4e2a\u91cd\u8981\u7684\u4fe1\u606f\uff1a\u5728\u8981\u9884\u6d4b\u7684\u63a5\u4e0b\u6765\u7684 10 \u5206\u949f\uff0c\u521d\u59cb\u72b6\u6001\u662f\u600e\u6837\u7684\uff1f \u56e0\u6b64\uff0c\u6211\u4eec\u6709\u5fc5\u8981\u4fdd\u7559 book \u6bcf\u4e2a time_id \u7684\u6700\u540e\u4e00\u6761\uff0c\u5728\u8fd9\u91cc\u6211\u8bb0\u5f55\u4e86 book \u7684\u4e70\u5356\u5dee\u4ef7\u4ee5\u53ca\u6bcf\u4e2a level \u7684\u603b\u6302\u5355\u91cf\uff1a # last book state last_state = raw_book . drop_duplicates ([ \"time_id\" ], keep = \"last\" ) . reset_index ( drop = True ) book_features [ \"last_total_volume_lv1\" ] = last_state . bid_size1 + last_state . ask_size1 book_features [ \"last_total_volume_lv12\" ] = ( book_features . last_total_volume_lv1 + last_state . bid_size2 + last_state . ask_size2 ) book_features [ \"last_bid_ask_spread\" ] = last_state . ask_price1 - last_state . bid_price1 return book_features","title":"1.1.2 \u6700\u540e\u65f6\u523b\u7279\u5f81"},{"location":"computer-science/lgbm/LgbmVol2/#113","text":"\u6211\u4eec\u53ef\u4ee5\u5c06 book \u548c trade \u8054\u5408\u8d77\u6765\u89c2\u5bdf\uff0c\u4f8b\u5982\uff0c\u4f7f\u7528 pd.merge_asof \u53ef\u4ee5\u77e5\u9053\u6bcf\u4e2a trade \u53d1\u751f\u65f6\u7684 book \u60c5\u51b5\u3002\u76f8\u6bd4\u4e8e\u5355\u7eaf\u7684 trade \u6570\u91cf\uff0c trade/book \u7684\u6bd4\u4f8b\u66f4\u80fd\u63cf\u8ff0\u5230\u5e95\u4ea4\u6613\u8005\u6709\u591a\u6fc0\u8fdb\u3002 merged = pd . merge_asof ( trade , raw_book [ [ \"time_id\" , \"time_seconds\" , \"bid_size1\" , \"ask_size1\" , \"bid_size2\" , \"ask_size2\" , ] ], by = \"time_id\" , on = \"time_seconds\" , ) merged [ \"trade_ratio_lv1\" ] = merged . trade_volume / ( merged . bid_size1 + merged . ask_size1 ) merged [ \"trade_ratio_lv12\" ] = merged . trade_volume / ( merged . bid_size1 + merged . ask_size1 + merged . bid_size2 + merged . ask_size2 ) \u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u80fd\u8bb0\u5f55 book \u53d1\u751f\u4e86\u591a\u5c11\u6b21 \u201cflip\u201d\uff0c\u5373\u4ea4\u6613\u4e00\u6574\u4e2a level \u7684\u60c5\u51b5\u3002","title":"1.1.3 \u4e00\u4e9b\u590d\u6742\u7684\u7279\u5f81"},{"location":"computer-science/lgbm/LgbmVol2/#12","text":"\u6211\u4eec\u76ee\u524d\u4e3a\u6b62\u90fd\u53ea\u6839\u636e\u4e00\u4e2a\u80a1\u7968\u7684\u4fe1\u606f\u505a\u9884\u6d4b\u3002\u5b9e\u9645\u4e0a\uff0c\u4e0d\u540c\u80a1\u7968\u4e4b\u95f4\u80af\u5b9a\u5b58\u5728\u5173\u8054\u7684\u3002\u4f8b\u5982\uff0c\u540c\u4e00\u677f\u5757\u3001\u540c\u4e00\u4e2a\u884c\u4e1a\u6216\u662f\u540c\u4e00\u4e2aETF\u7684\u80a1\u7968\u6ce2\u52a8\u7387\u663e\u7136\u662f\u76f8\u5173\u7684\u3002\u56e0\u6b64\uff0c\u5982\u679c\u80fd\u52a0\u5165\u4e00\u4e9b\u201d\u5168\u5c40\u201c\u7684\uff0c\u7c7b\u4f3c\u4e8e\u5927\u76d8\u4fe1\u606f\u7684\u7279\u5f81\uff0c\u5e94\u8be5\u4f1a\u5bf9\u9884\u6d4b\u7ed3\u679c\u6709\u5e2e\u52a9\u3002","title":"1.2 \u5168\u5c40\u7279\u5f81"},{"location":"computer-science/lgbm/LgbmVol2/#121-kmeans","text":"\u6211\u4eec\u9700\u8981\u628a\u80a1\u7968\u5927\u81f4\u5206\u7ec4\uff0c\u5e76\u6bcf\u4e2a\u7ec4\u5206\u522b\u7edf\u8ba1\u4e00\u4e9b\u7279\u5f81\uff0c\u4f5c\u4e3a\u8be5\u65f6\u6bb5\u7684\u5168\u5c40\u4fe1\u606f\u52a0\u5165\u8bad\u7ec3\u7279\u5f81\u4e2d\u3002 \u6211\u4eec\u5229\u7528 KMeans \u4f9d\u636e\u5386\u53f2\u6570\u636e\u7684\u6ce2\u52a8\u7387\u53d8\u5316\uff08\u800c\u975e\u6ce2\u52a8\u7387\uff09\u8fdb\u884c\u5206\u7ec4\u3002\u6211\u968f\u4fbf\u5c1d\u8bd5\u4e86\u4e0b KMeans \u548c DBSCAN\uff0c\u53d1\u73b0\u8fd9\u4e2a\u6570\u636e\u66f4\u9002\u5408\u7528 KMeans \u5206\uff0c\u5f53\u7136\u4e5f\u53ef\u4ee5\u4f7f\u7528\u66f4\u9ad8\u7ea7\u7684\u7b97\u6cd5\uff0c\u4e0d\u8fc7\u8fd9\u5e76\u4e0d\u662f\u91cd\u70b9\u3002 \u4e0d\u76f4\u63a5\u4f7f\u7528\u6ce2\u52a8\u7387\u662f\u56e0\u4e3a\u4e0d\u540c\u80a1\u7968\u4e4b\u95f4\u5b58\u5728\u57fa\u672c\u6ce2\u52a8\u7387\u7684\u5dee\u5f02\u3002\u4f46\u662f\u5982\u679c\u662f\u76f8\u5173\u7684\u80a1\u7968\uff08\u4f8b\u5982\u540c\u4e00\u4e2a\u884c\u4e1a\u7684\uff09\uff0c\u90a3\u4e48\u4ed6\u4eec\u6ce2\u52a8\u7387\u7684\u53d8\u52a8\u8d8b\u52bf\u5e94\u8be5\u662f\u7c7b\u4f3c\u7684\u3002 \u5206\u7ec4\u6b65\u9aa4\u5927\u6982\u662f\uff1a 1. \u83b7\u53d6\u6240\u6709\u80a1\u7968\u7684\u5386\u53f2\u6ce2\u52a8\u7387 (\u5728 train.csv \u4e2d\uff09 2. \u6839\u636e time_id \u5206\u7ec4\uff0c\u5e76\u6c42\u6bcf\u4e2a\u80a1\u7968\u7684\u76f8\u5173\u5ea6\u77e9\u9635 3. \u6839\u636e\u76f8\u5173\u5ea6\u77e9\u9635\u8fdb\u884c\u5206\u7ec4 def get_correlation ( y_path ): vol_true = pd . read_csv ( y_path ) . pivot ( index = \"time_id\" , columns = \"stock_id\" , values = \"target\" ) # correlation is based on the \"change rate\" of volatility # instead of the raw volatility, I think it is comparable between stocks return ( vol_true / vol_true . shift ( 1 )) . corr () \u4f8b\u5982\u6211\u4eec\u5c06\u5176\u5206\u4e3a 5 \u4e2a\u7ec4\uff0c\u6bcf\u4e2a\u7ec4\u7684\u80a1\u7968\u4e2a\u6570\u662f\uff1a group_id 0 41 1 14 2 25 3 28 4 4 dtype: int64 \u6700\u5927\u7684\u7ec4\uff0c\u7ec4 0 \u5185\u7684\u5143\u7d20\u662f\uff1a 2, 7, 13, 14, 15, 17, 19, 20, 23, 26, 28, 32, 34, 35, 39, 41, 42, 43, 46, 47, 48, 51, 52, 53, 59, 64, 67, 68, 70, 93, 95, 102, 104, 105, 107, 114, 118, 119, 120, 123, 125","title":"1.2.1 \u5c06\u80a1\u7968\u5206\u7ec4\uff08Kmeans\uff09"},{"location":"computer-science/lgbm/LgbmVol2/#122","text":"\u5bf9\u4e8e\u4e0d\u540c stock \u6bd4\u8f83 reasonable \u7684\u7edf\u8ba1\u6570\u636e\u5c31\u662f\u5747\u503c\u4e86\u3002\u6211\u4eec\u9700\u8981\u5728\u6bcf\u4e2a time_id\uff0c\u5bf9\u6bcf\u4e2a\u7ec4\u7edf\u8ba1\u6240\u9700\u7279\u5f81\u7684\u5747\u503c\u3002\u5b9e\u73b0\u5982\u4e0b\uff1a def get_stock_group_features ( train_features , corr , selected_features ): copied_corr = corr . copy () from sklearn.cluster import KMeans # clustering = DBSCAN(eps=0.4, min_samples=2).fit(corr.values) clustering = KMeans ( n_clusters = 5 , random_state = 0 ) . fit ( copied_corr ) copied_corr [ \"group_id\" ] = clustering . labels_ merged = train_features . merge ( copied_corr [[ \"group_id\" ]], on = \"stock_id\" ) group_features = ( merged . groupby ([ \"time_id_\" , \"group_id\" ]) . mean () . reindex ( selected_features , axis = 1 ) . reset_index () . pivot ( index = \"time_id_\" , columns = \"group_id\" ) ) group_features . columns = [ f \" { col [ 0 ] } _group { col [ 1 ] } \" for col in group_features . columns ] return group_features . reset_index () \u6700\u540e\u53ef\u4ee5\u5f97\u5230\u7c7b\u4f3c\u4e8e\u8fd9\u6837\u7684\u7279\u5f81\uff0c\u9644\u52a0\u5728\u6bcf\u4e2a stock \u81ea\u8eab\u7684\u7279\u5f81\u540e\u9762\uff1a","title":"1.2.2 \u83b7\u53d6\u6bcf\u4e2a\u7ec4\u7684\u7edf\u8ba1\u7279\u5f81"},{"location":"computer-science/lgbm/LgbmVol2/#13","text":"\u5728\u4e0a\u4e00\u7bc7\u6587\u7ae0 LightGBM \u5b9e\u6218\uff1a\u6ce2\u52a8\u7387\u9884\u6d4b(1) \u4e2d\uff0c\u5df2\u7ecf\u7b80\u5355\u4ecb\u7ecd\u4e86\u7279\u5f81\u91cd\u8981\u5ea6\u7684\u8ba1\u7b97\u65b9\u6cd5\u548c\u542b\u4e49\u3002\u8fd9\u91cc\uff0c\u6211\u4eec\u53ef\u4ee5\u5c1d\u8bd5\u4f7f\u7528\u5b83\u6765\u53bb\u6389\u5783\u573e\u7279\u5f81\uff0c\u4fdd\u7559\u4f18\u79c0\u7684\u7279\u5f81\u3002\u8fd9\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\uff0c\u907f\u514d\u8fc7\u62df\u5408\u3002 \u5728\u5f97\u5230\u6a21\u578b\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u753b\u51fa\u6bcf\u4e2a\u7279\u5f81\u91cd\u8981\u6027\uff1a lightgbm.plot_importance(model, max_num_features=20) \u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u4e0b\u9762\u7684\u51fd\u6570\u5f97\u5230\u4e00\u4e2a DataFrame\uff1a def get_feature_importance ( model ): return pd . DataFrame ( { \"feature\" : model . feature_name (), \"importance\" : model . feature_importance ()} ) . sort_values ( by = \"importance\" , ascending = False ) \u6574\u4f53\u770b\u6765\uff0c\u91cd\u8981\u7684\u7279\u5f81\u8fd8\u662f\u6bd4\u8f83\u7b26\u5408\u76f4\u89c9\u7684\u3002\u5c24\u5176\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5168\u5c40\u7279\u5f81\u6392\u540d\u975e\u5e38\u9760\u524d\u3002\u8fd9\u8bf4\u660e\u6211\u4eec\u5728 1.2 \u4e2d\u52a0\u5165\u5168\u5c40\u7279\u5f81\u662f\u975e\u5e38\u6709\u610f\u4e49\u7684\u3002","title":"1.3 \u5229\u7528\u7279\u5f81\u91cd\u8981\u5ea6\u7b5b\u9009\u7279\u5f81"},{"location":"computer-science/lgbm/LgbmVol2/#14","text":"\u4e0a\u8ff0\u7279\u5f81\u5e76\u6ca1\u6709\u5b8c\u5168\u5229\u7528\u8d77\u6765\uff0c\u56e0\u4e3a\u6211\u7535\u8111\u5b9e\u5728\u592a\u70c2\u4e86\uff0c\u7279\u5f81\u8d85\u8fc7 400 \u5c31\u5df2\u7ecf\u5185\u5b58\u4e0d\u8db3\u65e0\u6cd5\u8fd0\u884c\u4e86\uff0c\u56e0\u6b64\u5bf9\u4e8e group \u7684\u7279\u5f81\uff0c\u6211\u4ec5\u9009\u62e9\u4e86\u4e00\u90e8\u5206\uff1a selected_features = [] selected_features . extend ([ col for col in train_data . columns if 'trade_volume_mean' in col ]) selected_features . extend ([ col for col in train_data . columns if 'last' in col ]) selected_features . extend ([ col for col in train_data . columns if 'vwap11_realized_volatility' in col ]) # selected_features.extend([col for col in train_data.columns if 'gap' in col]) # selected_features.extend([col for col in train_data.columns if 'spread' in col]) selected_features . extend ([ col for col in train_data . columns if 'flip' in col ]) selected_features . extend ([ col for col in train_data . columns if 'count' in col ]) selected_features . extend ([ col for col in train_data . columns if 'trade_ratio_lv1_' in col ]) selected_features = set ( selected_features ) \u4f46\u662f\u7ed3\u679c\u5df2\u7ecf\u76f8\u5f53\u597d\u4e86\uff0c\u8f7b\u677e\u4ece\u4e4b\u524d\u7684 0.22~0.25 \u4f18\u5316\u5230\u4e86 0.19~0.20\uff08\u9ed8\u8ba4 LGBM \u53c2\u6570\u4e0b\uff09\u3002 Early stopping, best iteration is: [548] training's l2: 1.41377e-07 training's RMSPE: 0.173893 valid_1's l2: 1.79515e-07 valid_1's RMSPE: 0.196654 RMSPE = 0.19665403611036217 Early stopping, best iteration is: [744] training's l2: 1.3117e-07 training's RMSPE: 0.167791 valid_1's l2: 1.75072e-07 valid_1's RMSPE: 0.192851 RMSPE = 0.19285066677735865 Early stopping, best iteration is: [389] training's l2: 1.5088e-07 training's RMSPE: 0.179636 valid_1's l2: 2.03518e-07 valid_1's RMSPE: 0.209418 RMSPE = 0.20941792466116485 Early stopping, best iteration is: [764] training's l2: 1.30281e-07 training's RMSPE: 0.167222 valid_1's l2: 1.86109e-07 valid_1's RMSPE: 0.198835 RMSPE = 0.19883534222771257 Early stopping, best iteration is: [672] training's l2: 1.35331e-07 training's RMSPE: 0.170158 valid_1's l2: 1.79225e-07 valid_1's RMSPE: 0.196387 RMSPE = 0.19638739751965206","title":"1.4 \u7279\u5f81\u4f18\u5316\u7ed3\u679c"},{"location":"computer-science/lgbm/LgbmVol2/#2-light-gbm","text":"\u7279\u5f81\u786e\u5b9a\u540e\uff0c\u53c2\u6570\u8c03\u8282\u5f88\u96be\u518d\u5927\u5e45\u63d0\u9ad8\u7cbe\u5ea6\u4e86\uff0c\u6ca1\u6709\u5f88\u4e13\u4e1a\u7684\u8c03\u8282\uff0c\u56e0\u4e3a\u8fd9\u4e2a\u8fc7\u7a0b\u672c\u8eab\u6ca1\u4ec0\u4e48\u610f\u601d\uff0c\u6700\u7ec8\u8bef\u5dee\u7387\u5982\u4e0b\uff1a Did not meet early stopping. Best iteration is: [1000] training's l2: 1.29986e-07 training's RMSPE: 0.16674 valid_1's l2: 1.73911e-07 valid_1's RMSPE: 0.19356 RMSPE = 0.19355980904948505 Did not meet early stopping. Best iteration is: [1000] training's l2: 1.29211e-07 training's RMSPE: 0.166533 valid_1's l2: 1.69505e-07 valid_1's RMSPE: 0.18976 RMSPE = 0.18975971408050601 Early stopping, best iteration is: [467] training's l2: 1.51157e-07 training's RMSPE: 0.1798 valid_1's l2: 1.96557e-07 valid_1's RMSPE: 0.205806 RMSPE = 0.20580561455113955 Did not meet early stopping. Best iteration is: [1000] training's l2: 1.29565e-07 training's RMSPE: 0.166761 valid_1's l2: 1.78346e-07 valid_1's RMSPE: 0.194644 RMSPE = 0.19464427237056287 Did not meet early stopping. Best iteration is: [1000] training's l2: 1.30119e-07 training's RMSPE: 0.166848 valid_1's l2: 1.74124e-07 valid_1's RMSPE: 0.193572 RMSPE = 0.19357219429054603 \u8d21\u732e\u6700\u5927\u7684\u53c2\u6570\u5c31\u662f categorical_colum \u3002\u5c06 stock id \u6307\u5b9a\u4e3a\u7c7b\u522b\u7279\u5f81\u540e\uff0c\u6709\u660e\u663e\u7684\u63d0\u9ad8\u3002\u5176\u4f59\u53c2\u6570\u6211\u611f\u89c9\u5dee\u5f02\u4e0d\u5927\u3002\u6700\u7ec8\u4f7f\u7528\u7684\u53c2\u6570\u4e3a\uff1a params = { 'learning_rate' : 0.06 , 'bagging_fraction' : 0.72 , 'bagging_freq' : 4 , 'feature_fraction' : 0.6 , 'lambda_l1' : 0.5 , 'lambda_l2' : 1.0 , 'categorical_column' :[ 0 ]} model = lightgbm . train ( params = lgbm_params , train_set = train_dataset , valid_sets = [ train_dataset , validation_dataset ], feval = feval_rmspe , num_boost_round = 1000 , callbacks = [ lightgbm . early_stopping ( 200 ), lightgbm . log_evaluation ( 50 )], )","title":"2 Light GBM \u53c2\u6570\u8c03\u8282"},{"location":"computer-science/lgbm/LgbmVol2/#21","text":"\u80fd\u63d0\u9ad8\u7cbe\u5ea6\u7684\u53c2\u6570\u5e76\u4e0d\u662f\u975e\u5e38\u591a\uff0c\u6211\u53ea\u627e\u5230\u4e24\u4e2a\u3002\u4e2a\u4eba\u611f\u89c9\u53c2\u6570\u8c03\u8282\u66f4\u591a\u662f\u4e3a\u4e86\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u4ee5\u53ca\u907f\u514d\u8fc7\u62df\u5408\u3002","title":"2.1 \u63d0\u9ad8\u7cbe\u5ea6"},{"location":"computer-science/lgbm/LgbmVol2/#211-categorical-feature","text":"\u57fa\u4e8e\u6811\u7684\u65b9\u6cd5\u6709\u4e00\u4e2a\u4f18\u70b9\u662f\u80fd\u591f\u975e\u5e38\u597d\u7684\u5904\u7406\u7c7b\u522b\u7279\u5f81\uff08categorical feature\uff09\u3002\u5728\u8fd9\u4e2a\u9879\u76ee\u4e2d\uff0cstock_id \u5c31\u662f\u4e00\u4e2a\u7c7b\u522b\u7279\u5f81\uff0c\u5b83\u7684\u5927\u5c0f\u6ca1\u6709\u610f\u4e49\uff0c\u53ea\u662f\u8868\u660e\u7c7b\u578b\u3002 \u6211\u4eec\u53ef\u4ee5\u660e\u786e\u544a\u8bc9 LGBM stock_id \u662f categorical feature\uff0c\u8fd9\u6837\u505a\u6ca1\u6709\u4efb\u4f55\u526f\u4f5c\u7528\uff1a params = { 'categorical_column' :[ 0 ] } models = lgbm_train . train ( train_features . drop ( 'time_id_' , axis = 1 ), train_y . target , 5 , params ) \u4ec5\u4e00\u6761\u914d\u7f6e\u5c31\u80fd\u83b7\u5f97\u660e\u663e\u7684\u4f18\u5316 (\u8bef\u5dee\u4ece 0.196 \u4e0b\u964d\u5230 0.192)\uff0c\u5e76\u4e14 stock_id \u7684\u91cd\u8981\u6027\u663e\u8457\u63d0\u5347\uff0c\u66f4\u7b26\u5408\u76f4\u89c9\u3002 Early stopping, best iteration is: [824] training's l2: 1.16958e-07 training's RMSPE: 0.158164 valid_1's l2: 1.71789e-07 valid_1's RMSPE: 0.192376 RMSPE = 0.19237567863942145 Early stopping, best iteration is: [796] training's l2: 1.17188e-07 training's RMSPE: 0.158596 valid_1's l2: 1.71186e-07 valid_1's RMSPE: 0.190699 RMSPE = 0.19069872260565224 Early stopping, best iteration is: [550] training's l2: 1.29443e-07 training's RMSPE: 0.166386 valid_1's l2: 1.98206e-07 valid_1's RMSPE: 0.206667 RMSPE = 0.20666692821450117 Early stopping, best iteration is: [574] training's l2: 1.28093e-07 training's RMSPE: 0.165812 valid_1's l2: 1.79801e-07 valid_1's RMSPE: 0.195436 RMSPE = 0.19543642931738184 Early stopping, best iteration is: [393] training's l2: 1.40621e-07 training's RMSPE: 0.173451 valid_1's l2: 1.77851e-07 valid_1's RMSPE: 0.195633 RMSPE = 0.19563316948191248","title":"2.1.1 \u6307\u5b9a categorical feature"},{"location":"computer-science/lgbm/LgbmVol2/#212-learning-rate","text":"\u6700\u7b80\u5355\u7c97\u66b4\u7684\u63d0\u9ad8\u7cbe\u5ea6\u65b9\u6cd5\uff0c\u4f46\u662f\u968f\u4e4b\u800c\u6765\u662f\u8bad\u7ec3\u65f6\u95f4\u7684\u589e\u52a0\uff0c\u4e00\u822c\u914d\u5408\u4e0b\u9762\u7ae0\u8282\u4e2d\u7684\u63d0\u9ad8\u8bad\u7ec3\u901f\u5ea6\u7684\u53c2\u6570\u4f7f\u7528\u3002 'learning_rate': 0.06,","title":"2.1.2 \u8bbe\u7f6e\u66f4\u5c0f\u7684 learning rate"},{"location":"computer-science/lgbm/LgbmVol2/#22","text":"","title":"2.2 \u9632\u6b62\u8fc7\u62df\u5408 &amp; \u63d0\u9ad8\u8bad\u7ec3\u901f\u5ea6"},{"location":"computer-science/lgbm/LgbmVol2/#221-early-stopping","text":"early stopping \u9700\u8981\u5728\u8bad\u7ec3\u65f6\u989d\u5916\u63d0\u4f9b\u4e00\u4e2a\u9a8c\u8bc1\u6570\u636e\u96c6\uff0c\u5982\u679c\u9a8c\u8bc1\u6570\u636e\u96c6\u4e0a\u7684\u9884\u6d4b\u6548\u679c\u5728 N \u6b21\u8fed\u4ee3\u4e2d\u6ca1\u529e\u6cd5\u518d\u63d0\u9ad8\uff0c\u5c31\u63d0\u524d\u505c\u6b62\u3002\u6d89\u53ca\u5230 2 \u4e2a\u53c2\u6570\uff1a valid_sets \u4f7f\u7528 KFold \u5206\u7684\u9a8c\u8bc1\u96c6\u3002 callbacks=[lightgbm.early_stopping(100)] 100 \u6b21\u8fed\u4ee3\u6ca1\u6709\u63d0\u9ad8\uff0c\u5219\u8fd4\u56de\u5f53\u524d\u6700\u4f18\u6a21\u578b model = lightgbm . train ( params = lgbm_params , train_set = train_dataset , valid_sets = [ train_dataset , validation_dataset ], feval = feval_rmspe , num_boost_round = 1000 , callbacks = [ lightgbm . early_stopping ( 100 ), lightgbm . log_evaluation ( 50 )], ) \u5177\u4f53\u6548\u679c\u5c31\u662f\u6709\u65f6\u5019\u6ca1\u6709\u8bad\u7ec3\u5230 num_boost_round \u5c31\u63d0\u524d\u7ec8\u6b62\u4e86\uff1a Early stopping, best iteration is: [393] training's l2: 1.40621e-07 training's RMSPE: 0.173451 valid_1's l2: 1.77851e-07 valid_1's RMSPE: 0.195633 RMSPE = 0.19563316948191248","title":"2.2.1 \u8bbe\u7f6e early stopping"},{"location":"computer-science/lgbm/LgbmVol2/#222-subsampling","text":"\u901a\u8fc7\u968f\u673a\u4e22\u5f03\u4e00\u90e8\u5206\u6837\u672c\u6216\u8005\u7279\u5f81\uff0c\u52a0\u5feb\u8bad\u7ec3\u901f\u5ea6\uff0c\u907f\u514d\u8fc7\u62df\u5408\u3002 \u5206\u4e3a\u4e24\u79cd\uff0c\u4e00\u79cd\u662f\u5bf9\u6837\u672c\uff08\u5373 rows\uff09\uff1a 'bagging_fraction': 0.72, 'bagging_freq': 4, \u8fd9\u4e24\u4e2a\u5fc5\u987b\u4e00\u8d77\u4f7f\u7528\uff0c bagging_fraction \u8868\u793a\u4fdd\u7559\u591a\u5c11\u6837\u672c\uff0c bagging_freq \u8868\u793a\u6bcf\u9694\u591a\u5c11\u8f6e\u751f\u6548\u4e00\u6b21\uff0c\u8bbe\u7f6e\u4e3a 0 \u5219\u4e0d\u4f1a\u751f\u6548\u3002 \u8fd8\u6709\u4e00\u79cd\u662f\u5bf9\u7279\u5f81\uff08\u5373 columns\uff09\uff1a 'feature_fraction': 0.6,","title":"2.2.2 Subsampling"},{"location":"computer-science/lgbm/LgbmVol2/#223","text":"\u6211\u4eec\u77e5\u9053 lightgbm \u751f\u6210\u7684\u6a21\u578b\u5176\u5b9e\u662f\u4e00\u5806\u6811\u7684\u7ec4\u5408\u3002\u90a3\u4e48\u5c31\u53ef\u4ee5\u4ece\u4e24\u4e2a\u65b9\u5411\u63a7\u5236\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u907f\u514d\u8fc7\u62df\u5408\uff1a \u63a7\u5236\u6811\u7684\u603b\u6570 num_boost_round \u63a7\u5236\u6bcf\u68f5\u6811\u7684\u590d\u6742\u5ea6 min_data_in_leaf num_leaves max_depth","title":"2.2.3 \u63a7\u5236\u6a21\u578b\u590d\u6742\u5ea6"},{"location":"computer-science/lgbm/LgbmVol2/#224-regularization","text":"\u6b63\u5219\u5316\uff08Regularization\uff09\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u4e00\u79cd\u5e38\u7528\u7684\u6280\u672f\uff0c\u5176\u4e3b\u8981\u76ee\u7684\u662f\u63a7\u5236\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u51cf\u5c0f\u8fc7\u62df\u5408\u3002\u6700\u57fa\u672c\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u662f\u5728\u539f\u76ee\u6807\uff08\u4ee3\u4ef7\uff09\u51fd\u6570 \u4e2d\u6dfb\u52a0\u60e9\u7f5a\u9879\uff0c\u5bf9\u590d\u6742\u5ea6\u9ad8\u7684\u6a21\u578b\u8fdb\u884c\u201c\u60e9\u7f5a\u201d\u3002 \u6d89\u53ca 3 \u4e2a\u53c2\u6570\uff1a lambda_l1 \u8bbe\u7f6e\u4e00\u4e2a threshold\uff0cgain \u5c0f\u4e8e\u8fd9\u4e2a threshold \u76f4\u63a5\u8ba4\u4e3a\u662f 0\uff0c\u4e0d\u518d\u5206\u88c2\u3002 lambda_l2 \u4e3a gain \u7684\u5206\u6bcd\uff08\u5373\u8282\u70b9\u6837\u672c\u6570\uff09\u589e\u52a0\u4e00\u4e2a\u5e38\u6570\u9879\uff0c\u4f5c\u7528\u4e8e\u5168\u7a0b\uff0c\u5728\u8282\u70b9\u6837\u672c\u6570\u5df2\u7ecf\u5f88\u5c0f\u7684\u65f6\u5019\uff0c\u80fd\u663e\u8457\u51cf\u5c0f gain \u907f\u514d\u5206\u88c2\u3002 min_gain_to_split \u5982\u679c\u4e00\u4e2a\u8282\u70b9\u7684 gain \u4f4e\u4e8e\u8fd9\u4e2a\u6570\uff0c\u4e0d\u518d\u5206\u88c2\u3002 \u5728\u6211\u53e6\u4e00\u7bc7\u6587\u7ae0 LightGBM \u53c2\u6570\u4e2d\u7684 lambda_l1 \u548c lambda_l2 \u4e2d\u6709\u8be6\u7ec6\u7684\u4ecb\u7ecd\u3002","title":"2.2.4 Regularization"},{"location":"computer-science/lgbm/LgbmVol2/#_1","text":"clustering methods Understanding LightGBM Parameters (and How to Tune Them) - neptune.ai An Overview of LightGBM (avanwyk.com) \u6df1\u5165\u7406\u89e3L1\u3001L2\u6b63\u5219\u5316","title":"\u53c2\u8003"},{"location":"computer-science/lgbm/LightGBM/","text":"Light GBM \u539f\u7406 \u6211\u4eec\u5728 Boosting Trees \u4e2d\u4ecb\u7ecd\u4e86 Gradient Boosting Decision Tree (GBDT) \u7684\u539f\u7406\u3002Light GBM \u662f GBDT \u7684\u4e00\u4e2a\u884d\u751f\u65b9\u6cd5\u3002\u76f8\u6bd4\u5176\u4ed6\u7684\u884d\u751f\u65b9\u6cd5\uff08\u5982 XGBoost\uff09\uff0c\u5b83\u6700\u660e\u663e\u7684\u4f18\u52bf\u5c31\u662f\u8bad\u7ec3\u901f\u5ea6\u5feb\uff0c\u8fd9\u4e5f\u662f\u5b83\u88ab\u547d\u540d\u4e3a \"light\" \u7684\u539f\u56e0\u3002\u5b83\u5728\u4fdd\u6301\u8bad\u7ec3\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b\uff0c\u5c06\u4f20\u7edf GBDT \u7684\u8bad\u7ec3\u901f\u5ea6\u63d0\u9ad8\u4e86 20 \u500d\u3002 1. \u8bba\u6587\u8981\u70b9 LightGBM \u7684\u76ee\u7684\u662f\u7f29\u77ed\u8bad\u7ec3\u65f6\u95f4\uff0c\u800c\u8bad\u7ec3\u65f6\u95f4\u4e3b\u8981\u53d6\u51b3\u4e8e\u6837\u672c\u6570\u91cf\u548c\u7279\u5f81\u7ef4\u5ea6\u3002 \u5b83\u4f7f\u7528\u4e86\u4e09\u79cd\u91cd\u8981\u7684\u4f18\u5316\uff1a \uff08\u975e\u539f\u521b\uff09\u5728\u8bad\u7ec3\u6811\u7684\u65f6\u5019\uff0c\u4f7f\u7528\u76f4\u65b9\u56fe\u7b97\u6cd5\u6765\u5bfb\u627e\u6700\u4f73\u5212\u5206\u8282\u70b9 \uff08\u539f\u521b\uff09\u4f7f\u7528\u57fa\u4e8e\u68af\u5ea6\u7684\u5355\u8fb9\u91c7\u6837(GOSS)\u964d\u4f4e\u6837\u672c\u6570\u91cf \uff08\u539f\u521b\uff09\u4f7f\u7528\u4e92\u65a5\u7279\u5f81\u6346\u7ed1 (EFB)\u964d\u4f4e\u7279\u5f81\u7ef4\u5ea6 1.1 \u76f4\u65b9\u56fe\u7b97\u6cd5 \u5728 GBDT \u7684\u8bad\u7ec3\u4e2d\uff0c\u6bcf\u6b21\u8fed\u4ee3\uff0c\u6211\u4eec\u90fd\u4f1a\u62df\u5408\u8d1f\u68af\u5ea6\u6765\u751f\u6210\u4e00\u4e2a\u51b3\u7b56\u6811\uff0c\u8fd9\u4e5f\u662f GBDT \u8bad\u7ec3\u4e2d\u6700\u8017\u65f6\u7684\u90e8\u5206\u3002\u5176\u4e2d\uff0c\u8ba1\u7b97\u91cf\u6700\u5927\u7684\u90e8\u5206\u5c31\u662f\u5bfb\u627e\u6700\u4f73\u5212\u5206\u8282\u70b9\u3002 \u6700\u7b80\u5355\u76f4\u63a5\u7684\u65b9\u6cd5\u5c31\u662f\u9884\u6392\u5e8f\u6cd5\u3002\u5373\uff0c\u5148\u5c06\u6240\u6709\u6837\u672c\u4ee5\u67d0\u4e2a\u7279\u5f81\u4e3a\u6bd4\u8f83\u5bf9\u8c61\u6392\u5e8f\uff0c\u518d\u4f9d\u6b21\u904d\u5386\u5bfb\u627e\u6700\u4f18\u5212\u5206\u70b9\u3002\u8fd9\u79cd\u867d\u7136\u80fd\u627e\u5230\u6700\u4f18\u70b9\uff0c \u4f46\u662f\u7f3a\u70b9\u5f88\u660e\u663e\uff1a \u6548\u7387\u4f4e\u4e0b\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u662f \\(O(\\#data \\times \\#feature)\\) \u5bf9\u566a\u58f0\u654f\u611f LightGBM \u9009\u62e9\u4e86\u76f4\u65b9\u56fe\u6cd5\u3002\u5373\uff0c\u5148\u5c06\u6570\u636e\u5212\u5206\u5230\u591a\u4e2a bin \u4e2d\uff0c\u7528 bin \u7684\u503c\u8986\u76d6\u539f\u59cb\u503c\u8fdb\u884c\u8bad\u7ec3\u3002\u5b83\u7684\u4f18\u52bf\u662f\uff1a \u5c06\u65f6\u95f4\u590d\u6742\u5ea6\u964d\u4f4e\u5230\u4e86 \\(O(\\#bin \\times \\#feature)\\) \u3002\u7531\u4e8e bin \u7684\u6570\u91cf\u80af\u5b9a\u8fdc\u5c0f\u4e8e\u6837\u672c\u7684\u6570\u91cf\uff0c\u56e0\u6b64\u4f18\u5316\u5f88\u660e\u663e \u4e0d\u9700\u8981\u5bf9\u6837\u672c\u6570\u636e\u8fdb\u884c\u6392\u5e8f \u589e\u5f3a\u4e86\u5bf9\u6570\u636e\u566a\u58f0\u7684\u9c81\u68d2\u6027 \u5f53\u7136\uff0c\u5b83\u4e5f\u6709\u7f3a\u70b9\uff0c\u4f46\u662f\u90fd\u53ef\u4ee5\u63a5\u53d7\uff1a \u627e\u5230\u7684\u5212\u5206\u70b9\u4e0d\u4e00\u5b9a\u662f\u6700\u4f18\u7684 \u7531\u4e8e\u76f8\u4f3c\u7684\u6570\u636e\u88ab\u5212\u5206\u5230\u4e86\u4e00\u4e2a bin \u4e2d\uff0c\u5ffd\u7565\u4e86\u4e00\u4e9b\u7ec6\u8282\u7279\u5f81 bin \u7684\u6570\u91cf\u9009\u62e9\u8fc7\u5c11\u53ef\u80fd\u5bfc\u81f4\u6b20\u62df\u5408 \u76f4\u65b9\u56fe\u7b97\u6cd5\u5e76\u4e0d\u662f LightGBM \u7684\u539f\u521b\uff1a Scikit-learn\u548cgbm in R\u6f14\u53d8\u7b97\u6cd5\u4f7f\u7528\u4e86pre-sorted algorithm\u7b97\u6cd5\uff0cpGBRT\u7b97\u6cd5\u662f\u4f7f\u7528\u4e86histogram-based algorithm\uff0c\u800cXGBoost\u4e24\u8005\u90fd\u652f\u6301 1.2 \u57fa\u4e8e\u68af\u5ea6\u7684\u5355\u8fb9\u91c7\u6837 \u57fa\u4e8e\u68af\u5ea6\u7684\u5355\u8fb9\u91c7\u6837(Gradient-based One Side Sample, GOSS)\u662f LightGBM \u8bba\u6587\u4e2d\u63d0\u51fa\u7684\u4e00\u5927\u521b\u65b0\u70b9\uff0c\u7528\u4e8e\u51cf\u5c11\u8bad\u7ec3\u6837\u672c\uff0c\u4ece\u800c\u63d0\u9ad8\u6548\u7387\u3002 \u5728 AdaBoost \u4e2d\uff08\u89c1\u6211\u4e4b\u524d\u7684\u6587\u7ae0 ESL 10.1 Boosting Methods \uff09\uff0c\u6bcf\u4e2a\u6837\u672c\u90fd\u88ab\u8d4b\u4e88\u4e86\u6743\u91cd\uff0c\u56e0\u6b64\u53ef\u4ee5\u7b80\u5355\u5730\u4e22\u5f03\u6389\u6743\u91cd\u5c0f\u7684\u6837\u672c\u3002\u7136\u800c\uff0cGBDT \u4e2d\u7684\u6837\u672c\u5e76\u6ca1\u6709\u6743\u91cd\u8fd9\u4e00\u6982\u5ff5\u3002\u56e0\u6b64\uff0c\u6587\u4e2d\u63d0\u51fa\u4e86\u5229\u7528\u68af\u5ea6\u6765\u7b5b\u9009\u6837\u672c\u7684\u601d\u8def\u3002\u5982\u679c\u4e00\u4e2a\u6837\u672c\u7684\u68af\u5ea6\u8f83\u5c0f\uff0c\u8bf4\u660e\u5b83\u5df2\u7ecf\u662f\u5145\u5206\u8bad\u7ec3\u8fc7\u7684\u4e86\uff0c\u53ef\u4ee5\u4e22\u5f03\u3002 \u4f46\u662f\uff0c\u8fd9\u4e2a\u65b9\u6cd5\u7684\u95ee\u9898\u5728\u4e8e\u4e22\u5f03\u6837\u672c\u4f1a\u6539\u53d8\u6570\u636e\u7684\u5206\u5e03\uff0c\u5f71\u54cd\u6a21\u578b\u7cbe\u5ea6\u3002\u4e3a\u4e86\u907f\u514d\u8fd9\u4e2a\u95ee\u9898\uff0cLightGBM \u4fdd\u7559\u6240\u6709\u68af\u5ea6\u8f83\u5927\u7684\u6837\u672c\uff0c\u540c\u65f6\uff0c\u5bf9\u68af\u5ea6\u8f83\u5c0f\u7684\u6837\u672c\u8fdb\u884c__\u968f\u673a\u91c7\u6837__\uff0c\u56e0\u6b64\u79f0\u4e3a\u201c\u5355\u8fb9\u91c7\u6837\u201d\u3002 \u5176\u4e2d\u8f93\u5165\uff1a - \\(a\\) \u662f\u201c\u8f83\u5927\u68af\u5ea6\u6837\u672c\u201d\u7684\u6bd4\u4f8b\uff0ctop \\(a\\) \u7684\u6837\u672c\u90fd\u88ab\u5168\u90e8\u9009\u53d6 - \\(b\\) \u662f\u201c\u8f83\u5c0f\u68af\u5ea6\u6837\u672c\u201d\u91c7\u6837\u540e\u7684\u6bd4\u4f8b\uff08\u76f8\u5bf9\u4e8e\u6240\u6709\u6837\u672c\uff09 \u56e0\u6b64\u5fc5\u7136\u6709 \\(a + b < 1\\) \uff0c\u4e14 $ \\text{fact} = (1-a) / b > 1$\u3002 \u6838\u5fc3\u601d\u60f3\u662f\uff1a \u5c06\u6837\u672c\u68af\u5ea6\uff08\u6b8b\u5dee\uff09\u7531\u9ad8\u5230\u4f4e\u6392\u5e8f \u9009\u53d6\u524d \\(a * 100 \\%\\) \u7684\u6837\u672c\u4e3a\u96c6\u5408 A \u4ece\u540e \\((1-a) * 100 \\%\\) \u7684\u6837\u672c\u4e2d\u9009\u53d6 $ b * 100\\% $ \u7684\u6837\u672c\u4e3a\u96c6\u5408 B \u5c06\u88ab\u9009\u53d6\u7684\u6837\u672c\uff08A + B\uff09\u7528\u4e8e\u8bad\u7ec3 \u5728\u66f4\u65b0\u6a21\u578b\u65f6\uff0c\u9700\u8981\u5bf9\u96c6\u5408 B \u8fdb\u884c\u8865\u507f\uff0c\u4e58\u4ee5 \\((1-a)/b\\) 1.3 \u4e92\u65a5\u7279\u5f81\u6346\u7ed1 \u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u7279\u5f81\u4e4b\u95f4\u6709\u65f6\u662f\u5b58\u5728\u4e92\u65a5\u5173\u7cfb\u7684\uff0c\u5373\uff0c\u4ed6\u4eec\u4e0d\u4f1a\u540c\u65f6\u6709\u503c\u3002\u6211\u4eec\u53ef\u4ee5\u5c06\u8fd9\u4e00\u7c7b\u7279\u5f81\u201c\u6346\u7ed1\u201d\u6210\u4e00\u4e2a\u7279\u5f81\u3002\u8fd9\u6837\u6211\u4eec\u53ef\u4ee5\u628a\u65f6\u95f4\u590d\u6742\u5ea6\u7531 \\(O(\\#data \\times \\#feature)\\) \u964d\u4f4e\u5230 \\(O(\\#data \\times \\#bundles)\\) \u3002\u4e3a\u4e86\u80fd\u6346\u7ed1\u66f4\u591a\u7684\u7279\u5f81\uff0cLightGBM \u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u201d\u51b2\u7a81\u7387\u201c \\(\\gamma\\) \uff0c\u5373\u4e24\u4e2a\u7279\u5f81\u540c\u65f6\u4e0d\u4e3a 0 \u7684\u6bd4\u4f8b\u3002\u6211\u4eec\u901a\u8fc7\u8c03\u8282 \\(\\gamma\\) \u6765\u4f7f\u90e8\u5206\u51e0\u4e4e\u4e92\u65a5\u7684\u7279\u5f81\u4e5f\u53ef\u4ee5\u6346\u7ed1\u6210\u4e00\u4e2a\u3002 \u90a3\u4e48\u6211\u4eec\u5c31\u9700\u8981\u5904\u7406\u4e24\u4e2a\u95ee\u9898\uff1a \u5982\u4f55\u627e\u5230\u4e92\u65a5\u7279\u5f81 \u5982\u4f55\u6346\u7ed1 1.3.1 \u9009\u53d6\u4e92\u65a5\u7279\u5f81 \u5bfb\u627e\u4e92\u65a5\u7279\u5f81\u7684\u95ee\u9898\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u56fe\u7740\u8272\u95ee\u9898\u3002\u5047\u8bbe\u628a\u6bcf\u4e2a\u7279\u5f81\u770b\u4f5c\u56fe\u7684\u4e00\u4e2a\u9876\u70b9\uff0c\u82e5\u4e24\u4e2a\u7279\u5f81\u4e92\u65a5\uff0c\u90a3\u4ed6\u4eec\u4e4b\u95f4\u6ca1\u6709\u8def\u5f84\u3002\u8fd9\u6837\u5c31\u53ef\u4ee5\u6784\u9020\u4e00\u4e2a\u65e0\u5411\u56fe\u3002\u56fe\u7740\u8272\u95ee\u9898\u5c31\u662f\u4f7f\u56fe\u7684\u76f8\u90bb\u9876\u70b9\u989c\u8272\u4e0d\u540c\uff0c\u5373\u975e\u4e92\u65a5\u7684\u7279\u5f81\u4e0d\u5728\u540c\u4e00\u4e2a bundle \u91cc\u3002 \u5177\u4f53\u6765\u8bf4\uff0c\u7b97\u6cd5\u4e3a\uff1a \u6784\u9020\u4e00\u4e2a\u6709\u6743\u91cd\u7684\u65e0\u5411\u56fe\uff0c\u4ee5\u7279\u5f81\u4e3a\u9876\u70b9\uff0c\u6bcf\u6761\u8fb9\u7684\u6743\u91cd\u662f\u7279\u5f81\u4e4b\u95f4\u7684\u51b2\u7a81\u7387 \\(\\gamma\\) \u3002 \u5c06\u7279\u5f81\u6309\u4ed6\u4eec\u7684\u5ea6\uff08degree\uff0c\u5373\u8fb9\u7684\u6570\u91cf\uff09\u964d\u5e8f\u6392\u5217 \u68c0\u67e5\u6bcf\u4e2a\u7279\u5f81\uff0c\u82e5 \\(\\gamma\\) \u5c0f\u4e8e\u9608\u503c\uff0c\u5219\u5c06\u5176\u52a0\u5165\u73b0\u6709\u7684 bundle\uff0c\u5426\u5219\u521b\u5efa\u4e00\u4e2a\u65b0\u7684 bundle\u3002 \u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(\\# feature^2)\\) \uff0c\u800c\u4e14\u53ea\u7528\u8fd0\u884c\u4e00\u6b21\uff0c\u5b8c\u5168\u53ef\u4ee5\u63a5\u53d7\u3002 1.3.2 \u6346\u7ed1\u4e92\u65a5\u7279\u5f81 \u6211\u4eec\u5728 1.3.1 \u4e2d\u5df2\u7ecf\u5c06\u7279\u5f81\u7ec4\u5408\u6210\u4e86\u591a\u4e2a bundle\uff0c\u73b0\u5728\u9700\u8981\u8003\u8651\u5982\u4f55\u5c06\u540c\u4e00\u4e2a bundle \u5185\u7684\u7279\u5f81\u5728\u4e0d\u4e22\u5931\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u8f6c\u4e3a\u4e00\u4e2a\u7279\u5f81\u3002 \u4e00\u4e2a\u7b80\u5355\u76f4\u63a5\u7684\u65b9\u6cd5\u5c31\u662f\u9644\u52a0\u4e00\u4e2a\u504f\u79fb\u91cf\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u5df2\u77e5 A \u7279\u5f81\u53d6\u503c\u8303\u56f4\u662f [0, 10)\uff0cB \u7279\u5f81\u53d6\u503c\u8303\u56f4\u662f [0, 20)\u3002\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u6784\u5efa\u4e00\u4e2a\u5408\u5e76\u7684\u7279\u5f81\uff0c\u53d6\u503c\u8303\u56f4\u662f [0, 30)\uff0c\u5bf9\u4e8e\u6240\u6709\u7684 B \u7279\u5f81\u9644\u52a0\u4e00\u4e2a\u504f\u79fb\u91cf 10\u3002\u8fd9\u6837\u5c31\u5c06 B \u7279\u5f81\u4ece [0,20) \u6620\u5c04\u5230\u4e86 [10, 30)\u3002\u8fd9\u4e2a\u5408\u5e76\u7684\u7279\u5f81\u5c06\u66ff\u4ee3 A \u548c B \u4e24\u4e2a\u7279\u5f81\u8fdb\u884c\u8bad\u7ec3\u3002 \u5047\u8bbe\u4e92\u65a5\u7279\u5f81\u7a7a\u95f4 F \u4e2d\u6709 n \u4e2a\u7279\u5f81 f\u3002\u7531\u4e8e\u6211\u4eec\u91c7\u7528\u7684\u662f bin\uff0c\u4e0d\u540c\u7279\u5f81 f \u53ef\u80fd\u6709\u4e0d\u540c\u6570\u91cf\u7684 bin\u3002\u4ed6\u4eec\u6346\u7ed1\u8fc7\u540e\u7684\u5408\u5e76\u7279\u5f81 bin \u7684\u4e2a\u6570\u5e94\u8be5\u7b49\u4e8e\u6240\u6709\u7279\u5f81 bin \u7684\u4e2a\u6570\u4e4b\u548c\u3002 \u5bf9\u4e8e\u6bcf\u4e2a\u6837\u672c\uff0c\u5047\u8bbe\u5b83\u539f\u5148\u5c5e\u4e8e\u7b2c j \u4e2a\u7279\u5f81\u7684\u7b2c i \u4e2a bin\uff0c\u5219\u878d\u5408\u540e\u5b83\u5e94\u8be5\u5c5e\u4e8e\u7b2c$\\sum_{k=0}^{j-1} # bin_k + i $ \u4e2a bin\u3002\u5373\u9644\u52a0\u524d j-1 \u4e2a\u7279\u5f81\u7684 bin \u6570\u91cf\u4e4b\u548c\u7684\u504f\u79fb\u3002 2. \u5b9e\u4f8b\u8bf4\u660e \u8ba1\u5212\u7528\u8fd9\u4e2a\u6bd4\u8d5b\u7684\u6570\u636e Optiver Realized Volatility Prediction \uff0c\u5728\u53e6\u4e00\u7bc7\u66f4\u65b0\u3002 \uff08\u5df2\u66f4\u65b0\uff0c\u89c1 LightGBM \u5b9e\u6218\uff1a\u6ce2\u52a8\u7387\u9884\u6d4b(1) \uff09 Reference LightGBM \u8bba\u6587 \u6df1\u5165\u7406\u89e3LightGBM LightGBM \u6e90\u7801\u9605\u8bfb","title":"Light GBM \u539f\u7406"},{"location":"computer-science/lgbm/LightGBM/#light-gbm","text":"\u6211\u4eec\u5728 Boosting Trees \u4e2d\u4ecb\u7ecd\u4e86 Gradient Boosting Decision Tree (GBDT) \u7684\u539f\u7406\u3002Light GBM \u662f GBDT \u7684\u4e00\u4e2a\u884d\u751f\u65b9\u6cd5\u3002\u76f8\u6bd4\u5176\u4ed6\u7684\u884d\u751f\u65b9\u6cd5\uff08\u5982 XGBoost\uff09\uff0c\u5b83\u6700\u660e\u663e\u7684\u4f18\u52bf\u5c31\u662f\u8bad\u7ec3\u901f\u5ea6\u5feb\uff0c\u8fd9\u4e5f\u662f\u5b83\u88ab\u547d\u540d\u4e3a \"light\" \u7684\u539f\u56e0\u3002\u5b83\u5728\u4fdd\u6301\u8bad\u7ec3\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b\uff0c\u5c06\u4f20\u7edf GBDT \u7684\u8bad\u7ec3\u901f\u5ea6\u63d0\u9ad8\u4e86 20 \u500d\u3002","title":"Light GBM \u539f\u7406"},{"location":"computer-science/lgbm/LightGBM/#1","text":"LightGBM \u7684\u76ee\u7684\u662f\u7f29\u77ed\u8bad\u7ec3\u65f6\u95f4\uff0c\u800c\u8bad\u7ec3\u65f6\u95f4\u4e3b\u8981\u53d6\u51b3\u4e8e\u6837\u672c\u6570\u91cf\u548c\u7279\u5f81\u7ef4\u5ea6\u3002 \u5b83\u4f7f\u7528\u4e86\u4e09\u79cd\u91cd\u8981\u7684\u4f18\u5316\uff1a \uff08\u975e\u539f\u521b\uff09\u5728\u8bad\u7ec3\u6811\u7684\u65f6\u5019\uff0c\u4f7f\u7528\u76f4\u65b9\u56fe\u7b97\u6cd5\u6765\u5bfb\u627e\u6700\u4f73\u5212\u5206\u8282\u70b9 \uff08\u539f\u521b\uff09\u4f7f\u7528\u57fa\u4e8e\u68af\u5ea6\u7684\u5355\u8fb9\u91c7\u6837(GOSS)\u964d\u4f4e\u6837\u672c\u6570\u91cf \uff08\u539f\u521b\uff09\u4f7f\u7528\u4e92\u65a5\u7279\u5f81\u6346\u7ed1 (EFB)\u964d\u4f4e\u7279\u5f81\u7ef4\u5ea6","title":"1. \u8bba\u6587\u8981\u70b9"},{"location":"computer-science/lgbm/LightGBM/#11","text":"\u5728 GBDT \u7684\u8bad\u7ec3\u4e2d\uff0c\u6bcf\u6b21\u8fed\u4ee3\uff0c\u6211\u4eec\u90fd\u4f1a\u62df\u5408\u8d1f\u68af\u5ea6\u6765\u751f\u6210\u4e00\u4e2a\u51b3\u7b56\u6811\uff0c\u8fd9\u4e5f\u662f GBDT \u8bad\u7ec3\u4e2d\u6700\u8017\u65f6\u7684\u90e8\u5206\u3002\u5176\u4e2d\uff0c\u8ba1\u7b97\u91cf\u6700\u5927\u7684\u90e8\u5206\u5c31\u662f\u5bfb\u627e\u6700\u4f73\u5212\u5206\u8282\u70b9\u3002 \u6700\u7b80\u5355\u76f4\u63a5\u7684\u65b9\u6cd5\u5c31\u662f\u9884\u6392\u5e8f\u6cd5\u3002\u5373\uff0c\u5148\u5c06\u6240\u6709\u6837\u672c\u4ee5\u67d0\u4e2a\u7279\u5f81\u4e3a\u6bd4\u8f83\u5bf9\u8c61\u6392\u5e8f\uff0c\u518d\u4f9d\u6b21\u904d\u5386\u5bfb\u627e\u6700\u4f18\u5212\u5206\u70b9\u3002\u8fd9\u79cd\u867d\u7136\u80fd\u627e\u5230\u6700\u4f18\u70b9\uff0c \u4f46\u662f\u7f3a\u70b9\u5f88\u660e\u663e\uff1a \u6548\u7387\u4f4e\u4e0b\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u662f \\(O(\\#data \\times \\#feature)\\) \u5bf9\u566a\u58f0\u654f\u611f LightGBM \u9009\u62e9\u4e86\u76f4\u65b9\u56fe\u6cd5\u3002\u5373\uff0c\u5148\u5c06\u6570\u636e\u5212\u5206\u5230\u591a\u4e2a bin \u4e2d\uff0c\u7528 bin \u7684\u503c\u8986\u76d6\u539f\u59cb\u503c\u8fdb\u884c\u8bad\u7ec3\u3002\u5b83\u7684\u4f18\u52bf\u662f\uff1a \u5c06\u65f6\u95f4\u590d\u6742\u5ea6\u964d\u4f4e\u5230\u4e86 \\(O(\\#bin \\times \\#feature)\\) \u3002\u7531\u4e8e bin \u7684\u6570\u91cf\u80af\u5b9a\u8fdc\u5c0f\u4e8e\u6837\u672c\u7684\u6570\u91cf\uff0c\u56e0\u6b64\u4f18\u5316\u5f88\u660e\u663e \u4e0d\u9700\u8981\u5bf9\u6837\u672c\u6570\u636e\u8fdb\u884c\u6392\u5e8f \u589e\u5f3a\u4e86\u5bf9\u6570\u636e\u566a\u58f0\u7684\u9c81\u68d2\u6027 \u5f53\u7136\uff0c\u5b83\u4e5f\u6709\u7f3a\u70b9\uff0c\u4f46\u662f\u90fd\u53ef\u4ee5\u63a5\u53d7\uff1a \u627e\u5230\u7684\u5212\u5206\u70b9\u4e0d\u4e00\u5b9a\u662f\u6700\u4f18\u7684 \u7531\u4e8e\u76f8\u4f3c\u7684\u6570\u636e\u88ab\u5212\u5206\u5230\u4e86\u4e00\u4e2a bin \u4e2d\uff0c\u5ffd\u7565\u4e86\u4e00\u4e9b\u7ec6\u8282\u7279\u5f81 bin \u7684\u6570\u91cf\u9009\u62e9\u8fc7\u5c11\u53ef\u80fd\u5bfc\u81f4\u6b20\u62df\u5408 \u76f4\u65b9\u56fe\u7b97\u6cd5\u5e76\u4e0d\u662f LightGBM \u7684\u539f\u521b\uff1a Scikit-learn\u548cgbm in R\u6f14\u53d8\u7b97\u6cd5\u4f7f\u7528\u4e86pre-sorted algorithm\u7b97\u6cd5\uff0cpGBRT\u7b97\u6cd5\u662f\u4f7f\u7528\u4e86histogram-based algorithm\uff0c\u800cXGBoost\u4e24\u8005\u90fd\u652f\u6301","title":"1.1 \u76f4\u65b9\u56fe\u7b97\u6cd5"},{"location":"computer-science/lgbm/LightGBM/#12","text":"\u57fa\u4e8e\u68af\u5ea6\u7684\u5355\u8fb9\u91c7\u6837(Gradient-based One Side Sample, GOSS)\u662f LightGBM \u8bba\u6587\u4e2d\u63d0\u51fa\u7684\u4e00\u5927\u521b\u65b0\u70b9\uff0c\u7528\u4e8e\u51cf\u5c11\u8bad\u7ec3\u6837\u672c\uff0c\u4ece\u800c\u63d0\u9ad8\u6548\u7387\u3002 \u5728 AdaBoost \u4e2d\uff08\u89c1\u6211\u4e4b\u524d\u7684\u6587\u7ae0 ESL 10.1 Boosting Methods \uff09\uff0c\u6bcf\u4e2a\u6837\u672c\u90fd\u88ab\u8d4b\u4e88\u4e86\u6743\u91cd\uff0c\u56e0\u6b64\u53ef\u4ee5\u7b80\u5355\u5730\u4e22\u5f03\u6389\u6743\u91cd\u5c0f\u7684\u6837\u672c\u3002\u7136\u800c\uff0cGBDT \u4e2d\u7684\u6837\u672c\u5e76\u6ca1\u6709\u6743\u91cd\u8fd9\u4e00\u6982\u5ff5\u3002\u56e0\u6b64\uff0c\u6587\u4e2d\u63d0\u51fa\u4e86\u5229\u7528\u68af\u5ea6\u6765\u7b5b\u9009\u6837\u672c\u7684\u601d\u8def\u3002\u5982\u679c\u4e00\u4e2a\u6837\u672c\u7684\u68af\u5ea6\u8f83\u5c0f\uff0c\u8bf4\u660e\u5b83\u5df2\u7ecf\u662f\u5145\u5206\u8bad\u7ec3\u8fc7\u7684\u4e86\uff0c\u53ef\u4ee5\u4e22\u5f03\u3002 \u4f46\u662f\uff0c\u8fd9\u4e2a\u65b9\u6cd5\u7684\u95ee\u9898\u5728\u4e8e\u4e22\u5f03\u6837\u672c\u4f1a\u6539\u53d8\u6570\u636e\u7684\u5206\u5e03\uff0c\u5f71\u54cd\u6a21\u578b\u7cbe\u5ea6\u3002\u4e3a\u4e86\u907f\u514d\u8fd9\u4e2a\u95ee\u9898\uff0cLightGBM \u4fdd\u7559\u6240\u6709\u68af\u5ea6\u8f83\u5927\u7684\u6837\u672c\uff0c\u540c\u65f6\uff0c\u5bf9\u68af\u5ea6\u8f83\u5c0f\u7684\u6837\u672c\u8fdb\u884c__\u968f\u673a\u91c7\u6837__\uff0c\u56e0\u6b64\u79f0\u4e3a\u201c\u5355\u8fb9\u91c7\u6837\u201d\u3002 \u5176\u4e2d\u8f93\u5165\uff1a - \\(a\\) \u662f\u201c\u8f83\u5927\u68af\u5ea6\u6837\u672c\u201d\u7684\u6bd4\u4f8b\uff0ctop \\(a\\) \u7684\u6837\u672c\u90fd\u88ab\u5168\u90e8\u9009\u53d6 - \\(b\\) \u662f\u201c\u8f83\u5c0f\u68af\u5ea6\u6837\u672c\u201d\u91c7\u6837\u540e\u7684\u6bd4\u4f8b\uff08\u76f8\u5bf9\u4e8e\u6240\u6709\u6837\u672c\uff09 \u56e0\u6b64\u5fc5\u7136\u6709 \\(a + b < 1\\) \uff0c\u4e14 $ \\text{fact} = (1-a) / b > 1$\u3002 \u6838\u5fc3\u601d\u60f3\u662f\uff1a \u5c06\u6837\u672c\u68af\u5ea6\uff08\u6b8b\u5dee\uff09\u7531\u9ad8\u5230\u4f4e\u6392\u5e8f \u9009\u53d6\u524d \\(a * 100 \\%\\) \u7684\u6837\u672c\u4e3a\u96c6\u5408 A \u4ece\u540e \\((1-a) * 100 \\%\\) \u7684\u6837\u672c\u4e2d\u9009\u53d6 $ b * 100\\% $ \u7684\u6837\u672c\u4e3a\u96c6\u5408 B \u5c06\u88ab\u9009\u53d6\u7684\u6837\u672c\uff08A + B\uff09\u7528\u4e8e\u8bad\u7ec3 \u5728\u66f4\u65b0\u6a21\u578b\u65f6\uff0c\u9700\u8981\u5bf9\u96c6\u5408 B \u8fdb\u884c\u8865\u507f\uff0c\u4e58\u4ee5 \\((1-a)/b\\)","title":"1.2 \u57fa\u4e8e\u68af\u5ea6\u7684\u5355\u8fb9\u91c7\u6837"},{"location":"computer-science/lgbm/LightGBM/#13","text":"\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u7279\u5f81\u4e4b\u95f4\u6709\u65f6\u662f\u5b58\u5728\u4e92\u65a5\u5173\u7cfb\u7684\uff0c\u5373\uff0c\u4ed6\u4eec\u4e0d\u4f1a\u540c\u65f6\u6709\u503c\u3002\u6211\u4eec\u53ef\u4ee5\u5c06\u8fd9\u4e00\u7c7b\u7279\u5f81\u201c\u6346\u7ed1\u201d\u6210\u4e00\u4e2a\u7279\u5f81\u3002\u8fd9\u6837\u6211\u4eec\u53ef\u4ee5\u628a\u65f6\u95f4\u590d\u6742\u5ea6\u7531 \\(O(\\#data \\times \\#feature)\\) \u964d\u4f4e\u5230 \\(O(\\#data \\times \\#bundles)\\) \u3002\u4e3a\u4e86\u80fd\u6346\u7ed1\u66f4\u591a\u7684\u7279\u5f81\uff0cLightGBM \u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u201d\u51b2\u7a81\u7387\u201c \\(\\gamma\\) \uff0c\u5373\u4e24\u4e2a\u7279\u5f81\u540c\u65f6\u4e0d\u4e3a 0 \u7684\u6bd4\u4f8b\u3002\u6211\u4eec\u901a\u8fc7\u8c03\u8282 \\(\\gamma\\) \u6765\u4f7f\u90e8\u5206\u51e0\u4e4e\u4e92\u65a5\u7684\u7279\u5f81\u4e5f\u53ef\u4ee5\u6346\u7ed1\u6210\u4e00\u4e2a\u3002 \u90a3\u4e48\u6211\u4eec\u5c31\u9700\u8981\u5904\u7406\u4e24\u4e2a\u95ee\u9898\uff1a \u5982\u4f55\u627e\u5230\u4e92\u65a5\u7279\u5f81 \u5982\u4f55\u6346\u7ed1","title":"1.3 \u4e92\u65a5\u7279\u5f81\u6346\u7ed1"},{"location":"computer-science/lgbm/LightGBM/#131","text":"\u5bfb\u627e\u4e92\u65a5\u7279\u5f81\u7684\u95ee\u9898\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u56fe\u7740\u8272\u95ee\u9898\u3002\u5047\u8bbe\u628a\u6bcf\u4e2a\u7279\u5f81\u770b\u4f5c\u56fe\u7684\u4e00\u4e2a\u9876\u70b9\uff0c\u82e5\u4e24\u4e2a\u7279\u5f81\u4e92\u65a5\uff0c\u90a3\u4ed6\u4eec\u4e4b\u95f4\u6ca1\u6709\u8def\u5f84\u3002\u8fd9\u6837\u5c31\u53ef\u4ee5\u6784\u9020\u4e00\u4e2a\u65e0\u5411\u56fe\u3002\u56fe\u7740\u8272\u95ee\u9898\u5c31\u662f\u4f7f\u56fe\u7684\u76f8\u90bb\u9876\u70b9\u989c\u8272\u4e0d\u540c\uff0c\u5373\u975e\u4e92\u65a5\u7684\u7279\u5f81\u4e0d\u5728\u540c\u4e00\u4e2a bundle \u91cc\u3002 \u5177\u4f53\u6765\u8bf4\uff0c\u7b97\u6cd5\u4e3a\uff1a \u6784\u9020\u4e00\u4e2a\u6709\u6743\u91cd\u7684\u65e0\u5411\u56fe\uff0c\u4ee5\u7279\u5f81\u4e3a\u9876\u70b9\uff0c\u6bcf\u6761\u8fb9\u7684\u6743\u91cd\u662f\u7279\u5f81\u4e4b\u95f4\u7684\u51b2\u7a81\u7387 \\(\\gamma\\) \u3002 \u5c06\u7279\u5f81\u6309\u4ed6\u4eec\u7684\u5ea6\uff08degree\uff0c\u5373\u8fb9\u7684\u6570\u91cf\uff09\u964d\u5e8f\u6392\u5217 \u68c0\u67e5\u6bcf\u4e2a\u7279\u5f81\uff0c\u82e5 \\(\\gamma\\) \u5c0f\u4e8e\u9608\u503c\uff0c\u5219\u5c06\u5176\u52a0\u5165\u73b0\u6709\u7684 bundle\uff0c\u5426\u5219\u521b\u5efa\u4e00\u4e2a\u65b0\u7684 bundle\u3002 \u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(\\# feature^2)\\) \uff0c\u800c\u4e14\u53ea\u7528\u8fd0\u884c\u4e00\u6b21\uff0c\u5b8c\u5168\u53ef\u4ee5\u63a5\u53d7\u3002","title":"1.3.1 \u9009\u53d6\u4e92\u65a5\u7279\u5f81"},{"location":"computer-science/lgbm/LightGBM/#132","text":"\u6211\u4eec\u5728 1.3.1 \u4e2d\u5df2\u7ecf\u5c06\u7279\u5f81\u7ec4\u5408\u6210\u4e86\u591a\u4e2a bundle\uff0c\u73b0\u5728\u9700\u8981\u8003\u8651\u5982\u4f55\u5c06\u540c\u4e00\u4e2a bundle \u5185\u7684\u7279\u5f81\u5728\u4e0d\u4e22\u5931\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u8f6c\u4e3a\u4e00\u4e2a\u7279\u5f81\u3002 \u4e00\u4e2a\u7b80\u5355\u76f4\u63a5\u7684\u65b9\u6cd5\u5c31\u662f\u9644\u52a0\u4e00\u4e2a\u504f\u79fb\u91cf\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u5df2\u77e5 A \u7279\u5f81\u53d6\u503c\u8303\u56f4\u662f [0, 10)\uff0cB \u7279\u5f81\u53d6\u503c\u8303\u56f4\u662f [0, 20)\u3002\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u6784\u5efa\u4e00\u4e2a\u5408\u5e76\u7684\u7279\u5f81\uff0c\u53d6\u503c\u8303\u56f4\u662f [0, 30)\uff0c\u5bf9\u4e8e\u6240\u6709\u7684 B \u7279\u5f81\u9644\u52a0\u4e00\u4e2a\u504f\u79fb\u91cf 10\u3002\u8fd9\u6837\u5c31\u5c06 B \u7279\u5f81\u4ece [0,20) \u6620\u5c04\u5230\u4e86 [10, 30)\u3002\u8fd9\u4e2a\u5408\u5e76\u7684\u7279\u5f81\u5c06\u66ff\u4ee3 A \u548c B \u4e24\u4e2a\u7279\u5f81\u8fdb\u884c\u8bad\u7ec3\u3002 \u5047\u8bbe\u4e92\u65a5\u7279\u5f81\u7a7a\u95f4 F \u4e2d\u6709 n \u4e2a\u7279\u5f81 f\u3002\u7531\u4e8e\u6211\u4eec\u91c7\u7528\u7684\u662f bin\uff0c\u4e0d\u540c\u7279\u5f81 f \u53ef\u80fd\u6709\u4e0d\u540c\u6570\u91cf\u7684 bin\u3002\u4ed6\u4eec\u6346\u7ed1\u8fc7\u540e\u7684\u5408\u5e76\u7279\u5f81 bin \u7684\u4e2a\u6570\u5e94\u8be5\u7b49\u4e8e\u6240\u6709\u7279\u5f81 bin \u7684\u4e2a\u6570\u4e4b\u548c\u3002 \u5bf9\u4e8e\u6bcf\u4e2a\u6837\u672c\uff0c\u5047\u8bbe\u5b83\u539f\u5148\u5c5e\u4e8e\u7b2c j \u4e2a\u7279\u5f81\u7684\u7b2c i \u4e2a bin\uff0c\u5219\u878d\u5408\u540e\u5b83\u5e94\u8be5\u5c5e\u4e8e\u7b2c$\\sum_{k=0}^{j-1} # bin_k + i $ \u4e2a bin\u3002\u5373\u9644\u52a0\u524d j-1 \u4e2a\u7279\u5f81\u7684 bin \u6570\u91cf\u4e4b\u548c\u7684\u504f\u79fb\u3002","title":"1.3.2 \u6346\u7ed1\u4e92\u65a5\u7279\u5f81"},{"location":"computer-science/lgbm/LightGBM/#2","text":"\u8ba1\u5212\u7528\u8fd9\u4e2a\u6bd4\u8d5b\u7684\u6570\u636e Optiver Realized Volatility Prediction \uff0c\u5728\u53e6\u4e00\u7bc7\u66f4\u65b0\u3002 \uff08\u5df2\u66f4\u65b0\uff0c\u89c1 LightGBM \u5b9e\u6218\uff1a\u6ce2\u52a8\u7387\u9884\u6d4b(1) \uff09","title":"2. \u5b9e\u4f8b\u8bf4\u660e"},{"location":"computer-science/lgbm/LightGBM/#reference","text":"LightGBM \u8bba\u6587 \u6df1\u5165\u7406\u89e3LightGBM LightGBM \u6e90\u7801\u9605\u8bfb","title":"Reference"},{"location":"computer-science/memory/CPU_Caches/","text":"Memory3: CPU Caches \u8ba1\u7b97\u673a\u7684 RAM \u5206\u4e3a static RAM (SRAM) \u548c dynamic RAM (DRAM) \u4e24\u7c7b\u3002SRAM \u901f\u5ea6\u5feb\u4f46\u662f\u6210\u672c\u9ad8\u5bb9\u91cf\u5c0f\uff0cDRAM \u53cd\u4e4b\u3002\u4e3b\u8981\u539f\u56e0\u662f\u786c\u4ef6\u4e0a\uff0cSRAM \u8981\u590d\u6742\u8bb8\u591a\u3002 \u56e0\u6b64\uff0c\u73b0\u4ee3\u8ba1\u7b97\u673a\u4ec5\u5728 CPU cache \u4f7f\u7528 SRAM\uff0c\u5185\u5b58\u5219\u4f7f\u7528 DRAM\u3002\u8ba1\u7b97\u673a\u53ef\u4ee5\u901a\u8fc7\u5c06\u5185\u5b58\uff08\u6162\uff09\u4e2d\u7684\u6570\u636e\u7f13\u5b58\u5230 CPU cache\uff08\u5feb\uff09\u4e2d\u83b7\u53d6\u6781\u5927\u7684\u6027\u80fd\u63d0\u5347\u3002\u5176\u539f\u56e0\u4e3b\u8981\u662f\uff1a \u7a0b\u5e8f\u4f7f\u7528\u7684\u6307\u4ee4\u548c\u5185\u5b58\u5b58\u5728 \u7a7a\u95f4\u5c40\u90e8\u6027 (spatial locality) \u548c \u65f6\u95f4\u5c40\u90e8\u6027 (temporal locality)\u3002\u5177\u4f53\u662f\u6307\uff1a spatial locality: \u5185\u5b58\u4e0a\u5b58\u50a8\u4f4d\u7f6e\u63a5\u8fd1 temporal locality: \u88ab\u4f7f\u7528\u7684\u65f6\u95f4\u63a5\u8fd1 \u4f8b\u5b50\uff1a spatial locality temporal locality code \u5faa\u73af\u4e2d\u6267\u884c\u540c\u6837\u7684\u8bed\u53e5 \u5faa\u73af\u4e2d\u8c03\u7528\u51fd\u6570\uff08\u51fd\u6570\u5730\u5740\u4e0d\u63a5\u8fd1\uff0c\u4f46\u662f\u4f1a\u9ad8\u9891\u7387\u8c03\u7528\uff09 data \u4f7f\u7528\u6570\u7ec4 \u4f7f\u7528\u4e0d\u4e45\u524d\u4f7f\u7528\u8fc7\u7684\u6570\u636e 3.1 CPU Caches in the Big Picture \u9996\u5148\uff0c CPU \u4e0d\u76f4\u63a5\u4e0e\u5185\u5b58\u4ea4\u4e92\uff0c\u6240\u6709\u8bfb\u5199\u5fc5\u987b\u7ecf\u8fc7\u7f13\u5b58 \u3002\u73b0\u4ee3\u8ba1\u7b97\u673a\u7684\u7f13\u5b58\u67b6\u6784\u5982\u4e0b\uff1a \u53ef\u4ee5\u770b\u5230\uff0c\u8bfb\u5185\u5b58\u65f6\uff0c\u6570\u636e\u4ece\u5185\u5b58\u7ecf\u8fc7\u603b\u7ebf\u8fdb\u5165 CPU cache\u3002\u4f9d\u6b21\u5b58\u5165\u5404\u7ea7\u7f13\u5b58\uff0c\u4f9b CPU \u4f7f\u7528\u3002 \u6ce8\u610f\uff0c L1 Cache \u5206\u4e3a\u4e86\u6307\u4ee4\u7f13\u5b58 (L1i Cache) \u548c\u6570\u636e\u7f13\u5b58 (L1d Cache) \u3002\u8fd9\u6837\u8bbe\u8ba1\u7684\u539f\u56e0\u662f\u4e00\u822c\u60c5\u51b5\u4e0b\u6307\u4ee4\u548c\u6570\u636e\u662f\u4e0d\u76f8\u5173\u7684\u3002 \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u67e5\u770b\u7f13\u5b58\u5927\u5c0f\uff1a sysctl -a | grep -e 'hw.*cache' \u5f97\u5230\u7f13\u5b58\u4fe1\u606f\uff08Apple M1 Max\uff09\uff1a hw.cachelinesize: 128 hw.l1icachesize: 131072 hw.l1dcachesize: 65536 hw.l2cachesize: 4194304 \u5173\u952e\u4fe1\u606f\u662f\uff1a L1i Cache \u4e3a 128 kB L1d Cache \u4e3a 64 kB L2 Cache \u4e3a 4 MB cacheline \u662f CPU cache \u4e00\u6b21\u6027\u53ef\u4ee5\u52a0\u8f7d\u7684\u5185\u5b58\u5927\u5c0f\uff0c\u8fd9\u91cc\u662f 128 \u5b57\u8282\u3002 3.1.1 CPU Caches Sharing \u5728\u591a\u6838\u3001\u591a\u7ebf\u7a0b\uff08\u6307\u786c\u4ef6\u7ebf\u7a0b\uff0c\u5982 Intel \u7684\u8d85\u7ebf\u7a0b\uff09\u7684\u73b0\u4ee3 CPU \u67b6\u6784\u4e0b\uff0ccache \u7684\u5171\u4eab\u65b9\u5f0f\u4e3a\uff1a \u5373\uff1a \u6bcf\u4e2a\u6838\u62e5\u6709\u72ec\u7acb\u7684 L1 cache \u5982\u679c\u8fd9\u4e2a\u6838\u6709\u591a\u4e2a\u786c\u4ef6\u7ebf\u7a0b(e.g., Intel hyper-threading)\uff0c\u90a3\u4e48\u5b83\u4eec\u5171\u4eab L1 Cache\u3002 \u6240\u6709\u6838\u5171\u4eab L2 \u53ca\u4ee5\u4e0a\u7684 cache 3.2 Cache operation at high level \u4e3a\u4e86\u6548\u7387\uff0cCPU cache \u4e00\u6b21\u4f1a\u52a0\u8f7d cacheline \u5927\u5c0f\u7684\u5185\u5b58\u3002\u73b0\u5728\uff082022\uff09\u5e74\u7684\u666e\u901a CPU cacheline \u4e00\u822c\u662f 64 \u5b57\u8282\u6216\u8005 128 \u5b57\u8282\u3002 cacheline \u662f CPU cache \u8bfb\u5199\u7684\u6700\u5c0f\u5355\u4f4d \u3002 \u65e0\u8bba\u8bfb\u8fd8\u662f\u5199\uff0cCPU cache \u90fd\u9700\u8981\u5148\u52a0\u8f7d\u64cd\u4f5c\u7684\u5185\u5b58\u6240\u5728\u7684 cacheline \u3002\u6ce8\u610f\uff0c\u5199\u5165\u7684\u65f6\u5019\u4e5f\u662f\u8986\u76d6\u4e00\u6574\u6761 cacheline\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u5148\u52a0\u8f7d\u8fdb CPU cache \u518d\u505a\u4fee\u6539\uff0c\u5426\u5219\u5199\u5165\u7684\u65f6\u5019\uff0c\u9664\u4e86\u4fee\u6539\u7684\u5185\u5b58\uff0c\u6211\u4eec\u65e0\u6cd5\u77e5\u9053\u5176\u5b83\u5185\u5b58\u5e94\u8be5\u586b\u5199\u4ec0\u4e48\u503c\u3002 \u5f53 CPU \u66f4\u6539\u4e86 cache \u4e2d\u7684\u503c\uff0c\u4f46\u662f\u8fd8\u672a\u6765\u5f97\u53ca\u5199\u56de\u5185\u5b58\u65f6\uff0c\u8fd9\u4e2a cacheline \u88ab\u6807\u8bb0\u4e3a \"dirty\"\uff0c\u8fd9\u4e2a flag \u4f1a\u5728\u5199\u5165\u5185\u5b58\u540e\u6e05\u9664\u3002\u8fd9\u5728\u5355\u6838\u7684\u65f6\u5019\u975e\u5e38\u76f4\u89c2\uff0c\u4f46\u662f\u591a\u6838\u7684\u65f6\uff0c\u4e00\u4e2a\u6838\u5982\u4f55\u624d\u77e5\u9053\u4e00\u6bb5\u5185\u5b58\u662f\u4e0d\u662f \"dirty\" \u7684\uff0c\u4e5f\u5c31\u662f\u6b63\u5728\u88ab\u522b\u7684\u6838\u4fee\u6539\u5462\uff1f \u5bf9\u4e8e\u591a\u6838 CPU\uff0c \u6240\u6709\u5904\u7406\u5668\u89c2\u6d4b\u5230\u7684\u5185\u5b58\u5e94\u8be5\u662f\u4e00\u81f4\u7684(cache coherency) \u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e2a\u529f\u80fd\uff0c\u5904\u7406\u5668\u4f1a\u76d1\u542c\u5f7c\u6b64\u7684\u5199\u64cd\u4f5c\uff0c\u5e76\u4e14\u5c06\u5199\u5165\u7684\u5730\u5740\u4e0e\u81ea\u5df1\u7684 cache \u505a\u6bd4\u8f83\u3002\u5f53\u4fa6\u6d4b\u5230\u5199\u64cd\u4f5c\u65f6\uff0c\u4f1a\u5c06\u81ea\u5df1\u7684\u8fd9\u6bb5 cacheline \u6807\u8bb0\u4e3a\u5931\u6548\u3002\u4e00\u4e2a\u6700\u91cd\u8981\u7684\u7f13\u5b58\u4e00\u81f4\u6027\u534f\u8bae MESI \u53ef\u4ee5\u603b\u7ed3\u4e3a\uff1a \"dirty\" \u7684 cacheline \u4e0d\u4f1a\u51fa\u73b0\u5728\u9664\u4e86\u6267\u884c\u5199\u5165\u64cd\u4f5c\u7684\u5176\u5b83\u5904\u7406\u5668\u7684 cache \u4e2d\u3002 \"clean\" \u7684 cacheline \u53ef\u4ee5\u51fa\u73b0\u5728\u4efb\u610f\u591a\u4e2a cache \u4e2d\u3002 3.3 CPU Cache Implementation Details \u7565\u3002 3.3.3 Write Behavior \u6211\u4eec\u5df2\u7ecf\u63d0\u8fc7\uff0cCPU Cache \u9700\u8981\u4fdd\u8bc1\u4e00\u81f4\u6027\uff0c\u5e76\u4e14\u5176\u5b9e\u73b0\u5bf9\u4e8e\u7528\u6237\u662f\u900f\u660e\u7684\u3002\u5373\uff0c\u5982\u679c cacheline \u88ab\u66f4\u6539\u4e86\uff0c\u5728\u7528\u6237\u770b\u6765\u5e94\u8be5\u548c\u6ca1\u6709 CPU cache \u65f6\u4e00\u81f4\uff0c\u5373\u76f4\u63a5\u53cd\u6620\u5230\u4e86\u5185\u5b58\u4e0a\u3002 \u8981\u4fdd\u8bc1\u8fd9\u4e00\u70b9\uff0c\u6709\u4e24\u79cd\u5b9e\u73b0\u65b9\u6cd5\uff1a write-through write-back \u5728 write-through \u7684\u5b9e\u73b0\u4e2d\uff0c\u5982\u679c\u67d0\u4e2a cacheline \u88ab\u5199\u5165\u4e86\uff0c\u5904\u7406\u5668\u4f1a\u7acb\u5373\u5c06\u8fd9\u4e2a cacheline \u5199\u5230\u5185\u5b58\u3002\u8fd9\u6837\u7684\u5b9e\u73b0\u7b80\u5355\u4f46\u662f\u6bd4\u8f83\u6162\uff0c\u56e0\u4e3a CPU \u6bcf\u6b21\u66f4\u6539\u6570\u636e\u90fd\u4f1a\u8fdb\u884c\u5185\u5b58\u5199\u5165\u3002 write-back \u5b9e\u73b0\u6709\u66f4\u4f73\u7684\u6027\u80fd\u3002\u5f53 cacheline \u88ab\u4fee\u6539\u540e\uff0c\u5904\u7406\u5668\u4e0d\u9a6c\u4e0a\u5c06\u5176\u5199\u5165\u5185\u5b58\uff0c\u800c\u662f\u5c06\u5b83\u6807\u8bb0\u4e3a \"dirty\"\u3002\u5f53 cacheline \u4e0d\u518d\u4f7f\u7528\u65f6\uff0c\u5e26 \"dirty\" \u6807\u8bb0\u7684\u4f1a\u88ab\u5199\u56de\u5185\u5b58\u3002\u8fd9\u6837\u505a\u7684\u597d\u5904\u662f\u663e\u800c\u6613\u89c1\u7684\uff0c\u53ef\u4ee5\u907f\u514d\u603b\u7ebf\u901a\u4fe1\u548c\u5185\u5b58\u5199\u5165\u7684\u65f6\u95f4\u3002 \u4f46\u662f\uff0cwrite-back \u5b9e\u73b0\u5728\u591a\u6838 CPU \u4e0a\u5b58\u5728\u95ee\u9898\u3002\u5982\u679c\u4e00\u4e2a\u6838\u5c06\u67d0\u4e2a cacheline \u6807\u8bb0\u4e3a dirty\uff0c\u53e6\u4e00\u4e2a\u6838\u5c1d\u8bd5\u53bb\u8bfb\uff0c\u7531\u4e8e\u6700\u65b0\u7684\u66f4\u6539\u8fd8\u672a\u5199\u5165\u5230\u5185\u5b58\uff0c\u7b2c\u4e8c\u4e2a\u6838\u663e\u7136\u4e0d\u80fd\u76f4\u63a5\u53bb\u8bfb\u5185\u5b58\uff0c\u5426\u5219\u5c31\u7834\u574f\u4e86\u4e00\u81f4\u6027\u3002 3.3.4 Multi-Processor Support \u4e3a\u4e86\u89e3\u51b3 write-back \u5b9e\u73b0\u5728\u591a\u6838 CPU \u4e0a\u7684\u95ee\u9898\uff0c\u663e\u7136\uff0c\u8ba9\u4e00\u4e2a\u6838\u53bb\u76f4\u63a5\u8bbf\u95ee\u53e6\u4e00\u4e2a\u6838\u7684\u7f13\u5b58\u662f\u4e0d\u884c\u7684\u3002\u90a3\u4e48\uff0c\u53ea\u80fd\u5c06\u88ab\u6539\u52a8\u7684 cacheline \u62f7\u8d1d\u5230\u5176\u5b83\u6838\u7684\u7f13\u5b58\u4e2d\u3002\u6211\u4eec\u4e0d\u80fd\u7b80\u5355\u5728\u6bcf\u6b21\u5199\u5165\u540e\u90fd\u6267\u884c\u8fd9\u4e2a\u62f7\u8d1d\uff0c\u8fd9\u6837\u592a\u6162\u4e86\u3002\u4e8e\u662f\uff0c MESI(Modified, Exclusive, Shared, Invalid) \u7f13\u5b58\u4e00\u81f4\u6027\u534f\u8bae\u95ee\u4e16\u4e86\u3002 \u4e00\u5f00\u59cb\uff0c\u6240\u6709 cacheline \u90fd\u662f\u7a7a\u7684\uff0c\u5c5e\u4e8e Invalid \u72b6\u6001 \u56e0\u4e3a \u5199\u6570\u636e \u52a0\u8f7d\u7684 cacheline \u6807\u8bb0\u4e3a Modified \u56e0\u4e3a \u8bfb\u6570\u636e \u52a0\u8f7d\u7684 cacheline \u6709\u4e24\u79cd\u60c5\u51b5\uff1a \u5982\u679c \u5176\u5b83\u5904\u7406\u5668\u6ca1\u6709\u52a0\u8f7d \u8fd9\u4e2a cacheline\uff0c\u5219\u6807\u8bb0\u4e3a Exclusive \u5982\u679c \u5176\u5b83\u5904\u7406\u5668\u52a0\u8f7d\u4e86 \u8fd9\u4e2a cacheline\uff0c\u5219\u6807\u8bb0\u4e3a Shared \u8fd9\u91cc\u7684\u6bcf\u4e2a\u72b6\u6001\u90fd\u662f\u5bf9\u5f53\u524d\u5904\u7406\u5668\u800c\u8a00\u7684\u3002\u4f8b\u5982\uff0c Modified \u662f\u6307\u88ab\u5f53\u524d\u5904\u7406\u5668\u66f4\u6539\u8fc7\uff0c\u5982\u679c\u518d\u88ab\u5176\u5b83\u5904\u7406\u5668\u4fee\u6539\uff08remote write\uff09\uff0c\u5219\u53d8\u4e3a Invalid \u72b6\u6001\u3002 \u5f53\u5904\u7406\u5668\u5c1d\u8bd5\u5199\u5165\u72b6\u6001\u4e3a Shared \u6216\u8005 Invalid \u7684 cacheline \u65f6\uff0c\u5b83\u5fc5\u987b \u901a\u77e5\u6240\u6709\u5176\u5b83\u7684\u5904\u7406\u5668 \u5c06\u8fd9\u4e2a cacheline \u7684\u72b6\u6001\u8bbe\u7f6e\u4e3a Invalid \u3002\u8fd9\u4e2a\u64cd\u4f5c\u88ab\u79f0\u4e3a Request For Ownership(RFO) \u3002\u7531\u4e8e\u5b83\u975e\u5e38\u6602\u8d35\uff0c\u6211\u4eec\u9700\u8981\u6781\u529b\u907f\u514d\u5f15\u53d1 RFO \u7684\u64cd\u4f5c\u3002 \u5176\u72b6\u6001\u8f6c\u79fb\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4e00\u5171\u6709\u56db\u79cd\u64cd\u4f5c\uff0c\u603b\u7ed3\u5176\u5f71\u54cd\u5982\u4e0b\uff1a local read\uff0c\u4e0d\u53ef\u80fd\u5f15\u8d77 RFO local write\uff0c\u5982\u679c\u5199\u5165 Shared \u7684 cacheline\uff0c\u5f15\u8d77 RFO remote read by another processor\uff0c\u4e0d\u53ef\u80fd\u5f15\u8d77 RFO\uff0c\u4f46\u662f\u5bfc\u81f4 Exclusive \u53d8\u4e3a Shared remote write by another processor\uff0c\u5fc5\u7136\u5f15\u8d77 RFO \u56e0\u6b64\uff0cCPU \u603b\u662f\u5e0c\u671b\u5c3d\u53ef\u80fd\u591a\u7684 cacheline \u5904\u5728 Exclusive \u72b6\u6001\u3002\u56e0\u4e3a\u5728\u8be5\u72b6\u6001\u4e0b\u65e2\u53ef\u4ee5\u5229\u7528\u7f13\u5b58\u7684\u4f18\u52bf\uff0c\u53c8\u5bf9 local write \u6700\u4e3a\u53cb\u597d\u3002 Example \u73b0\u5728\u7528\u4e00\u4e2a\u4f8b\u5b50\u8bf4\u660e cacheline \u7684\u5f71\u54cd\u3002 \u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c\u6211\u4eec\u7528\u591a\u4e2a\u6838\u5e76\u884c\u66f4\u6539\u6570\u7ec4\u4e2d\u5143\u7d20\u7684\u503c\u3002\u7531\u4e8e\u4fdd\u8bc1\u4e86\u88ab\u66f4\u6539\u7684\u5143\u7d20\u4e0d\u662f\u540c\u4e00\u4e2a\uff0c\u4e0d\u5b58\u5728 data sharing \u4e5f\u4e0d\u5b58\u5728 race condition\u3002\u4f46\u662f\uff0c\u7531\u4e8e\u7f13\u5b58\u7684\u5f71\u54cd\uff08\u88ab\u4fee\u6539\u7684\u5143\u7d20\u53ef\u80fd\u5b58\u5728\u540c\u4e00\u4e2a cacheline\uff0c\u4e5f\u5c31\u662f\u7ecf\u5e38\u8bf4\u7684 false sharing\uff09\uff0c\u901f\u5ea6\u5b9e\u8d28\u4e0a\u4e5f\u6839\u636e\u9009\u62e9\u7684\u5143\u7d20\u4e0d\u540c\u800c\u4e0d\u540c\u3002 #include <chrono> #include <iostream> #include <thread> #include <vector> // a toy function to measure cache performance void func ( std :: vector < int > * counter , size_t index ) { for ( int i = 0 ; i < 1000000 ; ++ i ) { ( * counter )[ index ] += 1 ; } } auto run_in_parallel ( size_t thread_num , size_t offset ) { auto start = std :: chrono :: steady_clock :: now (); std :: vector < int > counter ( 1024 , 0 ); std :: vector < std :: thread > threads ; for ( size_t i = 0 ; i < thread_num ; ++ i ) { threads . emplace_back ( func , & counter , i * offset ); } for ( auto & t : threads ) { t . join (); } auto end = std :: chrono :: steady_clock :: now (); return std :: chrono :: duration_cast < std :: chrono :: microseconds > ( end - start ); } int main ( int argc , char const * argv []) { std :: cout << \"hardware_destructive_interference_size == \" << std :: hardware_destructive_interference_size << '\\n' << \"hardware_constructive_interference_size == \" << std :: hardware_constructive_interference_size << \" \\n \" ; size_t thread_num = 8 ; auto offset1 = std :: hardware_constructive_interference_size / sizeof ( int ); for ( size_t offset = 1 ; offset < offset1 ; offset *= 2 ) { auto elapsed_us = run_in_parallel ( thread_num , offset ). count (); std :: cout << \"Time elapsed: \" << elapsed_us << \"us for offset \" << offset << \" \\n \" ; } auto offset2 = std :: hardware_destructive_interference_size / sizeof ( int ); for ( size_t offset = offset1 ; offset <= offset2 + offset1 ; offset += offset1 ) { auto elapsed_us = run_in_parallel ( thread_num , offset ). count (); std :: cout << \"Time elapsed: \" << elapsed_us << \"us for offset \" << offset << \" \\n \" ; } return 0 ; } \u8fd9\u4e2a\u4f8b\u5b50\u7684\u8fd0\u884c\u7ed3\u679c\u662f\uff1a hardware_destructive_interference_size == 256 hardware_constructive_interference_size == 64 Time elapsed: 53215us for offset 1 Time elapsed: 33159us for offset 2 Time elapsed: 16543us for offset 4 Time elapsed: 11989us for offset 8 Time elapsed: 7003us for offset 16 Time elapsed: 6842us for offset 32 Time elapsed: 6059us for offset 48 Time elapsed: 6184us for offset 64 Time elapsed: 6113us for offset 80 \u53ef\u4ee5\u770b\u5230\uff0c\u5f53\u5e76\u884c\u4fee\u6539\u7684\u6570\u636e\u95f4\u9694\u5728 64 \u5b57\u8282\u4ee5\u4e0b\u65f6\uff0c\u901f\u5ea6\u660e\u663e\u6162\u4e86\u4e0d\u5c11\u3002\u7ed3\u5408\u4e4b\u524d\u7684 MESI \u534f\u8bae\uff0c\u8fd9\u662f\u7531\u4e8e\u4fee\u6539\u5904\u4e8e Shared \u72b6\u6001\u7684 cacheline \u5bfc\u81f4\u9891\u7e41 RFO \u7684\u5f71\u54cd\u3002","title":"Memory3: CPU Caches"},{"location":"computer-science/memory/CPU_Caches/#memory3-cpu-caches","text":"\u8ba1\u7b97\u673a\u7684 RAM \u5206\u4e3a static RAM (SRAM) \u548c dynamic RAM (DRAM) \u4e24\u7c7b\u3002SRAM \u901f\u5ea6\u5feb\u4f46\u662f\u6210\u672c\u9ad8\u5bb9\u91cf\u5c0f\uff0cDRAM \u53cd\u4e4b\u3002\u4e3b\u8981\u539f\u56e0\u662f\u786c\u4ef6\u4e0a\uff0cSRAM \u8981\u590d\u6742\u8bb8\u591a\u3002 \u56e0\u6b64\uff0c\u73b0\u4ee3\u8ba1\u7b97\u673a\u4ec5\u5728 CPU cache \u4f7f\u7528 SRAM\uff0c\u5185\u5b58\u5219\u4f7f\u7528 DRAM\u3002\u8ba1\u7b97\u673a\u53ef\u4ee5\u901a\u8fc7\u5c06\u5185\u5b58\uff08\u6162\uff09\u4e2d\u7684\u6570\u636e\u7f13\u5b58\u5230 CPU cache\uff08\u5feb\uff09\u4e2d\u83b7\u53d6\u6781\u5927\u7684\u6027\u80fd\u63d0\u5347\u3002\u5176\u539f\u56e0\u4e3b\u8981\u662f\uff1a \u7a0b\u5e8f\u4f7f\u7528\u7684\u6307\u4ee4\u548c\u5185\u5b58\u5b58\u5728 \u7a7a\u95f4\u5c40\u90e8\u6027 (spatial locality) \u548c \u65f6\u95f4\u5c40\u90e8\u6027 (temporal locality)\u3002\u5177\u4f53\u662f\u6307\uff1a spatial locality: \u5185\u5b58\u4e0a\u5b58\u50a8\u4f4d\u7f6e\u63a5\u8fd1 temporal locality: \u88ab\u4f7f\u7528\u7684\u65f6\u95f4\u63a5\u8fd1 \u4f8b\u5b50\uff1a spatial locality temporal locality code \u5faa\u73af\u4e2d\u6267\u884c\u540c\u6837\u7684\u8bed\u53e5 \u5faa\u73af\u4e2d\u8c03\u7528\u51fd\u6570\uff08\u51fd\u6570\u5730\u5740\u4e0d\u63a5\u8fd1\uff0c\u4f46\u662f\u4f1a\u9ad8\u9891\u7387\u8c03\u7528\uff09 data \u4f7f\u7528\u6570\u7ec4 \u4f7f\u7528\u4e0d\u4e45\u524d\u4f7f\u7528\u8fc7\u7684\u6570\u636e","title":"Memory3: CPU Caches"},{"location":"computer-science/memory/CPU_Caches/#31-cpu-caches-in-the-big-picture","text":"\u9996\u5148\uff0c CPU \u4e0d\u76f4\u63a5\u4e0e\u5185\u5b58\u4ea4\u4e92\uff0c\u6240\u6709\u8bfb\u5199\u5fc5\u987b\u7ecf\u8fc7\u7f13\u5b58 \u3002\u73b0\u4ee3\u8ba1\u7b97\u673a\u7684\u7f13\u5b58\u67b6\u6784\u5982\u4e0b\uff1a \u53ef\u4ee5\u770b\u5230\uff0c\u8bfb\u5185\u5b58\u65f6\uff0c\u6570\u636e\u4ece\u5185\u5b58\u7ecf\u8fc7\u603b\u7ebf\u8fdb\u5165 CPU cache\u3002\u4f9d\u6b21\u5b58\u5165\u5404\u7ea7\u7f13\u5b58\uff0c\u4f9b CPU \u4f7f\u7528\u3002 \u6ce8\u610f\uff0c L1 Cache \u5206\u4e3a\u4e86\u6307\u4ee4\u7f13\u5b58 (L1i Cache) \u548c\u6570\u636e\u7f13\u5b58 (L1d Cache) \u3002\u8fd9\u6837\u8bbe\u8ba1\u7684\u539f\u56e0\u662f\u4e00\u822c\u60c5\u51b5\u4e0b\u6307\u4ee4\u548c\u6570\u636e\u662f\u4e0d\u76f8\u5173\u7684\u3002 \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u67e5\u770b\u7f13\u5b58\u5927\u5c0f\uff1a sysctl -a | grep -e 'hw.*cache' \u5f97\u5230\u7f13\u5b58\u4fe1\u606f\uff08Apple M1 Max\uff09\uff1a hw.cachelinesize: 128 hw.l1icachesize: 131072 hw.l1dcachesize: 65536 hw.l2cachesize: 4194304 \u5173\u952e\u4fe1\u606f\u662f\uff1a L1i Cache \u4e3a 128 kB L1d Cache \u4e3a 64 kB L2 Cache \u4e3a 4 MB cacheline \u662f CPU cache \u4e00\u6b21\u6027\u53ef\u4ee5\u52a0\u8f7d\u7684\u5185\u5b58\u5927\u5c0f\uff0c\u8fd9\u91cc\u662f 128 \u5b57\u8282\u3002","title":"3.1 CPU Caches in the Big Picture"},{"location":"computer-science/memory/CPU_Caches/#311-cpu-caches-sharing","text":"\u5728\u591a\u6838\u3001\u591a\u7ebf\u7a0b\uff08\u6307\u786c\u4ef6\u7ebf\u7a0b\uff0c\u5982 Intel \u7684\u8d85\u7ebf\u7a0b\uff09\u7684\u73b0\u4ee3 CPU \u67b6\u6784\u4e0b\uff0ccache \u7684\u5171\u4eab\u65b9\u5f0f\u4e3a\uff1a \u5373\uff1a \u6bcf\u4e2a\u6838\u62e5\u6709\u72ec\u7acb\u7684 L1 cache \u5982\u679c\u8fd9\u4e2a\u6838\u6709\u591a\u4e2a\u786c\u4ef6\u7ebf\u7a0b(e.g., Intel hyper-threading)\uff0c\u90a3\u4e48\u5b83\u4eec\u5171\u4eab L1 Cache\u3002 \u6240\u6709\u6838\u5171\u4eab L2 \u53ca\u4ee5\u4e0a\u7684 cache","title":"3.1.1 CPU Caches Sharing"},{"location":"computer-science/memory/CPU_Caches/#32-cache-operation-at-high-level","text":"\u4e3a\u4e86\u6548\u7387\uff0cCPU cache \u4e00\u6b21\u4f1a\u52a0\u8f7d cacheline \u5927\u5c0f\u7684\u5185\u5b58\u3002\u73b0\u5728\uff082022\uff09\u5e74\u7684\u666e\u901a CPU cacheline \u4e00\u822c\u662f 64 \u5b57\u8282\u6216\u8005 128 \u5b57\u8282\u3002 cacheline \u662f CPU cache \u8bfb\u5199\u7684\u6700\u5c0f\u5355\u4f4d \u3002 \u65e0\u8bba\u8bfb\u8fd8\u662f\u5199\uff0cCPU cache \u90fd\u9700\u8981\u5148\u52a0\u8f7d\u64cd\u4f5c\u7684\u5185\u5b58\u6240\u5728\u7684 cacheline \u3002\u6ce8\u610f\uff0c\u5199\u5165\u7684\u65f6\u5019\u4e5f\u662f\u8986\u76d6\u4e00\u6574\u6761 cacheline\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u5148\u52a0\u8f7d\u8fdb CPU cache \u518d\u505a\u4fee\u6539\uff0c\u5426\u5219\u5199\u5165\u7684\u65f6\u5019\uff0c\u9664\u4e86\u4fee\u6539\u7684\u5185\u5b58\uff0c\u6211\u4eec\u65e0\u6cd5\u77e5\u9053\u5176\u5b83\u5185\u5b58\u5e94\u8be5\u586b\u5199\u4ec0\u4e48\u503c\u3002 \u5f53 CPU \u66f4\u6539\u4e86 cache \u4e2d\u7684\u503c\uff0c\u4f46\u662f\u8fd8\u672a\u6765\u5f97\u53ca\u5199\u56de\u5185\u5b58\u65f6\uff0c\u8fd9\u4e2a cacheline \u88ab\u6807\u8bb0\u4e3a \"dirty\"\uff0c\u8fd9\u4e2a flag \u4f1a\u5728\u5199\u5165\u5185\u5b58\u540e\u6e05\u9664\u3002\u8fd9\u5728\u5355\u6838\u7684\u65f6\u5019\u975e\u5e38\u76f4\u89c2\uff0c\u4f46\u662f\u591a\u6838\u7684\u65f6\uff0c\u4e00\u4e2a\u6838\u5982\u4f55\u624d\u77e5\u9053\u4e00\u6bb5\u5185\u5b58\u662f\u4e0d\u662f \"dirty\" \u7684\uff0c\u4e5f\u5c31\u662f\u6b63\u5728\u88ab\u522b\u7684\u6838\u4fee\u6539\u5462\uff1f \u5bf9\u4e8e\u591a\u6838 CPU\uff0c \u6240\u6709\u5904\u7406\u5668\u89c2\u6d4b\u5230\u7684\u5185\u5b58\u5e94\u8be5\u662f\u4e00\u81f4\u7684(cache coherency) \u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e2a\u529f\u80fd\uff0c\u5904\u7406\u5668\u4f1a\u76d1\u542c\u5f7c\u6b64\u7684\u5199\u64cd\u4f5c\uff0c\u5e76\u4e14\u5c06\u5199\u5165\u7684\u5730\u5740\u4e0e\u81ea\u5df1\u7684 cache \u505a\u6bd4\u8f83\u3002\u5f53\u4fa6\u6d4b\u5230\u5199\u64cd\u4f5c\u65f6\uff0c\u4f1a\u5c06\u81ea\u5df1\u7684\u8fd9\u6bb5 cacheline \u6807\u8bb0\u4e3a\u5931\u6548\u3002\u4e00\u4e2a\u6700\u91cd\u8981\u7684\u7f13\u5b58\u4e00\u81f4\u6027\u534f\u8bae MESI \u53ef\u4ee5\u603b\u7ed3\u4e3a\uff1a \"dirty\" \u7684 cacheline \u4e0d\u4f1a\u51fa\u73b0\u5728\u9664\u4e86\u6267\u884c\u5199\u5165\u64cd\u4f5c\u7684\u5176\u5b83\u5904\u7406\u5668\u7684 cache \u4e2d\u3002 \"clean\" \u7684 cacheline \u53ef\u4ee5\u51fa\u73b0\u5728\u4efb\u610f\u591a\u4e2a cache \u4e2d\u3002","title":"3.2 Cache operation at high level"},{"location":"computer-science/memory/CPU_Caches/#33-cpu-cache-implementation-details","text":"\u7565\u3002","title":"3.3 CPU Cache Implementation Details"},{"location":"computer-science/memory/CPU_Caches/#333-write-behavior","text":"\u6211\u4eec\u5df2\u7ecf\u63d0\u8fc7\uff0cCPU Cache \u9700\u8981\u4fdd\u8bc1\u4e00\u81f4\u6027\uff0c\u5e76\u4e14\u5176\u5b9e\u73b0\u5bf9\u4e8e\u7528\u6237\u662f\u900f\u660e\u7684\u3002\u5373\uff0c\u5982\u679c cacheline \u88ab\u66f4\u6539\u4e86\uff0c\u5728\u7528\u6237\u770b\u6765\u5e94\u8be5\u548c\u6ca1\u6709 CPU cache \u65f6\u4e00\u81f4\uff0c\u5373\u76f4\u63a5\u53cd\u6620\u5230\u4e86\u5185\u5b58\u4e0a\u3002 \u8981\u4fdd\u8bc1\u8fd9\u4e00\u70b9\uff0c\u6709\u4e24\u79cd\u5b9e\u73b0\u65b9\u6cd5\uff1a write-through write-back \u5728 write-through \u7684\u5b9e\u73b0\u4e2d\uff0c\u5982\u679c\u67d0\u4e2a cacheline \u88ab\u5199\u5165\u4e86\uff0c\u5904\u7406\u5668\u4f1a\u7acb\u5373\u5c06\u8fd9\u4e2a cacheline \u5199\u5230\u5185\u5b58\u3002\u8fd9\u6837\u7684\u5b9e\u73b0\u7b80\u5355\u4f46\u662f\u6bd4\u8f83\u6162\uff0c\u56e0\u4e3a CPU \u6bcf\u6b21\u66f4\u6539\u6570\u636e\u90fd\u4f1a\u8fdb\u884c\u5185\u5b58\u5199\u5165\u3002 write-back \u5b9e\u73b0\u6709\u66f4\u4f73\u7684\u6027\u80fd\u3002\u5f53 cacheline \u88ab\u4fee\u6539\u540e\uff0c\u5904\u7406\u5668\u4e0d\u9a6c\u4e0a\u5c06\u5176\u5199\u5165\u5185\u5b58\uff0c\u800c\u662f\u5c06\u5b83\u6807\u8bb0\u4e3a \"dirty\"\u3002\u5f53 cacheline \u4e0d\u518d\u4f7f\u7528\u65f6\uff0c\u5e26 \"dirty\" \u6807\u8bb0\u7684\u4f1a\u88ab\u5199\u56de\u5185\u5b58\u3002\u8fd9\u6837\u505a\u7684\u597d\u5904\u662f\u663e\u800c\u6613\u89c1\u7684\uff0c\u53ef\u4ee5\u907f\u514d\u603b\u7ebf\u901a\u4fe1\u548c\u5185\u5b58\u5199\u5165\u7684\u65f6\u95f4\u3002 \u4f46\u662f\uff0cwrite-back \u5b9e\u73b0\u5728\u591a\u6838 CPU \u4e0a\u5b58\u5728\u95ee\u9898\u3002\u5982\u679c\u4e00\u4e2a\u6838\u5c06\u67d0\u4e2a cacheline \u6807\u8bb0\u4e3a dirty\uff0c\u53e6\u4e00\u4e2a\u6838\u5c1d\u8bd5\u53bb\u8bfb\uff0c\u7531\u4e8e\u6700\u65b0\u7684\u66f4\u6539\u8fd8\u672a\u5199\u5165\u5230\u5185\u5b58\uff0c\u7b2c\u4e8c\u4e2a\u6838\u663e\u7136\u4e0d\u80fd\u76f4\u63a5\u53bb\u8bfb\u5185\u5b58\uff0c\u5426\u5219\u5c31\u7834\u574f\u4e86\u4e00\u81f4\u6027\u3002","title":"3.3.3 Write Behavior"},{"location":"computer-science/memory/CPU_Caches/#334-multi-processor-support","text":"\u4e3a\u4e86\u89e3\u51b3 write-back \u5b9e\u73b0\u5728\u591a\u6838 CPU \u4e0a\u7684\u95ee\u9898\uff0c\u663e\u7136\uff0c\u8ba9\u4e00\u4e2a\u6838\u53bb\u76f4\u63a5\u8bbf\u95ee\u53e6\u4e00\u4e2a\u6838\u7684\u7f13\u5b58\u662f\u4e0d\u884c\u7684\u3002\u90a3\u4e48\uff0c\u53ea\u80fd\u5c06\u88ab\u6539\u52a8\u7684 cacheline \u62f7\u8d1d\u5230\u5176\u5b83\u6838\u7684\u7f13\u5b58\u4e2d\u3002\u6211\u4eec\u4e0d\u80fd\u7b80\u5355\u5728\u6bcf\u6b21\u5199\u5165\u540e\u90fd\u6267\u884c\u8fd9\u4e2a\u62f7\u8d1d\uff0c\u8fd9\u6837\u592a\u6162\u4e86\u3002\u4e8e\u662f\uff0c MESI(Modified, Exclusive, Shared, Invalid) \u7f13\u5b58\u4e00\u81f4\u6027\u534f\u8bae\u95ee\u4e16\u4e86\u3002 \u4e00\u5f00\u59cb\uff0c\u6240\u6709 cacheline \u90fd\u662f\u7a7a\u7684\uff0c\u5c5e\u4e8e Invalid \u72b6\u6001 \u56e0\u4e3a \u5199\u6570\u636e \u52a0\u8f7d\u7684 cacheline \u6807\u8bb0\u4e3a Modified \u56e0\u4e3a \u8bfb\u6570\u636e \u52a0\u8f7d\u7684 cacheline \u6709\u4e24\u79cd\u60c5\u51b5\uff1a \u5982\u679c \u5176\u5b83\u5904\u7406\u5668\u6ca1\u6709\u52a0\u8f7d \u8fd9\u4e2a cacheline\uff0c\u5219\u6807\u8bb0\u4e3a Exclusive \u5982\u679c \u5176\u5b83\u5904\u7406\u5668\u52a0\u8f7d\u4e86 \u8fd9\u4e2a cacheline\uff0c\u5219\u6807\u8bb0\u4e3a Shared \u8fd9\u91cc\u7684\u6bcf\u4e2a\u72b6\u6001\u90fd\u662f\u5bf9\u5f53\u524d\u5904\u7406\u5668\u800c\u8a00\u7684\u3002\u4f8b\u5982\uff0c Modified \u662f\u6307\u88ab\u5f53\u524d\u5904\u7406\u5668\u66f4\u6539\u8fc7\uff0c\u5982\u679c\u518d\u88ab\u5176\u5b83\u5904\u7406\u5668\u4fee\u6539\uff08remote write\uff09\uff0c\u5219\u53d8\u4e3a Invalid \u72b6\u6001\u3002 \u5f53\u5904\u7406\u5668\u5c1d\u8bd5\u5199\u5165\u72b6\u6001\u4e3a Shared \u6216\u8005 Invalid \u7684 cacheline \u65f6\uff0c\u5b83\u5fc5\u987b \u901a\u77e5\u6240\u6709\u5176\u5b83\u7684\u5904\u7406\u5668 \u5c06\u8fd9\u4e2a cacheline \u7684\u72b6\u6001\u8bbe\u7f6e\u4e3a Invalid \u3002\u8fd9\u4e2a\u64cd\u4f5c\u88ab\u79f0\u4e3a Request For Ownership(RFO) \u3002\u7531\u4e8e\u5b83\u975e\u5e38\u6602\u8d35\uff0c\u6211\u4eec\u9700\u8981\u6781\u529b\u907f\u514d\u5f15\u53d1 RFO \u7684\u64cd\u4f5c\u3002 \u5176\u72b6\u6001\u8f6c\u79fb\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4e00\u5171\u6709\u56db\u79cd\u64cd\u4f5c\uff0c\u603b\u7ed3\u5176\u5f71\u54cd\u5982\u4e0b\uff1a local read\uff0c\u4e0d\u53ef\u80fd\u5f15\u8d77 RFO local write\uff0c\u5982\u679c\u5199\u5165 Shared \u7684 cacheline\uff0c\u5f15\u8d77 RFO remote read by another processor\uff0c\u4e0d\u53ef\u80fd\u5f15\u8d77 RFO\uff0c\u4f46\u662f\u5bfc\u81f4 Exclusive \u53d8\u4e3a Shared remote write by another processor\uff0c\u5fc5\u7136\u5f15\u8d77 RFO \u56e0\u6b64\uff0cCPU \u603b\u662f\u5e0c\u671b\u5c3d\u53ef\u80fd\u591a\u7684 cacheline \u5904\u5728 Exclusive \u72b6\u6001\u3002\u56e0\u4e3a\u5728\u8be5\u72b6\u6001\u4e0b\u65e2\u53ef\u4ee5\u5229\u7528\u7f13\u5b58\u7684\u4f18\u52bf\uff0c\u53c8\u5bf9 local write \u6700\u4e3a\u53cb\u597d\u3002","title":"3.3.4 Multi-Processor Support"},{"location":"computer-science/memory/CPU_Caches/#example","text":"\u73b0\u5728\u7528\u4e00\u4e2a\u4f8b\u5b50\u8bf4\u660e cacheline \u7684\u5f71\u54cd\u3002 \u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c\u6211\u4eec\u7528\u591a\u4e2a\u6838\u5e76\u884c\u66f4\u6539\u6570\u7ec4\u4e2d\u5143\u7d20\u7684\u503c\u3002\u7531\u4e8e\u4fdd\u8bc1\u4e86\u88ab\u66f4\u6539\u7684\u5143\u7d20\u4e0d\u662f\u540c\u4e00\u4e2a\uff0c\u4e0d\u5b58\u5728 data sharing \u4e5f\u4e0d\u5b58\u5728 race condition\u3002\u4f46\u662f\uff0c\u7531\u4e8e\u7f13\u5b58\u7684\u5f71\u54cd\uff08\u88ab\u4fee\u6539\u7684\u5143\u7d20\u53ef\u80fd\u5b58\u5728\u540c\u4e00\u4e2a cacheline\uff0c\u4e5f\u5c31\u662f\u7ecf\u5e38\u8bf4\u7684 false sharing\uff09\uff0c\u901f\u5ea6\u5b9e\u8d28\u4e0a\u4e5f\u6839\u636e\u9009\u62e9\u7684\u5143\u7d20\u4e0d\u540c\u800c\u4e0d\u540c\u3002 #include <chrono> #include <iostream> #include <thread> #include <vector> // a toy function to measure cache performance void func ( std :: vector < int > * counter , size_t index ) { for ( int i = 0 ; i < 1000000 ; ++ i ) { ( * counter )[ index ] += 1 ; } } auto run_in_parallel ( size_t thread_num , size_t offset ) { auto start = std :: chrono :: steady_clock :: now (); std :: vector < int > counter ( 1024 , 0 ); std :: vector < std :: thread > threads ; for ( size_t i = 0 ; i < thread_num ; ++ i ) { threads . emplace_back ( func , & counter , i * offset ); } for ( auto & t : threads ) { t . join (); } auto end = std :: chrono :: steady_clock :: now (); return std :: chrono :: duration_cast < std :: chrono :: microseconds > ( end - start ); } int main ( int argc , char const * argv []) { std :: cout << \"hardware_destructive_interference_size == \" << std :: hardware_destructive_interference_size << '\\n' << \"hardware_constructive_interference_size == \" << std :: hardware_constructive_interference_size << \" \\n \" ; size_t thread_num = 8 ; auto offset1 = std :: hardware_constructive_interference_size / sizeof ( int ); for ( size_t offset = 1 ; offset < offset1 ; offset *= 2 ) { auto elapsed_us = run_in_parallel ( thread_num , offset ). count (); std :: cout << \"Time elapsed: \" << elapsed_us << \"us for offset \" << offset << \" \\n \" ; } auto offset2 = std :: hardware_destructive_interference_size / sizeof ( int ); for ( size_t offset = offset1 ; offset <= offset2 + offset1 ; offset += offset1 ) { auto elapsed_us = run_in_parallel ( thread_num , offset ). count (); std :: cout << \"Time elapsed: \" << elapsed_us << \"us for offset \" << offset << \" \\n \" ; } return 0 ; } \u8fd9\u4e2a\u4f8b\u5b50\u7684\u8fd0\u884c\u7ed3\u679c\u662f\uff1a hardware_destructive_interference_size == 256 hardware_constructive_interference_size == 64 Time elapsed: 53215us for offset 1 Time elapsed: 33159us for offset 2 Time elapsed: 16543us for offset 4 Time elapsed: 11989us for offset 8 Time elapsed: 7003us for offset 16 Time elapsed: 6842us for offset 32 Time elapsed: 6059us for offset 48 Time elapsed: 6184us for offset 64 Time elapsed: 6113us for offset 80 \u53ef\u4ee5\u770b\u5230\uff0c\u5f53\u5e76\u884c\u4fee\u6539\u7684\u6570\u636e\u95f4\u9694\u5728 64 \u5b57\u8282\u4ee5\u4e0b\u65f6\uff0c\u901f\u5ea6\u660e\u663e\u6162\u4e86\u4e0d\u5c11\u3002\u7ed3\u5408\u4e4b\u524d\u7684 MESI \u534f\u8bae\uff0c\u8fd9\u662f\u7531\u4e8e\u4fee\u6539\u5904\u4e8e Shared \u72b6\u6001\u7684 cacheline \u5bfc\u81f4\u9891\u7e41 RFO \u7684\u5f71\u54cd\u3002","title":"Example"},{"location":"mathematics/CFR/CfrAndKuhnPoker/","text":"Counterfactual Regret Minimization and Kuhn Poker \u5728\u4e0a\u4e00\u7bc7\u6587\u7ae0 Regret Matching and Blotto Game \u4e2d\uff0c\u6211\u4eec\u7528 regret matching \u65b9\u6cd5\u6765\u627e\u535a\u5f08\u7684\u7eb3\u4ec0\u5747\u8861\u70b9\u3002 regret matching \u65b9\u6cd5\u7684\u5c40\u9650\u6027\u5728\u4e8e\uff0c\u5b83\u53ea\u9002\u7528\u4e8e\u80fd\u7528\u77e9\u9635\u8868\u793a\u7684\u535a\u5f08\uff0c\u5373\u6bcf\u4e2a\u73a9\u5bb6\u540c\u65f6\u91c7\u53d6\u884c\u52a8\u7684\u535a\u5f08\uff0c\u4f8b\u5982\u526a\u5200\u77f3\u5934\u5e03\u3001blotto game\u3002 1 Kuhn Poker \u8fd8\u6709\u4e00\u79cd\u535a\u5f08\u53eb\u505a\u201d\u8fde\u7eed\u535a\u5f08\u201c(sequential game)\uff0c\u5373\u73a9\u5bb6\u7684\u52a8\u4f5c\u5e76\u4e0d\u540c\u65f6\u53d1\u751f\uff0c\u800c\u662f\u4f9d\u6b21\u53d1\u751f\u7684\uff0c\u4f8b\u5982\u5fb7\u5dde\u6251\u514b\u3002\u5b83\u6709\u4e2a\u7b80\u5316\u7248\u672c Kuhn Poker\uff0c\u6211\u4eec\u5c06\u7528\u5b83\u4f5c\u4e3a\u4f8b\u5b50\u5b9e\u73b0 Counterfactual Regret Minimization\u3002 Kuhn Poker is a simple 3-card poker game by Harold E. Kuhn [8]. Two players each ante 1 chip, i.e. bet 1 chip blind into the pot before the deal. Three cards, marked with numbers 1, 2, and 3, are shuffled, and one card is dealt to each player and held as private information. Play alternates starting with player 1. On a turn, a player may either pass or bet. A player that bets places an additional chip into the pot. When a player passes after a bet, the opponent takes all chips in the pot. When there are two successive passes or two successive bets, both players reveal their cards, and the player with the higher card takes all chips in the pot. Kuhn Poker \u53ef\u4ee5\u7528\u6811\u6765\u8868\u793a\u3002\u4e00\u5171\u6709\u4e09\u7c7b\u8282\u70b9\uff1a chance node\uff0c\u5982\u56fe\u4e2d\u7684\u6839\u7ed3\u70b9\u8868\u793a\u7684\u53d1\u724c\u8282\u70b9 decision node\uff0c\u73a9\u5bb6\u505a\u51b3\u7b56\u7684\u8282\u70b9 terminal node\uff0c\u6e38\u620f\u7ed3\u675f\uff0c\u7ed3\u7b97 payoff \u7684\u8282\u70b9\uff0c\u5373\u6811\u4e2d\u7684\u53f6\u5b50\u8282\u70b9\u3002 Player 1 Player 2 Player 1 Payoff pass pass +1 to player with higher card pass bet pass +1 to player 2 pass bet bet +2 to player with higher card bet pass +1 to player 1 bet bet +2 to player with higher card \u56fe\u4e2d\u7684\u8981\u70b9\uff1a \u6bcf\u4e2a\u8282\u70b9\u4ee3\u8868\u4e00\u4e2a\u72b6\u6001\uff0c\u8282\u70b9\u4e0e\u8282\u70b9\u7684\u8fb9\u4ee3\u8868 action\u3002\u72b6\u6001\u5c31\u662f information set\uff0c\u5373__\u505a\u51b3\u7b56\u65f6__\u6240\u6709\u53ef\u4ee5\u83b7\u53d6\u7684\u4fe1\u606f\uff08\u5305\u62ec\u5386\u53f2 game \u4fe1\u606f\uff09 \u6bcf\u4e2a\u8282\u70b9\u6709\u4e24\u4e2a\u5206\u652f\uff0c\u5206\u522b\u4ee3\u8868\u8ddf\u724c (pass) \u548c\u52a0\u6ce8 (fold)\u3002 \u5982\u679c\u5728\u5bf9\u65b9 bet \u540e\u9009\u62e9 pass \u5219\u8ba4\u5b9a\u4e3a\u8d1f \u5982\u679c\u90fd bet \u6216\u8005\u90fd pass\uff0c\u724c\u5927\u7684\u80dc Kuhn \u5171\u6709 12 \u79cd information set\uff0c\u5bf9\u624b\u724c 1\uff0c2\uff0c3 \u5404\u6709 4 \u79cd\uff1a \u672c\u65b9\u5148\u624b\uff0c\u51b3\u5b9a pass \u8fd8\u662f bet \u672c\u65b9\u5148\u624b pass\uff0c\u5bf9\u624b bet\uff0c\u518d\u6b21\u51b3\u5b9a pass \u8fd8\u662f bet \u672c\u65b9\u540e\u624b\uff0c\u5bf9\u65b9 pass\uff0c\u51b3\u5b9a pass \u8fd8\u662f bet \u672c\u65b9\u540e\u624b\uff0c\u5bf9\u65b9 bet\uff0c\u51b3\u5b9a pass \u8fd8\u662f bet \u7531\u4e8e\u6211\u4eec\u65e0\u6cd5\u5f97\u77e5\u5bf9\u65b9\u624b\u724c\uff0c\u6bcf\u79cd information set \u5305\u62ec\u4e86 2 \u4e2a game state\u3002\u56e0\u4e3a\u603b\u5171\u6709 3 \u5f20\u724c\uff0c\u5bf9\u624b\u624b\u724c\u53ef\u80fd\u662f\u9664\u53bb\u6211\u4eec\u624b\u724c\u5916\u7684 2 \u5f20\u4efb\u610f\u4e00\u5f20\u3002 \u8fd9\u4e5f\u8bf4\u660e\u4e86 information set \u4e0e game state \u7684\u533a\u522b\u3002game state \u662f\u5ba2\u89c2\u5b58\u5728\u7684\u72b6\u6001\uff0c\u800c information set \u662f\u4e3b\u89c2\u89c2\u5bdf\u5230\u7684\u4fe1\u606f\uff0c\u5b83\u4e0d\u4e00\u5b9a\u662f\u5b8c\u6574\u7684\uff0c\u56e0\u6b64\u4e0e game state \u53ef\u80fd\u662f\u4e00\u5bf9\u591a\u7684\u5173\u7cfb\u3002 2 Counterfactual Regret Minimization \u201cCounterfactual\u201d means contrary to fact. Intuitively, the counterfactual regret closely measures the potential gain if we do something contrary to the fact, such as deliberately making action \\(a\\) at information set \\(I\\) instead of following strategy \\(\\sigma^t\\) . 2.1 Notation symbol term comment \\(h\\) action history from root of the game \\(\\sigma_i\\) player \\(i\\) 's strategy probability of choosing action \\(a\\) in information set \\(I\\) \\(\\sigma\\) strategy profile all player strategies together \\(\\pi ^ {\\sigma} (h)\\) reach probability reach probability of game history \\(h\\) with strategy profile \\(\\sigma\\) \\(u\\) utility payoff \\(t\\) time step every information set has an independent \\(t\\) , it is incremented with each visit to the information set 2.2 Formula Let \\(Z\\) denote the set of all terminal game histories (sequence from root to leaf). Then proper prefix \\(h \\sqsubset z\\) for \\(z \\in Z\\) is a nonterminal game history. Z are the all possible endings from h . Define the counterfactual value at non-terminal history \\(h\\) \u0012 for player \\(i\\) as : \\[ v_i(\\sigma, h) = \\sum_{z \\in Z, h \\sqsubset z } \\pi_{-i}^{\\sigma} (h) \\pi ^{\\sigma} (h, z) u_i (z) \\] \\(\\pi_{-i}^{\\sigma} (h)\\) is the probability of reaching \\(h\\) with strategy profile \\(\\sigma\\) excluding the randomness of player \\(i\\) 's actions (player \\(i\\) has probability 1.0 to take current actions). \\(\\pi^{\\sigma}(h, z)\\) is the probability of reaching \\(z\\) from \\(h\\) with strategy profile \\(\\sigma\\) . In the graph above, because \\(i = 0\\) , the p0 player has 100% probability to choose action \\(a_2\\) and \\(a_4\\) . That's why the probability of reaching \\(h\\) is \\(P(a_1)P(a_3|a_2)\\) . We treat the computation as if player \\(i\\) 's strategy was modified to have intentionally played to information set \\(I\\) . Put another way, we exclude the probabilities that factually came into player \\(i\\) \u2019s play from the computation. The counterfactual regret of not taking action \\(a\\) at history \\(h\\) is defined as: \\[r(h, a) = v_i(\\sigma_{I \\rightarrow a}, h) - v_i(\\sigma, h)\\] \\(\\sigma_{I \\rightarrow a}\\) denotes a profile equivalent to \\(\\sigma\\) , except that action \\(a\\) is always chosen at information set \\(I\\) . Since an information set may be reached through multiple game histories , the counterfactual regret of not taking action \\(a\\) at information set \\(I\\) is: \\[ r(I, a) = \\sum_{h \\in I} r(h, a) \\] Let \\(r_i^t(I, a)\\) refer to the regret in time \\(t\\) belonging to player \\(i\\) , the cumulative counterfactual regret is defined as: $$ R_i^T(I, a) = \\sum_{t=1}^T r_i^t(I, a) $$\u0012 For each information set \\(I\\) , the probability of choosing action \\(a\\) is calculated by: \\[ \\sigma^{T+1}_i (I, a) = \\begin{cases} \\frac{R_i^{T, +}(I, a)}{ \\sum_{a \\in A(I)} R_i^{T, +}(I, a) } & \\text{if} \\sum_{a \\in A(I)} R_i^{T, +}(I, a) > 0\\\\ \\frac{1}{|A(I)|} & \\text{otherwise.} \\end{cases} \\] \\(+\\) means positive (>0). It selects actions in proportion to positive regrets. This is the same as the regret matching algorithm in Regret Matching and Blotto Game . 2.3 Algorithm CFR \u53c2\u6570\uff1a action history: \\(h\\) learning player id: \\(i\\) time step: \\(t\\) reach probability of action history \\(h\\) for player 1: \\(\\pi_1\\) reach probability of action history \\(h\\) for player 2: \\(\\pi_2\\) \u8fd9\u4e2a\u7b97\u6cd5\u5176\u5b9e\u5199\u7684\u6bd4\u8f83\u6666\u6da9\uff0c\u53c2\u6570\u8bbe\u8ba1\u4e5f\u4e0d\u662f\u7279\u522b\u5408\u7406\u3002\u5b9e\u9645\u4e0a\uff0c\u6211\u4eec\u53ea\u9700\u8981\u4e09\u4e2a\u53c2\u6570\uff1a \u6e38\u620f\u5386\u53f2 history \u73a9\u5bb6\u7684\u624b\u724c cards \u6bcf\u4e2a\u73a9\u5bb6\u5230\u8fbe\u8fd9\u4e2a\u5386\u53f2\u8282\u70b9\u7684\u6982\u7387 reach_probs \u5f53\u524d\u73a9\u5bb6 id \u53ef\u4ee5\u901a\u8fc7\u6e38\u620f\u5386\u53f2\u6765\u63a8\u65ad\u3002 \u6211\u81ea\u5df1\u7684\u5b9e\u73b0\u5982\u4e0b\uff1a fn cfr ( & mut self , history : kuhn :: ActionHistory , cards : & Vec < i32 > , reach_probs : HashMap < i32 , f64 > , ) -> f64 { // current active player let player_id = ( history . 0. len () % 2 ) as i32 ; let maybe_payoff = kuhn :: get_payoff ( & history , cards ); if maybe_payoff . is_some () { let payoff = match player_id { 0 => maybe_payoff . unwrap (), 1 => - maybe_payoff . unwrap (), _ => panic! ( \"unexpected player id {}\" , player_id ), }; return payoff as f64 ; } // not the terminal node let info_set = InformationSet { action_history : history . clone (), hand_card : cards [ player_id as usize ], }; if self . cfr_info . contains_key ( & info_set ) == false { self . cfr_info . insert ( info_set . clone (), CfrNode :: new ()); } let action_probs = self . cfr_info . get ( & info_set ) . unwrap () . get_action_probability (); let mut action_payoffs = Vec :: new (); let mut node_value = 0.0 ; for ( action_id , action_prob ) in action_probs . iter (). enumerate () { // next history, appending the new action to it let mut next_history = history . clone (); next_history . 0 . push ( kuhn :: Action :: from_int ( action_id as u32 )); // update history probability let mut next_reach_probs = reach_probs . clone (); * next_reach_probs . get_mut ( & player_id ). unwrap () *= action_prob ; // recursive call, \"-\" here because the return value is the opponent's payoff action_payoffs . push ( - self . cfr ( next_history , cards , next_reach_probs )); node_value += action_prob * action_payoffs [ action_id ]; } assert_eq! ( action_payoffs . len (), 2 ); // update regret let node = self . cfr_info . get_mut ( & info_set ). unwrap (); for ( action_id , payoff ) in action_payoffs . iter (). enumerate () { let regret = payoff - node_value ; let opponent = 1 - player_id ; node . cum_regrets [ action_id ] += reach_probs [ & opponent ] * regret ; } for ( action_id , action_prob ) in action_probs . iter (). enumerate () { node . cum_strategy [ action_id ] += reach_probs [ & player_id ] * action_prob ; } return node_value ; } \u7b97\u6cd5\u4e2d\u7684 chance node \u5176\u5b9e\u5c31\u662f\u7c7b\u4f3c\u4e8e\u53d1\u724c\uff0c\u63b7\u9ab0\u5b50\u8fd9\u7c7b\u968f\u673a\u8282\u70b9\u3002\u5728 kuhn \u4e2d\u4ec5\u6709\u4e00\u4e2a\u968f\u673a\u8282\u70b9\uff0c\u5c31\u662f\u5f00\u5c40\u7684\u53d1\u724c\u73af\u8282\u3002\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u63d0\u524d\u968f\u673a\u53d1\u597d\u724c\uff0c\u4e0d\u7528\u5728 cfr \u7b97\u6cd5\u5185\u5904\u7406\u3002 \u8fd9\u662f\u4e00\u79cd\u591a\u53c9\u6811\u7684\u6df1\u5ea6\u4f18\u5148\u904d\u5386\u3002\u6bcf\u4e2a information set \u5c31\u662f\u4e00\u4e2a\u8282\u70b9\u3002\u6bcf\u4e2a\u8282\u70b9\u91c7\u53d6\u7684\u4e0d\u540c action \u4f1a\u901a\u5411\u4e0b\u4e00\u4e2a\u5b50\u8282\u70b9\uff0c\u76f4\u5230\u53f6\u5b50\u8282\u70b9\uff08\u5373\u6e38\u620f\u7ed3\u675f\uff0c\u6709\u5177\u4f53 payoff \u503c\u7684\u8282\u70b9\uff09\u3002 \u6838\u5fc3\u601d\u8def\uff1a \u6bcf\u4e2a\u8282\u70b9\u91c7\u53d6\u7684 action \u53ef\u4ee5\u901a\u5411\u4e0b\u4e00\u4e2a\u8282\u70b9\u3002 \u5bf9\u4e8e\u6bcf\u4e2a\u8282\u70b9\uff0c\u8282\u70b9\u4ef7\u503c\u7684\u8ba1\u7b97\u662f\u6240\u6709\u901a\u8fc7 action \u53ef\u4ee5\u5230\u8fbe\u7684\u5b50\u8282\u70b9\u4ef7\u503c\u7684\u52a0\u6743\u5e73\u5747\u3002\u6743\u91cd\u4e3a action \u7684\u9009\u53d6\u6982\u7387\u3002 action\u7684\u9009\u53d6\u6982\u7387\u6839\u636e regret matching \u7b97\u6cd5\u786e\u5b9a\uff0c\u82e5 regret \u5c1a\u672a\u521d\u59cb\u5316\u5c31\u968f\u673a\u9009\u62e9 action action \u7684 regret \u53ef\u4ee5\u7531\u9009\u53d6\u8be5 action \u5230\u8fbe\u7684\u5b50\u8282\u70b9\u4ef7\u503c\u51cf\u53bb\u5f53\u524d\u8282\u70b9\u4ef7\u503c\u5f97\u5230\u3002 \u6bcf\u6b21\u8fed\u4ee3\uff0c\u5c06 action \u7684 regret \u4e58\u4e0a\u5230\u8fbe\u8be5\u8282\u70b9\u6982\u7387 ( reach_probs[&opponent] )\uff0c\u7d2f\u8ba1\u5230\u8fd9\u4e2a\u8282\u70b9\u8fd9\u4e2a action \u7684 cum_regret \u4e2d\u3002\u8fd9\u91cc\u91c7\u7528 \u5bf9\u624b\u65b9 \u5230\u8fbe\u6982\u7387\u7684\u539f\u56e0\u662f\u5df1\u65b9 action \u6211\u4eec\u90fd\u662f\u4ee5 1.0 \u7684\u6982\u7387\u9009\u62e9\u7684\u3002 \u201c\u53cd\u4e8b\u5b9e\u201d\u4f53\u73b0\u5728\u6bcf\u4e2a\u8282\u70b9\uff0c\u867d\u7136\u4e8b\u5b9e\u4e0a\u6211\u4eec\u53ea\u80fd\u9009\u62e9\u4e00\u4e2a\u884c\u52a8\uff0c\u4f46\u662f\u6211\u4eec\u53ef\u4ee5\u865a\u62df\u5730\u5c1d\u8bd5\u6240\u6709\u7684\u884c\u52a8\u3002 \u6b64\u5916\uff0c\u6700\u540e\u8d8b\u8fd1\u4e8e Nash Equilibrium \u7684\u4e0d\u662f\u6211\u4eec\u7684 regret matching \u7b56\u7565\uff0c\u800c\u662f\u7d2f\u8ba1\u7b56\u7565\uff08 cum_strategy \uff09\uff0c\u8ba1\u7b97\u65b9\u5f0f\u89c1\u4ee3\u7801\u672b\u5c3e\u3002 2.4 \u7ed3\u8bba \u6709\u4e00\u4e9b\u7b80\u5355\u7684\u9a8c\u8bc1\u65b9\u6cd5\uff1a Kuhn Poker \u7684\u7b2c\u4e00\u4f4d\u73a9\u5bb6\u6bcf\u5c40\u6536\u76ca\u671f\u671b\u662f -1/18\uff0c\u56e0\u4e3a\u7b2c\u4e8c\u4f4d\u73a9\u5bb6\u6709\u4fe1\u606f\u4e0a\u7684\u4f18\u52bf\uff08\u77e5\u9053\u7b2c\u4e00\u4f4d\u73a9\u5bb6\u7684\u884c\u52a8\uff09\u3002 \u73a9\u5bb6 1 \u62ff\u5230\u624b\u724c 1 \u9009\u62e9 Bet \u7684\u6982\u7387\u5e94\u8be5\u5728 (0.0, 1/3) \u4e4b\u95f4\uff08\u539f\u56e0\u89c1 Q & A\uff09 \u73a9\u5bb6 1 \u62ff\u5230\u624b\u724c 2 \u5e94\u8be5\u6c38\u8fdc\u9009\u62e9 Check\uff0c\u56e0\u4e3a\u5982\u679c\u9009\u62e9 bet\uff0c\u5bf9\u65b9\u624b\u724c\u662f 3\uff0c\u5fc5\u5b9a bet\uff0c\u8f93 $ 2, \u5982\u679c\u5bf9\u65b9\u624b\u724c\u662f 1\uff0c\u5fc5\u5b9a\u4e5f check\uff0c\u8d62 $1\uff0c\u4e0e check \u8d62\u7684\u94b1\u4e00\u81f4\uff0c\u4f46\u662f\u989d\u5916\u627f\u53d7\u98ce\u9669\u3002 \u73a9\u5bb6 1 \u62ff\u5230\u624b\u724c 3 \u9009\u62e9 Bet \u7684\u6982\u7387\u5e94\u8be5\u662f\u624b\u724c 1 \u9009\u62e9 bet \u6982\u7387\u7684 3 \u500d\uff08\u539f\u56e0\u89c1 Q & A\uff09 \u5404 information set \u9009\u53d6 check \u6216\u8005 bet \u7684\u6982\u7387\uff08information set\u8868\u793a\u4e3a \u624b\u724c + \u5f53\u524d action history\uff09\uff1a History Check Probability Bet Probability 1 0.77 0.23 1C 0.67 0.33 1B 1.00 0.00 1CB 1.00 0.00 2 1.00 0.00 2C 1.00 0.00 2B 0.66 0.34 2CB 0.42 0.58 3 0.30 0.70 3C 0.00 1.00 3B 0.00 1.00 3CB 0.00 1.00 2.5 \u4e00\u4e9b\u96be\u70b9 \u672c\u8282\u4e3b\u8981\u4ee5 Q & A \u7684\u5f62\u5f0f\u9610\u660e\u4e00\u4e0b\u666e\u904d\u4f1a\u9047\u5230\u7684\u56f0\u60d1\u3002 2.5.1 \u4e3a\u4ec0\u4e48\u9700\u8981\u8003\u8651 reach probability \u8003\u8651 reach probability \u624d\u80fd\u7b97\u51fa\u52a8\u4f5c\u7684\u671f\u671b\u6536\u76ca\uff0c\u4ece\u800c\u8ba1\u7b97\u6700\u4f73\u5e94\u5bf9\uff08best response\uff09\u3002 \u7528\u4e00\u4e2a\u4f8b\u5b50\u8bf4\u660e\u3002\u5047\u8bbe\u73b0\u5728\u6211\u4eec\u624b\u724c\u662f 2\uff0c\u5bf9\u65b9 Bet\uff0c\u6211\u4eec\u65e0\u6cd5\u77e5\u9053\u5bf9\u65b9\u624b\u724c\u662f 1 \u8fd8\u662f 3\u3002\u4f46\u662f\u6211\u4eec\u77e5\u9053\uff1a \u5982\u679c\u5bf9\u65b9\u624b\u724c\u662f1\uff0c\u6211\u4eec\u8ddf Bet\uff0cpayoff = 2\uff0c\u5982\u679c\u9009\u62e9 Check\uff0cpayoff = -1 \u5982\u679c\u5bf9\u65b9\u624b\u724c\u662f3\uff0c\u6211\u4eec\u8ddf Bet\uff0cpayoff = -2\uff0c\u5982\u679c\u9009\u62e9 Check\uff0cpayoff = -1 \u5047\u8bbe\u5bf9\u624b\u4ee5\u624b\u724c 1 Bet \u7684\u6982\u7387\uff08\u5373 history= \u201c1B\u201d \u7684 reach probability\uff09\u4e3a \\(a\\) \uff0c\u4ee5\u624b\u724c 3 Bet \u7684\u6982\u7387\uff08\u5373 history = \u201c3B\u201d \u7684 reach probability\uff09\u662f \\(b\\) \u3002\u6211\u4eec\u53ef\u4ee5\u5f97\u5230 Check \u7684\u671f\u671b\u6536\u76ca\uff1a \\[ \\text{EV}_{Check} = - a - b \\] \u540c\u7406\uff0cBet \u7684\u671f\u671b\u6536\u76ca\uff1a \\[ \\text{EV}_{Bet} = 2a - 2b \\] \u6211\u4eec\u80af\u5b9a\u503e\u5411\u4e8e\u9009\u62e9\u671f\u671b\u6536\u76ca\u5927\u7684\u884c\u52a8\u3002\u5373\uff0c\u82e5 \\(b > 3a\\) \uff0c\u5219\u5e94\u8be5\u9009\u62e9 Check\uff0c\u53cd\u4e4b\u5219\u9009\u62e9 Bet\u3002\u5728 Nash Equilibrium \u60c5\u51b5\u4e0b\uff0c\u8fd9\u4e24\u4e2a\u52a8\u4f5c\u7684\u671f\u671b\u6536\u76ca\u5e94\u8be5\u76f8\u7b49\uff0c\u5373 \\(b = 3a\\) \uff0c\u6b64\u65f6\u6211\u4eec\u65e0\u6cd5exploit \u6211\u4eec\u7684\u5bf9\u624b\uff0c\u5f53\u7136\uff0c\u5bf9\u624b\u4e5f\u65e0\u6cd5 exploit \u6211\u4eec\u3002\u8fd9\u5c31\u662f\u4e4b\u524d\u9a8c\u8bc1\u7ed3\u679c\u65f6\u7684 \u201c3 \u500d\u201d \u7684\u539f\u56e0\u3002 2.5.2 \u4e3a\u4ec0\u4e48\u9700\u8981\u7ef4\u62a4\u4e00\u4e2a strategy sum \u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\uff0ccumulative regret \u7684\u503c\u4e0d\u662f\u5f88\u7a33\u5b9a\uff0c\u4e00\u4e9b\u91cd\u8981\u7684 action \u53ef\u80fd\u6070\u597d\u5728 0.0 \u9644\u8fd1\u6447\u6446\uff0c\u5982\u679c\u9009\u7528\u5b83\u6765\u6c42\u6700\u7ec8\u7684\u7b56\u7565\uff0c\u53ef\u80fd\u5bfc\u81f4\u6709\u7684\u52a8\u4f5c\u65e0\u6cd5\u88ab\u9009\u62e9\u3002 \u4f7f\u7528 strategy sum \u5c31\u4e0d\u5b58\u5728\u8fd9\u4e2a\u95ee\u9898\uff0c\u5b83\u6c38\u8fdc\u662f\u6b63\u503c\uff0c\u5e76\u4e14\u6570\u5b66\u4e0a\u6536\u655b\u5230 Nash Equilibrium\u3002 2.6 CFR \u7b97\u6cd5\u7684\u4e0d\u8db3 \u5b83\u9700\u8981\u904d\u5386\u6574\u4e2a\u6e38\u620f\u6811 \u5b83\u9700\u8981\u77e5\u9053\u5bf9\u624b\u7684\u7b56\u7565\uff0c\u8fd9\u5728\u5b9e\u9645\u60c5\u51b5\u4e0b\u5f88\u96be\u6ee1\u8db3 \u9488\u5bf9\u8fd9\u4e24\u4e2a\u7f3a\u70b9\uff0cMarc Lanctot \u7b49\u4eba\u63d0\u51fa\u4e86 Monte-Carlo CFR\u3002\u6211\u4eec\u5c06\u5728\u4e0b\u4e00\u7bc7\u6587\u7ae0\u4e2d\u4ecb\u7ecd\u3002 Reference Building a Poker AI Monte Carlo Sampling for Regret Minimization in Extensive Games","title":"Counterfactual Regret Minimization and Kuhn Poker"},{"location":"mathematics/CFR/CfrAndKuhnPoker/#counterfactual-regret-minimization-and-kuhn-poker","text":"\u5728\u4e0a\u4e00\u7bc7\u6587\u7ae0 Regret Matching and Blotto Game \u4e2d\uff0c\u6211\u4eec\u7528 regret matching \u65b9\u6cd5\u6765\u627e\u535a\u5f08\u7684\u7eb3\u4ec0\u5747\u8861\u70b9\u3002 regret matching \u65b9\u6cd5\u7684\u5c40\u9650\u6027\u5728\u4e8e\uff0c\u5b83\u53ea\u9002\u7528\u4e8e\u80fd\u7528\u77e9\u9635\u8868\u793a\u7684\u535a\u5f08\uff0c\u5373\u6bcf\u4e2a\u73a9\u5bb6\u540c\u65f6\u91c7\u53d6\u884c\u52a8\u7684\u535a\u5f08\uff0c\u4f8b\u5982\u526a\u5200\u77f3\u5934\u5e03\u3001blotto game\u3002","title":"Counterfactual Regret Minimization and Kuhn Poker"},{"location":"mathematics/CFR/CfrAndKuhnPoker/#1-kuhn-poker","text":"\u8fd8\u6709\u4e00\u79cd\u535a\u5f08\u53eb\u505a\u201d\u8fde\u7eed\u535a\u5f08\u201c(sequential game)\uff0c\u5373\u73a9\u5bb6\u7684\u52a8\u4f5c\u5e76\u4e0d\u540c\u65f6\u53d1\u751f\uff0c\u800c\u662f\u4f9d\u6b21\u53d1\u751f\u7684\uff0c\u4f8b\u5982\u5fb7\u5dde\u6251\u514b\u3002\u5b83\u6709\u4e2a\u7b80\u5316\u7248\u672c Kuhn Poker\uff0c\u6211\u4eec\u5c06\u7528\u5b83\u4f5c\u4e3a\u4f8b\u5b50\u5b9e\u73b0 Counterfactual Regret Minimization\u3002 Kuhn Poker is a simple 3-card poker game by Harold E. Kuhn [8]. Two players each ante 1 chip, i.e. bet 1 chip blind into the pot before the deal. Three cards, marked with numbers 1, 2, and 3, are shuffled, and one card is dealt to each player and held as private information. Play alternates starting with player 1. On a turn, a player may either pass or bet. A player that bets places an additional chip into the pot. When a player passes after a bet, the opponent takes all chips in the pot. When there are two successive passes or two successive bets, both players reveal their cards, and the player with the higher card takes all chips in the pot. Kuhn Poker \u53ef\u4ee5\u7528\u6811\u6765\u8868\u793a\u3002\u4e00\u5171\u6709\u4e09\u7c7b\u8282\u70b9\uff1a chance node\uff0c\u5982\u56fe\u4e2d\u7684\u6839\u7ed3\u70b9\u8868\u793a\u7684\u53d1\u724c\u8282\u70b9 decision node\uff0c\u73a9\u5bb6\u505a\u51b3\u7b56\u7684\u8282\u70b9 terminal node\uff0c\u6e38\u620f\u7ed3\u675f\uff0c\u7ed3\u7b97 payoff \u7684\u8282\u70b9\uff0c\u5373\u6811\u4e2d\u7684\u53f6\u5b50\u8282\u70b9\u3002 Player 1 Player 2 Player 1 Payoff pass pass +1 to player with higher card pass bet pass +1 to player 2 pass bet bet +2 to player with higher card bet pass +1 to player 1 bet bet +2 to player with higher card \u56fe\u4e2d\u7684\u8981\u70b9\uff1a \u6bcf\u4e2a\u8282\u70b9\u4ee3\u8868\u4e00\u4e2a\u72b6\u6001\uff0c\u8282\u70b9\u4e0e\u8282\u70b9\u7684\u8fb9\u4ee3\u8868 action\u3002\u72b6\u6001\u5c31\u662f information set\uff0c\u5373__\u505a\u51b3\u7b56\u65f6__\u6240\u6709\u53ef\u4ee5\u83b7\u53d6\u7684\u4fe1\u606f\uff08\u5305\u62ec\u5386\u53f2 game \u4fe1\u606f\uff09 \u6bcf\u4e2a\u8282\u70b9\u6709\u4e24\u4e2a\u5206\u652f\uff0c\u5206\u522b\u4ee3\u8868\u8ddf\u724c (pass) \u548c\u52a0\u6ce8 (fold)\u3002 \u5982\u679c\u5728\u5bf9\u65b9 bet \u540e\u9009\u62e9 pass \u5219\u8ba4\u5b9a\u4e3a\u8d1f \u5982\u679c\u90fd bet \u6216\u8005\u90fd pass\uff0c\u724c\u5927\u7684\u80dc Kuhn \u5171\u6709 12 \u79cd information set\uff0c\u5bf9\u624b\u724c 1\uff0c2\uff0c3 \u5404\u6709 4 \u79cd\uff1a \u672c\u65b9\u5148\u624b\uff0c\u51b3\u5b9a pass \u8fd8\u662f bet \u672c\u65b9\u5148\u624b pass\uff0c\u5bf9\u624b bet\uff0c\u518d\u6b21\u51b3\u5b9a pass \u8fd8\u662f bet \u672c\u65b9\u540e\u624b\uff0c\u5bf9\u65b9 pass\uff0c\u51b3\u5b9a pass \u8fd8\u662f bet \u672c\u65b9\u540e\u624b\uff0c\u5bf9\u65b9 bet\uff0c\u51b3\u5b9a pass \u8fd8\u662f bet \u7531\u4e8e\u6211\u4eec\u65e0\u6cd5\u5f97\u77e5\u5bf9\u65b9\u624b\u724c\uff0c\u6bcf\u79cd information set \u5305\u62ec\u4e86 2 \u4e2a game state\u3002\u56e0\u4e3a\u603b\u5171\u6709 3 \u5f20\u724c\uff0c\u5bf9\u624b\u624b\u724c\u53ef\u80fd\u662f\u9664\u53bb\u6211\u4eec\u624b\u724c\u5916\u7684 2 \u5f20\u4efb\u610f\u4e00\u5f20\u3002 \u8fd9\u4e5f\u8bf4\u660e\u4e86 information set \u4e0e game state \u7684\u533a\u522b\u3002game state \u662f\u5ba2\u89c2\u5b58\u5728\u7684\u72b6\u6001\uff0c\u800c information set \u662f\u4e3b\u89c2\u89c2\u5bdf\u5230\u7684\u4fe1\u606f\uff0c\u5b83\u4e0d\u4e00\u5b9a\u662f\u5b8c\u6574\u7684\uff0c\u56e0\u6b64\u4e0e game state \u53ef\u80fd\u662f\u4e00\u5bf9\u591a\u7684\u5173\u7cfb\u3002","title":"1 Kuhn Poker"},{"location":"mathematics/CFR/CfrAndKuhnPoker/#2-counterfactual-regret-minimization","text":"\u201cCounterfactual\u201d means contrary to fact. Intuitively, the counterfactual regret closely measures the potential gain if we do something contrary to the fact, such as deliberately making action \\(a\\) at information set \\(I\\) instead of following strategy \\(\\sigma^t\\) .","title":"2 Counterfactual Regret Minimization"},{"location":"mathematics/CFR/CfrAndKuhnPoker/#21-notation","text":"symbol term comment \\(h\\) action history from root of the game \\(\\sigma_i\\) player \\(i\\) 's strategy probability of choosing action \\(a\\) in information set \\(I\\) \\(\\sigma\\) strategy profile all player strategies together \\(\\pi ^ {\\sigma} (h)\\) reach probability reach probability of game history \\(h\\) with strategy profile \\(\\sigma\\) \\(u\\) utility payoff \\(t\\) time step every information set has an independent \\(t\\) , it is incremented with each visit to the information set","title":"2.1 Notation"},{"location":"mathematics/CFR/CfrAndKuhnPoker/#22-formula","text":"Let \\(Z\\) denote the set of all terminal game histories (sequence from root to leaf). Then proper prefix \\(h \\sqsubset z\\) for \\(z \\in Z\\) is a nonterminal game history. Z are the all possible endings from h . Define the counterfactual value at non-terminal history \\(h\\) \u0012 for player \\(i\\) as : \\[ v_i(\\sigma, h) = \\sum_{z \\in Z, h \\sqsubset z } \\pi_{-i}^{\\sigma} (h) \\pi ^{\\sigma} (h, z) u_i (z) \\] \\(\\pi_{-i}^{\\sigma} (h)\\) is the probability of reaching \\(h\\) with strategy profile \\(\\sigma\\) excluding the randomness of player \\(i\\) 's actions (player \\(i\\) has probability 1.0 to take current actions). \\(\\pi^{\\sigma}(h, z)\\) is the probability of reaching \\(z\\) from \\(h\\) with strategy profile \\(\\sigma\\) . In the graph above, because \\(i = 0\\) , the p0 player has 100% probability to choose action \\(a_2\\) and \\(a_4\\) . That's why the probability of reaching \\(h\\) is \\(P(a_1)P(a_3|a_2)\\) . We treat the computation as if player \\(i\\) 's strategy was modified to have intentionally played to information set \\(I\\) . Put another way, we exclude the probabilities that factually came into player \\(i\\) \u2019s play from the computation. The counterfactual regret of not taking action \\(a\\) at history \\(h\\) is defined as: \\[r(h, a) = v_i(\\sigma_{I \\rightarrow a}, h) - v_i(\\sigma, h)\\] \\(\\sigma_{I \\rightarrow a}\\) denotes a profile equivalent to \\(\\sigma\\) , except that action \\(a\\) is always chosen at information set \\(I\\) . Since an information set may be reached through multiple game histories , the counterfactual regret of not taking action \\(a\\) at information set \\(I\\) is: \\[ r(I, a) = \\sum_{h \\in I} r(h, a) \\] Let \\(r_i^t(I, a)\\) refer to the regret in time \\(t\\) belonging to player \\(i\\) , the cumulative counterfactual regret is defined as: $$ R_i^T(I, a) = \\sum_{t=1}^T r_i^t(I, a) $$\u0012 For each information set \\(I\\) , the probability of choosing action \\(a\\) is calculated by: \\[ \\sigma^{T+1}_i (I, a) = \\begin{cases} \\frac{R_i^{T, +}(I, a)}{ \\sum_{a \\in A(I)} R_i^{T, +}(I, a) } & \\text{if} \\sum_{a \\in A(I)} R_i^{T, +}(I, a) > 0\\\\ \\frac{1}{|A(I)|} & \\text{otherwise.} \\end{cases} \\] \\(+\\) means positive (>0). It selects actions in proportion to positive regrets. This is the same as the regret matching algorithm in Regret Matching and Blotto Game .","title":"2.2 Formula"},{"location":"mathematics/CFR/CfrAndKuhnPoker/#23-algorithm","text":"CFR \u53c2\u6570\uff1a action history: \\(h\\) learning player id: \\(i\\) time step: \\(t\\) reach probability of action history \\(h\\) for player 1: \\(\\pi_1\\) reach probability of action history \\(h\\) for player 2: \\(\\pi_2\\) \u8fd9\u4e2a\u7b97\u6cd5\u5176\u5b9e\u5199\u7684\u6bd4\u8f83\u6666\u6da9\uff0c\u53c2\u6570\u8bbe\u8ba1\u4e5f\u4e0d\u662f\u7279\u522b\u5408\u7406\u3002\u5b9e\u9645\u4e0a\uff0c\u6211\u4eec\u53ea\u9700\u8981\u4e09\u4e2a\u53c2\u6570\uff1a \u6e38\u620f\u5386\u53f2 history \u73a9\u5bb6\u7684\u624b\u724c cards \u6bcf\u4e2a\u73a9\u5bb6\u5230\u8fbe\u8fd9\u4e2a\u5386\u53f2\u8282\u70b9\u7684\u6982\u7387 reach_probs \u5f53\u524d\u73a9\u5bb6 id \u53ef\u4ee5\u901a\u8fc7\u6e38\u620f\u5386\u53f2\u6765\u63a8\u65ad\u3002 \u6211\u81ea\u5df1\u7684\u5b9e\u73b0\u5982\u4e0b\uff1a fn cfr ( & mut self , history : kuhn :: ActionHistory , cards : & Vec < i32 > , reach_probs : HashMap < i32 , f64 > , ) -> f64 { // current active player let player_id = ( history . 0. len () % 2 ) as i32 ; let maybe_payoff = kuhn :: get_payoff ( & history , cards ); if maybe_payoff . is_some () { let payoff = match player_id { 0 => maybe_payoff . unwrap (), 1 => - maybe_payoff . unwrap (), _ => panic! ( \"unexpected player id {}\" , player_id ), }; return payoff as f64 ; } // not the terminal node let info_set = InformationSet { action_history : history . clone (), hand_card : cards [ player_id as usize ], }; if self . cfr_info . contains_key ( & info_set ) == false { self . cfr_info . insert ( info_set . clone (), CfrNode :: new ()); } let action_probs = self . cfr_info . get ( & info_set ) . unwrap () . get_action_probability (); let mut action_payoffs = Vec :: new (); let mut node_value = 0.0 ; for ( action_id , action_prob ) in action_probs . iter (). enumerate () { // next history, appending the new action to it let mut next_history = history . clone (); next_history . 0 . push ( kuhn :: Action :: from_int ( action_id as u32 )); // update history probability let mut next_reach_probs = reach_probs . clone (); * next_reach_probs . get_mut ( & player_id ). unwrap () *= action_prob ; // recursive call, \"-\" here because the return value is the opponent's payoff action_payoffs . push ( - self . cfr ( next_history , cards , next_reach_probs )); node_value += action_prob * action_payoffs [ action_id ]; } assert_eq! ( action_payoffs . len (), 2 ); // update regret let node = self . cfr_info . get_mut ( & info_set ). unwrap (); for ( action_id , payoff ) in action_payoffs . iter (). enumerate () { let regret = payoff - node_value ; let opponent = 1 - player_id ; node . cum_regrets [ action_id ] += reach_probs [ & opponent ] * regret ; } for ( action_id , action_prob ) in action_probs . iter (). enumerate () { node . cum_strategy [ action_id ] += reach_probs [ & player_id ] * action_prob ; } return node_value ; } \u7b97\u6cd5\u4e2d\u7684 chance node \u5176\u5b9e\u5c31\u662f\u7c7b\u4f3c\u4e8e\u53d1\u724c\uff0c\u63b7\u9ab0\u5b50\u8fd9\u7c7b\u968f\u673a\u8282\u70b9\u3002\u5728 kuhn \u4e2d\u4ec5\u6709\u4e00\u4e2a\u968f\u673a\u8282\u70b9\uff0c\u5c31\u662f\u5f00\u5c40\u7684\u53d1\u724c\u73af\u8282\u3002\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u63d0\u524d\u968f\u673a\u53d1\u597d\u724c\uff0c\u4e0d\u7528\u5728 cfr \u7b97\u6cd5\u5185\u5904\u7406\u3002 \u8fd9\u662f\u4e00\u79cd\u591a\u53c9\u6811\u7684\u6df1\u5ea6\u4f18\u5148\u904d\u5386\u3002\u6bcf\u4e2a information set \u5c31\u662f\u4e00\u4e2a\u8282\u70b9\u3002\u6bcf\u4e2a\u8282\u70b9\u91c7\u53d6\u7684\u4e0d\u540c action \u4f1a\u901a\u5411\u4e0b\u4e00\u4e2a\u5b50\u8282\u70b9\uff0c\u76f4\u5230\u53f6\u5b50\u8282\u70b9\uff08\u5373\u6e38\u620f\u7ed3\u675f\uff0c\u6709\u5177\u4f53 payoff \u503c\u7684\u8282\u70b9\uff09\u3002 \u6838\u5fc3\u601d\u8def\uff1a \u6bcf\u4e2a\u8282\u70b9\u91c7\u53d6\u7684 action \u53ef\u4ee5\u901a\u5411\u4e0b\u4e00\u4e2a\u8282\u70b9\u3002 \u5bf9\u4e8e\u6bcf\u4e2a\u8282\u70b9\uff0c\u8282\u70b9\u4ef7\u503c\u7684\u8ba1\u7b97\u662f\u6240\u6709\u901a\u8fc7 action \u53ef\u4ee5\u5230\u8fbe\u7684\u5b50\u8282\u70b9\u4ef7\u503c\u7684\u52a0\u6743\u5e73\u5747\u3002\u6743\u91cd\u4e3a action \u7684\u9009\u53d6\u6982\u7387\u3002 action\u7684\u9009\u53d6\u6982\u7387\u6839\u636e regret matching \u7b97\u6cd5\u786e\u5b9a\uff0c\u82e5 regret \u5c1a\u672a\u521d\u59cb\u5316\u5c31\u968f\u673a\u9009\u62e9 action action \u7684 regret \u53ef\u4ee5\u7531\u9009\u53d6\u8be5 action \u5230\u8fbe\u7684\u5b50\u8282\u70b9\u4ef7\u503c\u51cf\u53bb\u5f53\u524d\u8282\u70b9\u4ef7\u503c\u5f97\u5230\u3002 \u6bcf\u6b21\u8fed\u4ee3\uff0c\u5c06 action \u7684 regret \u4e58\u4e0a\u5230\u8fbe\u8be5\u8282\u70b9\u6982\u7387 ( reach_probs[&opponent] )\uff0c\u7d2f\u8ba1\u5230\u8fd9\u4e2a\u8282\u70b9\u8fd9\u4e2a action \u7684 cum_regret \u4e2d\u3002\u8fd9\u91cc\u91c7\u7528 \u5bf9\u624b\u65b9 \u5230\u8fbe\u6982\u7387\u7684\u539f\u56e0\u662f\u5df1\u65b9 action \u6211\u4eec\u90fd\u662f\u4ee5 1.0 \u7684\u6982\u7387\u9009\u62e9\u7684\u3002 \u201c\u53cd\u4e8b\u5b9e\u201d\u4f53\u73b0\u5728\u6bcf\u4e2a\u8282\u70b9\uff0c\u867d\u7136\u4e8b\u5b9e\u4e0a\u6211\u4eec\u53ea\u80fd\u9009\u62e9\u4e00\u4e2a\u884c\u52a8\uff0c\u4f46\u662f\u6211\u4eec\u53ef\u4ee5\u865a\u62df\u5730\u5c1d\u8bd5\u6240\u6709\u7684\u884c\u52a8\u3002 \u6b64\u5916\uff0c\u6700\u540e\u8d8b\u8fd1\u4e8e Nash Equilibrium \u7684\u4e0d\u662f\u6211\u4eec\u7684 regret matching \u7b56\u7565\uff0c\u800c\u662f\u7d2f\u8ba1\u7b56\u7565\uff08 cum_strategy \uff09\uff0c\u8ba1\u7b97\u65b9\u5f0f\u89c1\u4ee3\u7801\u672b\u5c3e\u3002","title":"2.3 Algorithm"},{"location":"mathematics/CFR/CfrAndKuhnPoker/#24","text":"\u6709\u4e00\u4e9b\u7b80\u5355\u7684\u9a8c\u8bc1\u65b9\u6cd5\uff1a Kuhn Poker \u7684\u7b2c\u4e00\u4f4d\u73a9\u5bb6\u6bcf\u5c40\u6536\u76ca\u671f\u671b\u662f -1/18\uff0c\u56e0\u4e3a\u7b2c\u4e8c\u4f4d\u73a9\u5bb6\u6709\u4fe1\u606f\u4e0a\u7684\u4f18\u52bf\uff08\u77e5\u9053\u7b2c\u4e00\u4f4d\u73a9\u5bb6\u7684\u884c\u52a8\uff09\u3002 \u73a9\u5bb6 1 \u62ff\u5230\u624b\u724c 1 \u9009\u62e9 Bet \u7684\u6982\u7387\u5e94\u8be5\u5728 (0.0, 1/3) \u4e4b\u95f4\uff08\u539f\u56e0\u89c1 Q & A\uff09 \u73a9\u5bb6 1 \u62ff\u5230\u624b\u724c 2 \u5e94\u8be5\u6c38\u8fdc\u9009\u62e9 Check\uff0c\u56e0\u4e3a\u5982\u679c\u9009\u62e9 bet\uff0c\u5bf9\u65b9\u624b\u724c\u662f 3\uff0c\u5fc5\u5b9a bet\uff0c\u8f93 $ 2, \u5982\u679c\u5bf9\u65b9\u624b\u724c\u662f 1\uff0c\u5fc5\u5b9a\u4e5f check\uff0c\u8d62 $1\uff0c\u4e0e check \u8d62\u7684\u94b1\u4e00\u81f4\uff0c\u4f46\u662f\u989d\u5916\u627f\u53d7\u98ce\u9669\u3002 \u73a9\u5bb6 1 \u62ff\u5230\u624b\u724c 3 \u9009\u62e9 Bet \u7684\u6982\u7387\u5e94\u8be5\u662f\u624b\u724c 1 \u9009\u62e9 bet \u6982\u7387\u7684 3 \u500d\uff08\u539f\u56e0\u89c1 Q & A\uff09 \u5404 information set \u9009\u53d6 check \u6216\u8005 bet \u7684\u6982\u7387\uff08information set\u8868\u793a\u4e3a \u624b\u724c + \u5f53\u524d action history\uff09\uff1a History Check Probability Bet Probability 1 0.77 0.23 1C 0.67 0.33 1B 1.00 0.00 1CB 1.00 0.00 2 1.00 0.00 2C 1.00 0.00 2B 0.66 0.34 2CB 0.42 0.58 3 0.30 0.70 3C 0.00 1.00 3B 0.00 1.00 3CB 0.00 1.00","title":"2.4 \u7ed3\u8bba"},{"location":"mathematics/CFR/CfrAndKuhnPoker/#25","text":"\u672c\u8282\u4e3b\u8981\u4ee5 Q & A \u7684\u5f62\u5f0f\u9610\u660e\u4e00\u4e0b\u666e\u904d\u4f1a\u9047\u5230\u7684\u56f0\u60d1\u3002","title":"2.5 \u4e00\u4e9b\u96be\u70b9"},{"location":"mathematics/CFR/CfrAndKuhnPoker/#251-reach-probability","text":"\u8003\u8651 reach probability \u624d\u80fd\u7b97\u51fa\u52a8\u4f5c\u7684\u671f\u671b\u6536\u76ca\uff0c\u4ece\u800c\u8ba1\u7b97\u6700\u4f73\u5e94\u5bf9\uff08best response\uff09\u3002 \u7528\u4e00\u4e2a\u4f8b\u5b50\u8bf4\u660e\u3002\u5047\u8bbe\u73b0\u5728\u6211\u4eec\u624b\u724c\u662f 2\uff0c\u5bf9\u65b9 Bet\uff0c\u6211\u4eec\u65e0\u6cd5\u77e5\u9053\u5bf9\u65b9\u624b\u724c\u662f 1 \u8fd8\u662f 3\u3002\u4f46\u662f\u6211\u4eec\u77e5\u9053\uff1a \u5982\u679c\u5bf9\u65b9\u624b\u724c\u662f1\uff0c\u6211\u4eec\u8ddf Bet\uff0cpayoff = 2\uff0c\u5982\u679c\u9009\u62e9 Check\uff0cpayoff = -1 \u5982\u679c\u5bf9\u65b9\u624b\u724c\u662f3\uff0c\u6211\u4eec\u8ddf Bet\uff0cpayoff = -2\uff0c\u5982\u679c\u9009\u62e9 Check\uff0cpayoff = -1 \u5047\u8bbe\u5bf9\u624b\u4ee5\u624b\u724c 1 Bet \u7684\u6982\u7387\uff08\u5373 history= \u201c1B\u201d \u7684 reach probability\uff09\u4e3a \\(a\\) \uff0c\u4ee5\u624b\u724c 3 Bet \u7684\u6982\u7387\uff08\u5373 history = \u201c3B\u201d \u7684 reach probability\uff09\u662f \\(b\\) \u3002\u6211\u4eec\u53ef\u4ee5\u5f97\u5230 Check \u7684\u671f\u671b\u6536\u76ca\uff1a \\[ \\text{EV}_{Check} = - a - b \\] \u540c\u7406\uff0cBet \u7684\u671f\u671b\u6536\u76ca\uff1a \\[ \\text{EV}_{Bet} = 2a - 2b \\] \u6211\u4eec\u80af\u5b9a\u503e\u5411\u4e8e\u9009\u62e9\u671f\u671b\u6536\u76ca\u5927\u7684\u884c\u52a8\u3002\u5373\uff0c\u82e5 \\(b > 3a\\) \uff0c\u5219\u5e94\u8be5\u9009\u62e9 Check\uff0c\u53cd\u4e4b\u5219\u9009\u62e9 Bet\u3002\u5728 Nash Equilibrium \u60c5\u51b5\u4e0b\uff0c\u8fd9\u4e24\u4e2a\u52a8\u4f5c\u7684\u671f\u671b\u6536\u76ca\u5e94\u8be5\u76f8\u7b49\uff0c\u5373 \\(b = 3a\\) \uff0c\u6b64\u65f6\u6211\u4eec\u65e0\u6cd5exploit \u6211\u4eec\u7684\u5bf9\u624b\uff0c\u5f53\u7136\uff0c\u5bf9\u624b\u4e5f\u65e0\u6cd5 exploit \u6211\u4eec\u3002\u8fd9\u5c31\u662f\u4e4b\u524d\u9a8c\u8bc1\u7ed3\u679c\u65f6\u7684 \u201c3 \u500d\u201d \u7684\u539f\u56e0\u3002","title":"2.5.1 \u4e3a\u4ec0\u4e48\u9700\u8981\u8003\u8651 reach probability"},{"location":"mathematics/CFR/CfrAndKuhnPoker/#252-strategy-sum","text":"\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\uff0ccumulative regret \u7684\u503c\u4e0d\u662f\u5f88\u7a33\u5b9a\uff0c\u4e00\u4e9b\u91cd\u8981\u7684 action \u53ef\u80fd\u6070\u597d\u5728 0.0 \u9644\u8fd1\u6447\u6446\uff0c\u5982\u679c\u9009\u7528\u5b83\u6765\u6c42\u6700\u7ec8\u7684\u7b56\u7565\uff0c\u53ef\u80fd\u5bfc\u81f4\u6709\u7684\u52a8\u4f5c\u65e0\u6cd5\u88ab\u9009\u62e9\u3002 \u4f7f\u7528 strategy sum \u5c31\u4e0d\u5b58\u5728\u8fd9\u4e2a\u95ee\u9898\uff0c\u5b83\u6c38\u8fdc\u662f\u6b63\u503c\uff0c\u5e76\u4e14\u6570\u5b66\u4e0a\u6536\u655b\u5230 Nash Equilibrium\u3002","title":"2.5.2  \u4e3a\u4ec0\u4e48\u9700\u8981\u7ef4\u62a4\u4e00\u4e2a strategy sum"},{"location":"mathematics/CFR/CfrAndKuhnPoker/#26-cfr","text":"\u5b83\u9700\u8981\u904d\u5386\u6574\u4e2a\u6e38\u620f\u6811 \u5b83\u9700\u8981\u77e5\u9053\u5bf9\u624b\u7684\u7b56\u7565\uff0c\u8fd9\u5728\u5b9e\u9645\u60c5\u51b5\u4e0b\u5f88\u96be\u6ee1\u8db3 \u9488\u5bf9\u8fd9\u4e24\u4e2a\u7f3a\u70b9\uff0cMarc Lanctot \u7b49\u4eba\u63d0\u51fa\u4e86 Monte-Carlo CFR\u3002\u6211\u4eec\u5c06\u5728\u4e0b\u4e00\u7bc7\u6587\u7ae0\u4e2d\u4ecb\u7ecd\u3002","title":"2.6 CFR \u7b97\u6cd5\u7684\u4e0d\u8db3"},{"location":"mathematics/CFR/CfrAndKuhnPoker/#reference","text":"Building a Poker AI Monte Carlo Sampling for Regret Minimization in Extensive Games","title":"Reference"},{"location":"mathematics/CFR/MonteCarloCfr/","text":"Monte Carlo CFR \u5728\u4e0a\u4e00\u7bc7\u6587\u7ae0\u4e2d\uff0c\u6211\u4eec\u8bb2\u4e86\u7ecf\u5178\u7684 CFR \u7b97\u6cd5\u7684\u539f\u7406\u53ca\u5b9e\u73b0\u3002\u4f46\u662f\uff0c\u5b83\u4e5f\u6709\u4e24\u4e2a\u81f4\u547d\u7684\u7f3a\u9677\uff0c\u5bfc\u81f4\u65e0\u6cd5\u5e94\u7528\u5230\u5b9e\u9645\u7684\u590d\u6742\u535a\u5f08\u4e2d\uff1a \u5b83\u9700\u8981\u904d\u5386\u6574\u4e2a\u6e38\u620f\u6811 \u5b83\u9700\u8981\u77e5\u9053\u5bf9\u624b\u7684\u7b56\u7565\uff0c\u8fd9\u5728\u5b9e\u9645\u60c5\u51b5\u4e0b\u5f88\u96be\u6ee1\u8db3 \u672c\u6587\u5c06\u4ecb\u7ecd\u57fa\u4e8e Monte Carlo \u7684\u6539\u8fdb\u7b97\u6cd5\u3002\u5168\u90e8\u4ee3\u7801\u53ef\u4ee5\u53c2\u8003\u6211\u7684 github \u9879\u76ee\uff1a cfr-kuhn . Definition \u6838\u5fc3\u601d\u60f3\u662f\uff0c\u5728\u907f\u514d\u904d\u5386\u6574\u4e2a\u6e38\u620f\u6811\u7684\u524d\u63d0\u4e0b\uff0c\u6bcf\u4e2a information set \u7684\u6bcf\u4e2a action \u7684 counterfactual regret \u671f\u671b\u503c\u4fdd\u6301\u4e0d\u53d8\u3002 \u4ee4 \\(\\mathcal{Q} = \\{Q_1, Q_2, ..., Q_r \\}\\) \u662f\u6240\u6709 terminal node \\(Z\\) \u7684\u5b50\u96c6\uff0c\u5176\u4e2d\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20 \\(Q_j\\) \u6211\u4eec\u79f0\u4e3a block \uff0c\u6bcf\u4e2a block \u53ef\u80fd\u5305\u542b\u591a\u4e2a terminal node \u3002\u4ee4 \\(q_j > 0\\) \u662f\u9009\u62e9 \\(Q_j\\) \u7684\u6982\u7387\uff0c\u6ee1\u8db3 \\(\\sum_{j=1}^r q_j = 1\\) \u3002\u6bcf\u6b21\u8fed\u4ee3\uff0c\u6211\u4eec\u90fd\u4f1a\u4ece\u8fd9\u4e9b blocks \u4e2d\u91c7\u6837\u4e00\u4e2a\u5e76\u4e14\u53ea\u8003\u8651\u5728\u8be5 block \u4e2d\u7684 terminal node \u3002 \u56de\u5fc6 CFR \u7ecf\u5178\u7248\u7684 counterfactual value \u8ba1\u7b97\u516c\u5f0f\uff1a \\[ v_i(\\sigma, I) = \\sum_{z \\in Z_I } \\pi_{-i}^{\\sigma} (z[I]) \\pi ^{\\sigma} (z[I], z) u_i (z) \\] \u5728 MCCFR \u4e2d\uff0c\u5bf9\u4e8e block \\(Q_j\\) \u7684 sampled counterfactual value \u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\[v_i(\\sigma, I | j) = \\sum_{z \\in Q_j \\cap Z_I} \\frac{1}{q(z)} \\pi_{-i}^\\sigma (z[I]) \\pi^\\sigma (z[I], z) u_i(z)\\] \u5176\u4e2d\uff1a \\(z\\) \u662f terminal node \\(z_I\\) \u8868\u793a information set \\(I\\) \u53ef\u4ee5\u5230\u8fbe\u7684 \\(z\\) \u7684\u5168\u96c6 \\(z[I]\\) \u8868\u793a\u67d0\u4e2a\u53ef\u4ee5\u5230\u8fbe \\(z\\) \u7684 information set \\(i\\) \u8868\u793a\u73a9\u5bb6 id \\(j\\) \u8868\u793a block id \\(q(z)\\) \u8868\u793a \\(z\\) \u6240\u5728 block \u88ab\u9009\u4e2d\u7684\u6982\u7387\u4e4b\u548c\uff08\u4e00\u4e2a terminal node \u53ef\u4ee5\u88ab\u5206\u5230\u591a\u4e2a block \u4e2d\uff09 \u6211\u4eec\u53ef\u4ee5\u8bc1\u660e counterfactual value \u548c sampled counterfactual value \u671f\u671b\u662f\u76f8\u7b49\u7684\u3002 \u8fd9\u5c31\u662f MCCFR \u7684\u57fa\u672c\u601d\u60f3\u4e86\u3002\u4e8b\u5b9e\u4e0a\uff0cCFR \u53ef\u4ee5\u770b\u4f5c MCCFR \u5728 \\(\\mathcal{Q} = \\{Z\\}\\) \u4e14 \\(q_1 = 1.0\\) \u7684\u7279\u4f8b\u3002 \u6b64\u5916\uff0c\u6211\u4eec\u53ef\u4ee5__\u5c06\u6bcf\u4e00\u4e2a block \u9009\u4e3a chance node \u7684\u4e00\u4e2a\u5206\u652f__\u3002\u4ee5 Kuhn Poker \u4e3a\u4f8b\uff0c\u6211\u4eec\u5bf9\u4e8e\u624b\u724c 1\uff0c2\uff0c3 \u53ef\u4ee5\u5efa\u7acb 3 \u4e2a block\uff1a \\(\\{ Q_1, Q_2, Q_3 \\}\\) \uff0c\u5206\u522b\u5305\u542b\u624b\u724c\u4e3a 1\uff0c2\uff0c3 \u7684\u6240\u6709 terminal nodes\u3002\u4ece\u800c\uff0c\u6bcf\u4e2a block \u7684\u6982\u7387\u4e5f\u81ea\u7136\u4e3a \\(\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3}\\) \u3002\u8fd9\u5c31\u662f chance-sampled CFR\u3002 Outcome-Sampling MCCFR \u5728 outcome-sampling MCCFR \u4e2d\uff0c\u6211\u4eec__\u628a\u6bcf\u4e2a terminal node \u4f5c\u4e3a\u4e00\u4e2a block__\u3002\u6bcf\u6b21\u8fed\u4ee3\uff0c\u6211\u4eec\u62bd\u53d6\u4e00\u4e2a terminal node \u5e76\u66f4\u65b0\u5b83\u7684\u524d\u7f00 information set\u3002\u4e00\u4e2a terminal node \u51fa\u73b0\u6982\u7387\u8d8a\u9ad8\uff0c\u6211\u4eec\u91c7\u6837\u6982\u7387\u4e5f\u8d8a\u9ad8\u3002\u56e0\u6b64\u6211\u4eec\u5fc5\u987b\u5f97\u5230\u6bcf\u4e2a terminal node j \u51fa\u73b0\u7684\u6982\u7387\u4f5c\u4e3a \\(q_j\\) \u3002\u5982\u4f55\u5f97\u5230\u5462\uff1f \u5728 CFR \u4e2d\uff0c\u6211\u4eec\u5728\u8ba1\u7b97 regret \u7684\u65f6\u5019\uff0c\u4f1a\u8ba1\u7b97\u5230\u8fbe\u6bcf\u4e2a history \u7684\u6982\u7387\u3002\u5bf9\u4e8e terminal node j\uff0c\u8fd9\u4e2a\u6982\u7387\u5176\u5b9e\u5c31\u662f\u91c7\u6837\u6982\u7387 \\(q_j\\) \u3002 CFR \u7b97\u6cd5\u5305\u542b\u4e86\u4e24\u4e2a\u65b9\u5411\u7684\u904d\u5386\uff1a \u524d\u5411\u904d\u5386\u3002\u7528\u4e8e\u8ba1\u7b97\u6bcf\u4e2a\u73a9\u5bb6\u4ece\u539f\u70b9\u5230\u8fbe\u5f53\u524d history \u7684\u6982\u7387 \\(\\pi_i^{\\sigma}(h)\\) \u540e\u5411\u904d\u5386\u3002\u7528\u4e8e\u8ba1\u7b97\u6bcf\u4e2a\u73a9\u5bb6\u4ece\u5f53\u524d history \u8fdb\u884c\u5230 terminal node \u7684\u6982\u7387 \\(\\pi_i^{\\sigma}(h,z)\\) \uff0c\u5728\u6b64\u8fc7\u7a0b\u4e2d\uff0c\u8fd8\u4f1a\u8ba1\u7b97 sampled counterfactual regrets\u3002 \u540e\u5411\u904d\u5386\u4e2d\u8ba1\u7b97 sampled counterfactual regrets \u4f1a\u5206\u4e3a\u4e24\u79cd\u60c5\u51b5\u3002 \u5176\u4e00\u662f\u9009\u62e9\u4e86\u80fd\u901a\u5411\u5f53\u524d terminal node \\(z\\) \u7684 action\u3002\u5373\uff0c\u5728information set \\(I\\) \u91c7\u53d6\u4e86\u884c\u52a8 \\(a\\) \uff0c\u6b64\u65f6\u8ba1\u7b97\u65b9\u5f0f\u4e3a\uff1a \\[ \\begin{align} r(I, a) &= v_i(\\sigma_{I \\rightarrow a}, I) - v_i(\\sigma, I) \\\\ &= \\frac{\\pi_{-i}^\\sigma (z[I]) \\pi^\\sigma (z[I]a, z) u_i(z)}{q(z)} - \\frac{\\pi_{-i}^\\sigma (z[I]) \\pi^\\sigma (z[I], z) u_i(z)}{q(z)} \\\\ &= \\frac{\\pi_{-i}^\\sigma (z[I]) \\pi^\\sigma (z[I] a, z) u_i(z)}{q(z)} ( 1 - \\sigma(a|z[I])) \\end{align} \\] \u4e0a\u5f0f\u6bd4\u8f83\u96be\u4ee5\u7406\u89e3\u7684\u662f\uff1a \\[\\pi^\\sigma (z[I] a, z) \\cdot \\sigma(a|z[I]) = \\pi^\\sigma (z[I], z) \\] \u7ed3\u5408\u5b9a\u4e49\uff0c \\(\\pi^\\sigma (z[I] a, z)\\) \u662f\u4ece \\(I + a\\) \u5230\u8fbe \\(z\\) \u7684\u6982\u7387\uff0c\u76f8\u6bd4 \\(\\pi^\\sigma (z[I], z)\\) \u591a\u524d\u8fdb\u4e86\u4e00\u6b65\uff08\u9009\u62e9\u884c\u52a8 \\(a\\) \uff09\uff0c\u5728 \\(I\\) \u9009\u62e9 \\(a\\) \u7684\u6982\u7387\u662f \\(\\sigma(a|z[I])\\) \uff0c\u56e0\u6b64\uff0c\u5982\u679c\u4ece \\(I\\) \u5230 \\(z\\) \u7684\u6982\u7387\u4e3a \\(p\\) \uff0c\u7531\u4e8e \\(I + a\\) \u5c06\u9009\u62e9 \\(a\\) \u7684\u6982\u7387\u7531\u539f\u672c\u7684 \\(\\sigma(a|z[I])\\) \u53d8\u6210\u4e86 1.0\uff0c\u5b83\u5230 \\(z\\) \u7684\u6982\u7387\u5c31\u53d8\u6210\u4e86 \\(p / \\sigma(a|z[I])\\) \u3002 \u53e6\u4e00\u79cd\u60c5\u51b5\u662f\u9009\u62e9\u4e86\u5176\u4ed6\u884c\u52a8\uff0c\u6b64\u65f6 \\(I + a\\) \u4e0d\u662f \\(z\\) \u7684\u524d\u7f00\u3002\u6b64\u65f6\u7684 sampled counterfactual value \u662f\uff1a \\[ \\begin{align} r(I, a) &= 0 - v_i(\\sigma, I) \\\\ &= - \\frac{\\pi_{-i}^\\sigma (z[I]) \\pi^\\sigma (z[I] a, z) u_i(z)}{q(z)} \\sigma(a|z[I]) \\end{align} \\] \u9009\u53d6 0 \u662f\u56e0\u4e3a\u8be5\u52a8\u4f5c\u7684\u540e\u6094\u503c\u66f4\u65b0\u4e0d\u5f52 \\(z\\) \u7ba1\u3002\u5fc5\u7136\u6709\u522b\u7684 terminal node \u7684\u524d\u7f00\u662f \\(I + a\\) \uff0c\u5f53\u91c7\u6837\u5230\u8fd9\u4e9b terminal node \u7684\u65f6\u5019\u81ea\u7136\u4f1a\u66f4\u65b0\u3002 \u6211\u4eec\u4ee4\uff1a \\[ w_I = \\frac{\\pi_{-i}^\\sigma (z[I]) \\pi^\\sigma (z[I] a, z) u_i(z)}{q(z)} \\] \u7531\u4e8e\u5728 outcome sampling \u4e2d\uff0c\u6bcf\u4e2a terminal node \\(z\\) \u90fd\u5bf9\u5e94\u4e00\u4e2a block \\(Q\\) \uff0c\u56e0\u6b64 \\(q(z)\\) \u5c31\u662f\u9009\u4e2d \\(Q\\) \u7684\u6982\u7387\u3002\u7406\u8bba\u4e0a\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u91c7\u6837\u7684\u771f\u5b9e\u6027\uff0c\u8fd9\u4e2a\u6982\u7387\u5e94\u8be5\u4e0e\u6240\u6709\u73a9\u5bb6\u9075\u5faa\u7b56\u7565 \\(\\sigma\\) \u8fdb\u884c\u6e38\u620f\u5230\u8fbe \\(z\\) \u7684\u6982\u7387\u76f8\u540c\uff0c\u5373 \\[q(z) = \\pi^\\sigma(z)\\] \u6839\u636e\u5b9a\u4e49\uff0c \\(\\pi_{-i}^\\sigma (z)\\) \u662f\u5bf9\u624b\u5230\u8fbe \\(z\\) \u7684\u6982\u7387\uff0c\u5728\u8ba1\u7b97\u65f6\uff0c\u5047\u8bbe\u73a9\u5bb6 \\(i\\) \u4ee5 1.0 \u7684\u6982\u7387\u9009\u62e9\u52a8\u4f5c\uff0c\u800c \\(\\pi_i^\\sigma (z)\\) \u76f8\u53cd\u3002\u4e24\u8005\u7684\u4e58\u79ef\u5c31\u662f\u4ece\u5c40\u5916\u65c1\u89c2\u8005\u770b\u6765\u5230\u8fbe \\(z\\) \u7684\u6982\u7387\u3002\u56e0\u6b64\u6709\uff1a \\[ \\begin{align} q(z) &= \\pi^\\sigma(z) \\\\ &= \\pi^\\sigma(z[I]) \\cdot \\pi^\\sigma(z[I], z) \\\\ &= \\pi_i^\\sigma (z[I]) \\cdot \\pi_{-i}^\\sigma (z[I]) \\cdot \\pi^\\sigma(z[I], z) \\end{align} \\] \u5e26\u5165\u5f97\u5230\uff1a \\[\\begin{align} w_I &= \\frac{\\pi_{-i}^\\sigma (z[I]) \\pi^\\sigma (z[I] a, z) u_i(z)}{q(z)} \\\\ &= \\frac{\\pi^\\sigma (z[I] a, z) u_i(z)}{ \\pi_i^\\sigma (z[I]) \\cdot \\pi^\\sigma(z[I], z)} \\\\ &= \\frac{\\pi_i^\\sigma(z[I]a, z) u_i(z)}{\\pi_i^\\sigma(z)} \\\\ &= \\frac{u_i(z)}{ \\pi_i^\\sigma (z[I]) \\cdot \\sigma(a|z[I])} \\end{align}\\] \u6ce8\u610f\u5728\u8fd9\u4e2a\u8868\u8fbe\u5f0f\u4e2d\uff0c\u6211\u4eec\u4e0d\u518d\u9700\u8981\u5bf9\u624b\u7684\u4fe1\u606f \uff08\u53ea\u6709\u5e26\u4e0b\u6807 \\(i\\) \u7684\u90e8\u5206\u4e86\uff09\u3002\u6211\u4eec\u5728\u5316\u7b80\u4e2d\u523b\u610f\u6d88\u53bb\u4e86\u5bf9\u624b \\(-i\\) \u76f8\u5173\u7684\u4fe1\u606f\u3002 \u6bcf\u6b21\u8fed\u4ee3\u7d2f\u8ba1\u540e\u6094\u503c\u4f1a\u589e\u52a0\uff1a \\[ r(I,a) = \\begin{cases} w_I \\cdot (1 - \\sigma(a|z[I]) & \\text{if} ~ z(z[I]a) \\sqsubset z \\\\ -w_I \\cdot \\sigma(a|z[I]) & \\text{otherwise} \\end{cases}\\] \u8fd9\u6837\u8ba1\u7b97\u53ef\u4ee5\u4fdd\u8bc1\u7d2f\u8ba1\u540e\u6094\u503c\u7684\u671f\u671b\u662f\u4e0e\u4f20\u7edf cfr \u76f8\u540c\u7684\u3002 \u6bcf\u6b21\u8fed\u4ee3\uff0c\u6bcf\u4e2a\u52a8\u4f5c\u7684\u7d2f\u8ba1 strategy \u589e\u52a0\uff1a \\[s(I, a) = \\pi_i^\\sigma(z[I]) \\cdot \\sigma(a|z[I]) \\] \u6ce8\uff1a\u8bba\u6587\u4e2d\u8fd8\u589e\u52a0\u4e86 \\(t - c_I\\) \u6743\u91cd\uff0c\u5373\u672c\u6b21 iteration \u548c\u4e0a\u6b21\u8bbf\u95ee \\(I\\) \u7684 iteration \u4e4b\u5dee\uff0c\u4f46\u662f\u6211\u52a0\u4e0a\u6743\u91cd\u540e\u65e0\u6cd5\u5f97\u5230\u6b63\u786e\u7ed3\u679c\uff0c\u5c1a\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002 \u5b9e\u73b0\u7ec6\u8282 \u76f8\u6bd4 cfr\uff0cmccfr \u7684\u4e0d\u540c\u4e3b\u8981\u6709\uff1a 1. \u65e0\u9700\u5bf9\u624b\uff08-i\uff09\u7684\u4fe1\u606f 2. \u65e0\u9700\u904d\u5386\u6240\u6709\u884c\u52a8 3. \u8ba1\u7b97\u540e\u6094\u503c\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c\u9700\u8981\u589e\u52a0\u4e00\u4e2a\u57fa\u4e8e\u91c7\u6837\u6982\u7387\u7684\u6743\u91cd\u3002 4. \u9700\u8981\u5f15\u5165 epsilon \u4fdd\u8bc1\u63a2\u7d22\u6240\u6709 action fn mccfr ( & mut self , history : kuhn :: ActionHistory , cards : & Vec < i32 > , reach_probs : HashMap < i32 , f64 > , ) -> f64 { // current active player let player_id = ( history . 0. len () % 2 ) as i32 ; let opponent_id = 1 - player_id ; let maybe_payoff = kuhn :: get_payoff ( & history , cards ); if maybe_payoff . is_some () { let payoff = match player_id { 0 => maybe_payoff . unwrap (), 1 => - maybe_payoff . unwrap (), _ => panic! ( \"unexpected player id {}\" , player_id ), }; return payoff as f64 ; } // not the terminal node let info_set = InformationSet { action_history : history . clone (), hand_card : cards [ player_id as usize ], }; if self . cfr_info . contains_key ( & info_set ) == false { self . cfr_info . insert ( info_set . clone (), CfrNode :: new ( 0.06 )); } let action_probs = self . cfr_info . get ( & info_set ) . unwrap () . get_action_probability (); let chosen_action_id = sample ( & action_probs ); let chosen_action = kuhn :: Action :: from_int ( chosen_action_id ); let chosen_action_prob = action_probs [ chosen_action_id as usize ]; let mut next_history = history . clone (); next_history . 0. push ( chosen_action ); // modify reach prob for SELF (not opponent) // update history probability let mut next_reach_probs = reach_probs . clone (); * next_reach_probs . get_mut ( & player_id ). unwrap () *= chosen_action_prob ; // recursive call // final payoff of the terminal node let final_payoff = - self . mccfr ( next_history , cards , next_reach_probs ); // update regret value let node = self . cfr_info . get_mut ( & info_set ). unwrap (); for ( action_id , action_prob ) in action_probs . iter (). enumerate () { let action = kuhn :: Action :: from_int ( action_id ); // reach probability of SELF (not opponent) let weight = final_payoff / reach_probs [ & player_id ] / action_prob ; if action == chosen_action { node . cum_regrets [ action_id ] += weight * ( 1.0 - action_prob ); } else { node . cum_regrets [ action_id ] += - weight * action_prob ; } } // update strategy for ( action_id , action_prob ) in action_probs . iter (). enumerate () { node . cum_strategy [ action_id ] += action_prob * reach_probs [ & player_id ]; } return final_payoff ; } \u7ed3\u679c Explore with epsilon=0.06 . Average payoff = -0.05138 History Check Probability Bet Probability 1 0.805 0.195 1C 0.68 0.32 1B 0.97 0.03 1CB 0.97 0.03 2 0.97 0.03 2C 0.94 0.05 2B 0.56 0.44 2CB 0.47 0.53 3 0.422 0.578 3C 0.03 0.97 3B 0.03 0.97 3CB 0.03 0.97 We get 0.03 here because we choose epsilon = 0.06 and we have 2 actions to choose from. Reference Monte Carlo Counterfactual Regret Minimization MCCFR technical report","title":"Monte Carlo CFR"},{"location":"mathematics/CFR/MonteCarloCfr/#monte-carlo-cfr","text":"\u5728\u4e0a\u4e00\u7bc7\u6587\u7ae0\u4e2d\uff0c\u6211\u4eec\u8bb2\u4e86\u7ecf\u5178\u7684 CFR \u7b97\u6cd5\u7684\u539f\u7406\u53ca\u5b9e\u73b0\u3002\u4f46\u662f\uff0c\u5b83\u4e5f\u6709\u4e24\u4e2a\u81f4\u547d\u7684\u7f3a\u9677\uff0c\u5bfc\u81f4\u65e0\u6cd5\u5e94\u7528\u5230\u5b9e\u9645\u7684\u590d\u6742\u535a\u5f08\u4e2d\uff1a \u5b83\u9700\u8981\u904d\u5386\u6574\u4e2a\u6e38\u620f\u6811 \u5b83\u9700\u8981\u77e5\u9053\u5bf9\u624b\u7684\u7b56\u7565\uff0c\u8fd9\u5728\u5b9e\u9645\u60c5\u51b5\u4e0b\u5f88\u96be\u6ee1\u8db3 \u672c\u6587\u5c06\u4ecb\u7ecd\u57fa\u4e8e Monte Carlo \u7684\u6539\u8fdb\u7b97\u6cd5\u3002\u5168\u90e8\u4ee3\u7801\u53ef\u4ee5\u53c2\u8003\u6211\u7684 github \u9879\u76ee\uff1a cfr-kuhn .","title":"Monte Carlo CFR"},{"location":"mathematics/CFR/MonteCarloCfr/#definition","text":"\u6838\u5fc3\u601d\u60f3\u662f\uff0c\u5728\u907f\u514d\u904d\u5386\u6574\u4e2a\u6e38\u620f\u6811\u7684\u524d\u63d0\u4e0b\uff0c\u6bcf\u4e2a information set \u7684\u6bcf\u4e2a action \u7684 counterfactual regret \u671f\u671b\u503c\u4fdd\u6301\u4e0d\u53d8\u3002 \u4ee4 \\(\\mathcal{Q} = \\{Q_1, Q_2, ..., Q_r \\}\\) \u662f\u6240\u6709 terminal node \\(Z\\) \u7684\u5b50\u96c6\uff0c\u5176\u4e2d\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20 \\(Q_j\\) \u6211\u4eec\u79f0\u4e3a block \uff0c\u6bcf\u4e2a block \u53ef\u80fd\u5305\u542b\u591a\u4e2a terminal node \u3002\u4ee4 \\(q_j > 0\\) \u662f\u9009\u62e9 \\(Q_j\\) \u7684\u6982\u7387\uff0c\u6ee1\u8db3 \\(\\sum_{j=1}^r q_j = 1\\) \u3002\u6bcf\u6b21\u8fed\u4ee3\uff0c\u6211\u4eec\u90fd\u4f1a\u4ece\u8fd9\u4e9b blocks \u4e2d\u91c7\u6837\u4e00\u4e2a\u5e76\u4e14\u53ea\u8003\u8651\u5728\u8be5 block \u4e2d\u7684 terminal node \u3002 \u56de\u5fc6 CFR \u7ecf\u5178\u7248\u7684 counterfactual value \u8ba1\u7b97\u516c\u5f0f\uff1a \\[ v_i(\\sigma, I) = \\sum_{z \\in Z_I } \\pi_{-i}^{\\sigma} (z[I]) \\pi ^{\\sigma} (z[I], z) u_i (z) \\] \u5728 MCCFR \u4e2d\uff0c\u5bf9\u4e8e block \\(Q_j\\) \u7684 sampled counterfactual value \u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\[v_i(\\sigma, I | j) = \\sum_{z \\in Q_j \\cap Z_I} \\frac{1}{q(z)} \\pi_{-i}^\\sigma (z[I]) \\pi^\\sigma (z[I], z) u_i(z)\\] \u5176\u4e2d\uff1a \\(z\\) \u662f terminal node \\(z_I\\) \u8868\u793a information set \\(I\\) \u53ef\u4ee5\u5230\u8fbe\u7684 \\(z\\) \u7684\u5168\u96c6 \\(z[I]\\) \u8868\u793a\u67d0\u4e2a\u53ef\u4ee5\u5230\u8fbe \\(z\\) \u7684 information set \\(i\\) \u8868\u793a\u73a9\u5bb6 id \\(j\\) \u8868\u793a block id \\(q(z)\\) \u8868\u793a \\(z\\) \u6240\u5728 block \u88ab\u9009\u4e2d\u7684\u6982\u7387\u4e4b\u548c\uff08\u4e00\u4e2a terminal node \u53ef\u4ee5\u88ab\u5206\u5230\u591a\u4e2a block \u4e2d\uff09 \u6211\u4eec\u53ef\u4ee5\u8bc1\u660e counterfactual value \u548c sampled counterfactual value \u671f\u671b\u662f\u76f8\u7b49\u7684\u3002 \u8fd9\u5c31\u662f MCCFR \u7684\u57fa\u672c\u601d\u60f3\u4e86\u3002\u4e8b\u5b9e\u4e0a\uff0cCFR \u53ef\u4ee5\u770b\u4f5c MCCFR \u5728 \\(\\mathcal{Q} = \\{Z\\}\\) \u4e14 \\(q_1 = 1.0\\) \u7684\u7279\u4f8b\u3002 \u6b64\u5916\uff0c\u6211\u4eec\u53ef\u4ee5__\u5c06\u6bcf\u4e00\u4e2a block \u9009\u4e3a chance node \u7684\u4e00\u4e2a\u5206\u652f__\u3002\u4ee5 Kuhn Poker \u4e3a\u4f8b\uff0c\u6211\u4eec\u5bf9\u4e8e\u624b\u724c 1\uff0c2\uff0c3 \u53ef\u4ee5\u5efa\u7acb 3 \u4e2a block\uff1a \\(\\{ Q_1, Q_2, Q_3 \\}\\) \uff0c\u5206\u522b\u5305\u542b\u624b\u724c\u4e3a 1\uff0c2\uff0c3 \u7684\u6240\u6709 terminal nodes\u3002\u4ece\u800c\uff0c\u6bcf\u4e2a block \u7684\u6982\u7387\u4e5f\u81ea\u7136\u4e3a \\(\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3}\\) \u3002\u8fd9\u5c31\u662f chance-sampled CFR\u3002","title":"Definition"},{"location":"mathematics/CFR/MonteCarloCfr/#outcome-sampling-mccfr","text":"\u5728 outcome-sampling MCCFR \u4e2d\uff0c\u6211\u4eec__\u628a\u6bcf\u4e2a terminal node \u4f5c\u4e3a\u4e00\u4e2a block__\u3002\u6bcf\u6b21\u8fed\u4ee3\uff0c\u6211\u4eec\u62bd\u53d6\u4e00\u4e2a terminal node \u5e76\u66f4\u65b0\u5b83\u7684\u524d\u7f00 information set\u3002\u4e00\u4e2a terminal node \u51fa\u73b0\u6982\u7387\u8d8a\u9ad8\uff0c\u6211\u4eec\u91c7\u6837\u6982\u7387\u4e5f\u8d8a\u9ad8\u3002\u56e0\u6b64\u6211\u4eec\u5fc5\u987b\u5f97\u5230\u6bcf\u4e2a terminal node j \u51fa\u73b0\u7684\u6982\u7387\u4f5c\u4e3a \\(q_j\\) \u3002\u5982\u4f55\u5f97\u5230\u5462\uff1f \u5728 CFR \u4e2d\uff0c\u6211\u4eec\u5728\u8ba1\u7b97 regret \u7684\u65f6\u5019\uff0c\u4f1a\u8ba1\u7b97\u5230\u8fbe\u6bcf\u4e2a history \u7684\u6982\u7387\u3002\u5bf9\u4e8e terminal node j\uff0c\u8fd9\u4e2a\u6982\u7387\u5176\u5b9e\u5c31\u662f\u91c7\u6837\u6982\u7387 \\(q_j\\) \u3002 CFR \u7b97\u6cd5\u5305\u542b\u4e86\u4e24\u4e2a\u65b9\u5411\u7684\u904d\u5386\uff1a \u524d\u5411\u904d\u5386\u3002\u7528\u4e8e\u8ba1\u7b97\u6bcf\u4e2a\u73a9\u5bb6\u4ece\u539f\u70b9\u5230\u8fbe\u5f53\u524d history \u7684\u6982\u7387 \\(\\pi_i^{\\sigma}(h)\\) \u540e\u5411\u904d\u5386\u3002\u7528\u4e8e\u8ba1\u7b97\u6bcf\u4e2a\u73a9\u5bb6\u4ece\u5f53\u524d history \u8fdb\u884c\u5230 terminal node \u7684\u6982\u7387 \\(\\pi_i^{\\sigma}(h,z)\\) \uff0c\u5728\u6b64\u8fc7\u7a0b\u4e2d\uff0c\u8fd8\u4f1a\u8ba1\u7b97 sampled counterfactual regrets\u3002 \u540e\u5411\u904d\u5386\u4e2d\u8ba1\u7b97 sampled counterfactual regrets \u4f1a\u5206\u4e3a\u4e24\u79cd\u60c5\u51b5\u3002 \u5176\u4e00\u662f\u9009\u62e9\u4e86\u80fd\u901a\u5411\u5f53\u524d terminal node \\(z\\) \u7684 action\u3002\u5373\uff0c\u5728information set \\(I\\) \u91c7\u53d6\u4e86\u884c\u52a8 \\(a\\) \uff0c\u6b64\u65f6\u8ba1\u7b97\u65b9\u5f0f\u4e3a\uff1a \\[ \\begin{align} r(I, a) &= v_i(\\sigma_{I \\rightarrow a}, I) - v_i(\\sigma, I) \\\\ &= \\frac{\\pi_{-i}^\\sigma (z[I]) \\pi^\\sigma (z[I]a, z) u_i(z)}{q(z)} - \\frac{\\pi_{-i}^\\sigma (z[I]) \\pi^\\sigma (z[I], z) u_i(z)}{q(z)} \\\\ &= \\frac{\\pi_{-i}^\\sigma (z[I]) \\pi^\\sigma (z[I] a, z) u_i(z)}{q(z)} ( 1 - \\sigma(a|z[I])) \\end{align} \\] \u4e0a\u5f0f\u6bd4\u8f83\u96be\u4ee5\u7406\u89e3\u7684\u662f\uff1a \\[\\pi^\\sigma (z[I] a, z) \\cdot \\sigma(a|z[I]) = \\pi^\\sigma (z[I], z) \\] \u7ed3\u5408\u5b9a\u4e49\uff0c \\(\\pi^\\sigma (z[I] a, z)\\) \u662f\u4ece \\(I + a\\) \u5230\u8fbe \\(z\\) \u7684\u6982\u7387\uff0c\u76f8\u6bd4 \\(\\pi^\\sigma (z[I], z)\\) \u591a\u524d\u8fdb\u4e86\u4e00\u6b65\uff08\u9009\u62e9\u884c\u52a8 \\(a\\) \uff09\uff0c\u5728 \\(I\\) \u9009\u62e9 \\(a\\) \u7684\u6982\u7387\u662f \\(\\sigma(a|z[I])\\) \uff0c\u56e0\u6b64\uff0c\u5982\u679c\u4ece \\(I\\) \u5230 \\(z\\) \u7684\u6982\u7387\u4e3a \\(p\\) \uff0c\u7531\u4e8e \\(I + a\\) \u5c06\u9009\u62e9 \\(a\\) \u7684\u6982\u7387\u7531\u539f\u672c\u7684 \\(\\sigma(a|z[I])\\) \u53d8\u6210\u4e86 1.0\uff0c\u5b83\u5230 \\(z\\) \u7684\u6982\u7387\u5c31\u53d8\u6210\u4e86 \\(p / \\sigma(a|z[I])\\) \u3002 \u53e6\u4e00\u79cd\u60c5\u51b5\u662f\u9009\u62e9\u4e86\u5176\u4ed6\u884c\u52a8\uff0c\u6b64\u65f6 \\(I + a\\) \u4e0d\u662f \\(z\\) \u7684\u524d\u7f00\u3002\u6b64\u65f6\u7684 sampled counterfactual value \u662f\uff1a \\[ \\begin{align} r(I, a) &= 0 - v_i(\\sigma, I) \\\\ &= - \\frac{\\pi_{-i}^\\sigma (z[I]) \\pi^\\sigma (z[I] a, z) u_i(z)}{q(z)} \\sigma(a|z[I]) \\end{align} \\] \u9009\u53d6 0 \u662f\u56e0\u4e3a\u8be5\u52a8\u4f5c\u7684\u540e\u6094\u503c\u66f4\u65b0\u4e0d\u5f52 \\(z\\) \u7ba1\u3002\u5fc5\u7136\u6709\u522b\u7684 terminal node \u7684\u524d\u7f00\u662f \\(I + a\\) \uff0c\u5f53\u91c7\u6837\u5230\u8fd9\u4e9b terminal node \u7684\u65f6\u5019\u81ea\u7136\u4f1a\u66f4\u65b0\u3002 \u6211\u4eec\u4ee4\uff1a \\[ w_I = \\frac{\\pi_{-i}^\\sigma (z[I]) \\pi^\\sigma (z[I] a, z) u_i(z)}{q(z)} \\] \u7531\u4e8e\u5728 outcome sampling \u4e2d\uff0c\u6bcf\u4e2a terminal node \\(z\\) \u90fd\u5bf9\u5e94\u4e00\u4e2a block \\(Q\\) \uff0c\u56e0\u6b64 \\(q(z)\\) \u5c31\u662f\u9009\u4e2d \\(Q\\) \u7684\u6982\u7387\u3002\u7406\u8bba\u4e0a\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u91c7\u6837\u7684\u771f\u5b9e\u6027\uff0c\u8fd9\u4e2a\u6982\u7387\u5e94\u8be5\u4e0e\u6240\u6709\u73a9\u5bb6\u9075\u5faa\u7b56\u7565 \\(\\sigma\\) \u8fdb\u884c\u6e38\u620f\u5230\u8fbe \\(z\\) \u7684\u6982\u7387\u76f8\u540c\uff0c\u5373 \\[q(z) = \\pi^\\sigma(z)\\] \u6839\u636e\u5b9a\u4e49\uff0c \\(\\pi_{-i}^\\sigma (z)\\) \u662f\u5bf9\u624b\u5230\u8fbe \\(z\\) \u7684\u6982\u7387\uff0c\u5728\u8ba1\u7b97\u65f6\uff0c\u5047\u8bbe\u73a9\u5bb6 \\(i\\) \u4ee5 1.0 \u7684\u6982\u7387\u9009\u62e9\u52a8\u4f5c\uff0c\u800c \\(\\pi_i^\\sigma (z)\\) \u76f8\u53cd\u3002\u4e24\u8005\u7684\u4e58\u79ef\u5c31\u662f\u4ece\u5c40\u5916\u65c1\u89c2\u8005\u770b\u6765\u5230\u8fbe \\(z\\) \u7684\u6982\u7387\u3002\u56e0\u6b64\u6709\uff1a \\[ \\begin{align} q(z) &= \\pi^\\sigma(z) \\\\ &= \\pi^\\sigma(z[I]) \\cdot \\pi^\\sigma(z[I], z) \\\\ &= \\pi_i^\\sigma (z[I]) \\cdot \\pi_{-i}^\\sigma (z[I]) \\cdot \\pi^\\sigma(z[I], z) \\end{align} \\] \u5e26\u5165\u5f97\u5230\uff1a \\[\\begin{align} w_I &= \\frac{\\pi_{-i}^\\sigma (z[I]) \\pi^\\sigma (z[I] a, z) u_i(z)}{q(z)} \\\\ &= \\frac{\\pi^\\sigma (z[I] a, z) u_i(z)}{ \\pi_i^\\sigma (z[I]) \\cdot \\pi^\\sigma(z[I], z)} \\\\ &= \\frac{\\pi_i^\\sigma(z[I]a, z) u_i(z)}{\\pi_i^\\sigma(z)} \\\\ &= \\frac{u_i(z)}{ \\pi_i^\\sigma (z[I]) \\cdot \\sigma(a|z[I])} \\end{align}\\] \u6ce8\u610f\u5728\u8fd9\u4e2a\u8868\u8fbe\u5f0f\u4e2d\uff0c\u6211\u4eec\u4e0d\u518d\u9700\u8981\u5bf9\u624b\u7684\u4fe1\u606f \uff08\u53ea\u6709\u5e26\u4e0b\u6807 \\(i\\) \u7684\u90e8\u5206\u4e86\uff09\u3002\u6211\u4eec\u5728\u5316\u7b80\u4e2d\u523b\u610f\u6d88\u53bb\u4e86\u5bf9\u624b \\(-i\\) \u76f8\u5173\u7684\u4fe1\u606f\u3002 \u6bcf\u6b21\u8fed\u4ee3\u7d2f\u8ba1\u540e\u6094\u503c\u4f1a\u589e\u52a0\uff1a \\[ r(I,a) = \\begin{cases} w_I \\cdot (1 - \\sigma(a|z[I]) & \\text{if} ~ z(z[I]a) \\sqsubset z \\\\ -w_I \\cdot \\sigma(a|z[I]) & \\text{otherwise} \\end{cases}\\] \u8fd9\u6837\u8ba1\u7b97\u53ef\u4ee5\u4fdd\u8bc1\u7d2f\u8ba1\u540e\u6094\u503c\u7684\u671f\u671b\u662f\u4e0e\u4f20\u7edf cfr \u76f8\u540c\u7684\u3002 \u6bcf\u6b21\u8fed\u4ee3\uff0c\u6bcf\u4e2a\u52a8\u4f5c\u7684\u7d2f\u8ba1 strategy \u589e\u52a0\uff1a \\[s(I, a) = \\pi_i^\\sigma(z[I]) \\cdot \\sigma(a|z[I]) \\] \u6ce8\uff1a\u8bba\u6587\u4e2d\u8fd8\u589e\u52a0\u4e86 \\(t - c_I\\) \u6743\u91cd\uff0c\u5373\u672c\u6b21 iteration \u548c\u4e0a\u6b21\u8bbf\u95ee \\(I\\) \u7684 iteration \u4e4b\u5dee\uff0c\u4f46\u662f\u6211\u52a0\u4e0a\u6743\u91cd\u540e\u65e0\u6cd5\u5f97\u5230\u6b63\u786e\u7ed3\u679c\uff0c\u5c1a\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002","title":"Outcome-Sampling MCCFR"},{"location":"mathematics/CFR/MonteCarloCfr/#_1","text":"\u76f8\u6bd4 cfr\uff0cmccfr \u7684\u4e0d\u540c\u4e3b\u8981\u6709\uff1a 1. \u65e0\u9700\u5bf9\u624b\uff08-i\uff09\u7684\u4fe1\u606f 2. \u65e0\u9700\u904d\u5386\u6240\u6709\u884c\u52a8 3. \u8ba1\u7b97\u540e\u6094\u503c\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c\u9700\u8981\u589e\u52a0\u4e00\u4e2a\u57fa\u4e8e\u91c7\u6837\u6982\u7387\u7684\u6743\u91cd\u3002 4. \u9700\u8981\u5f15\u5165 epsilon \u4fdd\u8bc1\u63a2\u7d22\u6240\u6709 action fn mccfr ( & mut self , history : kuhn :: ActionHistory , cards : & Vec < i32 > , reach_probs : HashMap < i32 , f64 > , ) -> f64 { // current active player let player_id = ( history . 0. len () % 2 ) as i32 ; let opponent_id = 1 - player_id ; let maybe_payoff = kuhn :: get_payoff ( & history , cards ); if maybe_payoff . is_some () { let payoff = match player_id { 0 => maybe_payoff . unwrap (), 1 => - maybe_payoff . unwrap (), _ => panic! ( \"unexpected player id {}\" , player_id ), }; return payoff as f64 ; } // not the terminal node let info_set = InformationSet { action_history : history . clone (), hand_card : cards [ player_id as usize ], }; if self . cfr_info . contains_key ( & info_set ) == false { self . cfr_info . insert ( info_set . clone (), CfrNode :: new ( 0.06 )); } let action_probs = self . cfr_info . get ( & info_set ) . unwrap () . get_action_probability (); let chosen_action_id = sample ( & action_probs ); let chosen_action = kuhn :: Action :: from_int ( chosen_action_id ); let chosen_action_prob = action_probs [ chosen_action_id as usize ]; let mut next_history = history . clone (); next_history . 0. push ( chosen_action ); // modify reach prob for SELF (not opponent) // update history probability let mut next_reach_probs = reach_probs . clone (); * next_reach_probs . get_mut ( & player_id ). unwrap () *= chosen_action_prob ; // recursive call // final payoff of the terminal node let final_payoff = - self . mccfr ( next_history , cards , next_reach_probs ); // update regret value let node = self . cfr_info . get_mut ( & info_set ). unwrap (); for ( action_id , action_prob ) in action_probs . iter (). enumerate () { let action = kuhn :: Action :: from_int ( action_id ); // reach probability of SELF (not opponent) let weight = final_payoff / reach_probs [ & player_id ] / action_prob ; if action == chosen_action { node . cum_regrets [ action_id ] += weight * ( 1.0 - action_prob ); } else { node . cum_regrets [ action_id ] += - weight * action_prob ; } } // update strategy for ( action_id , action_prob ) in action_probs . iter (). enumerate () { node . cum_strategy [ action_id ] += action_prob * reach_probs [ & player_id ]; } return final_payoff ; }","title":"\u5b9e\u73b0\u7ec6\u8282"},{"location":"mathematics/CFR/MonteCarloCfr/#_2","text":"Explore with epsilon=0.06 . Average payoff = -0.05138 History Check Probability Bet Probability 1 0.805 0.195 1C 0.68 0.32 1B 0.97 0.03 1CB 0.97 0.03 2 0.97 0.03 2C 0.94 0.05 2B 0.56 0.44 2CB 0.47 0.53 3 0.422 0.578 3C 0.03 0.97 3B 0.03 0.97 3CB 0.03 0.97 We get 0.03 here because we choose epsilon = 0.06 and we have 2 actions to choose from.","title":"\u7ed3\u679c"},{"location":"mathematics/CFR/MonteCarloCfr/#reference","text":"Monte Carlo Counterfactual Regret Minimization MCCFR technical report","title":"Reference"},{"location":"mathematics/CFR/RegretMatchingAndBlottoGame/","text":"Regret Matching and Blotto Game 1 \u57fa\u672c\u6982\u5ff5 2000 \u5e74\uff0cHart \u548c Mas-Colell \u4ecb\u7ecd\u4e86\u4e00\u4e2a\u91cd\u8981\u7684\u535a\u5f08\u8bba\u7b97\u6cd5 regret matching\u3002\u535a\u5f08\u53cc\u65b9\u901a\u8fc7\uff1a \u8bb0\u5f55\u540e\u6094\u503c \u6839\u636e\u540e\u6094\u503c\u7684\u6bd4\u4f8b\u5730\u9009\u62e9\u4e0b\u4e00\u6b65\u884c\u52a8 \u8fbe\u5230\u7eb3\u4ec0\u5747\u8861 (Nash equilibrium)\u3002\u8fd9\u4e2a\u80fd\u5f88\u597d\u5730\u89e3\u51b3\u6b63\u5219\u5f62\u5f0f\u7684\u535a\u5f08\uff08normal-form game\uff09\uff0c\u4f46\u662f\u5bf9\u6269\u5c55\u5f62\u5f0f\u7684\u535a\u5f08\uff08extensive-form game\uff09\u4e0d\u9002\u7528\u3002 \u6240\u8c13\u6b63\u5219\u5f62\u5f0f\uff0c\u662f\u4e00\u79cd\u63cf\u8ff0\u535a\u5f08\u7684\u65b9\u5f0f\u3002\u6b63\u5219\u5f62\u5f0f\u7528 n \u7ef4\u77e9\u9635\u6765\u63cf\u8ff0\u535a\u5f08\uff0c\u800c\u6269\u5c55\u5f62\u5f0f\u4f7f\u7528\u56fe\u3002\u6b63\u5219\u5f62\u5f0f\u53ea\u80fd\u63cf\u8ff0\u73a9\u5bb6\u540c\u65f6\u884c\u52a8\u7684\u535a\u5f08\u3002 1.1 \u535a\u5f08\u7684\u6b63\u5219\u5f62\u5f0f\u63cf\u8ff0 \u6b63\u5219\u5f62\u5f0f\u7684\u77e9\u9635\u63cf\u8ff0\u6709\u4ee5\u4e0b\u51e0\u4e2a\u8981\u7d20\uff1a 1. \u73a9\u5bb6\u6570\u91cf n \u5373\u7ef4\u5ea6 2. \u7ef4\u5ea6 i \u4e0a\u7684\u503c\u662f\u73a9\u5bb6 i \u7684\u884c\u52a8 3. \u77e9\u9635\u7684\u5143\u7d20\u662f\u5956\u52b1( payoff ) \u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u5982\u4e0b\u77e9\u9635\u6765\u63cf\u8ff0\u526a\u5200\u77f3\u5934\u5e03\u6e38\u620f\uff1a \u526a\u5200 \u77f3\u5934 \u5e03 \u526a\u5200 (0, 0) (-1, 1) (1, -1) \u77f3\u5934 (1, -1) (0, 0) (-1, 1) \u5e03 (-1, 1) (1, -1) (0, 0) \u5982\u679c\u77e9\u9635\u4e2d\u6240\u6709 payoff \u7684\u503c\u7684\u548c\u4e3a 0\uff0c\u5219\u79f0\u4e3a\u96f6\u548c\u535a\u5f08\u3002 1.2 \u73a9\u5bb6\u7b56\u7565 \u5982\u679c\u67d0\u4e2a\u73a9\u5bb6\u4ee5 100% \u7684\u6982\u7387\u91c7\u53d6\u4e00\u4e2a\u884c\u52a8 \uff08\u4f8b\u5982\u5fb7\u6251\u5168\u7a0b all in\uff09\uff0c\u79f0\u4e3a pure strategy\u3002\u5982\u679c\u4e00\u4e2a\u73a9\u5bb6\u53ef\u80fd\u91c7\u53d6\u591a\u79cd\u884c\u52a8\uff0c\u5c31\u79f0\u4e3a mixed strategy\u3002 \u6211\u4eec\u4f7f\u7528 \\(\\sigma\\) \u8868\u793a mixed strategy\uff0c \\(\\sigma_i(s)\\) \u8868\u793a\u73a9\u5bb6 \\(i\\) \u9009\u62e9\u884c\u52a8 \\(s\\) \u7684\u6982\u7387\uff0c \\(-i\\) \u8868\u793a \\(i\\) \u7684\u5bf9\u624b\u3002 \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u6cd5\u8ba1\u7b97\u73a9\u5bb6\u7684\u671f\u671b payoff\uff1a \\[u_i(\\sigma_i, \\sigma_{-i}) = \\sum_{s \\in S_i}\\sum_{s' \\in S_{-i}} \\sigma_i(s) \\sigma_{-i}(s')u_i(s, s')\\] \u5176\u5b9e\u5c31\u662f\u52a0\u6743\u6c42\u548c\u3002 2 Regret Matching and Minimization Regret matching \u7b97\u6cd5\u53ea\u80fd\u7528\u4e8e\u6b63\u5219\u5f62\u5f0f\u7684\u535a\u5f08\u3002\u5176\u57fa\u672c\u601d\u60f3\u4e3a\u6839\u636e payoff \u5bf9\u4e4b\u524d\u7684\u884c\u52a8\u4f5c\u6c42\u53cd\u6094\u503c\u3002\u518d\u5229\u7528\u7d2f\u8ba1\u7684\u53cd\u6094\u503c\u6307\u5bfc\u4e0b\u4e00\u6b65\u884c\u52a8\u3002 \u4ee5\u521a\u624d\u7684\u77f3\u5934\u526a\u5200\u5e03\u6e38\u620f\u4e3a\u4f8b\uff0c\u6211\u4eec\u51fa\u4e86\u77f3\u5934\uff0c\u5bf9\u624b\u51fa\u4e86\u5e03\uff0c\u6211\u4eec\u8f93\u6389\u4e86 1 \u5757\u94b1\uff0cpayoff \u662f -1\u3002\u6211\u4eec\u5982\u679c\u51fa\u5e03\uff0c\u662f\u5e73\u5c40\uff0cpayoff \u662f 0\uff0c\u5982\u679c\u51fa\u526a\u5200\uff0c\u5c31\u8d62\u4e86\uff0cpayoff \u662f 1\u3002payoff \u5dee\u503c\u5373\u53cd\u6094\u503c\u5206\u522b\u662f (0\uff0c1\uff0c2)\u3002\u5c06\u5176 normalize\uff0c\u4e0b\u4e00\u6b21\u51fa\u77f3\u5934\u3001\u5e03\u3001\u526a\u5200\u7684\u6982\u7387\u5206\u522b\u662f (0\uff0c1/3\uff0c2/3)\u3002 \u5047\u8bbe\u7b2c\u4e8c\u6b21\u6211\u4eec\u51fa\u4e86\u526a\u5200\uff0c\u5bf9\u624b\u51fa\u4e86\u77f3\u5934\u3002\u6211\u4eec\u518d\u6b21\u8f93\u6389\u4e86 1 \u5757\u94b1\u3002\u8fd9\u6b21\u6211\u4eec\u5bf9\u77f3\u5934\u3001\u5e03\u3001\u526a\u5200\u7684\u53cd\u6094\u503c\u5206\u522b\u662f(1\uff0c2\uff0c0)\u3002\u7d2f\u52a0\u5230\u4e4b\u524d\u7684 (0\uff0c1\uff0c2) \u4e0a\u4e3a (1\uff0c3\uff0c2)\u3002\u4e0b\u4e00\u6b21\u51fa\u77f3\u5934\u3001\u5e03\u3001\u526a\u5200\u7684\u6982\u7387\u4e3a (1/6, 3/6, 2/6)\u3002 Exercise: Colonel Blotto Colonel Blotto and his arch-enemy, Boba Fett, are at war. Each commander has S soldiers in total, and each soldier can be assigned to one of N < S battlefields. Naturally, these commanders do not communicate and hence direct their soldiers independently. Any number of soldiers can be allocated to each battlefield, including zero. A commander claims a battlefield if they send more soldiers to the battlefield than their opponent. The commander\u2019s job is to break down his pool of soldiers into groups to which he assigned to each battlefield. The winning commander is the one who claims the most battlefields. For example, with (S,N) = (10,4) a Colonel Blotto may choose to play (2,2,2,4) while Boba Fett may choose to play (8,1,1,0). In this case, Colonel Blotto would win by claiming three of the four battlefields. The war ends in a draw if both commanders claim the same number of battlefields. \u8ba9\u4e24\u4e2a\u4f7f\u7528 regret matching \u7684\u73a9\u5bb6\u8fdb\u884c\u5bf9\u6218\uff0c\u9009\u5b9a S=5 \u548c N=3\uff0c\u627e\u5230 Nash Equilibrium\u3002 \u8981\u70b9\uff1a \u5217\u51fa\u6240\u6709\u5206\u914d\u65b9\u6cd5\uff0c\u4f5c\u4e3a\u53ef\u80fd\u7684 action set\uff0c\u4ece 0 \u5f00\u59cb\u4f9d\u6b21\u7f16\u53f7 \u7528\u4e00\u4e2a 2 \u7ef4\u77e9\u9635\u5b58\u50a8 action \u5bf9 action \u7684\u80dc\u8d1f\u8868\uff0c\u5373\u5f97\u5230 blotto \u535a\u5f08\u7684\u77e9\u9635\u63cf\u8ff0 \u5404\u4e2a\u73a9\u5bb6\u6839\u636e\u5728\u5177\u6709\u6b63\u53cd\u6094\u503c\u7684 action \u4e2d\uff0c\u6839\u636e\u53cd\u6094\u503c\u968f\u673a\u9009\u62e9\u4e00\u4e2a action\u3002\u82e5\u4e0d\u5b58\u5728\u6b63\u53cd\u6094\u503c\u7684 action\uff08\u4f8b\u5982\u7b2c\u4e00\u8f6e\uff09\uff0c\u5219\u968f\u673a\u9009\u62e9\u521d\u59cb action\u3002 \u5404\u4e2a\u73a9\u5bb6\u5728\u6e38\u620f\u7ed3\u675f\u65f6\u5f97\u5230\u5bf9\u624b\u7684 action\uff0c\u5e76\u66f4\u65b0\u81ea\u5df1\u7684\u53cd\u6094\u503c \u4ee3\u7801\u5b9e\u73b0\u89c1 https://github.com/double-free/cfr \uff0c\u8fd0\u884c 10 \u4e07\u6b21\u7ed3\u679c\u5982\u4e0b\uff08\u7ed3\u679c\u5177\u6709\u4e00\u5b9a\u968f\u673a\u6027\uff09\u3002 \u53ef\u80fd\u7684\u5206\u914d\u65b9\u5f0f\uff1a [0, 0, 5], [0, 1, 4], [0, 2, 3], [0, 3, 2], [0, 4, 1], [0, 5, 0], [1, 0, 4], [1, 1, 3], [1, 2, 2], [1, 3, 1], [1, 4, 0], [2, 0, 3], [2, 1, 2], [2, 2, 1], [2, 3, 0], [3, 0, 2], [3, 1, 1], [3, 2, 0], [4, 0, 1], [4, 1, 0], [5, 0, 0], \u6bcf\u4e2a\u5206\u914d\u65b9\u5f0f\u5bf9\u5e94\u7684\u53cd\u6094\u503c\uff1a player 1: for opponent 0, regret sum for each action [-55002, -10612, -45, -41, -11250, -55644, -10426, 25, -11075, 127, -11068, 109, -11107, -11009, 207, -74, -92, 20, -11636, -11640, -56029] \u6700\u7ec8\u8fd8\u5177\u6709\u6b63\u53cd\u6094\u503c\u7684 action\uff1a player 1: for opponent 0, candidate strategy Allocation { soldiers: [1, 1, 3] } has positive regret 25 player 1: for opponent 0, candidate strategy Allocation { soldiers: [1, 3, 1] } has positive regret 127 player 1: for opponent 0, candidate strategy Allocation { soldiers: [2, 0, 3] } has positive regret 109 player 1: for opponent 0, candidate strategy Allocation { soldiers: [2, 3, 0] } has positive regret 207 player 1: for opponent 0, candidate strategy Allocation { soldiers: [3, 2, 0] } has positive regret 20 \u7ed3\u679c\u8fd8\u662f\u76f8\u5bf9\u7b26\u5408\u76f4\u89c9\u7684\u3002 Reference \u53cd\u4e8b\u5b9e\u540e\u6094\u6700\u5c0f\u5316 An Introduction to Counterfactual Regret Minimization Game Basics Monte Carlo Tree Search Counterfactual Regret Minimization","title":"Regret Matching and Blotto Game"},{"location":"mathematics/CFR/RegretMatchingAndBlottoGame/#regret-matching-and-blotto-game","text":"","title":"Regret Matching and Blotto Game"},{"location":"mathematics/CFR/RegretMatchingAndBlottoGame/#1","text":"2000 \u5e74\uff0cHart \u548c Mas-Colell \u4ecb\u7ecd\u4e86\u4e00\u4e2a\u91cd\u8981\u7684\u535a\u5f08\u8bba\u7b97\u6cd5 regret matching\u3002\u535a\u5f08\u53cc\u65b9\u901a\u8fc7\uff1a \u8bb0\u5f55\u540e\u6094\u503c \u6839\u636e\u540e\u6094\u503c\u7684\u6bd4\u4f8b\u5730\u9009\u62e9\u4e0b\u4e00\u6b65\u884c\u52a8 \u8fbe\u5230\u7eb3\u4ec0\u5747\u8861 (Nash equilibrium)\u3002\u8fd9\u4e2a\u80fd\u5f88\u597d\u5730\u89e3\u51b3\u6b63\u5219\u5f62\u5f0f\u7684\u535a\u5f08\uff08normal-form game\uff09\uff0c\u4f46\u662f\u5bf9\u6269\u5c55\u5f62\u5f0f\u7684\u535a\u5f08\uff08extensive-form game\uff09\u4e0d\u9002\u7528\u3002 \u6240\u8c13\u6b63\u5219\u5f62\u5f0f\uff0c\u662f\u4e00\u79cd\u63cf\u8ff0\u535a\u5f08\u7684\u65b9\u5f0f\u3002\u6b63\u5219\u5f62\u5f0f\u7528 n \u7ef4\u77e9\u9635\u6765\u63cf\u8ff0\u535a\u5f08\uff0c\u800c\u6269\u5c55\u5f62\u5f0f\u4f7f\u7528\u56fe\u3002\u6b63\u5219\u5f62\u5f0f\u53ea\u80fd\u63cf\u8ff0\u73a9\u5bb6\u540c\u65f6\u884c\u52a8\u7684\u535a\u5f08\u3002","title":"1 \u57fa\u672c\u6982\u5ff5"},{"location":"mathematics/CFR/RegretMatchingAndBlottoGame/#11","text":"\u6b63\u5219\u5f62\u5f0f\u7684\u77e9\u9635\u63cf\u8ff0\u6709\u4ee5\u4e0b\u51e0\u4e2a\u8981\u7d20\uff1a 1. \u73a9\u5bb6\u6570\u91cf n \u5373\u7ef4\u5ea6 2. \u7ef4\u5ea6 i \u4e0a\u7684\u503c\u662f\u73a9\u5bb6 i \u7684\u884c\u52a8 3. \u77e9\u9635\u7684\u5143\u7d20\u662f\u5956\u52b1( payoff ) \u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u5982\u4e0b\u77e9\u9635\u6765\u63cf\u8ff0\u526a\u5200\u77f3\u5934\u5e03\u6e38\u620f\uff1a \u526a\u5200 \u77f3\u5934 \u5e03 \u526a\u5200 (0, 0) (-1, 1) (1, -1) \u77f3\u5934 (1, -1) (0, 0) (-1, 1) \u5e03 (-1, 1) (1, -1) (0, 0) \u5982\u679c\u77e9\u9635\u4e2d\u6240\u6709 payoff \u7684\u503c\u7684\u548c\u4e3a 0\uff0c\u5219\u79f0\u4e3a\u96f6\u548c\u535a\u5f08\u3002","title":"1.1 \u535a\u5f08\u7684\u6b63\u5219\u5f62\u5f0f\u63cf\u8ff0"},{"location":"mathematics/CFR/RegretMatchingAndBlottoGame/#12","text":"\u5982\u679c\u67d0\u4e2a\u73a9\u5bb6\u4ee5 100% \u7684\u6982\u7387\u91c7\u53d6\u4e00\u4e2a\u884c\u52a8 \uff08\u4f8b\u5982\u5fb7\u6251\u5168\u7a0b all in\uff09\uff0c\u79f0\u4e3a pure strategy\u3002\u5982\u679c\u4e00\u4e2a\u73a9\u5bb6\u53ef\u80fd\u91c7\u53d6\u591a\u79cd\u884c\u52a8\uff0c\u5c31\u79f0\u4e3a mixed strategy\u3002 \u6211\u4eec\u4f7f\u7528 \\(\\sigma\\) \u8868\u793a mixed strategy\uff0c \\(\\sigma_i(s)\\) \u8868\u793a\u73a9\u5bb6 \\(i\\) \u9009\u62e9\u884c\u52a8 \\(s\\) \u7684\u6982\u7387\uff0c \\(-i\\) \u8868\u793a \\(i\\) \u7684\u5bf9\u624b\u3002 \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u6cd5\u8ba1\u7b97\u73a9\u5bb6\u7684\u671f\u671b payoff\uff1a \\[u_i(\\sigma_i, \\sigma_{-i}) = \\sum_{s \\in S_i}\\sum_{s' \\in S_{-i}} \\sigma_i(s) \\sigma_{-i}(s')u_i(s, s')\\] \u5176\u5b9e\u5c31\u662f\u52a0\u6743\u6c42\u548c\u3002","title":"1.2 \u73a9\u5bb6\u7b56\u7565"},{"location":"mathematics/CFR/RegretMatchingAndBlottoGame/#2-regret-matching-and-minimization","text":"Regret matching \u7b97\u6cd5\u53ea\u80fd\u7528\u4e8e\u6b63\u5219\u5f62\u5f0f\u7684\u535a\u5f08\u3002\u5176\u57fa\u672c\u601d\u60f3\u4e3a\u6839\u636e payoff \u5bf9\u4e4b\u524d\u7684\u884c\u52a8\u4f5c\u6c42\u53cd\u6094\u503c\u3002\u518d\u5229\u7528\u7d2f\u8ba1\u7684\u53cd\u6094\u503c\u6307\u5bfc\u4e0b\u4e00\u6b65\u884c\u52a8\u3002 \u4ee5\u521a\u624d\u7684\u77f3\u5934\u526a\u5200\u5e03\u6e38\u620f\u4e3a\u4f8b\uff0c\u6211\u4eec\u51fa\u4e86\u77f3\u5934\uff0c\u5bf9\u624b\u51fa\u4e86\u5e03\uff0c\u6211\u4eec\u8f93\u6389\u4e86 1 \u5757\u94b1\uff0cpayoff \u662f -1\u3002\u6211\u4eec\u5982\u679c\u51fa\u5e03\uff0c\u662f\u5e73\u5c40\uff0cpayoff \u662f 0\uff0c\u5982\u679c\u51fa\u526a\u5200\uff0c\u5c31\u8d62\u4e86\uff0cpayoff \u662f 1\u3002payoff \u5dee\u503c\u5373\u53cd\u6094\u503c\u5206\u522b\u662f (0\uff0c1\uff0c2)\u3002\u5c06\u5176 normalize\uff0c\u4e0b\u4e00\u6b21\u51fa\u77f3\u5934\u3001\u5e03\u3001\u526a\u5200\u7684\u6982\u7387\u5206\u522b\u662f (0\uff0c1/3\uff0c2/3)\u3002 \u5047\u8bbe\u7b2c\u4e8c\u6b21\u6211\u4eec\u51fa\u4e86\u526a\u5200\uff0c\u5bf9\u624b\u51fa\u4e86\u77f3\u5934\u3002\u6211\u4eec\u518d\u6b21\u8f93\u6389\u4e86 1 \u5757\u94b1\u3002\u8fd9\u6b21\u6211\u4eec\u5bf9\u77f3\u5934\u3001\u5e03\u3001\u526a\u5200\u7684\u53cd\u6094\u503c\u5206\u522b\u662f(1\uff0c2\uff0c0)\u3002\u7d2f\u52a0\u5230\u4e4b\u524d\u7684 (0\uff0c1\uff0c2) \u4e0a\u4e3a (1\uff0c3\uff0c2)\u3002\u4e0b\u4e00\u6b21\u51fa\u77f3\u5934\u3001\u5e03\u3001\u526a\u5200\u7684\u6982\u7387\u4e3a (1/6, 3/6, 2/6)\u3002","title":"2 Regret Matching and Minimization"},{"location":"mathematics/CFR/RegretMatchingAndBlottoGame/#exercise-colonel-blotto","text":"Colonel Blotto and his arch-enemy, Boba Fett, are at war. Each commander has S soldiers in total, and each soldier can be assigned to one of N < S battlefields. Naturally, these commanders do not communicate and hence direct their soldiers independently. Any number of soldiers can be allocated to each battlefield, including zero. A commander claims a battlefield if they send more soldiers to the battlefield than their opponent. The commander\u2019s job is to break down his pool of soldiers into groups to which he assigned to each battlefield. The winning commander is the one who claims the most battlefields. For example, with (S,N) = (10,4) a Colonel Blotto may choose to play (2,2,2,4) while Boba Fett may choose to play (8,1,1,0). In this case, Colonel Blotto would win by claiming three of the four battlefields. The war ends in a draw if both commanders claim the same number of battlefields. \u8ba9\u4e24\u4e2a\u4f7f\u7528 regret matching \u7684\u73a9\u5bb6\u8fdb\u884c\u5bf9\u6218\uff0c\u9009\u5b9a S=5 \u548c N=3\uff0c\u627e\u5230 Nash Equilibrium\u3002 \u8981\u70b9\uff1a \u5217\u51fa\u6240\u6709\u5206\u914d\u65b9\u6cd5\uff0c\u4f5c\u4e3a\u53ef\u80fd\u7684 action set\uff0c\u4ece 0 \u5f00\u59cb\u4f9d\u6b21\u7f16\u53f7 \u7528\u4e00\u4e2a 2 \u7ef4\u77e9\u9635\u5b58\u50a8 action \u5bf9 action \u7684\u80dc\u8d1f\u8868\uff0c\u5373\u5f97\u5230 blotto \u535a\u5f08\u7684\u77e9\u9635\u63cf\u8ff0 \u5404\u4e2a\u73a9\u5bb6\u6839\u636e\u5728\u5177\u6709\u6b63\u53cd\u6094\u503c\u7684 action \u4e2d\uff0c\u6839\u636e\u53cd\u6094\u503c\u968f\u673a\u9009\u62e9\u4e00\u4e2a action\u3002\u82e5\u4e0d\u5b58\u5728\u6b63\u53cd\u6094\u503c\u7684 action\uff08\u4f8b\u5982\u7b2c\u4e00\u8f6e\uff09\uff0c\u5219\u968f\u673a\u9009\u62e9\u521d\u59cb action\u3002 \u5404\u4e2a\u73a9\u5bb6\u5728\u6e38\u620f\u7ed3\u675f\u65f6\u5f97\u5230\u5bf9\u624b\u7684 action\uff0c\u5e76\u66f4\u65b0\u81ea\u5df1\u7684\u53cd\u6094\u503c \u4ee3\u7801\u5b9e\u73b0\u89c1 https://github.com/double-free/cfr \uff0c\u8fd0\u884c 10 \u4e07\u6b21\u7ed3\u679c\u5982\u4e0b\uff08\u7ed3\u679c\u5177\u6709\u4e00\u5b9a\u968f\u673a\u6027\uff09\u3002 \u53ef\u80fd\u7684\u5206\u914d\u65b9\u5f0f\uff1a [0, 0, 5], [0, 1, 4], [0, 2, 3], [0, 3, 2], [0, 4, 1], [0, 5, 0], [1, 0, 4], [1, 1, 3], [1, 2, 2], [1, 3, 1], [1, 4, 0], [2, 0, 3], [2, 1, 2], [2, 2, 1], [2, 3, 0], [3, 0, 2], [3, 1, 1], [3, 2, 0], [4, 0, 1], [4, 1, 0], [5, 0, 0], \u6bcf\u4e2a\u5206\u914d\u65b9\u5f0f\u5bf9\u5e94\u7684\u53cd\u6094\u503c\uff1a player 1: for opponent 0, regret sum for each action [-55002, -10612, -45, -41, -11250, -55644, -10426, 25, -11075, 127, -11068, 109, -11107, -11009, 207, -74, -92, 20, -11636, -11640, -56029] \u6700\u7ec8\u8fd8\u5177\u6709\u6b63\u53cd\u6094\u503c\u7684 action\uff1a player 1: for opponent 0, candidate strategy Allocation { soldiers: [1, 1, 3] } has positive regret 25 player 1: for opponent 0, candidate strategy Allocation { soldiers: [1, 3, 1] } has positive regret 127 player 1: for opponent 0, candidate strategy Allocation { soldiers: [2, 0, 3] } has positive regret 109 player 1: for opponent 0, candidate strategy Allocation { soldiers: [2, 3, 0] } has positive regret 207 player 1: for opponent 0, candidate strategy Allocation { soldiers: [3, 2, 0] } has positive regret 20 \u7ed3\u679c\u8fd8\u662f\u76f8\u5bf9\u7b26\u5408\u76f4\u89c9\u7684\u3002","title":"Exercise: Colonel Blotto"},{"location":"mathematics/CFR/RegretMatchingAndBlottoGame/#reference","text":"\u53cd\u4e8b\u5b9e\u540e\u6094\u6700\u5c0f\u5316 An Introduction to Counterfactual Regret Minimization Game Basics Monte Carlo Tree Search Counterfactual Regret Minimization","title":"Reference"},{"location":"mathematics/ESL/ESL10_BoostingMethods/","text":"ESL 10.1: Boosting Methods Boosting \u6700\u521d\u662f\u4e3a\u89e3\u51b3\u5206\u7c7b\u95ee\u9898\u8bbe\u8ba1\u7684\uff0c\u540e\u6765\u53c8\u88ab\u6269\u5c55\u5230\u4e86\u56de\u5f52\u95ee\u9898\u3002Boosting \u7684\u539f\u7406\u662f\u5c06\u5f88\u591a\u5f31\u5206\u7c7b\u5668\u7ec4\u5408\u8d77\u6765\u4ea7\u751f\u4e00\u4e2a\u5f3a\u5206\u7c7b\u5668\u3002 \u4e00\u4e2a\u5f31\u5206\u7c7b\u5668\u662f\u67d0\u79cd\u6bd4\u968f\u673a\u731c\u6d4b\u7ed3\u679c\u7565\u597d\u7684\u7b80\u5355\u5206\u7c7b\u5668\u3002Boosting \u6bcf\u6b21\u5c06\u8f93\u5165\u7279\u5f81\u8d4b\u4e88\u4e0d\u540c\u7684\u6743\u91cd\uff0c\u5e76\u5e94\u7528\u5f31\u5206\u7c7b\u5668\u8fdb\u884c\u5206\u7c7b\uff0c\u6700\u540e\u5c06\u6240\u6709\u7ed3\u679c\u901a\u8fc7\u6295\u7968\u7684\u5f62\u5f0f\u4ea7\u751f\u6700\u7ec8\u7ed3\u679c\u3002 AdaBoost \u6211\u4eec\u4ece\u6700\u57fa\u672c\u7684 AdaBoost \u5f00\u59cb\u4ecb\u7ecd\u3002 \u5047\u8bbe\u67d0\u4e2a\u5206\u7c7b\u95ee\u9898\u7ed3\u679c\u4e3a -1 \u6216\u8005 +1\u3002\u4e00\u5171\u6709 \\(N\\) \u4e2a\u6837\u672c\uff0c\u5e76\u4e14\u6211\u4eec\u5df2\u6709 \\(M\\) \u4e2a\u5f31\u5206\u7c7b\u5668\u3002AdaBoost\u7b97\u6cd5\u8868\u8ff0\u4e3a\uff1a \u521d\u59cb\u5316\u6743\u91cd \\(w_i = 1/N, i = 1,2,...,N\\) For \\(m = 1\\) to \\(M\\) : a. \u5bf9\u6bcf\u4e2a\u6837\u672c \\(x_i\\) \u9644\u52a0\u6743\u91cd \\(w_i\\) \u5e76\u9001\u5165\u5206\u7c7b\u5668 \\(G_m(x)\\) b. \u8ba1\u7b97\u9519\u8bef\u7387\uff1a \\[ \\text{err}_m = \\sum_{i=1}^N w_i I(y_i \\neq G_m(x_i)) \\] c. \u6839\u636e\u9519\u8bef\u7387\u8ba1\u7b97\u8be5\u5206\u7c7b\u5668\u6743\u91cd\uff08\u9519\u8bef\u7387\u8d8a\u4f4e\u6743\u91cd\u8d8a\u9ad8\uff09 \\[\\alpha_m = \\ln((1- \\text{err}_m)/\\text{err}_m)\\] d. \u66f4\u65b0\u5206\u7c7b\u9519\u8bef\u7684\u6837\u672c\u6743\u91cd\uff0c\u5e76\u5f52\u4e00\u5316\u5904\u7406\uff08\u5224\u65ad\u9519\u8bef\u7684\u6837\u672c\u6743\u91cd\u63d0\u9ad8\uff0c\u4ea4\u7531\u4e0b\u4e00\u4e2a\u5206\u7c7b\u5668\u5206\u7c7b\uff09 \\[w_i = \\text{normalize} [ w_i e^{\\alpha_m I(y_i \\neq G_m(x_i))} ]\\] \u6700\u7ec8\u751f\u6210\u7684\u5f3a\u5206\u7c7b\u5668\u4e3a\uff1a \\[G(x) = \\text{sign} [ \\sum_{m=1}^M \\alpha_m G_m(x)] \\] \u5176\u4e2d\uff0c \\(I(x)\\) \u662f\u6761\u4ef6\u5224\u65ad\u3002false = 0, true = 1\u3002 2.d \u6bd4\u8f83\u96be\u7406\u89e3\u3002\u8c03\u6574\u6837\u672c\u6743\u91cd\u7684\u610f\u4e49\u5728\u4e8e\uff0c\u5982\u679c\u67d0\u4e2a\u5206\u7c7b\u5668\u5df2\u7ecf\u6b63\u786e\u5206\u7c7b i \u6837\u672c\uff0c\u540e\u7eed\u7684\u5206\u7c7b\u5668\u7684\u8d23\u4efb\u5728\u4e8e\u201c\u8865\u5168\u201d A \u5206\u7c7b\u5668\u7684\u529f\u80fd\uff0c\u5373\uff0c\u4e0d\u8981\u91cd\u590d\u6b63\u786e\u7684\u7ed3\u8bba\uff0c\u5e94\u8be5\u628a\u91cd\u70b9\u653e\u5728 A \u5206\u7c7b\u9519\u8bef\u7684\u6837\u672c\u4e0a\u3002 \u5982\u679c\u540e\u7eed\u67d0\u4e2a\u5206\u7c7b\u5668\u4e0e A \u5206\u7c7b\u5668\u7684\u7ed3\u8bba\u91cd\u590d\uff0c\u90a3\u7531 2.c \u5f97\u5230\u7684\u5206\u7c7b\u5668\u6743\u91cd\u4f1a\u5f88\u4f4e\u3002\u5728\u6700\u7ec8\u7684\u5f3a\u5206\u7c7b\u5668\u4e2d\uff0c\u51e0\u4e4e\u4e0d\u4ea7\u751f\u5f71\u54cd\u3002\u53cd\u4e4b\uff0c\u5982\u679c\u4e0e A \u4e92\u8865\uff0c\u90a3\u53ef\u80fd\u4f1a\u5f97\u5230\u4e00\u4e2a\u5f88\u9ad8\u7684\u6743\u91cd\u3002 AdaBoost \u7b80\u5355\u4f8b\u5b50 \u5047\u8bbe\u6709\u5982\u4e0b\u8bad\u7ec3\u6570\u636e\uff0c\u4e24\u4e2a\u70b9 (0.5, 1.5) \u548c (1.5, 1.5) \u88ab\u6807\u8bb0\u4e86 + \u7c7b\uff0c\u4e09\u4e2a\u70b9 (1.5, 0.5), (2.5, 1.5) \u548c (2.5, 2.5) \u88ab\u6807\u8bb0\u4e86 - \u7c7b\u3002 \u6211\u4eec\u6709\u5982\u4e0b\u5206\u7c7b\u5668\uff08\u90fd\u6bd4\u968f\u673a\u731c\u6d4b\u7565\u597d\uff09\uff1a \\[G_1(x) = \\begin{cases} +1 & x_1 \\leq 2 \\\\ -1 & x_1 > 2 \\end{cases} \\] \\[G_2(x) = \\begin{cases} -1 & x_2 \\leq 1 \\\\ +1 & x_2 > 1 \\\\ \\end{cases} \\] \\[G_3(x) = \\begin{cases} +1 & x_1 \\leq 1 \\\\ -1 & x_1 > 1 \\end{cases} \\] \u9996\u5148\uff0c\u7531\u4e8e\u6211\u4eec\u6709 5 \u4e2a\u6837\u672c\uff0c\u6211\u4eec\u5c06\u6837\u672c\u521d\u59cb\u6743\u91cd\u8bbe\u7f6e\u4e3a \\(w_i = 0.2\\) \uff0c\u5e94\u7528 \\(G_1\\) \u5206\u7c7b\u5668\uff0c\u53d1\u73b0\u4ec5\u6709\u4f4d\u4e8e (1.5, 0.5) \u7684\u70b9\u5206\u7c7b\u9519\u8bef\uff0c\u56e0\u6b64 \\(G_1\\) \u5206\u7c7b\u5668\u9519\u8bef\u7387\u4e3a\uff1a \\[\\text{err}_1 = 0.2 \\] \u8ba1\u7b97 \\(G_1\\) \u5206\u7c7b\u5668\u6743\u91cd\uff1a \\[ \\alpha_1 = \\ln ((1-0.2) / 0.2) = \\ln 4\\] \u8c03\u6574\u5206\u7c7b\u9519\u8bef\u7684\u6837\u672c\u6743\u91cd\u5e76\u5f52\u4e00\u5316\uff1a \\[ w_i = \\text{normalize} [ 0.2, 0.2, 0.2, 0.2, 0.8] = [\\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{4}{8}] \\] \u6b64\u540e\u518d\u5c06\u65b0\u7684\u6743\u91cd\u7528\u4e8e \\(G_2\\) \u7684\u5206\u7c7b\uff0c \\(G_2\\) \u5728 (2.5, 1.5) \u548c (2.5, 2.5) \u5206\u7c7b\u9519\u8bef\uff0c\u5176\u9519\u8bef\u7387\u4e3a\uff1a \\[ \\text{err}_2 = \\frac{1 }{8} *1 + \\frac{1}{8} *1 = \\frac{1}{4} \\] \\(G_2\\) \u7684\u5206\u7c7b\u5668\u6743\u91cd\u4e3a\uff1a \\[ \\alpha_2 = \\ln ((1-0.25) / 0.25) = \\ln 3\\] \u63a5\u4e0b\u6765\uff0c\u66f4\u65b0\u6837\u672c\u6743\u91cd\uff0c\u5c06\u5206\u7c7b\u9519\u8bef\u7684\u6837\u672c\u6743\u91cd\u63d0\u9ad8\uff1a \\[ w_i = \\text{normalize} [\\frac{3}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{3}{8}, \\frac{4}{8}] = [\\frac{3}{12}, \\frac{1}{12}, \\frac{1}{12}, \\frac{3}{12}, \\frac{4}{12}] \\] \u518d\u7528 \\(G_3\\) \u5206\u7c7b\uff0c\u540c\u4e0a\uff0c\u5b83\u5728 (1.5, 1.5) \u70b9\u5206\u7c7b\u9519\u8bef\uff0c\u800c\u8be5\u70b9\u6743\u91cd\u76ee\u524d\u4e3a \\(\\frac{1}{12}\\) \uff0c\u56e0\u6b64\u5176\u9519\u8bef\u7387\uff1a \\[ \\text{err}_3 = \\frac{1 }{12} \\] \\(G_3\\) \u5206\u7c7b\u5668\u6743\u91cd\u4e3a\uff1a \\[ \\alpha_3 = \\ln 11\\] \u5f97\u51fa\u6700\u7ec8 boosted \u5206\u7c7b\u5668\uff08\u6ce8\u610f\uff0c\u8fd9\u91cc\u4f53\u73b0\u4e86 \u52a0\u6027\u6a21\u578b \u7279\u70b9\uff09\uff1a \\[G(x) = \\text{sign} [\\ln4 G_1(x) + \\ln3 G_2(x) + \\ln11 G_3(x)] \\] \u5bf9\u4e8e\u6bcf\u4e2a\u533a\u57df\uff0c\u6211\u4eec\u8ba1\u7b97\u5176\u503c\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e \\(x_1\\) \u548c \\(x_2\\) \u90fd\u5c5e\u4e8e [0, 1) \u533a\u95f4\u7684\u70b9\uff1a \\[ G(x_0) = \\text{sign} [\\ln4 \\times 1 + \\ln3 \\times (-1) + \\ln11 \\times 1] = \\text{sign} 2.69 = 1 \\] \u4f9d\u6b21\u8ba1\u7b97\u5404\u4e2a\u533a\u57df\uff0c\u5f97\u5230\u7684\u8fb9\u754c\u4e3a\uff1a \u8fd9\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\u63ed\u793a\u4e86 AdaBoost \u7684\u5de5\u4f5c\u539f\u7406\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u5b83\u5982\u4f55\u5bf9 \u7ebf\u6027 \u5206\u7c7b\u5668\u8fdb\u884c \u7ebf\u6027\u7ec4\u5408 \uff0c\u6700\u7ec8\u5f97\u5230\u4e00\u4e2a \u975e\u7ebf\u6027 \u7684\u5206\u754c\u9762\u3002 Boosting Trees \u5b9e\u9645\u95ee\u9898\u4e2d\u7684\u6570\u636e\u5f80\u5f80\u4e0d\u50cf\u4f8b\u5b50\u4e2d\u90a3\u4e48\u7b80\u5355\u3002\u901a\u5e38\uff0c\u8f93\u5165\u53ef\u80fd\u662f\u4e0d\u540c\u7c7b\u578b\u7684\u7ec4\u5408\uff08\u6570\u5b57\u3001\u7c7b\u522b\u3001bool \u7b49\uff09\uff0c\u8fd8\u5b58\u5728\u4e22\u5931\u90e8\u5206\u6570\u636e\u7b49\u95ee\u9898\u3002\u201coff-the-shelf\u201c \u7684\u65b9\u6cd5\u5c31\u662f\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u672a\u7ecf\u8fc7\u590d\u6742\u7684\u9884\u5904\u7406\u7684\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u7684\u65b9\u6cd5\u3002 \u5728\u6240\u6709\u5df2\u77e5\u7684\u5b66\u4e60\u65b9\u6cd5\u4e2d\uff0c\u51b3\u7b56\u6811\u662f\u6700\u63a5\u8fd1 \u201doff-the-shelf\u201c \u7684\u65b9\u6cd5\u3002\u5b83\u7684 \u552f\u4e00\u95ee\u9898\u5c31\u662f\u4e0d\u591f\u7cbe\u786e \uff0c\u4f46\u662f\u5982\u679c\u6211\u4eec\u5c06\u51b3\u7b56\u6811\u4f5c\u4e3a\u57fa\u672c\u7684\u5206\u7c7b\u5668\u8fdb\u884c boost\uff0c\u5c31\u53ef\u4ee5\u5927\u5927\u63d0\u9ad8\u5b83\u7684\u7cbe\u786e\u5ea6\u3002\u5f53\u7136\uff0c\u8fd9\u4f1a\u727a\u7272\u51b3\u7b56\u6811\u7684\u901f\u5ea6\u3001\u589e\u52a0\u5b83\u7684\u590d\u6742\u5ea6\uff0c\u8fd8\u4f1a\u964d\u4f4e\u9c81\u68d2\u6027\u3002Gradient Boosted \u6a21\u578b\u89e3\u51b3\u4e86 boosting tree \u7684\u8fd9\u4e9b\u95ee\u9898\u3002\u6211\u4eec\u540c\u6837\u7528 spam mail \u7684\u6570\u636e\u96c6\u6765\u8bd5\u9a8c\uff1a from sklearn.model_selection import KFold from sklearn.ensemble import GradientBoostingClassifier for train_index , test_index in KFold ( n_splits = 5 , shuffle = True , random_state = 1 ) . split ( X ): # print(\"TRAIN:\", train_index, \"TEST:\", test_index) trainX , testX = X . loc [ train_index ], X . loc [ test_index ] trainY , testY = y . loc [ train_index ], y . loc [ test_index ] model = GradientBoostingClassifier () . fit ( trainX , trainY ) print ( f \"GBM accurracy: { model . score ( testX , testY ) } \" ) \u4ece\u4e0b\u9762\u7ed3\u679c\u53ef\u4ee5\u770b\u51fa\uff0c\u76ee\u524d\u6211\u4eec\u5c1d\u8bd5\u7684\u65b9\u6cd5\u4e2d\uff0c\u4ece\u7cbe\u786e\u5ea6\u4e0a\u6765\u8bb2\uff0c\u6709 Gradient Boosting Trees > Generalized Additive Models > Linear Regression > Classification Tree. GBM accurracy: 0.9500542888165038 GBM accurracy: 0.9402173913043478 GBM accurracy: 0.9434782608695652 GBM accurracy: 0.95 GBM accurracy: 0.9434782608695652 \u6211\u4eec\u5c06\u5728\u4e0b\u4e00\u7bc7\u6587\u7ae0\u8be6\u7ec6\u4ecb\u7ecd Gradient Boosted Trees. \u53c2\u8003\u8d44\u6599 Lectures on Machine Learning","title":"ESL 10.1: Boosting Methods"},{"location":"mathematics/ESL/ESL10_BoostingMethods/#esl-101-boosting-methods","text":"Boosting \u6700\u521d\u662f\u4e3a\u89e3\u51b3\u5206\u7c7b\u95ee\u9898\u8bbe\u8ba1\u7684\uff0c\u540e\u6765\u53c8\u88ab\u6269\u5c55\u5230\u4e86\u56de\u5f52\u95ee\u9898\u3002Boosting \u7684\u539f\u7406\u662f\u5c06\u5f88\u591a\u5f31\u5206\u7c7b\u5668\u7ec4\u5408\u8d77\u6765\u4ea7\u751f\u4e00\u4e2a\u5f3a\u5206\u7c7b\u5668\u3002 \u4e00\u4e2a\u5f31\u5206\u7c7b\u5668\u662f\u67d0\u79cd\u6bd4\u968f\u673a\u731c\u6d4b\u7ed3\u679c\u7565\u597d\u7684\u7b80\u5355\u5206\u7c7b\u5668\u3002Boosting \u6bcf\u6b21\u5c06\u8f93\u5165\u7279\u5f81\u8d4b\u4e88\u4e0d\u540c\u7684\u6743\u91cd\uff0c\u5e76\u5e94\u7528\u5f31\u5206\u7c7b\u5668\u8fdb\u884c\u5206\u7c7b\uff0c\u6700\u540e\u5c06\u6240\u6709\u7ed3\u679c\u901a\u8fc7\u6295\u7968\u7684\u5f62\u5f0f\u4ea7\u751f\u6700\u7ec8\u7ed3\u679c\u3002","title":"ESL 10.1: Boosting Methods"},{"location":"mathematics/ESL/ESL10_BoostingMethods/#adaboost","text":"\u6211\u4eec\u4ece\u6700\u57fa\u672c\u7684 AdaBoost \u5f00\u59cb\u4ecb\u7ecd\u3002 \u5047\u8bbe\u67d0\u4e2a\u5206\u7c7b\u95ee\u9898\u7ed3\u679c\u4e3a -1 \u6216\u8005 +1\u3002\u4e00\u5171\u6709 \\(N\\) \u4e2a\u6837\u672c\uff0c\u5e76\u4e14\u6211\u4eec\u5df2\u6709 \\(M\\) \u4e2a\u5f31\u5206\u7c7b\u5668\u3002AdaBoost\u7b97\u6cd5\u8868\u8ff0\u4e3a\uff1a \u521d\u59cb\u5316\u6743\u91cd \\(w_i = 1/N, i = 1,2,...,N\\) For \\(m = 1\\) to \\(M\\) : a. \u5bf9\u6bcf\u4e2a\u6837\u672c \\(x_i\\) \u9644\u52a0\u6743\u91cd \\(w_i\\) \u5e76\u9001\u5165\u5206\u7c7b\u5668 \\(G_m(x)\\) b. \u8ba1\u7b97\u9519\u8bef\u7387\uff1a \\[ \\text{err}_m = \\sum_{i=1}^N w_i I(y_i \\neq G_m(x_i)) \\] c. \u6839\u636e\u9519\u8bef\u7387\u8ba1\u7b97\u8be5\u5206\u7c7b\u5668\u6743\u91cd\uff08\u9519\u8bef\u7387\u8d8a\u4f4e\u6743\u91cd\u8d8a\u9ad8\uff09 \\[\\alpha_m = \\ln((1- \\text{err}_m)/\\text{err}_m)\\] d. \u66f4\u65b0\u5206\u7c7b\u9519\u8bef\u7684\u6837\u672c\u6743\u91cd\uff0c\u5e76\u5f52\u4e00\u5316\u5904\u7406\uff08\u5224\u65ad\u9519\u8bef\u7684\u6837\u672c\u6743\u91cd\u63d0\u9ad8\uff0c\u4ea4\u7531\u4e0b\u4e00\u4e2a\u5206\u7c7b\u5668\u5206\u7c7b\uff09 \\[w_i = \\text{normalize} [ w_i e^{\\alpha_m I(y_i \\neq G_m(x_i))} ]\\] \u6700\u7ec8\u751f\u6210\u7684\u5f3a\u5206\u7c7b\u5668\u4e3a\uff1a \\[G(x) = \\text{sign} [ \\sum_{m=1}^M \\alpha_m G_m(x)] \\] \u5176\u4e2d\uff0c \\(I(x)\\) \u662f\u6761\u4ef6\u5224\u65ad\u3002false = 0, true = 1\u3002 2.d \u6bd4\u8f83\u96be\u7406\u89e3\u3002\u8c03\u6574\u6837\u672c\u6743\u91cd\u7684\u610f\u4e49\u5728\u4e8e\uff0c\u5982\u679c\u67d0\u4e2a\u5206\u7c7b\u5668\u5df2\u7ecf\u6b63\u786e\u5206\u7c7b i \u6837\u672c\uff0c\u540e\u7eed\u7684\u5206\u7c7b\u5668\u7684\u8d23\u4efb\u5728\u4e8e\u201c\u8865\u5168\u201d A \u5206\u7c7b\u5668\u7684\u529f\u80fd\uff0c\u5373\uff0c\u4e0d\u8981\u91cd\u590d\u6b63\u786e\u7684\u7ed3\u8bba\uff0c\u5e94\u8be5\u628a\u91cd\u70b9\u653e\u5728 A \u5206\u7c7b\u9519\u8bef\u7684\u6837\u672c\u4e0a\u3002 \u5982\u679c\u540e\u7eed\u67d0\u4e2a\u5206\u7c7b\u5668\u4e0e A \u5206\u7c7b\u5668\u7684\u7ed3\u8bba\u91cd\u590d\uff0c\u90a3\u7531 2.c \u5f97\u5230\u7684\u5206\u7c7b\u5668\u6743\u91cd\u4f1a\u5f88\u4f4e\u3002\u5728\u6700\u7ec8\u7684\u5f3a\u5206\u7c7b\u5668\u4e2d\uff0c\u51e0\u4e4e\u4e0d\u4ea7\u751f\u5f71\u54cd\u3002\u53cd\u4e4b\uff0c\u5982\u679c\u4e0e A \u4e92\u8865\uff0c\u90a3\u53ef\u80fd\u4f1a\u5f97\u5230\u4e00\u4e2a\u5f88\u9ad8\u7684\u6743\u91cd\u3002","title":"AdaBoost"},{"location":"mathematics/ESL/ESL10_BoostingMethods/#adaboost_1","text":"\u5047\u8bbe\u6709\u5982\u4e0b\u8bad\u7ec3\u6570\u636e\uff0c\u4e24\u4e2a\u70b9 (0.5, 1.5) \u548c (1.5, 1.5) \u88ab\u6807\u8bb0\u4e86 + \u7c7b\uff0c\u4e09\u4e2a\u70b9 (1.5, 0.5), (2.5, 1.5) \u548c (2.5, 2.5) \u88ab\u6807\u8bb0\u4e86 - \u7c7b\u3002 \u6211\u4eec\u6709\u5982\u4e0b\u5206\u7c7b\u5668\uff08\u90fd\u6bd4\u968f\u673a\u731c\u6d4b\u7565\u597d\uff09\uff1a \\[G_1(x) = \\begin{cases} +1 & x_1 \\leq 2 \\\\ -1 & x_1 > 2 \\end{cases} \\] \\[G_2(x) = \\begin{cases} -1 & x_2 \\leq 1 \\\\ +1 & x_2 > 1 \\\\ \\end{cases} \\] \\[G_3(x) = \\begin{cases} +1 & x_1 \\leq 1 \\\\ -1 & x_1 > 1 \\end{cases} \\] \u9996\u5148\uff0c\u7531\u4e8e\u6211\u4eec\u6709 5 \u4e2a\u6837\u672c\uff0c\u6211\u4eec\u5c06\u6837\u672c\u521d\u59cb\u6743\u91cd\u8bbe\u7f6e\u4e3a \\(w_i = 0.2\\) \uff0c\u5e94\u7528 \\(G_1\\) \u5206\u7c7b\u5668\uff0c\u53d1\u73b0\u4ec5\u6709\u4f4d\u4e8e (1.5, 0.5) \u7684\u70b9\u5206\u7c7b\u9519\u8bef\uff0c\u56e0\u6b64 \\(G_1\\) \u5206\u7c7b\u5668\u9519\u8bef\u7387\u4e3a\uff1a \\[\\text{err}_1 = 0.2 \\] \u8ba1\u7b97 \\(G_1\\) \u5206\u7c7b\u5668\u6743\u91cd\uff1a \\[ \\alpha_1 = \\ln ((1-0.2) / 0.2) = \\ln 4\\] \u8c03\u6574\u5206\u7c7b\u9519\u8bef\u7684\u6837\u672c\u6743\u91cd\u5e76\u5f52\u4e00\u5316\uff1a \\[ w_i = \\text{normalize} [ 0.2, 0.2, 0.2, 0.2, 0.8] = [\\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{4}{8}] \\] \u6b64\u540e\u518d\u5c06\u65b0\u7684\u6743\u91cd\u7528\u4e8e \\(G_2\\) \u7684\u5206\u7c7b\uff0c \\(G_2\\) \u5728 (2.5, 1.5) \u548c (2.5, 2.5) \u5206\u7c7b\u9519\u8bef\uff0c\u5176\u9519\u8bef\u7387\u4e3a\uff1a \\[ \\text{err}_2 = \\frac{1 }{8} *1 + \\frac{1}{8} *1 = \\frac{1}{4} \\] \\(G_2\\) \u7684\u5206\u7c7b\u5668\u6743\u91cd\u4e3a\uff1a \\[ \\alpha_2 = \\ln ((1-0.25) / 0.25) = \\ln 3\\] \u63a5\u4e0b\u6765\uff0c\u66f4\u65b0\u6837\u672c\u6743\u91cd\uff0c\u5c06\u5206\u7c7b\u9519\u8bef\u7684\u6837\u672c\u6743\u91cd\u63d0\u9ad8\uff1a \\[ w_i = \\text{normalize} [\\frac{3}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{3}{8}, \\frac{4}{8}] = [\\frac{3}{12}, \\frac{1}{12}, \\frac{1}{12}, \\frac{3}{12}, \\frac{4}{12}] \\] \u518d\u7528 \\(G_3\\) \u5206\u7c7b\uff0c\u540c\u4e0a\uff0c\u5b83\u5728 (1.5, 1.5) \u70b9\u5206\u7c7b\u9519\u8bef\uff0c\u800c\u8be5\u70b9\u6743\u91cd\u76ee\u524d\u4e3a \\(\\frac{1}{12}\\) \uff0c\u56e0\u6b64\u5176\u9519\u8bef\u7387\uff1a \\[ \\text{err}_3 = \\frac{1 }{12} \\] \\(G_3\\) \u5206\u7c7b\u5668\u6743\u91cd\u4e3a\uff1a \\[ \\alpha_3 = \\ln 11\\] \u5f97\u51fa\u6700\u7ec8 boosted \u5206\u7c7b\u5668\uff08\u6ce8\u610f\uff0c\u8fd9\u91cc\u4f53\u73b0\u4e86 \u52a0\u6027\u6a21\u578b \u7279\u70b9\uff09\uff1a \\[G(x) = \\text{sign} [\\ln4 G_1(x) + \\ln3 G_2(x) + \\ln11 G_3(x)] \\] \u5bf9\u4e8e\u6bcf\u4e2a\u533a\u57df\uff0c\u6211\u4eec\u8ba1\u7b97\u5176\u503c\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e \\(x_1\\) \u548c \\(x_2\\) \u90fd\u5c5e\u4e8e [0, 1) \u533a\u95f4\u7684\u70b9\uff1a \\[ G(x_0) = \\text{sign} [\\ln4 \\times 1 + \\ln3 \\times (-1) + \\ln11 \\times 1] = \\text{sign} 2.69 = 1 \\] \u4f9d\u6b21\u8ba1\u7b97\u5404\u4e2a\u533a\u57df\uff0c\u5f97\u5230\u7684\u8fb9\u754c\u4e3a\uff1a \u8fd9\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\u63ed\u793a\u4e86 AdaBoost \u7684\u5de5\u4f5c\u539f\u7406\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u5b83\u5982\u4f55\u5bf9 \u7ebf\u6027 \u5206\u7c7b\u5668\u8fdb\u884c \u7ebf\u6027\u7ec4\u5408 \uff0c\u6700\u7ec8\u5f97\u5230\u4e00\u4e2a \u975e\u7ebf\u6027 \u7684\u5206\u754c\u9762\u3002","title":"AdaBoost \u7b80\u5355\u4f8b\u5b50"},{"location":"mathematics/ESL/ESL10_BoostingMethods/#boosting-trees","text":"\u5b9e\u9645\u95ee\u9898\u4e2d\u7684\u6570\u636e\u5f80\u5f80\u4e0d\u50cf\u4f8b\u5b50\u4e2d\u90a3\u4e48\u7b80\u5355\u3002\u901a\u5e38\uff0c\u8f93\u5165\u53ef\u80fd\u662f\u4e0d\u540c\u7c7b\u578b\u7684\u7ec4\u5408\uff08\u6570\u5b57\u3001\u7c7b\u522b\u3001bool \u7b49\uff09\uff0c\u8fd8\u5b58\u5728\u4e22\u5931\u90e8\u5206\u6570\u636e\u7b49\u95ee\u9898\u3002\u201coff-the-shelf\u201c \u7684\u65b9\u6cd5\u5c31\u662f\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u672a\u7ecf\u8fc7\u590d\u6742\u7684\u9884\u5904\u7406\u7684\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u7684\u65b9\u6cd5\u3002 \u5728\u6240\u6709\u5df2\u77e5\u7684\u5b66\u4e60\u65b9\u6cd5\u4e2d\uff0c\u51b3\u7b56\u6811\u662f\u6700\u63a5\u8fd1 \u201doff-the-shelf\u201c \u7684\u65b9\u6cd5\u3002\u5b83\u7684 \u552f\u4e00\u95ee\u9898\u5c31\u662f\u4e0d\u591f\u7cbe\u786e \uff0c\u4f46\u662f\u5982\u679c\u6211\u4eec\u5c06\u51b3\u7b56\u6811\u4f5c\u4e3a\u57fa\u672c\u7684\u5206\u7c7b\u5668\u8fdb\u884c boost\uff0c\u5c31\u53ef\u4ee5\u5927\u5927\u63d0\u9ad8\u5b83\u7684\u7cbe\u786e\u5ea6\u3002\u5f53\u7136\uff0c\u8fd9\u4f1a\u727a\u7272\u51b3\u7b56\u6811\u7684\u901f\u5ea6\u3001\u589e\u52a0\u5b83\u7684\u590d\u6742\u5ea6\uff0c\u8fd8\u4f1a\u964d\u4f4e\u9c81\u68d2\u6027\u3002Gradient Boosted \u6a21\u578b\u89e3\u51b3\u4e86 boosting tree \u7684\u8fd9\u4e9b\u95ee\u9898\u3002\u6211\u4eec\u540c\u6837\u7528 spam mail \u7684\u6570\u636e\u96c6\u6765\u8bd5\u9a8c\uff1a from sklearn.model_selection import KFold from sklearn.ensemble import GradientBoostingClassifier for train_index , test_index in KFold ( n_splits = 5 , shuffle = True , random_state = 1 ) . split ( X ): # print(\"TRAIN:\", train_index, \"TEST:\", test_index) trainX , testX = X . loc [ train_index ], X . loc [ test_index ] trainY , testY = y . loc [ train_index ], y . loc [ test_index ] model = GradientBoostingClassifier () . fit ( trainX , trainY ) print ( f \"GBM accurracy: { model . score ( testX , testY ) } \" ) \u4ece\u4e0b\u9762\u7ed3\u679c\u53ef\u4ee5\u770b\u51fa\uff0c\u76ee\u524d\u6211\u4eec\u5c1d\u8bd5\u7684\u65b9\u6cd5\u4e2d\uff0c\u4ece\u7cbe\u786e\u5ea6\u4e0a\u6765\u8bb2\uff0c\u6709 Gradient Boosting Trees > Generalized Additive Models > Linear Regression > Classification Tree. GBM accurracy: 0.9500542888165038 GBM accurracy: 0.9402173913043478 GBM accurracy: 0.9434782608695652 GBM accurracy: 0.95 GBM accurracy: 0.9434782608695652 \u6211\u4eec\u5c06\u5728\u4e0b\u4e00\u7bc7\u6587\u7ae0\u8be6\u7ec6\u4ecb\u7ecd Gradient Boosted Trees.","title":"Boosting Trees"},{"location":"mathematics/ESL/ESL10_BoostingMethods/#_1","text":"Lectures on Machine Learning","title":"\u53c2\u8003\u8d44\u6599"},{"location":"mathematics/ESL/ESL10_BoostingTrees/","text":"ESL 10.9: Boosting Trees \u201coff-the-shelf\u201c \u7684\u65b9\u6cd5\u662f\u53ef\u4ee5\u65e0\u9700\u7ecf\u8fc7\u590d\u6742\u7684\u9884\u5904\u7406\uff08\u5982\u5f52\u4e00\u5316\uff09\uff0c\u4e5f\u65e0\u9700\u4ed4\u7ec6\u8c03\u53c2\u5373\u53ef\u7528\u4e8e\u6570\u636e\u8bad\u7ec3\u548c\u9884\u6d4b\u7684\u65b9\u6cd5\u3002 \u5b9e\u9645\u95ee\u9898\u4e2d\u7684\u6570\u636e\u5f80\u5f80\u4e0d\u50cf\u4f8b\u5b50\u4e2d\u90a3\u4e48\u7b80\u5355\u3002\u901a\u5e38\uff0c\u8f93\u5165\u53ef\u80fd\u662f\u4e0d\u540c\u7c7b\u578b\u7684\u7ec4\u5408\uff08\u6570\u5b57\u3001\u7c7b\u522b\u3001bool \u7b49\uff09\uff0c\u8fd8\u5b58\u5728\u4e22\u5931\u90e8\u5206\u6570\u636e\u7b49\u95ee\u9898\u3002\u800c\u51b3\u7b56\u6811\u5929\u751f\u5c31\u5177\u5907\u5904\u7406\u8fd9\u4e9b\u8f93\u5165\u7684\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u5728\u6240\u6709\u5df2\u77e5\u7684\u5b66\u4e60\u65b9\u6cd5\u4e2d\uff0c\u51b3\u7b56\u6811\u662f\u6700\u63a5\u8fd1 \u201doff-the-shelf\u201c \u7684\u65b9\u6cd5\u3002 \u51b3\u7b56\u6811\u7684\u552f\u4e00\u95ee\u9898\u5c31\u662f\u4e0d\u591f\u7cbe\u786e\uff0c\u4f46\u662f\u5982\u679c\u6211\u4eec\u5c06 Boosting \u65b9\u6cd5\u4e0e\u51b3\u7b56\u6811\u7ed3\u5408\uff0c\u5c31\u53ef\u4ee5\u5927\u5927\u63d0\u9ad8\u5b83\u7684\u7cbe\u786e\u5ea6\u3002 Regression Tree \u6211\u4eec\u5728 9.2 Tree-Based Methods \u4e2d\u5df2\u7ecf\u4ecb\u7ecd\u4e86\u56de\u5f52\u6811\u3002\u56de\u5f52\u6811\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\[ T(x; \\Theta) = \\sum _ {j=1} ^ J \\gamma_j I( x \\in R_j) \\] \u5176\u4e2d\uff1a \\(x\\) \uff1a\u7279\u5f81\u503c \\(J\\) \uff1a\u603b\u533a\u57df\uff08\u53f6\u5b50\u8282\u70b9\uff09\u6570 \\(R_j\\) \uff1a\u7b2c j \u4e2a\u533a\u57df \\(\\gamma_j\\) \uff1a\u7b2c j \u4e2a\u533a\u57df\u7684\u9884\u6d4b\u503c \\(I\\) \uff1a\u7b26\u5408\u6761\u4ef6\u5219\u4e3a 1\uff0c \u5426\u5219\u4e3a 0 \\(\\Theta\\) \uff1a\u6240\u6709\u53c2\u6570\u7684\u7ec4\u5408\uff0c\u5373 J \u7ec4 \\(\\{ R_j, \\gamma_j \\}\\) pair\uff0c\u4ee3\u8868\u4e86\u6700\u7ec8\u8bad\u7ec3\u51fa\u6765\u7684\u6a21\u578b \u5982 9.2 \u4e2d\u6240\u8ff0\uff0c\u5bf9\u4e8e\u7ed9\u5b9a\u8bad\u7ec3\u6570\u636e\uff0c\u6700\u4f18\u7684\u6811\u662f\u53ef\u4ee5\u786e\u5b9a\u7684\u3002\u56e0\u6b64 \\(J\\) \u662f\u53ef\u4ee5\u901a\u8fc7\u8bad\u7ec3\u6570\u636e\u5f97\u5230\u7684\u3002\u5728 J \u5df2\u77e5\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u9700\u8981\u6c42\u89e3\u4f18\u5316\u95ee\u9898\u6765\u5f97\u5230 \\(\\Theta\\) \uff1a \\[ \\hat{\\Theta} = \\arg \\min _{\\Theta} \\sum_{j=1}^J \\sum_{x_i \\in R_j} L(y_i, \\gamma_j) \\] \u5373\uff0c\u627e\u5230 \\(\\Theta\\) \u4f7f\u5404\u533a\u57df\u635f\u5931\u51fd\u6570 \\(L\\) \uff08\u4f8b\u5982 MSE\uff09\u4e4b\u548c\u6700\u5c0f\u3002 \u8fd9\u662f\u4e00\u4e2a\u96be\u4ee5\u6c42\u89e3\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u6211\u4eec\u628a\u8fd9\u4e2a\u6c42\u89e3\u8fc7\u7a0b\u5206\u4e3a\u4e24\u4e2a\u90e8\u5206\uff0c\u5e76\u5bfb\u6c42\u4e00\u4e2a\u8f83\u4f18\u89e3\u800c\u975e\u6700\u4f18\u89e3\uff1a \uff08\u5bb9\u6613\uff09\u7ed9\u5b9a \\(R_j\\) \u6c42 \\(\\gamma_j\\) \uff1a\u4e00\u822c\u6765\u8bb2\u76f4\u63a5\u4f7f\u7528\u843d\u5728 \\(R_j\\) \u5185\u7684\u6240\u6709\u6837\u672c\u7684\u5747\u503c \\(\\overline y_j\\) \u3002 \uff08\u56f0\u96be\uff09\u786e\u5b9a \\(R_j\\) \uff1a\u901a\u5e38\u6211\u4eec\u91c7\u7528\u81ea\u9876\u5411\u4e0b\u7684\u8d2a\u5a6a\u7b97\u6cd5\u6765\u9012\u5f52\u5730\u5206\u533a \u3002\u6211\u4eec\u5728 9.2 Tree-Based Methods \u6709\u8be6\u7ec6\u7684\u4ecb\u7ecd\u3002 Boosting Trees \u73b0\u5728\u6211\u4eec\u5df2\u7ecf\u53ef\u4ee5\u77e5\u9053\u5355\u4e2a\u6811\u7684\u6c42\u89e3\u4e86\u3002Boosting Trees \u672c\u8d28\u4e0a\u662f\u591a\u4e2a\u6811\u76f8\u52a0\u5f97\u5230\uff1a \\[ f_M(x) = \\sum_{m=1}^M T(x;\\Theta_m) \\] \u5176\u4e2d M \u662f\u6811\u7684\u603b\u6570\u3002 \u6811\u7684\u6c42\u548c\u53ef\u80fd\u6bd4\u8f83\u96be\u76f4\u89c2\u7406\u89e3\u3002\u5b9e\u8d28\u4e0a\u975e\u5e38\u7b80\u5355\uff0c\u5c31\u662f\u9488\u5bf9 \u6bcf\u4e2a\u6837\u672c \uff0c\u5bf9\u5176\u5728\u6bcf\u4e2a\u6811\u7684\u503c\u6c42\u548c\u3002 \u4f18\u5316\u7684\u76ee\u6807\u5c31\u662f\u627e\u5230\u4e00\u7ec4\u6811\uff0c\u4f7f\u5f97\u6240\u6709\u6837\u672c\u7684\u9884\u6d4b\u8bef\u5dee\u6700\u5c0f\u3002\u5176\u4e2d\u9884\u6d4b\u8bef\u5dee\u7528\u635f\u5931\u51fd\u6570 \\(L\\) \u8ba1\u7b97\uff1a \\[ L(f) = \\sum_{i=1}^N L(y_i, f(x_i)) \\] \u6211\u4eec\u91c7\u7528 additive \u7684\u65b9\u5f0f\u6765\u6c42\u89e3\u8fd9\u7ec4\u6811\uff0c\u6bcf\u4e00\u6b65\u53ea\u6c42\u89e3\u4e00\u4e2a\u6811\u3002\u57fa\u4e8e\u524d k-1 \u4e2a\u6811\u7684\u6a21\u578b \\(f_{k-1}(x)\\) \uff0c\u7b2c k \u4e2a\u6811\u9009\u62e9\u4e00\u4e2a\u80fd\u6700\u5c0f\u5316\u5168\u5c40\u635f\u5931\u51fd\u6570\u7684\u6811\uff1a \\[ \\hat{\\Theta}_k = \\arg \\min _{\\Theta_k} \\sum_{i=1}^N L(y_i, f_{k-1}(x_i) + T(x_i; \\Theta_k)) \\] \u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 \u6700\u901f\u4e0b\u964d\u6cd5 \u5b9e\u73b0\u3002 \u5bf9\u4e8e\u7b2c k \u6b65\u7684\u4e0b\u964d\u65b9\u5411\uff0c\u6211\u4eec\u53ef\u4ee5\u9009\u62e9\u7b2c k-1 \u6b65\u7684\u8d1f\u68af\u5ea6\u65b9\u5411\u3002\u8bad\u7ec3\u6837\u672c i \u7684\u68af\u5ea6\u65b9\u5411\u4e3a\uff1a \\[g_{ik} = \\frac{\\partial L(y_i, f(x_i))}{\\partial f(x_i)} | _{f= f_{k-1}}\\] \u4e0b\u964d\u6b65\u957f\u662f\u4ee5\u4e0b\u4f18\u5316\u95ee\u9898\u7684\u89e3\uff1a \\[ \\rho_k = \\arg \\min_{\\rho} (f_{k-1} - \\rho g_k)\\] \u4e8e\u662f\u53ef\u4ee5\u5f97\u5230\uff1a \\[ f_k = f_{k-1} - \\rho_kg_k\\] \u8fd9\u5c31\u662f Gradient Boosting \u4e86\u3002 Gradient Boosting Trees Gradient Boosting \u7684\u57fa\u672c\u601d\u60f3\u662f\uff1a\u4e32\u884c\u5730\u751f\u6210\u591a\u4e2a\u5f31\u5b66\u4e60\u5668\uff0c\u6bcf\u4e2a\u5f31\u5b66\u4e60\u5668\u7684\u76ee\u6807\u662f\u62df\u5408\u5148\u524d\u7d2f\u52a0\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\u7684\u8d1f\u68af\u5ea6\uff0c \u4f7f\u52a0\u4e0a\u8be5\u5f31\u5b66\u4e60\u5668\u540e\u7684\u7d2f\u79ef\u6a21\u578b\u635f\u5931\u5f80\u8d1f\u68af\u5ea6\u7684\u65b9\u5411\u51cf\u5c11\u3002 \u56de\u60f3\u4e0a\u9762\u6811\u7684\u52a0\u6cd5\u7684\u56fe\uff0c\u6bcf\u4e00\u9897\u6811\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u6a21\u578b\uff08\u5f31\u5b66\u4e60\u5668\uff09\uff0c\u5047\u8bbe\u67d0\u4e2a\u6837\u672c\u7684\u771f\u5b9e\u503c\u4e3a 10\uff0c\u7b2c\u4e00\u4e2a\u6a21\u578b\u62df\u5408\u7ed3\u679c\u662f 7\uff0c\u5219\u8bef\u5dee\u4e3a 7-10 = -3\uff0c\u7b2c\u4e8c\u4e2a\u6a21\u578b\u5219\u4ee5 3 \u4e3a\u62df\u5408\u76ee\u6807\uff0c\u4ee5\u6b64\u7c7b\u63a8\u3002 \u6211\u4eec\u4e00\u822c\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u662f\u7528\u6765\u8c03\u6574\u201c\u53c2\u6570\u8bef\u5dee\u201d\u3002\u5bf9\u4e8e Boosting Trees\uff0c\u5982\u679c\u6211\u4eec\u4e0d\u628a\u6811\u770b\u6210\u53c2\u6570\u800c\u662f\u770b\u4f5c\u6a21\u578b\uff0c\u4e5f\u53ef\u4ee5\u8ba4\u4e3a\u5b9e\u9645\u4e0a\u6211\u4eec\u5728\u8c03\u6574\u201c\u6a21\u578b\u8bef\u5dee\u201d\uff0c\u5373\u901a\u8fc7\u6dfb\u52a0\u65b0\u7684\u6811\u6765\u4fee\u6b63\u6a21\u578b\u3002 \u53c2\u6570 \\(M\\) - \u603b\u5171\u7684\u6811\u7684\u6570\u91cf \\(D\\) - \u6bcf\u4e2a\u6811\u7684\u6700\u5927\u6df1\u5ea6 \\(\\rho\\) - \u6b65\u957f\uff0c\u5373\u5b66\u4e60\u7387 \u4e3a\u4ec0\u4e48\u9700\u8981\u8bbe\u7f6e\u6811\u7684\u6700\u5927\u6df1\u5ea6\uff1f \u7684\u786e\uff0c\u5728\u4e0a\u9762 Regression tree \u7684\u751f\u6210\u4e2d\uff0c\u6211\u4eec\u662f\u76f4\u63a5\u5bfb\u627e\u201c\u6700\u4f18\u6811\u201d\u3002\u5e76\u4e0d\u9650\u5236\u8282\u70b9\u548c\u6df1\u5ea6\uff0c\u800c\u662f\u5148\u6784\u9020\u4e00\u4e2a\u8db3\u591f\u5927\u7684\u6811\uff0c\u901a\u8fc7\u201c\u526a\u679d\u201d\u64cd\u4f5c\u6765\u5f97\u5230\u5408\u9002\u7684\u8282\u70b9\u6570\u3002 \u7531\u4e8e boosting trees \u5305\u542b\u591a\u4e2a\u6811\uff0c\u6211\u4eec\u5bf9\u6bcf\u4e2a\u6811\u5e76\u4e0d\u8981\u6c42\u201c\u6700\u4f18\u201d\uff0c\u8bbe\u7f6e\u4e00\u4e2a\u6700\u5927\u6df1\u5ea6\u53ef\u4ee5\u6781\u5927\u5730\u7b80\u5316\u8ba1\u7b97\u3002 \u7b97\u6cd5 \u521d\u59cb\u5316\u4e00\u4e2a\u4ec5\u6709\u4e00\u4e2a\u8282\u70b9\u7684\u6811\uff0c\u5305\u542b\u6240\u6709\u6837\u672c\uff0c\u8282\u70b9\u7684\u503c \\(\\gamma\\) \u4e3a\u4ee5\u4e0b\u4f18\u5316\u95ee\u9898\u7684\u89e3\uff1a \\[f_0(x) = \\arg \\min_{ \\gamma } \\sum_{i=1}^N L(y_i, \\gamma) \\] \u5bf9\u6bcf\u68f5\u6811 \\(k = 1\\) to \\(M\\) \uff1a a. \u5bf9\u6bcf\u4e2a\u6837\u672c\u8ba1\u7b97\u8d1f\u68af\u5ea6\uff1a \\[ r_{ik} = - \\frac{ \\partial L(y_i, f(x_i)) }{ \\partial f(x_i) } | _{f= f_{k-1}} \\] b. \u4ee5\u8d1f\u68af\u5ea6\u4e3a\u76ee\u6807\u62df\u5408\u4e00\u4e2a\u6811 c. \u5c06\u8fd9\u4e2a\u6811\u52a0\u5165\u6a21\u578b\uff0c\u5e76\u66f4\u65b0\u9884\u6d4b\u503c Gradient Boosting Trees \u5b9e\u73b0 \u4ee5\u4e0b\u4ee3\u7801\u662f\u5f53\u635f\u5931\u51fd\u6570\u5b9a\u4e49\u4e3a\u5747\u65b9\u635f\u5931(mean squared error)\u65f6\u7684\u5b9e\u73b0\uff0c\u6b64\u65f6\u8d1f\u68af\u5ea6\u53ef\u4ee5\u7528 \\(g_m = y - f(x)\\) \u6c42\u5f97\u3002 from sklearn.model_selection import KFold from sklearn.metrics import mean_squared_error from sklearn.ensemble import GradientBoostingRegressor class MyGbm : def __init__ ( self , tree_num , tree_depth , learn_rate ): self . tree_num = tree_num self . tree_depth = tree_depth self . learn_rate = learn_rate self . boosting_trees = [] self . predict0 = 0 def fit ( self , train_X , train_y ): self . predict0 = train_y . mean () prediction = pd . Series ( data = self . predict0 , index = train_y . index ) for i in range ( 1 , self . tree_num ): # assuming loss function is squared error # 1. compute negative gradients neg_grads = train_y - prediction # 2. fit a regression tree tree = DecisionTreeRegressor ( max_depth = self . tree_depth ) tree . fit ( train_X , neg_grads ) # 3. update prediction self . boosting_trees . append ( tree ) prediction += tree . predict ( train_X ) * self . learn_rate def predict ( self , test_X ): # must be trained assert len ( self . boosting_trees ) > 0 prediction = pd . Series ( data = self . predict0 , index = test_X . index ) for tree in self . boosting_trees : prediction += tree . predict ( test_X ) * self . learn_rate return prediction \u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u4e0e sklearn \u5b98\u65b9\u7684 GradientBoostingRegressor \u76f8\u6bd4\u8f83\uff08\u901a\u8fc7enable/disable official \uff09\u3002\u9009\u53d6\u7684\u6570\u636e\u96c6\u662f Black Friday Dataset \uff0c\u6bd4\u8f83\u57fa\u51c6\u662f\u5747\u65b9\u6839\u8bef\u5dee\uff0c\u56e0\u4e3a\u7535\u8111\u7834\u6240\u4ee5\u53ea\u9009\u62e9\u4e86\u524d 10000 \u884c\u6570\u636e\u3002 official = False kf = KFold ( n_splits = 5 , shuffle = False , random_state = None ) for train_index , test_index in kf . split ( X ): print ( \"TRAIN:\" , train_index , \"TEST:\" , test_index ) X_train , X_test = X . loc [ train_index ], X . loc [ test_index ] y_train , y_test = y . loc [ train_index ], y . loc [ test_index ] n_estimators = 100 learning_rate = 0.1 max_depth = 10 if official : gbm = GradientBoostingRegressor ( n_estimators = n_estimators , max_depth = max_depth , learning_rate = learning_rate ) else : gbm = MyGbm ( n_estimators , max_depth , learning_rate ) gbm . fit ( X_train , y_train ) y_pred = gbm . predict ( X_test ) # root mean square error rmse = np . sqrt ( mean_squared_error ( y_true = y_test , y_pred = y_pred )) print ( 'rmse:' , rmse ) \u5b98\u65b9\u5b9e\u73b0\u7684 GBM\uff1a TRAIN: [2000 2001 2002 ... 9997 9998 9999] TEST: [ 0 1 2 ... 1997 1998 1999] rmse: 3581.9870271000086 TRAIN: [ 0 1 2 ... 9997 9998 9999] TEST: [2000 2001 2002 ... 3997 3998 3999] rmse: 2907.6311604609245 TRAIN: [ 0 1 2 ... 9997 9998 9999] TEST: [4000 4001 4002 ... 5997 5998 5999] rmse: 2944.398603563586 TRAIN: [ 0 1 2 ... 9997 9998 9999] TEST: [6000 6001 6002 ... 7997 7998 7999] rmse: 2999.08249707528 TRAIN: [ 0 1 2 ... 7997 7998 7999] TEST: [8000 8001 8002 ... 9997 9998 9999] rmse: 3416.907798496119 \u81ea\u5df1\u5b9e\u73b0\u7684GBM\uff1a TRAIN: [2000 2001 2002 ... 9997 9998 9999] TEST: [ 0 1 2 ... 1997 1998 1999] rmse: 3607.182565950029 TRAIN: [ 0 1 2 ... 9997 9998 9999] TEST: [2000 2001 2002 ... 3997 3998 3999] rmse: 2907.502318685874 TRAIN: [ 0 1 2 ... 9997 9998 9999] TEST: [4000 4001 4002 ... 5997 5998 5999] rmse: 2941.2904466354057 TRAIN: [ 0 1 2 ... 9997 9998 9999] TEST: [6000 6001 6002 ... 7997 7998 7999] rmse: 3005.347599886747 TRAIN: [ 0 1 2 ... 7997 7998 7999] TEST: [8000 8001 8002 ... 9997 9998 9999] rmse: 3407.221705763073 \u53ef\u4ee5\u770b\u51fa\u5dee\u8ddd\u4e0d\u5927\uff0c\u56e0\u6b64\u8fd9\u4e2a\u5b9e\u73b0\u662f\u6b63\u786e\u7684\u3002 Reference Introduction to Boosted Trees Gradient Boosting Black Friday Dataset Cross Validation Decision Tree Regressor Preprocess category features","title":"ESL 10.9: Boosting Trees"},{"location":"mathematics/ESL/ESL10_BoostingTrees/#esl-109-boosting-trees","text":"\u201coff-the-shelf\u201c \u7684\u65b9\u6cd5\u662f\u53ef\u4ee5\u65e0\u9700\u7ecf\u8fc7\u590d\u6742\u7684\u9884\u5904\u7406\uff08\u5982\u5f52\u4e00\u5316\uff09\uff0c\u4e5f\u65e0\u9700\u4ed4\u7ec6\u8c03\u53c2\u5373\u53ef\u7528\u4e8e\u6570\u636e\u8bad\u7ec3\u548c\u9884\u6d4b\u7684\u65b9\u6cd5\u3002 \u5b9e\u9645\u95ee\u9898\u4e2d\u7684\u6570\u636e\u5f80\u5f80\u4e0d\u50cf\u4f8b\u5b50\u4e2d\u90a3\u4e48\u7b80\u5355\u3002\u901a\u5e38\uff0c\u8f93\u5165\u53ef\u80fd\u662f\u4e0d\u540c\u7c7b\u578b\u7684\u7ec4\u5408\uff08\u6570\u5b57\u3001\u7c7b\u522b\u3001bool \u7b49\uff09\uff0c\u8fd8\u5b58\u5728\u4e22\u5931\u90e8\u5206\u6570\u636e\u7b49\u95ee\u9898\u3002\u800c\u51b3\u7b56\u6811\u5929\u751f\u5c31\u5177\u5907\u5904\u7406\u8fd9\u4e9b\u8f93\u5165\u7684\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u5728\u6240\u6709\u5df2\u77e5\u7684\u5b66\u4e60\u65b9\u6cd5\u4e2d\uff0c\u51b3\u7b56\u6811\u662f\u6700\u63a5\u8fd1 \u201doff-the-shelf\u201c \u7684\u65b9\u6cd5\u3002 \u51b3\u7b56\u6811\u7684\u552f\u4e00\u95ee\u9898\u5c31\u662f\u4e0d\u591f\u7cbe\u786e\uff0c\u4f46\u662f\u5982\u679c\u6211\u4eec\u5c06 Boosting \u65b9\u6cd5\u4e0e\u51b3\u7b56\u6811\u7ed3\u5408\uff0c\u5c31\u53ef\u4ee5\u5927\u5927\u63d0\u9ad8\u5b83\u7684\u7cbe\u786e\u5ea6\u3002","title":"ESL 10.9: Boosting Trees"},{"location":"mathematics/ESL/ESL10_BoostingTrees/#regression-tree","text":"\u6211\u4eec\u5728 9.2 Tree-Based Methods \u4e2d\u5df2\u7ecf\u4ecb\u7ecd\u4e86\u56de\u5f52\u6811\u3002\u56de\u5f52\u6811\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\[ T(x; \\Theta) = \\sum _ {j=1} ^ J \\gamma_j I( x \\in R_j) \\] \u5176\u4e2d\uff1a \\(x\\) \uff1a\u7279\u5f81\u503c \\(J\\) \uff1a\u603b\u533a\u57df\uff08\u53f6\u5b50\u8282\u70b9\uff09\u6570 \\(R_j\\) \uff1a\u7b2c j \u4e2a\u533a\u57df \\(\\gamma_j\\) \uff1a\u7b2c j \u4e2a\u533a\u57df\u7684\u9884\u6d4b\u503c \\(I\\) \uff1a\u7b26\u5408\u6761\u4ef6\u5219\u4e3a 1\uff0c \u5426\u5219\u4e3a 0 \\(\\Theta\\) \uff1a\u6240\u6709\u53c2\u6570\u7684\u7ec4\u5408\uff0c\u5373 J \u7ec4 \\(\\{ R_j, \\gamma_j \\}\\) pair\uff0c\u4ee3\u8868\u4e86\u6700\u7ec8\u8bad\u7ec3\u51fa\u6765\u7684\u6a21\u578b \u5982 9.2 \u4e2d\u6240\u8ff0\uff0c\u5bf9\u4e8e\u7ed9\u5b9a\u8bad\u7ec3\u6570\u636e\uff0c\u6700\u4f18\u7684\u6811\u662f\u53ef\u4ee5\u786e\u5b9a\u7684\u3002\u56e0\u6b64 \\(J\\) \u662f\u53ef\u4ee5\u901a\u8fc7\u8bad\u7ec3\u6570\u636e\u5f97\u5230\u7684\u3002\u5728 J \u5df2\u77e5\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u9700\u8981\u6c42\u89e3\u4f18\u5316\u95ee\u9898\u6765\u5f97\u5230 \\(\\Theta\\) \uff1a \\[ \\hat{\\Theta} = \\arg \\min _{\\Theta} \\sum_{j=1}^J \\sum_{x_i \\in R_j} L(y_i, \\gamma_j) \\] \u5373\uff0c\u627e\u5230 \\(\\Theta\\) \u4f7f\u5404\u533a\u57df\u635f\u5931\u51fd\u6570 \\(L\\) \uff08\u4f8b\u5982 MSE\uff09\u4e4b\u548c\u6700\u5c0f\u3002 \u8fd9\u662f\u4e00\u4e2a\u96be\u4ee5\u6c42\u89e3\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u6211\u4eec\u628a\u8fd9\u4e2a\u6c42\u89e3\u8fc7\u7a0b\u5206\u4e3a\u4e24\u4e2a\u90e8\u5206\uff0c\u5e76\u5bfb\u6c42\u4e00\u4e2a\u8f83\u4f18\u89e3\u800c\u975e\u6700\u4f18\u89e3\uff1a \uff08\u5bb9\u6613\uff09\u7ed9\u5b9a \\(R_j\\) \u6c42 \\(\\gamma_j\\) \uff1a\u4e00\u822c\u6765\u8bb2\u76f4\u63a5\u4f7f\u7528\u843d\u5728 \\(R_j\\) \u5185\u7684\u6240\u6709\u6837\u672c\u7684\u5747\u503c \\(\\overline y_j\\) \u3002 \uff08\u56f0\u96be\uff09\u786e\u5b9a \\(R_j\\) \uff1a\u901a\u5e38\u6211\u4eec\u91c7\u7528\u81ea\u9876\u5411\u4e0b\u7684\u8d2a\u5a6a\u7b97\u6cd5\u6765\u9012\u5f52\u5730\u5206\u533a \u3002\u6211\u4eec\u5728 9.2 Tree-Based Methods \u6709\u8be6\u7ec6\u7684\u4ecb\u7ecd\u3002","title":"Regression Tree"},{"location":"mathematics/ESL/ESL10_BoostingTrees/#boosting-trees","text":"\u73b0\u5728\u6211\u4eec\u5df2\u7ecf\u53ef\u4ee5\u77e5\u9053\u5355\u4e2a\u6811\u7684\u6c42\u89e3\u4e86\u3002Boosting Trees \u672c\u8d28\u4e0a\u662f\u591a\u4e2a\u6811\u76f8\u52a0\u5f97\u5230\uff1a \\[ f_M(x) = \\sum_{m=1}^M T(x;\\Theta_m) \\] \u5176\u4e2d M \u662f\u6811\u7684\u603b\u6570\u3002 \u6811\u7684\u6c42\u548c\u53ef\u80fd\u6bd4\u8f83\u96be\u76f4\u89c2\u7406\u89e3\u3002\u5b9e\u8d28\u4e0a\u975e\u5e38\u7b80\u5355\uff0c\u5c31\u662f\u9488\u5bf9 \u6bcf\u4e2a\u6837\u672c \uff0c\u5bf9\u5176\u5728\u6bcf\u4e2a\u6811\u7684\u503c\u6c42\u548c\u3002 \u4f18\u5316\u7684\u76ee\u6807\u5c31\u662f\u627e\u5230\u4e00\u7ec4\u6811\uff0c\u4f7f\u5f97\u6240\u6709\u6837\u672c\u7684\u9884\u6d4b\u8bef\u5dee\u6700\u5c0f\u3002\u5176\u4e2d\u9884\u6d4b\u8bef\u5dee\u7528\u635f\u5931\u51fd\u6570 \\(L\\) \u8ba1\u7b97\uff1a \\[ L(f) = \\sum_{i=1}^N L(y_i, f(x_i)) \\] \u6211\u4eec\u91c7\u7528 additive \u7684\u65b9\u5f0f\u6765\u6c42\u89e3\u8fd9\u7ec4\u6811\uff0c\u6bcf\u4e00\u6b65\u53ea\u6c42\u89e3\u4e00\u4e2a\u6811\u3002\u57fa\u4e8e\u524d k-1 \u4e2a\u6811\u7684\u6a21\u578b \\(f_{k-1}(x)\\) \uff0c\u7b2c k \u4e2a\u6811\u9009\u62e9\u4e00\u4e2a\u80fd\u6700\u5c0f\u5316\u5168\u5c40\u635f\u5931\u51fd\u6570\u7684\u6811\uff1a \\[ \\hat{\\Theta}_k = \\arg \\min _{\\Theta_k} \\sum_{i=1}^N L(y_i, f_{k-1}(x_i) + T(x_i; \\Theta_k)) \\] \u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 \u6700\u901f\u4e0b\u964d\u6cd5 \u5b9e\u73b0\u3002 \u5bf9\u4e8e\u7b2c k \u6b65\u7684\u4e0b\u964d\u65b9\u5411\uff0c\u6211\u4eec\u53ef\u4ee5\u9009\u62e9\u7b2c k-1 \u6b65\u7684\u8d1f\u68af\u5ea6\u65b9\u5411\u3002\u8bad\u7ec3\u6837\u672c i \u7684\u68af\u5ea6\u65b9\u5411\u4e3a\uff1a \\[g_{ik} = \\frac{\\partial L(y_i, f(x_i))}{\\partial f(x_i)} | _{f= f_{k-1}}\\] \u4e0b\u964d\u6b65\u957f\u662f\u4ee5\u4e0b\u4f18\u5316\u95ee\u9898\u7684\u89e3\uff1a \\[ \\rho_k = \\arg \\min_{\\rho} (f_{k-1} - \\rho g_k)\\] \u4e8e\u662f\u53ef\u4ee5\u5f97\u5230\uff1a \\[ f_k = f_{k-1} - \\rho_kg_k\\] \u8fd9\u5c31\u662f Gradient Boosting \u4e86\u3002","title":"Boosting Trees"},{"location":"mathematics/ESL/ESL10_BoostingTrees/#gradient-boosting-trees","text":"Gradient Boosting \u7684\u57fa\u672c\u601d\u60f3\u662f\uff1a\u4e32\u884c\u5730\u751f\u6210\u591a\u4e2a\u5f31\u5b66\u4e60\u5668\uff0c\u6bcf\u4e2a\u5f31\u5b66\u4e60\u5668\u7684\u76ee\u6807\u662f\u62df\u5408\u5148\u524d\u7d2f\u52a0\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\u7684\u8d1f\u68af\u5ea6\uff0c \u4f7f\u52a0\u4e0a\u8be5\u5f31\u5b66\u4e60\u5668\u540e\u7684\u7d2f\u79ef\u6a21\u578b\u635f\u5931\u5f80\u8d1f\u68af\u5ea6\u7684\u65b9\u5411\u51cf\u5c11\u3002 \u56de\u60f3\u4e0a\u9762\u6811\u7684\u52a0\u6cd5\u7684\u56fe\uff0c\u6bcf\u4e00\u9897\u6811\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u6a21\u578b\uff08\u5f31\u5b66\u4e60\u5668\uff09\uff0c\u5047\u8bbe\u67d0\u4e2a\u6837\u672c\u7684\u771f\u5b9e\u503c\u4e3a 10\uff0c\u7b2c\u4e00\u4e2a\u6a21\u578b\u62df\u5408\u7ed3\u679c\u662f 7\uff0c\u5219\u8bef\u5dee\u4e3a 7-10 = -3\uff0c\u7b2c\u4e8c\u4e2a\u6a21\u578b\u5219\u4ee5 3 \u4e3a\u62df\u5408\u76ee\u6807\uff0c\u4ee5\u6b64\u7c7b\u63a8\u3002 \u6211\u4eec\u4e00\u822c\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u662f\u7528\u6765\u8c03\u6574\u201c\u53c2\u6570\u8bef\u5dee\u201d\u3002\u5bf9\u4e8e Boosting Trees\uff0c\u5982\u679c\u6211\u4eec\u4e0d\u628a\u6811\u770b\u6210\u53c2\u6570\u800c\u662f\u770b\u4f5c\u6a21\u578b\uff0c\u4e5f\u53ef\u4ee5\u8ba4\u4e3a\u5b9e\u9645\u4e0a\u6211\u4eec\u5728\u8c03\u6574\u201c\u6a21\u578b\u8bef\u5dee\u201d\uff0c\u5373\u901a\u8fc7\u6dfb\u52a0\u65b0\u7684\u6811\u6765\u4fee\u6b63\u6a21\u578b\u3002","title":"Gradient Boosting\u00a0Trees"},{"location":"mathematics/ESL/ESL10_BoostingTrees/#_1","text":"\\(M\\) - \u603b\u5171\u7684\u6811\u7684\u6570\u91cf \\(D\\) - \u6bcf\u4e2a\u6811\u7684\u6700\u5927\u6df1\u5ea6 \\(\\rho\\) - \u6b65\u957f\uff0c\u5373\u5b66\u4e60\u7387 \u4e3a\u4ec0\u4e48\u9700\u8981\u8bbe\u7f6e\u6811\u7684\u6700\u5927\u6df1\u5ea6\uff1f \u7684\u786e\uff0c\u5728\u4e0a\u9762 Regression tree \u7684\u751f\u6210\u4e2d\uff0c\u6211\u4eec\u662f\u76f4\u63a5\u5bfb\u627e\u201c\u6700\u4f18\u6811\u201d\u3002\u5e76\u4e0d\u9650\u5236\u8282\u70b9\u548c\u6df1\u5ea6\uff0c\u800c\u662f\u5148\u6784\u9020\u4e00\u4e2a\u8db3\u591f\u5927\u7684\u6811\uff0c\u901a\u8fc7\u201c\u526a\u679d\u201d\u64cd\u4f5c\u6765\u5f97\u5230\u5408\u9002\u7684\u8282\u70b9\u6570\u3002 \u7531\u4e8e boosting trees \u5305\u542b\u591a\u4e2a\u6811\uff0c\u6211\u4eec\u5bf9\u6bcf\u4e2a\u6811\u5e76\u4e0d\u8981\u6c42\u201c\u6700\u4f18\u201d\uff0c\u8bbe\u7f6e\u4e00\u4e2a\u6700\u5927\u6df1\u5ea6\u53ef\u4ee5\u6781\u5927\u5730\u7b80\u5316\u8ba1\u7b97\u3002","title":"\u53c2\u6570"},{"location":"mathematics/ESL/ESL10_BoostingTrees/#_2","text":"\u521d\u59cb\u5316\u4e00\u4e2a\u4ec5\u6709\u4e00\u4e2a\u8282\u70b9\u7684\u6811\uff0c\u5305\u542b\u6240\u6709\u6837\u672c\uff0c\u8282\u70b9\u7684\u503c \\(\\gamma\\) \u4e3a\u4ee5\u4e0b\u4f18\u5316\u95ee\u9898\u7684\u89e3\uff1a \\[f_0(x) = \\arg \\min_{ \\gamma } \\sum_{i=1}^N L(y_i, \\gamma) \\] \u5bf9\u6bcf\u68f5\u6811 \\(k = 1\\) to \\(M\\) \uff1a a. \u5bf9\u6bcf\u4e2a\u6837\u672c\u8ba1\u7b97\u8d1f\u68af\u5ea6\uff1a \\[ r_{ik} = - \\frac{ \\partial L(y_i, f(x_i)) }{ \\partial f(x_i) } | _{f= f_{k-1}} \\] b. \u4ee5\u8d1f\u68af\u5ea6\u4e3a\u76ee\u6807\u62df\u5408\u4e00\u4e2a\u6811 c. \u5c06\u8fd9\u4e2a\u6811\u52a0\u5165\u6a21\u578b\uff0c\u5e76\u66f4\u65b0\u9884\u6d4b\u503c","title":"\u7b97\u6cd5"},{"location":"mathematics/ESL/ESL10_BoostingTrees/#gradient-boosting-trees_1","text":"\u4ee5\u4e0b\u4ee3\u7801\u662f\u5f53\u635f\u5931\u51fd\u6570\u5b9a\u4e49\u4e3a\u5747\u65b9\u635f\u5931(mean squared error)\u65f6\u7684\u5b9e\u73b0\uff0c\u6b64\u65f6\u8d1f\u68af\u5ea6\u53ef\u4ee5\u7528 \\(g_m = y - f(x)\\) \u6c42\u5f97\u3002 from sklearn.model_selection import KFold from sklearn.metrics import mean_squared_error from sklearn.ensemble import GradientBoostingRegressor class MyGbm : def __init__ ( self , tree_num , tree_depth , learn_rate ): self . tree_num = tree_num self . tree_depth = tree_depth self . learn_rate = learn_rate self . boosting_trees = [] self . predict0 = 0 def fit ( self , train_X , train_y ): self . predict0 = train_y . mean () prediction = pd . Series ( data = self . predict0 , index = train_y . index ) for i in range ( 1 , self . tree_num ): # assuming loss function is squared error # 1. compute negative gradients neg_grads = train_y - prediction # 2. fit a regression tree tree = DecisionTreeRegressor ( max_depth = self . tree_depth ) tree . fit ( train_X , neg_grads ) # 3. update prediction self . boosting_trees . append ( tree ) prediction += tree . predict ( train_X ) * self . learn_rate def predict ( self , test_X ): # must be trained assert len ( self . boosting_trees ) > 0 prediction = pd . Series ( data = self . predict0 , index = test_X . index ) for tree in self . boosting_trees : prediction += tree . predict ( test_X ) * self . learn_rate return prediction \u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u4e0e sklearn \u5b98\u65b9\u7684 GradientBoostingRegressor \u76f8\u6bd4\u8f83\uff08\u901a\u8fc7enable/disable official \uff09\u3002\u9009\u53d6\u7684\u6570\u636e\u96c6\u662f Black Friday Dataset \uff0c\u6bd4\u8f83\u57fa\u51c6\u662f\u5747\u65b9\u6839\u8bef\u5dee\uff0c\u56e0\u4e3a\u7535\u8111\u7834\u6240\u4ee5\u53ea\u9009\u62e9\u4e86\u524d 10000 \u884c\u6570\u636e\u3002 official = False kf = KFold ( n_splits = 5 , shuffle = False , random_state = None ) for train_index , test_index in kf . split ( X ): print ( \"TRAIN:\" , train_index , \"TEST:\" , test_index ) X_train , X_test = X . loc [ train_index ], X . loc [ test_index ] y_train , y_test = y . loc [ train_index ], y . loc [ test_index ] n_estimators = 100 learning_rate = 0.1 max_depth = 10 if official : gbm = GradientBoostingRegressor ( n_estimators = n_estimators , max_depth = max_depth , learning_rate = learning_rate ) else : gbm = MyGbm ( n_estimators , max_depth , learning_rate ) gbm . fit ( X_train , y_train ) y_pred = gbm . predict ( X_test ) # root mean square error rmse = np . sqrt ( mean_squared_error ( y_true = y_test , y_pred = y_pred )) print ( 'rmse:' , rmse ) \u5b98\u65b9\u5b9e\u73b0\u7684 GBM\uff1a TRAIN: [2000 2001 2002 ... 9997 9998 9999] TEST: [ 0 1 2 ... 1997 1998 1999] rmse: 3581.9870271000086 TRAIN: [ 0 1 2 ... 9997 9998 9999] TEST: [2000 2001 2002 ... 3997 3998 3999] rmse: 2907.6311604609245 TRAIN: [ 0 1 2 ... 9997 9998 9999] TEST: [4000 4001 4002 ... 5997 5998 5999] rmse: 2944.398603563586 TRAIN: [ 0 1 2 ... 9997 9998 9999] TEST: [6000 6001 6002 ... 7997 7998 7999] rmse: 2999.08249707528 TRAIN: [ 0 1 2 ... 7997 7998 7999] TEST: [8000 8001 8002 ... 9997 9998 9999] rmse: 3416.907798496119 \u81ea\u5df1\u5b9e\u73b0\u7684GBM\uff1a TRAIN: [2000 2001 2002 ... 9997 9998 9999] TEST: [ 0 1 2 ... 1997 1998 1999] rmse: 3607.182565950029 TRAIN: [ 0 1 2 ... 9997 9998 9999] TEST: [2000 2001 2002 ... 3997 3998 3999] rmse: 2907.502318685874 TRAIN: [ 0 1 2 ... 9997 9998 9999] TEST: [4000 4001 4002 ... 5997 5998 5999] rmse: 2941.2904466354057 TRAIN: [ 0 1 2 ... 9997 9998 9999] TEST: [6000 6001 6002 ... 7997 7998 7999] rmse: 3005.347599886747 TRAIN: [ 0 1 2 ... 7997 7998 7999] TEST: [8000 8001 8002 ... 9997 9998 9999] rmse: 3407.221705763073 \u53ef\u4ee5\u770b\u51fa\u5dee\u8ddd\u4e0d\u5927\uff0c\u56e0\u6b64\u8fd9\u4e2a\u5b9e\u73b0\u662f\u6b63\u786e\u7684\u3002","title":"Gradient Boosting Trees \u5b9e\u73b0"},{"location":"mathematics/ESL/ESL10_BoostingTrees/#reference","text":"Introduction to Boosted Trees Gradient Boosting Black Friday Dataset Cross Validation Decision Tree Regressor Preprocess category features","title":"Reference"},{"location":"mathematics/ESL/ESL11_NeuralNetworks/","text":"ESL 11: Neural Networks \u795e\u7ecf\u7f51\u7edc\u7684\u4e2d\u5fc3\u601d\u60f3\u662f\u5c06\u8f93\u5165 \u7ebf\u6027\u7ec4\u5408 \u4e3a\u4e00\u4e9b\u884d\u751f\u7684\u7279\u5f81\uff0c\u518d\u5efa\u7acb\u8f93\u51fa\u4e0e\u8fd9\u4e9b\u7279\u5f81\u4e4b\u95f4\u7684 \u975e\u7ebf\u6027 \u6a21\u578b\u3002 11.2 Projection Pursuit Regression \u4ee5\u4e00\u4e2a\u901a\u7528\u7684\u76d1\u7763\u5b66\u4e60\u95ee\u9898\u4e3a\u4f8b\uff0c\u5047\u8bbe\u6211\u4eec\u6709 \\(p\\) \u7ef4\u8f93\u5165 \\(X\\) \uff0c\u8f93\u51fa\u662f \\(Y\\) \u3002 \\(w_m\\) \u662f \\(p\\) \u7ef4\u5355\u4f4d\u5411\u91cf\uff0c\u6211\u4eec\u53ef\u4ee5\u628a projection pursuit regression \u6a21\u578b\u8868\u793a\u4e3a\uff1a \\[f(X) = \\sum_{m=1}^M g_m (w_m^T X) \\] \u53ef\u4ee5\u770b\u51fa\uff0c\u8fd9\u4e5f\u662f\u4e00\u4e2a\u52a0\u6027\u6a21\u578b\u3002\u4f46\u662f\u533a\u522b\u5728\u4e8e\uff0c\u5b83\u7684\u81ea\u53d8\u91cf\u4e0d\u662f\u76f4\u63a5\u8f93\u5165 \\(X\\) \uff0c\u800c\u662f\u8f93\u5165\u7684\u7ebf\u6027\u7ec4\u5408 \\(w_m^T X\\) \u3002 \\(g_m(w_m^T X)\\) \u88ab\u79f0\u4e3a\u201c\u5cad\u51fd\u6570\u201d (Ridge Function)\u3002\u5b83\u53ea\u6cbf\u7740 \\(w_m\\) \u7684\u65b9\u5411\u53d8\u5316\uff0c\u800c\u6807\u91cf \\(V_m = w_m^T X\\) \u5c31\u662f\u8f93\u5165 \\(X\\) \u5728 \\(w_m\\) \u65b9\u5411\u4e0a\u7684\u6295\u5f71 (projection)\u3002 \u6211\u4eec\u7684\u76ee\u6807\u662f\u5bfb\u627e \\(w_m\\) \uff08\u5373\u6295\u5f71\u65b9\u5411\uff09\u4f7f\u5f97\u6a21\u578b\u4f30\u8ba1\u8bef\u5dee\u6700\u5c0f\u3002\u56e0\u6b64\uff0c\u8fd9\u4e2a\u65b9\u6cd5\u53eb\u505a projection pursuit\u3002\u5b83\u7684 \u4f18\u70b9 \u662f\u5982\u679c\u5b50\u6a21\u578b\u6570\u91cf M \u8db3\u591f\u5927\uff0c\u5b83\u80fd\u591f\u5b8c\u7f8e\u62df\u5408\u4efb\u4f55\u8fde\u7eed\u51fd\u6570\u3002 \u7f3a\u70b9 \u662f\u53ef\u89e3\u91ca\u6027\u5dee\u3002\u56e0\u6b64\u9002\u7528\u4e8e\u53ea\u9700\u8981\u505a\u9884\u6d4b\uff0c\u4e0d\u9700\u8981\u5f52\u56e0\u7684\u573a\u666f\u3002 PPR \u62df\u5408 \u7ed9\u5b9a\u8bad\u7ec3\u6570\u636e \\((x_i, y_i), i=1,2,\\dots,N\\) \uff0c\u6211\u4eec\u7684\u76ee\u6807\u662f\u786e\u5b9a\u51fd\u6570 \\(g\\) \u548c\u65b9\u5411 \\(w\\) \uff0c\u4f7f\u9884\u6d4b\u7ed3\u679c\u7684 squared error \u6700\u5c0f\uff1a \\[ g, w = \\mathop{\\arg \\min}_{g, w} \\sum_{i=1}^N [y_i - \\sum_{m=1}^M g_m(w_m^T x_i)]^2 \\] \u5047\u8bbe\u4ec5\u6709\u4e00\u4e2a\u5b50\u6a21\u578b\uff0c\u5373 M = 1 \uff0c\u786e\u5b9a \\(g\\) \u7684\u8fc7\u7a0b\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u4e00\u7ef4 smoothing \u95ee\u9898\u3002\u56e0\u6b64\uff0c \\(g\\) \u53ef\u4ee5\u9009\u62e9\u4f7f\u7528 spline\u3002 \u5df2\u77e5\u51fd\u6570 \\(g\\) \u7684\u5f62\u5f0f\uff0c\u6211\u4eec\u9700\u8981\u786e\u5b9a\u4f7f\u4f30\u8ba1\u8bef\u5dee\u6700\u5c0f\u7684\u65b9\u5411 \\(w\\) \u3002\u8fd9\u662f\u4e00\u4e2a \u65e0\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898 \uff0c\u4e14 \\(g\\) \u53ef\u5bfc\uff0c\u56e0\u6b64\u53ef\u4ee5\u4f7f\u7528\u725b\u987f\u6cd5\u6765\u89e3\u51b3\u3002 \u5047\u8bbe\u5f53\u524d\u5bf9 \\(w\\) \u7684\u4f30\u8ba1\u4e3a \\(w_{\\text{old}}\\) \uff0c\u6211\u4eec\u5bf9 \\(g\\) \u8fdb\u884c\u6cf0\u52d2\u5c55\u5f00\uff0c\u5ffd\u7565 2 \u9636\u4ee5\u4e0a\u6709\uff1a \\[ g(w^T x_i) \\approx g(w_{\\text{old}}^T x_i) + g'(w_{\\text{old}}^T x_i)(w - w_{\\text{old}})^T x_i \\] \u7531\u4e8e M = 1\uff0csquared error \u53ef\u4ee5\u7b80\u5316\u4e3a\uff1a \\[\\begin{align} \\sum_{i=1}^N [y_i - g(w^T x_i)]^2 &= \\sum_{i=1}^N [y_i - g(w_{\\text{old}}^T x_i) - g'(w_{\\text{old}}^T x_i)(w - w_{\\text{old}})^T x_i]^2 \\\\ &= \\sum_{i=1}^N g'(w_{\\text{old}}^T x_i)^2 [w^T x_i - (w_{\\text{old}}^T x_i + \\dfrac{y_i - g(w_{\\text{old}}^T x_i)}{g'(w_{\\text{old}}^T x_i)})]^2 \\end{align}\\] \u7b49\u5f0f\u53f3\u8fb9\u53ef\u4ee5\u770b\u4f5c\u4e00\u4e2a least squares regression \u95ee\u9898\u3002\u6709 N \u4e2a\u6837\u672c\u70b9\uff0c\u5bf9\u4e8e\u7b2c i \u4e2a\u6837\u672c\uff0c\u5176\u5e73\u65b9\u8bef\u5dee\u7684\u6743\u91cd\u4e3a \\(g'(w_{\\text{old}}^T x_i)^2\\) \uff0c\u76ee\u6807\u662f \\(w_{\\text{new}}^T x_i\\) \u5c3d\u91cf\u9760\u8fd1 \\(w_{\\text{old}}^T x_i + \\frac{y_i - g(w_{\\text{old}}^T x_i)}{g'(w_{\\text{old}}^T x_i)}\\) \u3002 \u6c42\u89e3\u8fd9\u4e2a least squares regression \u6211\u4eec\u5f97\u5230\u4e00\u7ec4\u65b0\u7684\u7cfb\u6570 \\(w_{\\text{new}}\\) \uff0c\u66f4\u65b0 \\(w_{\\text{old}} = w_{\\text{new}}\\) \u5e76\u8fdb\u884c\u4e0b\u4e00\u8f6e\u8fed\u4ee3\uff0c\u76f4\u5230 \\(g'(w_{\\text{old}}^T x_i)\\) \u5c0f\u4e8e\u67d0\u4e2a\u9608\u503c\u3002 \u7531\u4e8e\u5176\u8ba1\u7b97\u91cf\u8fc7\u5927\uff0cPPR \u7684\u5e94\u7528\u5e76\u4e0d\u5f88\u5e7f\u6cdb\u3002\u4f46\u662f\uff0c\u5b83\u662f\u540e\u6765\u83b7\u5f97\u5e7f\u6cdb\u5e94\u7528\u7684 \u795e\u7ecf\u7f51\u7edc\u6280\u672f\u7684\u524d\u8eab \u3002\u6211\u4eec\u5c06\u5728\u4e0b\u9762\u7684\u7ae0\u8282\u4ecb\u7ecd\u795e\u7ecf\u7f51\u7edc\u3002 11.3 Neural Networks \u201c\u795e\u7ecf\u7f51\u7edc\u201d\u8fd9\u4e2a\u540d\u5b57\u6e90\u4e8e\u8be5\u65b9\u6cd5\u6700\u65e9\u88ab\u5e94\u7528\u4e8e\u4eba\u8111\u7684\u5efa\u6a21\u3002\u6bcf\u4e2a\u8282\u70b9\u662f\u4e00\u4e2a\u795e\u7ecf\u5143\uff0c\u4ed6\u4eec\u4e4b\u95f4\u7684\u8fde\u63a5\u4ee3\u8868\u7a81\u89e6\u3002\u5355\u201c\u9690\u85cf\u5c42\u201d\u7684\u795e\u7ecf\u7f51\u7edc\u4e0e\u521a\u624d\u4ecb\u7ecd\u7684 Projection Pursuit Regression \u6a21\u578b\u975e\u5e38\u76f8\u4f3c\uff0c\u6211\u4eec\u4ee5\u5b83\u4e3a\u4f8b\u8bb2\u89e3\u3002 \u6211\u4eec\u53ef\u4ee5\u770b\u5230\u8be5\u795e\u7ecf\u7f51\u7edc\u5206\u4e3a 3 \u5c42\u3002\u5176\u4e2d \\(X\\) \u662f\u8f93\u5165\uff0c \\(Y\\) \u662f\u8f93\u51fa\uff0c \\(Z\\) \u662f\u6240\u8c13\u7684\u201c\u9690\u85cf\u5c42\u201d\uff0c\u5b83\u88ab\u79f0\u4e3a\u9690\u85cf\u5c42\u662f\u56e0\u4e3a\u5b83\u4e0d\u76f4\u63a5\u53ef\u89c1\u3002 \u7c7b\u4f3c\u4e8e PPR\uff0c\u9690\u85cf\u5c42 \\(Z\\) \u7531\u8f93\u5165 \\(X\\) \u7ebf\u6027\u7ec4\u5408\uff0c\u518d\u9644\u52a0\u4e00\u4e2a\u201c\u6fc0\u6d3b\u51fd\u6570\u201d \\(\\sigma\\) \u5f97\u51fa\u3002 \\[ Z_m = \\sigma(\\alpha_0 + \\alpha_m^T X), \\quad m = 1,\\dots,M \\] \u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570\u5982 sigmoid\uff1a \\[ \\sigma(v) = \\dfrac{1}{1 + e^{-v}} \\] \u800c\u8f93\u51fa \\(Y\\) \u7531\u9690\u85cf\u5c42 \\(Z\\) \u7ebf\u6027\u7ec4\u5408\uff0c\u518d\u9644\u52a0\u4e00\u4e2a\u201c\u8f93\u51fa\u51fd\u6570\u201d \\(g\\) \u5f97\u51fa\u3002 \\[ Y_k = g_k(T) = g_k(\\beta_0 + \\beta_k^T Z) \\] \u5bf9\u4e8e\u56de\u5f52\u95ee\u9898\uff0c \\(g\\) \u53ef\u4ee5\u7701\u7565\uff0c\u5bf9\u4e8e\u5206\u7c7b\u95ee\u9898\uff0c\u4e3a\u786e\u4fdd\u8f93\u51fa\u90fd\u662f\u6574\u6570\u4e14\u548c\u4e3a 1.0\uff0c\u901a\u5e38\u9009\u7528 softmax \u51fd\u6570\uff0c\u5c5e\u4e8e\u7b2c k \u7c7b\u7684\u6982\u7387\u4e3a: \\[ g_k(T) = \\dfrac{e^{T_k}}{\\sum_{l=1}^K e^{T_l}} \\] \u6211\u4eec\u770b\u51fa\uff0c\u5176\u5b9e PPR \u4e0e NN \u7684\u5dee\u5f02\u5c31\u5728\u4e8e NN \u4f7f\u7528\u7684\u6fc0\u6d3b\u51fd\u6570\u76f8\u6bd4 PPR \u4f7f\u7528\u7684 spline \u7b80\u5355\u5f88\u591a\uff0c\u8fd9\u5c31\u4f7f\u5f97 NN \u7684\u8ba1\u7b97\u91cf\u5c0f\u5f88\u591a\uff0c\u83b7\u5f97\u4e86\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u3002 11.4 Fitting Neural Networks \u62df\u5408\u795e\u7ecf\u7f51\u7edc\u5b9e\u9645\u4e0a\u5c31\u662f\u627e\u5230\u521a\u624d\u63d0\u5230\u7684\u4e24\u7ec4\u53c2\u6570\uff1a \u7531\u8f93\u5165 \\(X\\) \u5230\u9690\u85cf\u5c42 \\(Z\\) \u7684\u7ebf\u6027\u7ec4\u5408\u7cfb\u6570 \\(\\bf{\\alpha}\\) \u3002\u7531\u4e8e\u6709 M \u4e2a\u9690\u85cf\u5c42\u8282\u70b9\uff0c\u800c\u6bcf\u4e2a\u8282\u70b9\u5bf9\u5e94\u7684\u7cfb\u6570\u90fd\u662f \\(p + 1\\) \u7ef4\uff08+1 for bias\uff09\u3002\u56e0\u6b64\u662f\u4e00\u4e2a \\(M \\times (p+1)\\) \u77e9\u9635\u3002 \u7531\u9690\u85cf\u5c42 \\(Z\\) \u5230\u8f93\u51fa \\(Y\\) \u7684\u7ebf\u6027\u7ec4\u5408\u7cfb\u6570 \\(\\bf{\\beta}\\) \u3002\u7531\u4e8e\u6709 K \u4e2a\u8f93\u51fa\u8282\u70b9\uff0c\u800c\u6bcf\u4e2a\u8282\u70b9\u5bf9\u5e94\u7684\u7cfb\u6570\u90fd\u662f \\(M + 1\\) \u7ef4\uff08+1 for bias\uff09\u3002\u56e0\u6b64\u662f\u4e00\u4e2a \\(K \\times (M+1)\\) \u77e9\u9635\u3002 \u6211\u4eec\u9996\u5148\u4ee5\u635f\u5931\u51fd\u6570 sum-of-squared-errors \u4e3a\u4f8b: \\[ R(\\theta) = \\sum_{i=1}^N R_i = \\sum_{i=1}^N \\sum_{k=1}^K (y_{ik} - f_k(x_i))^2 \\] \u8bb0 \\(l, m, k\\) \u5206\u522b\u4e3a\u8f93\u5165 \\(X\\) \uff0c\u9690\u85cf\u5c42 \\(Z\\) \u548c\u8f93\u51fa \\(Y\\) \u7684\u5e8f\u53f7\uff0c\u5bf9 \\(\\alpha_{ml}\\) \u548c \\(\\beta_{km}\\) \u6c42\u5bfc\uff0c\u6839\u636e\u94fe\u5f0f\u6cd5\u5219\u6709\uff1a \\[ \\dfrac{\\partial R_i}{\\partial \\beta_{km}} = - 2(y_{ik} - f_k(x_i)) g_k'(\\beta_k^T z_i) z_{mi} \\] \\[ \\dfrac{\\partial R_i}{\\partial \\alpha_{ml}} = - \\sum_{k=1}^K 2(y_{ik} - f_k(x_i)) g_k'(\\beta_k^T z_i) \\beta_{km} \\sigma'(\\alpha_m^T x_i) x_{il} \\] \u6ce8\u610f\uff0c\u5bf9 \\(\\beta_{km}\\) \u6c42\u5bfc\u7ed3\u679c\u4e2d\u4e0d\u542b \\(\\sum_{k=1}^K\\) \u3002\u6211\u4eec\u5047\u8bbe\u73b0\u5728\u7528\u7b2c \\(j(j \\neq k)\\) \u4e2a\u8f93\u51fa\u5bf9 \\(\\beta_{km}\\) \u6c42\u5bfc\uff0c\u7531\u4e8e \\(\\beta_{km}\\) \u610f\u4e49\u662f\u7b2c k \u4e2a\u8f93\u51fa\u4e0e\u7b2c m \u4e2a\u9690\u85cf\u8282\u70b9\u7684\u7cfb\u6570\uff0c\u4e0e\u7b2c j \u4e2a\u8f93\u51fa\u65e0\u5173\uff0c\u7ed3\u679c\u5fc5\u7136\u4e3a 0\u3002\u800c\u5bf9\u4e8e \\(\\alpha_{ml}\\) \u6c42\u5bfc\u65f6\uff0c\u7531\u4e8e\u7b2c m \u4e2a\u9690\u85cf\u8282\u70b9\u4f1a\u4f5c\u7528\u7ed9\u7b2c k \u4e2a\u548c\u7b2c j \u4e2a\u8f93\u51fa\uff0c\u6240\u4ee5\u5b58\u5728 \\(\\sum_{k=1}^K\\) \u3002 \u5f97\u5230\u8fd9\u4e9b\u5bfc\u6570\uff0c\u6211\u4eec\u53ef\u4ee5\u8bbe\u5b9a learning rate \\(\\gamma_r\\) \uff0c\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u8fed\u4ee3\u66f4\u65b0\uff1a \\[ \\beta_{km}^{(r+1)} = \\beta_{km}^{(r)} - \\gamma_r \\sum_{i=1}^N \\dfrac{\\partial R_i}{\\partial \\beta_{km}^{(r)}} \\] \\[ \\alpha_{ml}^{(r+1)} = \\alpha_{ml}^{(r)} - \\gamma_r \\sum_{i=1}^N \\dfrac{\\partial R_i}{\\partial \\beta_{ml}^{(r)}} \\] \u73b0\u5728\u4ee4\uff1a \\[ \\dfrac{\\partial R_i}{\\partial \\beta_{km}} = \\delta_{ki} z_{mi} \\] \\[ \\dfrac{\\partial R_i}{\\partial \\alpha_{ml}} = s_{mi} x_{il} \\] \u6211\u4eec\u53ef\u4ee5\u5f97\u51fa\u5173\u7cfb\uff1a \\[ s_{mi} = \\sigma'(\\alpha_m^T x_i) \\sum_{k=1}^K \\beta_{km} \\delta_{ki} \\] \u8fd9\u4e2a\u7b49\u5f0f\u88ab\u79f0\u4e3a back-propagation equation\u3002\u5229\u7528\u8fd9\u4e2a\u7b49\u5f0f\uff0c\u66f4\u65b0\u65f6\u53ef\u4ee5\u7b80\u5316 \\(s_{mi}\\) \u7684\u8ba1\u7b97\u3002back-propagation \u7684\u8fc7\u7a0b\u53ef\u4ee5\u63cf\u8ff0\u4e3a\u4e00\u4e2a \u53cc\u5411\u4f20\u64ad \u7684\u8fc7\u7a0b\uff1a \u6b63\u5411\u4f20\u64ad\uff0c\u5229\u7528\u8f93\u5165 \\(X\\) \u548c\u5f53\u524d\u7684 weights \u6765\u8ba1\u7b97\u9884\u6d4b\u503c \\(\\hat{f}_k(x_i)\\) \u53cd\u5411\u4f20\u64ad\uff0c\u9996\u5148\u8ba1\u7b97\u51fa\u9690\u85cf\u5c42 \\(Z\\) \u5230\u8f93\u51fa\u5c42 \\(Y\\) \u7684 \\(\\delta_{ki}\\) \uff0c\u518d\u5229\u7528\u4e0a\u9762\u7684\u7b49\u5f0f\u8ba1\u7b97 \\(s_{mi}\\) \uff0c\u5f97\u51fa\u4e24\u4e2a\u68af\u5ea6\u7684\u503c\uff0c\u518d\u66f4\u65b0 weights \u8fd9\u4e2a\u7b97\u6cd5\u7684\u4f18\u52bf\u5728\u4e8e\u7b80\u5355\u5e76\u4e14\u6613\u4e8e\u5e76\u884c\uff0c\u52a3\u52bf\u5728\u4e8e\u8ba1\u7b97\u91cf\u5927\u3002 11.5 Some Issues in Training Neural Networks \u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u5e76\u4e0d\u662f\u50cf\u7b97\u6cd5\u539f\u7406\u90a3\u4e48\u7b80\u5355\u3002\u795e\u7ecf\u7f51\u7edc\u662f\u4e00\u4e2a\u53c2\u6570\u5f88\u591a\u7684\u6a21\u578b\uff0c\u5b83\u4ece\u539f\u7406\u4e0a\u503e\u5411\u4e8e overfit\u3002 11.5.1 Starting Values sigmoid \u51fd\u6570\u5728 0 \u9644\u8fd1\u8fd1\u4f3c\u4e8e\u7ebf\u6027\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06 weights \u7684\u521d\u59cb\u503c\u9009\u5728 0 \u9644\u8fd1 \uff0c\u8fd9\u6837\u6211\u4eec\u4ece\u4e00\u4e2a\u8fd1\u4f3c\u7ebf\u6027\u7684\u6a21\u578b\u5f00\u59cb\u8bad\u7ec3\uff0c\u7136\u540e\u975e\u7ebf\u6027\u9010\u6b65\u589e\u5f3a\u3002\u6ce8\u610f\uff0c\u521d\u59cb\u6743\u91cd\u4e0d\u80fd\u4e3a 0\uff0c\u6211\u4eec\u7531\u516c\u5f0f\u53ef\u4ee5\u770b\u51fa\u5176\u68af\u5ea6\u4e3a 0\uff0c\u65e0\u6cd5\u6536\u655b\u3002 11.5.2 Overfitting \u7531\u4e8e\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5f88\u591a\uff0c\u4e00\u822c\u6211\u4eec\u901a\u8fc7 early stopping \u6765\u907f\u514d overfitting\u3002\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u65bd\u52a0\u60e9\u7f5a\u9879\u6765\u8fdb\u884c regularization\u3002 11.5.3 Scaling of the Inputs \u521d\u59cb\u65f6\uff0c\u6211\u4eec\u9700\u8981\u628a\u6240\u6709\u8f93\u5165\u90fd\u6620\u5c04\u4e3a \u6807\u51c6\u6b63\u6001\u5206\u5e03 \uff0c\u540c\u65f6\uff0c\u521d\u59cb\u7684 weights \u8bbe\u7f6e\u4e3a [-0.7, +0.7] \u4e4b\u95f4\u7684\u5747\u5300\u5206\u5e03\u3002 11.5.4 Number of Hidden Units and Layers \u901a\u5e38\u9690\u85cf\u5c42\u8282\u70b9\u7684\u6570\u91cf\u5728 [5, 100] \u4e4b\u95f4\u9009\u62e9\uff0c\u8f93\u5165\u6570\u91cf\u8d8a\u591a\uff0c\u9690\u85cf\u5c42\u8282\u70b9\u8d8a\u591a\u3002 \u9690\u85cf\u5c42\u5c42\u6570\u4e00\u822c\u901a\u8fc7\u7ecf\u9a8c\u548c\u80cc\u666f\u77e5\u8bc6\u9009\u62e9\u3002 11.6 Example \u6211\u4eec\u91c7\u7528\u624b\u5199\u6570\u5b57\u8bc6\u522b\u6765\u68c0\u9a8c\u795e\u7ecf\u7f51\u7edc\u7684\u5206\u7c7b\u6027\u80fd\u3002 import pandas as pd from sklearn import datasets from sklearn.neural_network import MLPClassifier from sklearn.model_selection import KFold digits = datasets . load_digits () X = pd . DataFrame ( digits . data , columns = digits . feature_names ) y = pd . Series ( digits . target ) for train_index , test_index in KFold ( n_splits = 5 , shuffle = True , random_state = 1 ) . split ( X ): # print(\"TRAIN:\", train_index, \"TEST:\", test_index) trainX , testX = X . loc [ train_index ], X . loc [ test_index ] trainY , testY = y . loc [ train_index ], y . loc [ test_index ] model = MLPClassifier ( solver = 'lbfgs' , hidden_layer_sizes = ( 12 ,), random_state = 1 ) . fit ( trainX , trainY ) print ( f \"MLP accurracy: { model . score ( testX , testY ) } \" ) \u6ce8\u610f\uff0c hidden_layer_sizes=(12,) \u8868\u660e\u6211\u4eec\u9009\u62e9\u4e86 1 \u5c42\u9690\u85cf\u5c42\uff0c\u8be5\u9690\u85cf\u5c42\u5305\u542b 12 \u4e2a\u8282\u70b9\u3002 \u5176\u5206\u7c7b\u7ed3\u679c\u4e3a\uff1a MLP accurracy: 0.8833333333333333 MLP accurracy: 0.9111111111111111 MLP accurracy: 0.8885793871866295 MLP accurracy: 0.9303621169916435 MLP accurracy: 0.8997214484679665 \u53ef\u4ee5\u770b\u51fa\u5176\u51c6\u786e\u7387\u5728 90% \u5de6\u53f3\u3002 11.6.1 Improvement \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7 \u589e\u52a0\u9690\u85cf\u5c42 \u6765\u63d0\u9ad8\u5206\u7c7b\u7cbe\u786e\u5ea6\uff0c\u4f8b\u5982\uff0c\u6211\u4eec\u7b80\u5355\u589e\u52a0\u4e00\u5c42 hidden_layer_sizes=(12,12) \uff0c\u5206\u7c7b\u7ed3\u679c\u4e3a\uff1a MLP accurracy: 0.9111111111111111 MLP accurracy: 0.9388888888888889 MLP accurracy: 0.9387186629526463 MLP accurracy: 0.9415041782729805 MLP accurracy: 0.9220055710306406 \u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u6709\u66f4\u7cbe\u5999\u7684\u65b9\u6cd5\uff0c\u4f8b\u5982\u6539\u53d8\u7f51\u7edc\u7ed3\u6784\u3002 \u5c40\u90e8\u8fde\u63a5\uff08local connectivity\uff09\uff1a\u6211\u4eec\u53ef\u4ee5\u9650\u5b9a\u6bcf\u4e2a\u9690\u85cf\u5c42\u8282\u70b9\u53ea\u8fde\u63a5\u5230\u4e0b\u4e00\u5c42\u7684\u67d0\u4e00\u90e8\u5206\u8282\u70b9\u3002\u4f8b\u5982 3x3 \u7684\u5c0f\u65b9\u5757\u3002\u5c40\u90e8\u8fde\u63a5\u53ef\u4ee5\u63d0\u53d6\u4e0b\u4e00\u5c42\u7684\u5c40\u90e8\u7279\u5f81\uff0c\u5e76\u5927\u5927\u964d\u4f4e\u9700\u8981\u8bad\u7ec3\u7684 weights \u603b\u6570\u3002 \u5171\u4eab\u6743\u91cd\uff08shared weights\uff09\uff1a\u5728\u5c40\u90e8\u8fde\u63a5\u7684\u57fa\u7840\u4e0a\uff0c\u6211\u4eec\u8fd8\u53ef\u4ee5\u8ba9\u6bcf\u4e2a\u5c40\u90e8\u533a\u57df\u4f7f\u7528\u76f8\u540c\u7684 weights\u3002\u8fd9\u4e48\u505a\u7684\u7ed3\u679c\u662f\u5bf9\u56fe\u50cf\u4e0d\u540c\u7684\u533a\u57df\u91c7\u7528\u540c\u6837\u7684\u64cd\u4f5c\u3002\u8fd9\u4e5f\u88ab\u79f0\u4f5c \u5377\u79ef\u7f51\u7edc (convolutional networks)\u3002 \u4ee5\u4e0b\u9762\u51e0\u79cd\u7f51\u7edc\u4e3a\u4f8b\uff0c\u6211\u4eec\u8ba1\u7b97\u5176\u6743\u91cd\u6570\u91cf\uff1a \u53ea\u6709\u8f93\u5165\u548c\u8f93\u51fa\u5c42\uff0c\u8f93\u5165\u5c42\u8282\u70b9 16x16\uff0c\u8f93\u51fa\u5c42\u8282\u70b9 10\uff0c\u4e00\u5171 16x16x10 = 2560\u3002\u518d\u52a0\u4e0a 10 \u4e2a bias\uff0c\u5171 2570 \u4e2a\u53c2\u6570\u3002 \u6709\u4e00\u5c42\u9690\u85cf\u5c42\uff0c12\u4e2a\u9690\u85cf\u8282\u70b9\u3002 16x16x12 + 12x10 = 3192\uff0c\u518d\u52a0\u4e0a 12 \u4e2a\u9690\u85cf\u8282\u70b9\u548c 10 \u4e2a\u8f93\u51fa\u8282\u70b9\u7684 bias\uff0c\u5171 3214 \u4e2a\u53c2\u6570\u3002 \u6709\u4e24\u5c42\u5c40\u90e8\u8fde\u63a5\u7684\u9690\u85cf\u5c42\u3002\u7531\u4e8e\u662f\u5c40\u90e8\u8fde\u63a5\uff0c\u8ba1\u7b97\u65b9\u5f0f\u4e3a patch \u5927\u5c0f\u4e58\u4ee5\u4e0a\u4e00\u5c42\u8282\u70b9\u6570\uff1a(3x3)x8x8 + (5x5)x4x4 + 4x4x10 = 1136\uff0c\u518d\u52a0\u4e0a 64 + 16 + 10 \u4e2a bias\uff0c\u5171 1226 \u4e2a\u53c2\u6570\u3002 \u4e24\u5c42\u5c40\u90e8\u8fde\u63a5\u9690\u85cf\u5c42\uff0c\u7b2c\u4e00\u5c42\u5171\u4eab\u6743\u91cd\u3002\u7531\u4e8e\u662f\u5171\u4eab\u6743\u91cd\uff0c\u6bcf\u5c42\u53c2\u6570\u4e2a\u6570\u56fa\u5b9a\u30023x3x2 + (5x5)x4x4x2 + 4x4x10 = 978\u3002\u518d\u52a0\u4e0a 64x2 + 16 + 10 \u4e2a bias\uff0c\u5171 1132 \u4e2a\u53c2\u6570\u3002 \u7531\u4e8e\u5b58\u5728\u5171\u4eab\u6743\u91cd\uff0c\u8fde\u63a5\u6570\u548c\u53c2\u6570\u4e2a\u6570\u4e0d\u540c\u3002\u4ece\u8f93\u5165\u5c42\u5230\u7b2c\u4e00\u5c42\u9690\u85cf\u5c42\uff0c\u8fde\u63a5\u6570\u662f (3x3)x8x8x2 = 1152\uff0c\u4f46\u662f\u53ea\u6709 18 \u4e2a\u6743\u91cd\u3002\u56e0\u6b64\u603b\u8fde\u63a5\u6570\u662f 1152 - 18 + 1132 = 2266\u3002 \u4e24\u5c42\u90fd\u662f\u5c40\u90e8\u8fde\u63a5 + \u5171\u4eab\u6743\u91cd\u30023x3x2 + 5x5x4x2 + 4x4x4x10 = 858\uff0c\u518d\u52a0\u4e0a 64x2 + 4x4x4 + 10 \u4e2a bias\uff0c\u5171 1060 \u4e2a\u53c2\u6570\u3002\u5176\u4e24\u4e2a\u9690\u85cf\u5c42\u603b\u8fde\u63a5\u6570\u4e3a (3x3)x8x8x2 + (5x5)x4x4x4x2 = 4352 \u4e2a\uff0c\u4f46\u662f\u4ec5\u6709 218 \u4e2a\u53c2\u6570\u3002\u56e0\u6b64\u603b\u8fde\u63a5\u6570\u662f 4352 - 218 + 1060 = 5194\u3002 Network Name Network Architecture Links Weights %Correct LeNet-1 No hidden layer, equivalent to multinomial logistic regression 2570 2570 80.0% LeNet-2 One hidden layer, 12 hidden units fully connected 3214 3214 87.0% LeNet-3 Two hidden layers locally connected 1226 1226 88.5% LeNet-4 Two hidden layers, locally connected with weight sharing 2266 1132 94.0% LeNet-5 Two hidden layers, locally connected, two levels of weight sharing 5194 1060 98.4%","title":"ESL 11: Neural Networks"},{"location":"mathematics/ESL/ESL11_NeuralNetworks/#esl-11-neural-networks","text":"\u795e\u7ecf\u7f51\u7edc\u7684\u4e2d\u5fc3\u601d\u60f3\u662f\u5c06\u8f93\u5165 \u7ebf\u6027\u7ec4\u5408 \u4e3a\u4e00\u4e9b\u884d\u751f\u7684\u7279\u5f81\uff0c\u518d\u5efa\u7acb\u8f93\u51fa\u4e0e\u8fd9\u4e9b\u7279\u5f81\u4e4b\u95f4\u7684 \u975e\u7ebf\u6027 \u6a21\u578b\u3002","title":"ESL 11: Neural Networks"},{"location":"mathematics/ESL/ESL11_NeuralNetworks/#112-projection-pursuit-regression","text":"\u4ee5\u4e00\u4e2a\u901a\u7528\u7684\u76d1\u7763\u5b66\u4e60\u95ee\u9898\u4e3a\u4f8b\uff0c\u5047\u8bbe\u6211\u4eec\u6709 \\(p\\) \u7ef4\u8f93\u5165 \\(X\\) \uff0c\u8f93\u51fa\u662f \\(Y\\) \u3002 \\(w_m\\) \u662f \\(p\\) \u7ef4\u5355\u4f4d\u5411\u91cf\uff0c\u6211\u4eec\u53ef\u4ee5\u628a projection pursuit regression \u6a21\u578b\u8868\u793a\u4e3a\uff1a \\[f(X) = \\sum_{m=1}^M g_m (w_m^T X) \\] \u53ef\u4ee5\u770b\u51fa\uff0c\u8fd9\u4e5f\u662f\u4e00\u4e2a\u52a0\u6027\u6a21\u578b\u3002\u4f46\u662f\u533a\u522b\u5728\u4e8e\uff0c\u5b83\u7684\u81ea\u53d8\u91cf\u4e0d\u662f\u76f4\u63a5\u8f93\u5165 \\(X\\) \uff0c\u800c\u662f\u8f93\u5165\u7684\u7ebf\u6027\u7ec4\u5408 \\(w_m^T X\\) \u3002 \\(g_m(w_m^T X)\\) \u88ab\u79f0\u4e3a\u201c\u5cad\u51fd\u6570\u201d (Ridge Function)\u3002\u5b83\u53ea\u6cbf\u7740 \\(w_m\\) \u7684\u65b9\u5411\u53d8\u5316\uff0c\u800c\u6807\u91cf \\(V_m = w_m^T X\\) \u5c31\u662f\u8f93\u5165 \\(X\\) \u5728 \\(w_m\\) \u65b9\u5411\u4e0a\u7684\u6295\u5f71 (projection)\u3002 \u6211\u4eec\u7684\u76ee\u6807\u662f\u5bfb\u627e \\(w_m\\) \uff08\u5373\u6295\u5f71\u65b9\u5411\uff09\u4f7f\u5f97\u6a21\u578b\u4f30\u8ba1\u8bef\u5dee\u6700\u5c0f\u3002\u56e0\u6b64\uff0c\u8fd9\u4e2a\u65b9\u6cd5\u53eb\u505a projection pursuit\u3002\u5b83\u7684 \u4f18\u70b9 \u662f\u5982\u679c\u5b50\u6a21\u578b\u6570\u91cf M \u8db3\u591f\u5927\uff0c\u5b83\u80fd\u591f\u5b8c\u7f8e\u62df\u5408\u4efb\u4f55\u8fde\u7eed\u51fd\u6570\u3002 \u7f3a\u70b9 \u662f\u53ef\u89e3\u91ca\u6027\u5dee\u3002\u56e0\u6b64\u9002\u7528\u4e8e\u53ea\u9700\u8981\u505a\u9884\u6d4b\uff0c\u4e0d\u9700\u8981\u5f52\u56e0\u7684\u573a\u666f\u3002","title":"11.2 Projection Pursuit Regression"},{"location":"mathematics/ESL/ESL11_NeuralNetworks/#ppr","text":"\u7ed9\u5b9a\u8bad\u7ec3\u6570\u636e \\((x_i, y_i), i=1,2,\\dots,N\\) \uff0c\u6211\u4eec\u7684\u76ee\u6807\u662f\u786e\u5b9a\u51fd\u6570 \\(g\\) \u548c\u65b9\u5411 \\(w\\) \uff0c\u4f7f\u9884\u6d4b\u7ed3\u679c\u7684 squared error \u6700\u5c0f\uff1a \\[ g, w = \\mathop{\\arg \\min}_{g, w} \\sum_{i=1}^N [y_i - \\sum_{m=1}^M g_m(w_m^T x_i)]^2 \\] \u5047\u8bbe\u4ec5\u6709\u4e00\u4e2a\u5b50\u6a21\u578b\uff0c\u5373 M = 1 \uff0c\u786e\u5b9a \\(g\\) \u7684\u8fc7\u7a0b\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u4e00\u7ef4 smoothing \u95ee\u9898\u3002\u56e0\u6b64\uff0c \\(g\\) \u53ef\u4ee5\u9009\u62e9\u4f7f\u7528 spline\u3002 \u5df2\u77e5\u51fd\u6570 \\(g\\) \u7684\u5f62\u5f0f\uff0c\u6211\u4eec\u9700\u8981\u786e\u5b9a\u4f7f\u4f30\u8ba1\u8bef\u5dee\u6700\u5c0f\u7684\u65b9\u5411 \\(w\\) \u3002\u8fd9\u662f\u4e00\u4e2a \u65e0\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898 \uff0c\u4e14 \\(g\\) \u53ef\u5bfc\uff0c\u56e0\u6b64\u53ef\u4ee5\u4f7f\u7528\u725b\u987f\u6cd5\u6765\u89e3\u51b3\u3002 \u5047\u8bbe\u5f53\u524d\u5bf9 \\(w\\) \u7684\u4f30\u8ba1\u4e3a \\(w_{\\text{old}}\\) \uff0c\u6211\u4eec\u5bf9 \\(g\\) \u8fdb\u884c\u6cf0\u52d2\u5c55\u5f00\uff0c\u5ffd\u7565 2 \u9636\u4ee5\u4e0a\u6709\uff1a \\[ g(w^T x_i) \\approx g(w_{\\text{old}}^T x_i) + g'(w_{\\text{old}}^T x_i)(w - w_{\\text{old}})^T x_i \\] \u7531\u4e8e M = 1\uff0csquared error \u53ef\u4ee5\u7b80\u5316\u4e3a\uff1a \\[\\begin{align} \\sum_{i=1}^N [y_i - g(w^T x_i)]^2 &= \\sum_{i=1}^N [y_i - g(w_{\\text{old}}^T x_i) - g'(w_{\\text{old}}^T x_i)(w - w_{\\text{old}})^T x_i]^2 \\\\ &= \\sum_{i=1}^N g'(w_{\\text{old}}^T x_i)^2 [w^T x_i - (w_{\\text{old}}^T x_i + \\dfrac{y_i - g(w_{\\text{old}}^T x_i)}{g'(w_{\\text{old}}^T x_i)})]^2 \\end{align}\\] \u7b49\u5f0f\u53f3\u8fb9\u53ef\u4ee5\u770b\u4f5c\u4e00\u4e2a least squares regression \u95ee\u9898\u3002\u6709 N \u4e2a\u6837\u672c\u70b9\uff0c\u5bf9\u4e8e\u7b2c i \u4e2a\u6837\u672c\uff0c\u5176\u5e73\u65b9\u8bef\u5dee\u7684\u6743\u91cd\u4e3a \\(g'(w_{\\text{old}}^T x_i)^2\\) \uff0c\u76ee\u6807\u662f \\(w_{\\text{new}}^T x_i\\) \u5c3d\u91cf\u9760\u8fd1 \\(w_{\\text{old}}^T x_i + \\frac{y_i - g(w_{\\text{old}}^T x_i)}{g'(w_{\\text{old}}^T x_i)}\\) \u3002 \u6c42\u89e3\u8fd9\u4e2a least squares regression \u6211\u4eec\u5f97\u5230\u4e00\u7ec4\u65b0\u7684\u7cfb\u6570 \\(w_{\\text{new}}\\) \uff0c\u66f4\u65b0 \\(w_{\\text{old}} = w_{\\text{new}}\\) \u5e76\u8fdb\u884c\u4e0b\u4e00\u8f6e\u8fed\u4ee3\uff0c\u76f4\u5230 \\(g'(w_{\\text{old}}^T x_i)\\) \u5c0f\u4e8e\u67d0\u4e2a\u9608\u503c\u3002 \u7531\u4e8e\u5176\u8ba1\u7b97\u91cf\u8fc7\u5927\uff0cPPR \u7684\u5e94\u7528\u5e76\u4e0d\u5f88\u5e7f\u6cdb\u3002\u4f46\u662f\uff0c\u5b83\u662f\u540e\u6765\u83b7\u5f97\u5e7f\u6cdb\u5e94\u7528\u7684 \u795e\u7ecf\u7f51\u7edc\u6280\u672f\u7684\u524d\u8eab \u3002\u6211\u4eec\u5c06\u5728\u4e0b\u9762\u7684\u7ae0\u8282\u4ecb\u7ecd\u795e\u7ecf\u7f51\u7edc\u3002","title":"PPR \u62df\u5408"},{"location":"mathematics/ESL/ESL11_NeuralNetworks/#113-neural-networks","text":"\u201c\u795e\u7ecf\u7f51\u7edc\u201d\u8fd9\u4e2a\u540d\u5b57\u6e90\u4e8e\u8be5\u65b9\u6cd5\u6700\u65e9\u88ab\u5e94\u7528\u4e8e\u4eba\u8111\u7684\u5efa\u6a21\u3002\u6bcf\u4e2a\u8282\u70b9\u662f\u4e00\u4e2a\u795e\u7ecf\u5143\uff0c\u4ed6\u4eec\u4e4b\u95f4\u7684\u8fde\u63a5\u4ee3\u8868\u7a81\u89e6\u3002\u5355\u201c\u9690\u85cf\u5c42\u201d\u7684\u795e\u7ecf\u7f51\u7edc\u4e0e\u521a\u624d\u4ecb\u7ecd\u7684 Projection Pursuit Regression \u6a21\u578b\u975e\u5e38\u76f8\u4f3c\uff0c\u6211\u4eec\u4ee5\u5b83\u4e3a\u4f8b\u8bb2\u89e3\u3002 \u6211\u4eec\u53ef\u4ee5\u770b\u5230\u8be5\u795e\u7ecf\u7f51\u7edc\u5206\u4e3a 3 \u5c42\u3002\u5176\u4e2d \\(X\\) \u662f\u8f93\u5165\uff0c \\(Y\\) \u662f\u8f93\u51fa\uff0c \\(Z\\) \u662f\u6240\u8c13\u7684\u201c\u9690\u85cf\u5c42\u201d\uff0c\u5b83\u88ab\u79f0\u4e3a\u9690\u85cf\u5c42\u662f\u56e0\u4e3a\u5b83\u4e0d\u76f4\u63a5\u53ef\u89c1\u3002 \u7c7b\u4f3c\u4e8e PPR\uff0c\u9690\u85cf\u5c42 \\(Z\\) \u7531\u8f93\u5165 \\(X\\) \u7ebf\u6027\u7ec4\u5408\uff0c\u518d\u9644\u52a0\u4e00\u4e2a\u201c\u6fc0\u6d3b\u51fd\u6570\u201d \\(\\sigma\\) \u5f97\u51fa\u3002 \\[ Z_m = \\sigma(\\alpha_0 + \\alpha_m^T X), \\quad m = 1,\\dots,M \\] \u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570\u5982 sigmoid\uff1a \\[ \\sigma(v) = \\dfrac{1}{1 + e^{-v}} \\] \u800c\u8f93\u51fa \\(Y\\) \u7531\u9690\u85cf\u5c42 \\(Z\\) \u7ebf\u6027\u7ec4\u5408\uff0c\u518d\u9644\u52a0\u4e00\u4e2a\u201c\u8f93\u51fa\u51fd\u6570\u201d \\(g\\) \u5f97\u51fa\u3002 \\[ Y_k = g_k(T) = g_k(\\beta_0 + \\beta_k^T Z) \\] \u5bf9\u4e8e\u56de\u5f52\u95ee\u9898\uff0c \\(g\\) \u53ef\u4ee5\u7701\u7565\uff0c\u5bf9\u4e8e\u5206\u7c7b\u95ee\u9898\uff0c\u4e3a\u786e\u4fdd\u8f93\u51fa\u90fd\u662f\u6574\u6570\u4e14\u548c\u4e3a 1.0\uff0c\u901a\u5e38\u9009\u7528 softmax \u51fd\u6570\uff0c\u5c5e\u4e8e\u7b2c k \u7c7b\u7684\u6982\u7387\u4e3a: \\[ g_k(T) = \\dfrac{e^{T_k}}{\\sum_{l=1}^K e^{T_l}} \\] \u6211\u4eec\u770b\u51fa\uff0c\u5176\u5b9e PPR \u4e0e NN \u7684\u5dee\u5f02\u5c31\u5728\u4e8e NN \u4f7f\u7528\u7684\u6fc0\u6d3b\u51fd\u6570\u76f8\u6bd4 PPR \u4f7f\u7528\u7684 spline \u7b80\u5355\u5f88\u591a\uff0c\u8fd9\u5c31\u4f7f\u5f97 NN \u7684\u8ba1\u7b97\u91cf\u5c0f\u5f88\u591a\uff0c\u83b7\u5f97\u4e86\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u3002","title":"11.3 Neural Networks"},{"location":"mathematics/ESL/ESL11_NeuralNetworks/#114-fitting-neural-networks","text":"\u62df\u5408\u795e\u7ecf\u7f51\u7edc\u5b9e\u9645\u4e0a\u5c31\u662f\u627e\u5230\u521a\u624d\u63d0\u5230\u7684\u4e24\u7ec4\u53c2\u6570\uff1a \u7531\u8f93\u5165 \\(X\\) \u5230\u9690\u85cf\u5c42 \\(Z\\) \u7684\u7ebf\u6027\u7ec4\u5408\u7cfb\u6570 \\(\\bf{\\alpha}\\) \u3002\u7531\u4e8e\u6709 M \u4e2a\u9690\u85cf\u5c42\u8282\u70b9\uff0c\u800c\u6bcf\u4e2a\u8282\u70b9\u5bf9\u5e94\u7684\u7cfb\u6570\u90fd\u662f \\(p + 1\\) \u7ef4\uff08+1 for bias\uff09\u3002\u56e0\u6b64\u662f\u4e00\u4e2a \\(M \\times (p+1)\\) \u77e9\u9635\u3002 \u7531\u9690\u85cf\u5c42 \\(Z\\) \u5230\u8f93\u51fa \\(Y\\) \u7684\u7ebf\u6027\u7ec4\u5408\u7cfb\u6570 \\(\\bf{\\beta}\\) \u3002\u7531\u4e8e\u6709 K \u4e2a\u8f93\u51fa\u8282\u70b9\uff0c\u800c\u6bcf\u4e2a\u8282\u70b9\u5bf9\u5e94\u7684\u7cfb\u6570\u90fd\u662f \\(M + 1\\) \u7ef4\uff08+1 for bias\uff09\u3002\u56e0\u6b64\u662f\u4e00\u4e2a \\(K \\times (M+1)\\) \u77e9\u9635\u3002 \u6211\u4eec\u9996\u5148\u4ee5\u635f\u5931\u51fd\u6570 sum-of-squared-errors \u4e3a\u4f8b: \\[ R(\\theta) = \\sum_{i=1}^N R_i = \\sum_{i=1}^N \\sum_{k=1}^K (y_{ik} - f_k(x_i))^2 \\] \u8bb0 \\(l, m, k\\) \u5206\u522b\u4e3a\u8f93\u5165 \\(X\\) \uff0c\u9690\u85cf\u5c42 \\(Z\\) \u548c\u8f93\u51fa \\(Y\\) \u7684\u5e8f\u53f7\uff0c\u5bf9 \\(\\alpha_{ml}\\) \u548c \\(\\beta_{km}\\) \u6c42\u5bfc\uff0c\u6839\u636e\u94fe\u5f0f\u6cd5\u5219\u6709\uff1a \\[ \\dfrac{\\partial R_i}{\\partial \\beta_{km}} = - 2(y_{ik} - f_k(x_i)) g_k'(\\beta_k^T z_i) z_{mi} \\] \\[ \\dfrac{\\partial R_i}{\\partial \\alpha_{ml}} = - \\sum_{k=1}^K 2(y_{ik} - f_k(x_i)) g_k'(\\beta_k^T z_i) \\beta_{km} \\sigma'(\\alpha_m^T x_i) x_{il} \\] \u6ce8\u610f\uff0c\u5bf9 \\(\\beta_{km}\\) \u6c42\u5bfc\u7ed3\u679c\u4e2d\u4e0d\u542b \\(\\sum_{k=1}^K\\) \u3002\u6211\u4eec\u5047\u8bbe\u73b0\u5728\u7528\u7b2c \\(j(j \\neq k)\\) \u4e2a\u8f93\u51fa\u5bf9 \\(\\beta_{km}\\) \u6c42\u5bfc\uff0c\u7531\u4e8e \\(\\beta_{km}\\) \u610f\u4e49\u662f\u7b2c k \u4e2a\u8f93\u51fa\u4e0e\u7b2c m \u4e2a\u9690\u85cf\u8282\u70b9\u7684\u7cfb\u6570\uff0c\u4e0e\u7b2c j \u4e2a\u8f93\u51fa\u65e0\u5173\uff0c\u7ed3\u679c\u5fc5\u7136\u4e3a 0\u3002\u800c\u5bf9\u4e8e \\(\\alpha_{ml}\\) \u6c42\u5bfc\u65f6\uff0c\u7531\u4e8e\u7b2c m \u4e2a\u9690\u85cf\u8282\u70b9\u4f1a\u4f5c\u7528\u7ed9\u7b2c k \u4e2a\u548c\u7b2c j \u4e2a\u8f93\u51fa\uff0c\u6240\u4ee5\u5b58\u5728 \\(\\sum_{k=1}^K\\) \u3002 \u5f97\u5230\u8fd9\u4e9b\u5bfc\u6570\uff0c\u6211\u4eec\u53ef\u4ee5\u8bbe\u5b9a learning rate \\(\\gamma_r\\) \uff0c\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u8fed\u4ee3\u66f4\u65b0\uff1a \\[ \\beta_{km}^{(r+1)} = \\beta_{km}^{(r)} - \\gamma_r \\sum_{i=1}^N \\dfrac{\\partial R_i}{\\partial \\beta_{km}^{(r)}} \\] \\[ \\alpha_{ml}^{(r+1)} = \\alpha_{ml}^{(r)} - \\gamma_r \\sum_{i=1}^N \\dfrac{\\partial R_i}{\\partial \\beta_{ml}^{(r)}} \\] \u73b0\u5728\u4ee4\uff1a \\[ \\dfrac{\\partial R_i}{\\partial \\beta_{km}} = \\delta_{ki} z_{mi} \\] \\[ \\dfrac{\\partial R_i}{\\partial \\alpha_{ml}} = s_{mi} x_{il} \\] \u6211\u4eec\u53ef\u4ee5\u5f97\u51fa\u5173\u7cfb\uff1a \\[ s_{mi} = \\sigma'(\\alpha_m^T x_i) \\sum_{k=1}^K \\beta_{km} \\delta_{ki} \\] \u8fd9\u4e2a\u7b49\u5f0f\u88ab\u79f0\u4e3a back-propagation equation\u3002\u5229\u7528\u8fd9\u4e2a\u7b49\u5f0f\uff0c\u66f4\u65b0\u65f6\u53ef\u4ee5\u7b80\u5316 \\(s_{mi}\\) \u7684\u8ba1\u7b97\u3002back-propagation \u7684\u8fc7\u7a0b\u53ef\u4ee5\u63cf\u8ff0\u4e3a\u4e00\u4e2a \u53cc\u5411\u4f20\u64ad \u7684\u8fc7\u7a0b\uff1a \u6b63\u5411\u4f20\u64ad\uff0c\u5229\u7528\u8f93\u5165 \\(X\\) \u548c\u5f53\u524d\u7684 weights \u6765\u8ba1\u7b97\u9884\u6d4b\u503c \\(\\hat{f}_k(x_i)\\) \u53cd\u5411\u4f20\u64ad\uff0c\u9996\u5148\u8ba1\u7b97\u51fa\u9690\u85cf\u5c42 \\(Z\\) \u5230\u8f93\u51fa\u5c42 \\(Y\\) \u7684 \\(\\delta_{ki}\\) \uff0c\u518d\u5229\u7528\u4e0a\u9762\u7684\u7b49\u5f0f\u8ba1\u7b97 \\(s_{mi}\\) \uff0c\u5f97\u51fa\u4e24\u4e2a\u68af\u5ea6\u7684\u503c\uff0c\u518d\u66f4\u65b0 weights \u8fd9\u4e2a\u7b97\u6cd5\u7684\u4f18\u52bf\u5728\u4e8e\u7b80\u5355\u5e76\u4e14\u6613\u4e8e\u5e76\u884c\uff0c\u52a3\u52bf\u5728\u4e8e\u8ba1\u7b97\u91cf\u5927\u3002","title":"11.4 Fitting Neural Networks"},{"location":"mathematics/ESL/ESL11_NeuralNetworks/#115-some-issues-in-training-neural-networks","text":"\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u5e76\u4e0d\u662f\u50cf\u7b97\u6cd5\u539f\u7406\u90a3\u4e48\u7b80\u5355\u3002\u795e\u7ecf\u7f51\u7edc\u662f\u4e00\u4e2a\u53c2\u6570\u5f88\u591a\u7684\u6a21\u578b\uff0c\u5b83\u4ece\u539f\u7406\u4e0a\u503e\u5411\u4e8e overfit\u3002","title":"11.5 Some Issues in Training Neural Networks"},{"location":"mathematics/ESL/ESL11_NeuralNetworks/#1151-starting-values","text":"sigmoid \u51fd\u6570\u5728 0 \u9644\u8fd1\u8fd1\u4f3c\u4e8e\u7ebf\u6027\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06 weights \u7684\u521d\u59cb\u503c\u9009\u5728 0 \u9644\u8fd1 \uff0c\u8fd9\u6837\u6211\u4eec\u4ece\u4e00\u4e2a\u8fd1\u4f3c\u7ebf\u6027\u7684\u6a21\u578b\u5f00\u59cb\u8bad\u7ec3\uff0c\u7136\u540e\u975e\u7ebf\u6027\u9010\u6b65\u589e\u5f3a\u3002\u6ce8\u610f\uff0c\u521d\u59cb\u6743\u91cd\u4e0d\u80fd\u4e3a 0\uff0c\u6211\u4eec\u7531\u516c\u5f0f\u53ef\u4ee5\u770b\u51fa\u5176\u68af\u5ea6\u4e3a 0\uff0c\u65e0\u6cd5\u6536\u655b\u3002","title":"11.5.1 Starting Values"},{"location":"mathematics/ESL/ESL11_NeuralNetworks/#1152-overfitting","text":"\u7531\u4e8e\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5f88\u591a\uff0c\u4e00\u822c\u6211\u4eec\u901a\u8fc7 early stopping \u6765\u907f\u514d overfitting\u3002\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u65bd\u52a0\u60e9\u7f5a\u9879\u6765\u8fdb\u884c regularization\u3002","title":"11.5.2 Overfitting"},{"location":"mathematics/ESL/ESL11_NeuralNetworks/#1153-scaling-of-the-inputs","text":"\u521d\u59cb\u65f6\uff0c\u6211\u4eec\u9700\u8981\u628a\u6240\u6709\u8f93\u5165\u90fd\u6620\u5c04\u4e3a \u6807\u51c6\u6b63\u6001\u5206\u5e03 \uff0c\u540c\u65f6\uff0c\u521d\u59cb\u7684 weights \u8bbe\u7f6e\u4e3a [-0.7, +0.7] \u4e4b\u95f4\u7684\u5747\u5300\u5206\u5e03\u3002","title":"11.5.3 Scaling of the Inputs"},{"location":"mathematics/ESL/ESL11_NeuralNetworks/#1154-number-of-hidden-units-and-layers","text":"\u901a\u5e38\u9690\u85cf\u5c42\u8282\u70b9\u7684\u6570\u91cf\u5728 [5, 100] \u4e4b\u95f4\u9009\u62e9\uff0c\u8f93\u5165\u6570\u91cf\u8d8a\u591a\uff0c\u9690\u85cf\u5c42\u8282\u70b9\u8d8a\u591a\u3002 \u9690\u85cf\u5c42\u5c42\u6570\u4e00\u822c\u901a\u8fc7\u7ecf\u9a8c\u548c\u80cc\u666f\u77e5\u8bc6\u9009\u62e9\u3002","title":"11.5.4 Number of Hidden Units and Layers"},{"location":"mathematics/ESL/ESL11_NeuralNetworks/#116-example","text":"\u6211\u4eec\u91c7\u7528\u624b\u5199\u6570\u5b57\u8bc6\u522b\u6765\u68c0\u9a8c\u795e\u7ecf\u7f51\u7edc\u7684\u5206\u7c7b\u6027\u80fd\u3002 import pandas as pd from sklearn import datasets from sklearn.neural_network import MLPClassifier from sklearn.model_selection import KFold digits = datasets . load_digits () X = pd . DataFrame ( digits . data , columns = digits . feature_names ) y = pd . Series ( digits . target ) for train_index , test_index in KFold ( n_splits = 5 , shuffle = True , random_state = 1 ) . split ( X ): # print(\"TRAIN:\", train_index, \"TEST:\", test_index) trainX , testX = X . loc [ train_index ], X . loc [ test_index ] trainY , testY = y . loc [ train_index ], y . loc [ test_index ] model = MLPClassifier ( solver = 'lbfgs' , hidden_layer_sizes = ( 12 ,), random_state = 1 ) . fit ( trainX , trainY ) print ( f \"MLP accurracy: { model . score ( testX , testY ) } \" ) \u6ce8\u610f\uff0c hidden_layer_sizes=(12,) \u8868\u660e\u6211\u4eec\u9009\u62e9\u4e86 1 \u5c42\u9690\u85cf\u5c42\uff0c\u8be5\u9690\u85cf\u5c42\u5305\u542b 12 \u4e2a\u8282\u70b9\u3002 \u5176\u5206\u7c7b\u7ed3\u679c\u4e3a\uff1a MLP accurracy: 0.8833333333333333 MLP accurracy: 0.9111111111111111 MLP accurracy: 0.8885793871866295 MLP accurracy: 0.9303621169916435 MLP accurracy: 0.8997214484679665 \u53ef\u4ee5\u770b\u51fa\u5176\u51c6\u786e\u7387\u5728 90% \u5de6\u53f3\u3002","title":"11.6 Example"},{"location":"mathematics/ESL/ESL11_NeuralNetworks/#1161-improvement","text":"\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7 \u589e\u52a0\u9690\u85cf\u5c42 \u6765\u63d0\u9ad8\u5206\u7c7b\u7cbe\u786e\u5ea6\uff0c\u4f8b\u5982\uff0c\u6211\u4eec\u7b80\u5355\u589e\u52a0\u4e00\u5c42 hidden_layer_sizes=(12,12) \uff0c\u5206\u7c7b\u7ed3\u679c\u4e3a\uff1a MLP accurracy: 0.9111111111111111 MLP accurracy: 0.9388888888888889 MLP accurracy: 0.9387186629526463 MLP accurracy: 0.9415041782729805 MLP accurracy: 0.9220055710306406 \u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u6709\u66f4\u7cbe\u5999\u7684\u65b9\u6cd5\uff0c\u4f8b\u5982\u6539\u53d8\u7f51\u7edc\u7ed3\u6784\u3002 \u5c40\u90e8\u8fde\u63a5\uff08local connectivity\uff09\uff1a\u6211\u4eec\u53ef\u4ee5\u9650\u5b9a\u6bcf\u4e2a\u9690\u85cf\u5c42\u8282\u70b9\u53ea\u8fde\u63a5\u5230\u4e0b\u4e00\u5c42\u7684\u67d0\u4e00\u90e8\u5206\u8282\u70b9\u3002\u4f8b\u5982 3x3 \u7684\u5c0f\u65b9\u5757\u3002\u5c40\u90e8\u8fde\u63a5\u53ef\u4ee5\u63d0\u53d6\u4e0b\u4e00\u5c42\u7684\u5c40\u90e8\u7279\u5f81\uff0c\u5e76\u5927\u5927\u964d\u4f4e\u9700\u8981\u8bad\u7ec3\u7684 weights \u603b\u6570\u3002 \u5171\u4eab\u6743\u91cd\uff08shared weights\uff09\uff1a\u5728\u5c40\u90e8\u8fde\u63a5\u7684\u57fa\u7840\u4e0a\uff0c\u6211\u4eec\u8fd8\u53ef\u4ee5\u8ba9\u6bcf\u4e2a\u5c40\u90e8\u533a\u57df\u4f7f\u7528\u76f8\u540c\u7684 weights\u3002\u8fd9\u4e48\u505a\u7684\u7ed3\u679c\u662f\u5bf9\u56fe\u50cf\u4e0d\u540c\u7684\u533a\u57df\u91c7\u7528\u540c\u6837\u7684\u64cd\u4f5c\u3002\u8fd9\u4e5f\u88ab\u79f0\u4f5c \u5377\u79ef\u7f51\u7edc (convolutional networks)\u3002 \u4ee5\u4e0b\u9762\u51e0\u79cd\u7f51\u7edc\u4e3a\u4f8b\uff0c\u6211\u4eec\u8ba1\u7b97\u5176\u6743\u91cd\u6570\u91cf\uff1a \u53ea\u6709\u8f93\u5165\u548c\u8f93\u51fa\u5c42\uff0c\u8f93\u5165\u5c42\u8282\u70b9 16x16\uff0c\u8f93\u51fa\u5c42\u8282\u70b9 10\uff0c\u4e00\u5171 16x16x10 = 2560\u3002\u518d\u52a0\u4e0a 10 \u4e2a bias\uff0c\u5171 2570 \u4e2a\u53c2\u6570\u3002 \u6709\u4e00\u5c42\u9690\u85cf\u5c42\uff0c12\u4e2a\u9690\u85cf\u8282\u70b9\u3002 16x16x12 + 12x10 = 3192\uff0c\u518d\u52a0\u4e0a 12 \u4e2a\u9690\u85cf\u8282\u70b9\u548c 10 \u4e2a\u8f93\u51fa\u8282\u70b9\u7684 bias\uff0c\u5171 3214 \u4e2a\u53c2\u6570\u3002 \u6709\u4e24\u5c42\u5c40\u90e8\u8fde\u63a5\u7684\u9690\u85cf\u5c42\u3002\u7531\u4e8e\u662f\u5c40\u90e8\u8fde\u63a5\uff0c\u8ba1\u7b97\u65b9\u5f0f\u4e3a patch \u5927\u5c0f\u4e58\u4ee5\u4e0a\u4e00\u5c42\u8282\u70b9\u6570\uff1a(3x3)x8x8 + (5x5)x4x4 + 4x4x10 = 1136\uff0c\u518d\u52a0\u4e0a 64 + 16 + 10 \u4e2a bias\uff0c\u5171 1226 \u4e2a\u53c2\u6570\u3002 \u4e24\u5c42\u5c40\u90e8\u8fde\u63a5\u9690\u85cf\u5c42\uff0c\u7b2c\u4e00\u5c42\u5171\u4eab\u6743\u91cd\u3002\u7531\u4e8e\u662f\u5171\u4eab\u6743\u91cd\uff0c\u6bcf\u5c42\u53c2\u6570\u4e2a\u6570\u56fa\u5b9a\u30023x3x2 + (5x5)x4x4x2 + 4x4x10 = 978\u3002\u518d\u52a0\u4e0a 64x2 + 16 + 10 \u4e2a bias\uff0c\u5171 1132 \u4e2a\u53c2\u6570\u3002 \u7531\u4e8e\u5b58\u5728\u5171\u4eab\u6743\u91cd\uff0c\u8fde\u63a5\u6570\u548c\u53c2\u6570\u4e2a\u6570\u4e0d\u540c\u3002\u4ece\u8f93\u5165\u5c42\u5230\u7b2c\u4e00\u5c42\u9690\u85cf\u5c42\uff0c\u8fde\u63a5\u6570\u662f (3x3)x8x8x2 = 1152\uff0c\u4f46\u662f\u53ea\u6709 18 \u4e2a\u6743\u91cd\u3002\u56e0\u6b64\u603b\u8fde\u63a5\u6570\u662f 1152 - 18 + 1132 = 2266\u3002 \u4e24\u5c42\u90fd\u662f\u5c40\u90e8\u8fde\u63a5 + \u5171\u4eab\u6743\u91cd\u30023x3x2 + 5x5x4x2 + 4x4x4x10 = 858\uff0c\u518d\u52a0\u4e0a 64x2 + 4x4x4 + 10 \u4e2a bias\uff0c\u5171 1060 \u4e2a\u53c2\u6570\u3002\u5176\u4e24\u4e2a\u9690\u85cf\u5c42\u603b\u8fde\u63a5\u6570\u4e3a (3x3)x8x8x2 + (5x5)x4x4x4x2 = 4352 \u4e2a\uff0c\u4f46\u662f\u4ec5\u6709 218 \u4e2a\u53c2\u6570\u3002\u56e0\u6b64\u603b\u8fde\u63a5\u6570\u662f 4352 - 218 + 1060 = 5194\u3002 Network Name Network Architecture Links Weights %Correct LeNet-1 No hidden layer, equivalent to multinomial logistic regression 2570 2570 80.0% LeNet-2 One hidden layer, 12 hidden units fully connected 3214 3214 87.0% LeNet-3 Two hidden layers locally connected 1226 1226 88.5% LeNet-4 Two hidden layers, locally connected with weight sharing 2266 1132 94.0% LeNet-5 Two hidden layers, locally connected, two levels of weight sharing 5194 1060 98.4%","title":"11.6.1 Improvement"},{"location":"mathematics/ESL/ESL12_SVM/","text":"ESL 12: Support Vector Machines and Flexibile Discriminants 12.1 Introduction \u5f53\u4e24\u4e2a\u7c7b \u7ebf\u6027\u53ef\u5206 \u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u7528 Linear Discriminant Analysis \u627e\u5230\u5b83\u4eec\u7684\u6700\u4f18\u5206\u754c\u9762\u3002\u5f53\u5b83\u4eec\u4e0d\u662f\u7ebf\u6027\u53ef\u5206\uff0c\u76f8\u4e92\u91cd\u53e0\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u5728 \u66f4\u9ad8\u7ef4\u7684\u7279\u5f81\u7a7a\u95f4 \u4e2d\u6784\u9020 \u7ebf\u6027 \u5206\u754c\u9762\u3002\u8fd9\u79cd\u65b9\u6cd5\u53eb\u505a\u652f\u6301\u5411\u91cf\u673a\uff08support vector machine\uff09\u3002\u5b83\u662f LDA \u7684\u4e00\u4e2a\u6269\u5c55\u3002 \u76f8\u5bf9\u4e8e LDA\uff0c\u5b83\u7684\u4e3b\u8981\u4f18\u52bf\u662f\uff1a \u53ef\u4ee5\u5904\u7406\u975e\u7ebf\u6027\u573a\u666f \u5206\u754c\u9762\u4e3b\u8981\u7531\u8fb9\u754c\u4e0a\u7684\u6837\u672c\u70b9\u786e\u5b9a\uff08LDA \u9700\u8981\u5404\u7c7b\u6837\u672c\u4e2d\u5fc3\u70b9\uff09 12.2 The Support Vector Classifier \u5728\u7b2c\u56db\u7ae0\u4e2d\u6211\u4eec\u8ba8\u8bba\u4e86 \u7ebf\u6027\u53ef\u5206 \u7c7b\u578b\u7684\u6700\u4f18\u5206\u754c\u9762\uff0c\u8fd9\u91cc\uff0c\u6211\u4eec\u9700\u8981\u5c06\u5176\u6269\u5c55\u81f3 \u7ebf\u6027\u4e0d\u53ef\u5206 \u7684\u60c5\u5f62\u3002 \u5047\u8bbe\u6211\u4eec\u6709 N \u4e2a\u8bad\u7ec3\u6570\u636e\uff1a \\((x_1, y_1), (x_2, y_2), \\dots, (x_N, y_N)\\) \uff0c\u5176\u4e2d\uff0c \\(x_i\\) \u662f \\(p\\) \u7ef4\u8f93\u5165\uff0c \\(y_i \\in {-1, 1}\\) \u662f\u7c7b\u578b\u8f93\u51fa\u3002 \u5b9a\u4e49\u8d85\u5e73\u9762\uff08\u81ea\u53d8\u91cf \\(x\\) \uff09 \\[ {x: f(x) = x^T \\beta + \\beta_0 = 0}, \\] \u4e0a\u5f0f\u7684\u5de6\u8fb9\u5b9a\u4e49\u4e86\u67d0\u4e2a\u70b9 \\(x\\) \u4e0e\u8be5\u5e73\u9762\u7684\u8ddd\u79bb\uff08\u6709\u7b26\u53f7\uff09\u3002\u5176\u4e2d\uff0c\u7cfb\u6570 \\(\\beta\\) \u662f \u5355\u4f4d\u5411\u91cf \\(\\| {\\beta} \\| = 1\\) \u3002\u5206\u7c7b\u6807\u51c6\u4e3a\uff1a \\[ G(x) = \\text{sign}[x^T \\beta + \\beta_0]\\] \u6211\u4eec\u7684\u76ee\u7684\u662f\u627e\u5230\u5728\u4e24\u4e2a\u7c7b\u578b\u7684\u6570\u636e\u4e2d margin \u6700\u5927\u7684\u5206\u754c\u9762\u3002 \u7ebf\u6027\u5206\u7c7b\u95ee\u9898 \u5bf9\u4e8e\u7ebf\u6027\u5206\u7c7b\u95ee\u9898\uff0cmargin \u53ef\u4ee5\u5b9a\u4e49\u4e3a\u5206\u754c\u9762\u8ddd\u79bb\u6700\u8fd1\u7684\u6837\u672c\u70b9\u7684\u8ddd\u79bb\u3002\u5373\uff1a \\[\\begin{align} & & \\mathop{\\arg \\max}_{\\beta, \\beta_0, \\| \\beta \\| = 1} ~ M \\\\ & \\text{s.t.} & y_i(x_i^T \\beta + \\beta_0) \\geq M, ~~~ i=1,\\dots,N \\end{align}\\] \u5176\u4e2d\uff0c \\(x^T \\beta + \\beta_0 = 0\\) \u662f\u5206\u754c\u9762\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u6837\u672c\uff0c\u9884\u6d4b\u503c \\(x_i^T \\beta + \\beta_0\\) \u53ef\u80fd\u4e3a\u6b63\u6216\u8005\u8d1f\uff0c\u76ee\u6807\u662f\u627e\u5230\u4e00\u7ec4\u53c2\u6570 \\(\\beta, \\beta_0\\) \uff0c\u4f7f\u5f97 margin \u6700\u5927\u3002 \u8be5\u4f18\u5316\u95ee\u9898\u5e76\u4e0d\u662f\u4e00\u4e2a\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u6bd4\u8f83\u96be\u4ee5\u6c42\u89e3\u3002 \u9996\u5148\uff0c\u6211\u4eec\u4e0d\u518d\u8981\u6c42 \\(\\beta\\) \u662f\u5355\u4f4d\u5411\u91cf\uff0c\u800c\u662f\u624b\u52a8\u5728\u7ea6\u675f\u91cc\u5c06\u5176\u5355\u4f4d\u5316\uff0c\u5373\uff1a \\[\\begin{align} & & \\mathop{\\arg \\max}_{\\beta, \\beta_0} ~ M \\\\ & \\text{s.t.} & y_i(x_i^T \\beta + \\beta_0) \\geq M \\| \\beta \\| , ~~~ i=1,\\dots,N \\end{align}\\] \u4ee4\uff1a \\[\\theta = \\frac{\\beta}{M\\| \\beta \\|}\\] \\[\\theta_0 = \\frac{\\beta_0}{M\\| \\beta \\|}\\] \u7ea6\u675f\u6761\u4ef6\u53ef\u4ee5\u6539\u5199\u4e3a\uff1a \\[ y_i(x_i^T \\theta + \\theta_0) \\geq 1 \\] \u8fd9\u4e2a\u53d8\u6362\u8868\u793a\uff0c\u5bf9\u4e8e\u8be5\u4f18\u5316\u95ee\u9898\uff0c\u5bf9\u5e94\u4e0d\u540c\u7684 M \u53d6\u503c\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\u5f88\u591a\u7ec4\u89e3\u3002\u7b49\u5f0f\u53f3\u8fb9\u7684 1 \u8868\u793a\u5bf9\u4e8e\u53c2\u6570 \\(\\theta\\) \u7684 \\(M_\\theta\\) \u6ee1\u8db3\uff1a \\[ M_\\theta \\| \\theta \\| = 1 \\] \u663e\u7136\uff0c\u6b64\u65f6\u6c42 \\(M_\\theta\\) \u7684\u6700\u5927\u503c\u5c31\u662f\u6c42 \\(\\| \\theta \\|\\) \u7684\u6700\u5c0f\u503c\u3002\u56e0\u6b64\uff0c\u4f18\u5316\u95ee\u9898\u7b80\u5316\u4e3a\uff1a \\[\\begin{align} & & \\mathop{\\arg \\min}_{\\theta, \\theta_0} ~ \\| \\theta \\| \\\\ & \\text{s.t.} & y_i(x_i^T \\theta + \\theta_0) \\geq 1, ~~~ i=1,\\dots,N \\end{align}\\] \u8fd9\u662f\u4e00\u4e2a\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u901a\u5e38 SVM \u7528\u8fd9\u4e2a\u5f62\u5f0f\u63cf\u8ff0\u3002 \u975e\u7ebf\u6027\u5206\u7c7b\u95ee\u9898 \u73b0\u5b9e\u4e2d\uff0c\u53ef\u80fd\u4e0d\u540c\u7684\u7c7b\u522b\u5728\u7279\u5f81\u7a7a\u95f4\u4e2d\u6709\u91cd\u53e0\u3002\u56e0\u6b64\uff0c\u5b83\u4eec\u4e0d\u80fd\u7528\u4e00\u4e2a\u7ebf\u6027\u5206\u754c\u9762\u5206\u5272\u3002\u5bf9\u4e8e\u8fd9\u7c7b\u60c5\u51b5\uff0c\u6211\u4eec \u5bf9\u6bcf\u4e2a\u6837\u672c\u5f15\u5165\u677e\u5f1b\u53d8\u91cf \\(\\xi\\) \u3002\u5e76\u5c06\u7ea6\u675f\u6761\u4ef6\u653e\u677e\u4e3a\uff1a \\[ y_i (x_i^T \\beta + \\beta_0 ) \\geq M(1 - \\xi_i) \\] \\(\\xi_i\\) \u8868\u793a\u6837\u672c i \u201c\u8d8a\u754c\u201d\u4e86\u591a\u5c11\uff08normalized by margin\uff09\u3002 \u8fd9\u91cc\u7684\u8d8a\u754c\u6307\u7684\u5e76\u975e\u5206\u754c\u9762\uff0c\u800c\u662f\u9644\u52a0 margin \u540e\u5f62\u6210\u7684\u754c\u9650\u3002 \\(\\xi_i > 1\\) \u8bf4\u660e\u8bad\u7ec3\u51fa\u7684\u5206\u754c\u9762\u5bf9\u6837\u672c i \u8fdb\u884c\u4e86\u9519\u8bef\u7684\u5206\u7c7b\u3002 \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u9650\u5236 \\(\\sum \\xi_i \\leq C\\) \u6765\u9650\u5236\u6211\u4eec\u677e\u5f1b\u7684\u7a0b\u5ea6\u3002\u76f8\u5bf9\u4e8e\u7ebf\u6027\u5206\u7c7b\u7684\u4f18\u5316\u95ee\u9898\uff0c\u975e\u7ebf\u6027\u5206\u7c7b\u9700\u8981\u989d\u5916\u5f15\u5165\u677e\u5f1b\u53d8\u91cf\uff0c\u5e76\u589e\u52a0\u4e00\u4e2a\u7ea6\u675f\u6761\u4ef6\uff1a \\[\\begin{align} & & \\mathop{\\arg \\min}_{\\theta, \\theta_0} ~ \\| \\theta \\| &\\\\ & \\text{s.t.} & ~ y_i(x_i^T \\theta + \\theta_0) \\geq 1 - \\xi_i, & \\\\ & & \\xi_i \\geq 0, \\sum_{i=1}^N \\xi_i \\leq C & ~~~~ (i=1,\\dots,N) \\end{align}\\] 12.2.1 Computing the Support Vector Classifier \u6211\u4eec\u53ef\u4ee5\u628a\u8be5\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u6210\u4e00\u4e2a\u4e8c\u6b21\u51fd\u6570\u7684\u51f8\u4f18\u5316\u95ee\u9898\uff1a \\[\\begin{align} & & \\mathop{\\arg \\min}_{\\theta, \\theta_0} ~ \\frac{1}{2} \\| \\theta \\|^2 + C \\sum_{i=1}^N \\xi_i & \\\\ & \\text{s.t.} & ~ y_i(x_i^T \\theta + \\theta_0) \\geq 1 - \\xi_i, & \\\\ & & \\xi_i \\geq 0 & ~~~~ (i=1,\\dots,N) \\end{align}\\] \u6ce8\u610f\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u505a\u4e86\u4e24\u4e2a\u7b49\u6548\u53d8\u6362\uff1a \u5c06 \\(\\| \\theta \\|\\) \u53d8\u6210\u4e86 \\(\\frac{1}{2} \\| \\theta \\|^2\\) . \u5c06\u7ea6\u675f\u6761\u4ef6 \\(\\sum_{i=1}^N \\xi_i \\leq C\\) \u8f6c\u4e3a\u4e00\u4e2a\u60e9\u7f5a\u9879 \\(C \\sum_{i=1}^N\\) . \u5f15\u5165\u62c9\u683c\u6717\u65e5\u4e58\u5b50 \\(\\alpha_i, \\mu_i\\) \u6709\uff1a \\[ L_p = \\frac{1}{2} \\| \\theta \\|^2 + C \\sum_{i=1}^N \\xi_i - \\sum_{i=1}^N \\alpha_i[y_i(x_i^T \\theta + \\theta_0) - (1 - \\xi_i)] - \\sum_{i=1}^N(\\mu_i \\xi_i) \\] \u6211\u4eec\u5c06\u5176\u8f6c\u5316\u4e3a\u5bf9\u5076\u95ee\u9898\uff0c\u9700\u8981\u6ee1\u8db3 KKT \u6761\u4ef6\u3002 \u6761\u4ef6\u4e00\uff1a\u5e73\u7a33\u6027\u6761\u4ef6 \u3002\u5206\u522b\u5bf9\u53c2\u6570 \\(\\theta, \\theta_0, \\xi_i\\) \u6c42\u5bfc\u5e76\u4ee4\u5bfc\u6570\u4e3a 0\uff0c\u5f97\u5230\uff1a \\[\\begin{align} \\mathbf{\\theta} &= \\sum_{i=1}^N \\alpha_i y_i \\mathbf{x_i} \\\\ 0 &= \\sum_{i=1}^N \\alpha_i y_i \\\\ \\alpha_i &= C - \\mu_i \\end{align}\\] \u5c06\u4e0a\u5f0f\u4ee3\u5165 \\(L_p\\) \u5f97\u5230\u5176\u5bf9\u5076\u95ee\u9898\uff1a \\[\\begin{align} L_D &= \\frac{1}{2} \\| \\theta \\|^2 + \\sum_{i=1}^N \\alpha_i - \\sum_{i=1}^N \\alpha_i y_i(x_i^T \\theta + \\theta_0) \\\\ &= \\frac{1}{2} \\| \\theta \\|^2 + \\sum_{i=1}^N \\alpha_i - \\sum_{i=1}^N \\theta^T \\theta - \\theta_0 \\sum_{i=1}^N \\alpha_i y_i \\\\ &= \\sum_{i=1}^N \\alpha_i - \\frac{1}{2} \\sum_{i=1}^N \\theta^T \\theta \\\\ &= \\sum_{i=1}^N \\alpha_i - \\frac{1}{2} \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_i \\alpha_j y_i y_j x_i^T x_j \\end{align}\\] \u7531\u4e8e\u662f\u5bf9\u5076\u95ee\u9898\uff0c\u6211\u4eec\u9700\u8981 \u6700\u5927\u5316 \\(L_D\\) \u3002\u6b64\u65f6\uff0c \\(L_D\\) \u4e2d\u53ea\u5305\u542b\u672a\u77e5\u53c2\u6570 \\(\\alpha_i\\) \u3002\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u53ef\u4ee5\u7528 \u987a\u5e8f\u6700\u5c0f\u5316\u7b97\u6cd5 (Sequential Minimal Optimization)\u6c42\u89e3\uff0c\u8fd9\u91cc\u4e0d\u8868\u3002 \u6211\u4eec\u53ef\u4ee5\u5047\u8bbe\u5df2\u7ecf\u5f97\u5230\u4e00\u7ec4\u6700\u4f18\u7684 \\(\\hat{\\alpha}_i\\) \u3002\u4ee3\u5165\u4e0b\u5f0f\u53ef\u4ee5\u6c42\u5f97 \\(\\theta\\) \uff1a \\[ \\mathbf{\\theta} = \\sum_{i=1}^N \\alpha_i y_i \\mathbf{x_i} \\] \u5bf9\u4e8e\u53c2\u6570 \\(\\theta_0\\) \uff0c\u6211\u4eec\u8fd8\u9700\u8981\u5176\u4ed6\u7684 KKT \u6761\u4ef6\u7ea6\u675f\u6c42\u89e3\u3002 \u6761\u4ef6\u4e8c\uff1a\u539f\u95ee\u9898\u53ef\u884c\u6027 \u3002 \\[\\begin{align} y_i(x_i^T \\theta + \\theta_0) &\\geq (1 - \\xi_i) \\\\ \\xi_i &\\geq 0 \\end{align}\\] \u6761\u4ef6\u4e09\uff1a\u5bf9\u5076\u95ee\u9898\u53ef\u884c\u6027 \u3002 \\[\\begin{align} \\alpha_i & \\geq 0 \\\\ \\mu_i & \\geq 0 \\end{align}\\] \u6761\u4ef6\u56db\uff1a\u4e92\u8865\u677e\u5f1b \u3002 \\[\\begin{align} \\alpha_i[y_i(x_i^T \\theta + \\theta_0) - (1 - \\xi_i)] &= 0 \\\\ \\mu_i \\xi_i &= 0 \\end{align}\\] \u901a\u8fc7\u5e73\u7a33\u6027\u6761\u4ef6\uff0c\u6211\u4eec\u5df2\u7ecf\u5f97\u5230\u5173\u7cfb\uff1a \\[ \\hat{\\theta} = \\sum_{i=1}^N \\hat{\\alpha_i} y_i x_i \\] \u53e6\uff0c\u6839\u636e\u4e92\u8865\u677e\u5f1b\u6761\u4ef6\uff0c\u7cfb\u6570 \\(\\hat{\\alpha_i}\\) \u4ec5\u5728\u7ea6\u675f \\(y_i(x_i^T \\theta + \\theta_0) \\geq (1 - \\xi_i)\\) \u7b49\u53f7\u6210\u7acb \u65f6\u53d6\u975e 0\uff0c\u5373\uff1a \\[ y_i(x_i^T \\theta + \\theta_0) = (1 - \\xi_i) \\] \u8fd9\u4e9b\u4f7f\u7b49\u53f7\u6210\u7acb\u7684\u6837\u672c\u70b9\u88ab\u79f0\u4e3a\u201c \u652f\u6301\u5411\u91cf \u201d (support vectors)\uff0c\u56e0\u4e3a\u7cfb\u6570 \\(\\hat{\\theta}\\) \u7684\u53d6\u503c\u53ea\u8ddf\u4ed6\u4eec\u6709\u5173\u3002 \u6839\u636e\u7ea6\u675f\uff1a \\[ \\alpha_i[y_i(x_i^T \\theta + \\theta_0) - (1 - \\xi_i)] = 0 \\] \u652f\u6301\u5411\u91cf\u4e2d\u7684\u4efb\u4f55\u4e00\u4e2a\u6837\u672c\u90fd\u53ef\u4ee5\u7528\u4e8e\u6c42\u89e3 \\(\\theta_0\\) \uff0c\u4e3a\u4e86\u6570\u503c\u7a33\u5b9a\u6027\uff0c\u6211\u4eec\u4f7f\u7528\u6240\u6709\u89e3\u7684 \u5e73\u5747\u503c \u3002 \u6211\u4eec\u518d\u770b\u4ee5\u4e0b\u4e24\u4e2a\u7ea6\u675f\u6761\u4ef6\uff0c\u989d\u5916\u5b9a\u6027\u5206\u6790\u4e00\u4e0b\u8fd9\u4e9b\u652f\u6301\u5411\u91cf\uff1a \\[\\begin{align} \\alpha_i &= C - \\mu_i \\\\ \\mu_i \\xi_i &= 0 \\end{align}\\] \u5728\u8fd9\u4e9b\u6837\u672c\u70b9\u4e2d\uff1a \u5982\u679c \\(\\xi_i = 0\\) \uff0c\u5373\u6837\u672c \\(x_i\\) \u5728 margin \u7684\u8fb9\u754c\u4e0a\u3002\u6b64\u65f6 \\(\\mu_i > 0\\) \u4e14 \\(0 \\leq \\alpha_i \\leq C\\) \u3002 \u5982\u679c \\(\\xi_i > 0\\) \uff0c\u5373\u6837\u672c \\(x_i\\) \u8d8a\u8fc7\u4e86 margin \u8fb9\u754c\uff0c\u5305\u62ec\u88ab\u9519\u8bef\u5206\u7c7b\u7684\u6837\u672c\u3002\u6b64\u65f6 \\(\\mu_i = 0\\) \u4e14 \\(\\alpha_i = C\\) \u3002 KKT \u6761\u4ef6 KKT \u65b9\u6cd5\u662f\u5bf9\u62c9\u683c\u6717\u65e5\u4e58\u5b50\u6cd5\u7684\u4e00\u4e2a\u6269\u5c55\u3002\u62c9\u683c\u6717\u65e5\u4e58\u5b50\u6cd5\u53ea\u80fd\u5e94\u7528\u5728\u7b49\u5f0f\u7ea6\u675f\u4e0a\uff0c\u800c KKT\u5141\u8bb8\u4e0d\u7b49\u5f0f\u7ea6\u675f \u3002 \u5bf9\u4e8e\u4f18\u5316\u95ee\u9898\uff1a \\[\\begin{align} &\\text{optimize} & f(x) & \\\\ &\\text{subject to:} & g_i(x) \\leq 0 & (i = 1, \\dots, m)\\\\ & & h_j(x) = 0 & (j = 1, \\dots, n) \\end{align}\\] \u5176\u4e2d \\(f(x)\\) \u662f\u76ee\u6807\u51fd\u6570\uff0c \\(g_i(x)\\) \u662f\u4e0d\u7b49\u5f0f\u7ea6\u675f\uff0c \\(h_j(x)\\) \u662f\u7b49\u5f0f\u7ea6\u675f\u3002\u5bf9\u5e94\u62c9\u683c\u6717\u65e5\u51fd\u6570\uff1a \\[L(x, \\alpha, \\beta) = f(x) + \\sum_{i=1}^m \\alpha_i g_i(x) + \\sum_{j=1}^n \\beta_j h_j(x)\\] \u5047\u8bbe\u5b58\u5728\u5c40\u90e8\u6700\u4f18\u89e3 \\(x^*\\) \uff0c\u5219\u5b83\u5e94\u8be5\u6ee1\u8db3\u4ee5\u4e0b 4 \u7ec4\u7ea6\u675f\uff08\u5373\u53ef\u4ee5\u7528\u4ee5\u4e0b\u7ea6\u675f\u6c42\u89e3\uff09\uff1a \u62c9\u683c\u6717\u65e5\u5e73\u7a33\u6027\u6761\u4ef6(Stationarity) \u8fd9\u662f\u62c9\u683c\u6717\u65e5\u51fd\u6570\u53d6\u6781\u503c\u65f6\u7684\u5fc5\u8981\u6761\u4ef6\uff0c\u8be5\u70b9\u5bfc\u6570\u4e3a0: \\[ \\frac{ \\partial L(x, \\alpha, \\beta) }{\\partial x} |_{x=x^*} = 0 \\] \u539f\u95ee\u9898\u53ef\u884c\u6761\u4ef6(Primal feasibility) \u9700\u8981\u6ee1\u8db3\u539f\u95ee\u9898\u7684\u53ef\u884c\u6027\uff1a \\[\\begin{align} g_i(x^*) \\leq 0 \\\\ h_j(x^*) = 0 \\end{align}\\] \u5bf9\u5076\u95ee\u9898\u53ef\u884c\u6761\u4ef6(Dual feasibility) \u5bf9\u4e8e\u4e0d\u7b49\u5f0f\u7ea6\u675f\uff0c\u4e3a\u4e86\u4f7f \\(g_i(x)\\) \u68af\u5ea6\u65b9\u5411\u603b\u662f\u6307\u5411\u53ef\u884c\u57df\u5185\u90e8 \uff0c\u9700\u8981\u6ee1\u8db3\u7cfb\u6570\u975e\u8d1f\uff1a \\[ \\alpha_i \\geq 0 \\] \u4e92\u8865\u677e\u5f1b\u6761\u4ef6(Complementary slackness) \u6700\u4f18\u89e3\u65e0\u975e\u6709\u4e24\u79cd\u60c5\u51b5\uff0c\u4e00\u79cd\u5728\u4e0d\u7b49\u5f0f\u7ea6\u675f\u6761\u4ef6\u5185\u90e8\uff0c\u5373 \\(g_i(x^*) < 0\\) \uff0c\u6b64\u65f6\u7ea6\u675f\u6761\u4ef6\u4e0d\u8d77\u4f5c\u7528\uff0c\u53ef\u4ee5\u5c06\u5bf9\u5e94\u7684\u677e\u5f1b\u53d8\u91cf\u8bbe\u4e3a \\(\\alpha_i = 0\\) \u3002\u53e6\u4e00\u79cd\u662f\u5728\u8fb9\u754c\u4e0a\uff0c\u5373 \\(g_i(x^*) = 0\\) \uff0c\u6b64\u65f6\u7ea6\u675f\u6761\u4ef6\u6709\u6548\u3002\u65e0\u8bba\u662f\u4ee5\u4e0a\u54ea\u79cd\u60c5\u51b5\uff0c\u90fd\u6709\uff1a \\[ \\alpha_i g_i(x^*) = 0 \\]","title":"ESL 12: Support Vector Machines and Flexibile Discriminants"},{"location":"mathematics/ESL/ESL12_SVM/#esl-12-support-vector-machines-and-flexibile-discriminants","text":"","title":"ESL 12: Support Vector Machines and Flexibile Discriminants"},{"location":"mathematics/ESL/ESL12_SVM/#121-introduction","text":"\u5f53\u4e24\u4e2a\u7c7b \u7ebf\u6027\u53ef\u5206 \u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u7528 Linear Discriminant Analysis \u627e\u5230\u5b83\u4eec\u7684\u6700\u4f18\u5206\u754c\u9762\u3002\u5f53\u5b83\u4eec\u4e0d\u662f\u7ebf\u6027\u53ef\u5206\uff0c\u76f8\u4e92\u91cd\u53e0\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u5728 \u66f4\u9ad8\u7ef4\u7684\u7279\u5f81\u7a7a\u95f4 \u4e2d\u6784\u9020 \u7ebf\u6027 \u5206\u754c\u9762\u3002\u8fd9\u79cd\u65b9\u6cd5\u53eb\u505a\u652f\u6301\u5411\u91cf\u673a\uff08support vector machine\uff09\u3002\u5b83\u662f LDA \u7684\u4e00\u4e2a\u6269\u5c55\u3002 \u76f8\u5bf9\u4e8e LDA\uff0c\u5b83\u7684\u4e3b\u8981\u4f18\u52bf\u662f\uff1a \u53ef\u4ee5\u5904\u7406\u975e\u7ebf\u6027\u573a\u666f \u5206\u754c\u9762\u4e3b\u8981\u7531\u8fb9\u754c\u4e0a\u7684\u6837\u672c\u70b9\u786e\u5b9a\uff08LDA \u9700\u8981\u5404\u7c7b\u6837\u672c\u4e2d\u5fc3\u70b9\uff09","title":"12.1 Introduction"},{"location":"mathematics/ESL/ESL12_SVM/#122-the-support-vector-classifier","text":"\u5728\u7b2c\u56db\u7ae0\u4e2d\u6211\u4eec\u8ba8\u8bba\u4e86 \u7ebf\u6027\u53ef\u5206 \u7c7b\u578b\u7684\u6700\u4f18\u5206\u754c\u9762\uff0c\u8fd9\u91cc\uff0c\u6211\u4eec\u9700\u8981\u5c06\u5176\u6269\u5c55\u81f3 \u7ebf\u6027\u4e0d\u53ef\u5206 \u7684\u60c5\u5f62\u3002 \u5047\u8bbe\u6211\u4eec\u6709 N \u4e2a\u8bad\u7ec3\u6570\u636e\uff1a \\((x_1, y_1), (x_2, y_2), \\dots, (x_N, y_N)\\) \uff0c\u5176\u4e2d\uff0c \\(x_i\\) \u662f \\(p\\) \u7ef4\u8f93\u5165\uff0c \\(y_i \\in {-1, 1}\\) \u662f\u7c7b\u578b\u8f93\u51fa\u3002 \u5b9a\u4e49\u8d85\u5e73\u9762\uff08\u81ea\u53d8\u91cf \\(x\\) \uff09 \\[ {x: f(x) = x^T \\beta + \\beta_0 = 0}, \\] \u4e0a\u5f0f\u7684\u5de6\u8fb9\u5b9a\u4e49\u4e86\u67d0\u4e2a\u70b9 \\(x\\) \u4e0e\u8be5\u5e73\u9762\u7684\u8ddd\u79bb\uff08\u6709\u7b26\u53f7\uff09\u3002\u5176\u4e2d\uff0c\u7cfb\u6570 \\(\\beta\\) \u662f \u5355\u4f4d\u5411\u91cf \\(\\| {\\beta} \\| = 1\\) \u3002\u5206\u7c7b\u6807\u51c6\u4e3a\uff1a \\[ G(x) = \\text{sign}[x^T \\beta + \\beta_0]\\] \u6211\u4eec\u7684\u76ee\u7684\u662f\u627e\u5230\u5728\u4e24\u4e2a\u7c7b\u578b\u7684\u6570\u636e\u4e2d margin \u6700\u5927\u7684\u5206\u754c\u9762\u3002","title":"12.2 The Support Vector Classifier"},{"location":"mathematics/ESL/ESL12_SVM/#_1","text":"\u5bf9\u4e8e\u7ebf\u6027\u5206\u7c7b\u95ee\u9898\uff0cmargin \u53ef\u4ee5\u5b9a\u4e49\u4e3a\u5206\u754c\u9762\u8ddd\u79bb\u6700\u8fd1\u7684\u6837\u672c\u70b9\u7684\u8ddd\u79bb\u3002\u5373\uff1a \\[\\begin{align} & & \\mathop{\\arg \\max}_{\\beta, \\beta_0, \\| \\beta \\| = 1} ~ M \\\\ & \\text{s.t.} & y_i(x_i^T \\beta + \\beta_0) \\geq M, ~~~ i=1,\\dots,N \\end{align}\\] \u5176\u4e2d\uff0c \\(x^T \\beta + \\beta_0 = 0\\) \u662f\u5206\u754c\u9762\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u6837\u672c\uff0c\u9884\u6d4b\u503c \\(x_i^T \\beta + \\beta_0\\) \u53ef\u80fd\u4e3a\u6b63\u6216\u8005\u8d1f\uff0c\u76ee\u6807\u662f\u627e\u5230\u4e00\u7ec4\u53c2\u6570 \\(\\beta, \\beta_0\\) \uff0c\u4f7f\u5f97 margin \u6700\u5927\u3002 \u8be5\u4f18\u5316\u95ee\u9898\u5e76\u4e0d\u662f\u4e00\u4e2a\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u6bd4\u8f83\u96be\u4ee5\u6c42\u89e3\u3002 \u9996\u5148\uff0c\u6211\u4eec\u4e0d\u518d\u8981\u6c42 \\(\\beta\\) \u662f\u5355\u4f4d\u5411\u91cf\uff0c\u800c\u662f\u624b\u52a8\u5728\u7ea6\u675f\u91cc\u5c06\u5176\u5355\u4f4d\u5316\uff0c\u5373\uff1a \\[\\begin{align} & & \\mathop{\\arg \\max}_{\\beta, \\beta_0} ~ M \\\\ & \\text{s.t.} & y_i(x_i^T \\beta + \\beta_0) \\geq M \\| \\beta \\| , ~~~ i=1,\\dots,N \\end{align}\\] \u4ee4\uff1a \\[\\theta = \\frac{\\beta}{M\\| \\beta \\|}\\] \\[\\theta_0 = \\frac{\\beta_0}{M\\| \\beta \\|}\\] \u7ea6\u675f\u6761\u4ef6\u53ef\u4ee5\u6539\u5199\u4e3a\uff1a \\[ y_i(x_i^T \\theta + \\theta_0) \\geq 1 \\] \u8fd9\u4e2a\u53d8\u6362\u8868\u793a\uff0c\u5bf9\u4e8e\u8be5\u4f18\u5316\u95ee\u9898\uff0c\u5bf9\u5e94\u4e0d\u540c\u7684 M \u53d6\u503c\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\u5f88\u591a\u7ec4\u89e3\u3002\u7b49\u5f0f\u53f3\u8fb9\u7684 1 \u8868\u793a\u5bf9\u4e8e\u53c2\u6570 \\(\\theta\\) \u7684 \\(M_\\theta\\) \u6ee1\u8db3\uff1a \\[ M_\\theta \\| \\theta \\| = 1 \\] \u663e\u7136\uff0c\u6b64\u65f6\u6c42 \\(M_\\theta\\) \u7684\u6700\u5927\u503c\u5c31\u662f\u6c42 \\(\\| \\theta \\|\\) \u7684\u6700\u5c0f\u503c\u3002\u56e0\u6b64\uff0c\u4f18\u5316\u95ee\u9898\u7b80\u5316\u4e3a\uff1a \\[\\begin{align} & & \\mathop{\\arg \\min}_{\\theta, \\theta_0} ~ \\| \\theta \\| \\\\ & \\text{s.t.} & y_i(x_i^T \\theta + \\theta_0) \\geq 1, ~~~ i=1,\\dots,N \\end{align}\\] \u8fd9\u662f\u4e00\u4e2a\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u901a\u5e38 SVM \u7528\u8fd9\u4e2a\u5f62\u5f0f\u63cf\u8ff0\u3002","title":"\u7ebf\u6027\u5206\u7c7b\u95ee\u9898"},{"location":"mathematics/ESL/ESL12_SVM/#_2","text":"\u73b0\u5b9e\u4e2d\uff0c\u53ef\u80fd\u4e0d\u540c\u7684\u7c7b\u522b\u5728\u7279\u5f81\u7a7a\u95f4\u4e2d\u6709\u91cd\u53e0\u3002\u56e0\u6b64\uff0c\u5b83\u4eec\u4e0d\u80fd\u7528\u4e00\u4e2a\u7ebf\u6027\u5206\u754c\u9762\u5206\u5272\u3002\u5bf9\u4e8e\u8fd9\u7c7b\u60c5\u51b5\uff0c\u6211\u4eec \u5bf9\u6bcf\u4e2a\u6837\u672c\u5f15\u5165\u677e\u5f1b\u53d8\u91cf \\(\\xi\\) \u3002\u5e76\u5c06\u7ea6\u675f\u6761\u4ef6\u653e\u677e\u4e3a\uff1a \\[ y_i (x_i^T \\beta + \\beta_0 ) \\geq M(1 - \\xi_i) \\] \\(\\xi_i\\) \u8868\u793a\u6837\u672c i \u201c\u8d8a\u754c\u201d\u4e86\u591a\u5c11\uff08normalized by margin\uff09\u3002 \u8fd9\u91cc\u7684\u8d8a\u754c\u6307\u7684\u5e76\u975e\u5206\u754c\u9762\uff0c\u800c\u662f\u9644\u52a0 margin \u540e\u5f62\u6210\u7684\u754c\u9650\u3002 \\(\\xi_i > 1\\) \u8bf4\u660e\u8bad\u7ec3\u51fa\u7684\u5206\u754c\u9762\u5bf9\u6837\u672c i \u8fdb\u884c\u4e86\u9519\u8bef\u7684\u5206\u7c7b\u3002 \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u9650\u5236 \\(\\sum \\xi_i \\leq C\\) \u6765\u9650\u5236\u6211\u4eec\u677e\u5f1b\u7684\u7a0b\u5ea6\u3002\u76f8\u5bf9\u4e8e\u7ebf\u6027\u5206\u7c7b\u7684\u4f18\u5316\u95ee\u9898\uff0c\u975e\u7ebf\u6027\u5206\u7c7b\u9700\u8981\u989d\u5916\u5f15\u5165\u677e\u5f1b\u53d8\u91cf\uff0c\u5e76\u589e\u52a0\u4e00\u4e2a\u7ea6\u675f\u6761\u4ef6\uff1a \\[\\begin{align} & & \\mathop{\\arg \\min}_{\\theta, \\theta_0} ~ \\| \\theta \\| &\\\\ & \\text{s.t.} & ~ y_i(x_i^T \\theta + \\theta_0) \\geq 1 - \\xi_i, & \\\\ & & \\xi_i \\geq 0, \\sum_{i=1}^N \\xi_i \\leq C & ~~~~ (i=1,\\dots,N) \\end{align}\\]","title":"\u975e\u7ebf\u6027\u5206\u7c7b\u95ee\u9898"},{"location":"mathematics/ESL/ESL12_SVM/#1221-computing-the-support-vector-classifier","text":"\u6211\u4eec\u53ef\u4ee5\u628a\u8be5\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u6210\u4e00\u4e2a\u4e8c\u6b21\u51fd\u6570\u7684\u51f8\u4f18\u5316\u95ee\u9898\uff1a \\[\\begin{align} & & \\mathop{\\arg \\min}_{\\theta, \\theta_0} ~ \\frac{1}{2} \\| \\theta \\|^2 + C \\sum_{i=1}^N \\xi_i & \\\\ & \\text{s.t.} & ~ y_i(x_i^T \\theta + \\theta_0) \\geq 1 - \\xi_i, & \\\\ & & \\xi_i \\geq 0 & ~~~~ (i=1,\\dots,N) \\end{align}\\] \u6ce8\u610f\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u505a\u4e86\u4e24\u4e2a\u7b49\u6548\u53d8\u6362\uff1a \u5c06 \\(\\| \\theta \\|\\) \u53d8\u6210\u4e86 \\(\\frac{1}{2} \\| \\theta \\|^2\\) . \u5c06\u7ea6\u675f\u6761\u4ef6 \\(\\sum_{i=1}^N \\xi_i \\leq C\\) \u8f6c\u4e3a\u4e00\u4e2a\u60e9\u7f5a\u9879 \\(C \\sum_{i=1}^N\\) . \u5f15\u5165\u62c9\u683c\u6717\u65e5\u4e58\u5b50 \\(\\alpha_i, \\mu_i\\) \u6709\uff1a \\[ L_p = \\frac{1}{2} \\| \\theta \\|^2 + C \\sum_{i=1}^N \\xi_i - \\sum_{i=1}^N \\alpha_i[y_i(x_i^T \\theta + \\theta_0) - (1 - \\xi_i)] - \\sum_{i=1}^N(\\mu_i \\xi_i) \\] \u6211\u4eec\u5c06\u5176\u8f6c\u5316\u4e3a\u5bf9\u5076\u95ee\u9898\uff0c\u9700\u8981\u6ee1\u8db3 KKT \u6761\u4ef6\u3002 \u6761\u4ef6\u4e00\uff1a\u5e73\u7a33\u6027\u6761\u4ef6 \u3002\u5206\u522b\u5bf9\u53c2\u6570 \\(\\theta, \\theta_0, \\xi_i\\) \u6c42\u5bfc\u5e76\u4ee4\u5bfc\u6570\u4e3a 0\uff0c\u5f97\u5230\uff1a \\[\\begin{align} \\mathbf{\\theta} &= \\sum_{i=1}^N \\alpha_i y_i \\mathbf{x_i} \\\\ 0 &= \\sum_{i=1}^N \\alpha_i y_i \\\\ \\alpha_i &= C - \\mu_i \\end{align}\\] \u5c06\u4e0a\u5f0f\u4ee3\u5165 \\(L_p\\) \u5f97\u5230\u5176\u5bf9\u5076\u95ee\u9898\uff1a \\[\\begin{align} L_D &= \\frac{1}{2} \\| \\theta \\|^2 + \\sum_{i=1}^N \\alpha_i - \\sum_{i=1}^N \\alpha_i y_i(x_i^T \\theta + \\theta_0) \\\\ &= \\frac{1}{2} \\| \\theta \\|^2 + \\sum_{i=1}^N \\alpha_i - \\sum_{i=1}^N \\theta^T \\theta - \\theta_0 \\sum_{i=1}^N \\alpha_i y_i \\\\ &= \\sum_{i=1}^N \\alpha_i - \\frac{1}{2} \\sum_{i=1}^N \\theta^T \\theta \\\\ &= \\sum_{i=1}^N \\alpha_i - \\frac{1}{2} \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_i \\alpha_j y_i y_j x_i^T x_j \\end{align}\\] \u7531\u4e8e\u662f\u5bf9\u5076\u95ee\u9898\uff0c\u6211\u4eec\u9700\u8981 \u6700\u5927\u5316 \\(L_D\\) \u3002\u6b64\u65f6\uff0c \\(L_D\\) \u4e2d\u53ea\u5305\u542b\u672a\u77e5\u53c2\u6570 \\(\\alpha_i\\) \u3002\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u53ef\u4ee5\u7528 \u987a\u5e8f\u6700\u5c0f\u5316\u7b97\u6cd5 (Sequential Minimal Optimization)\u6c42\u89e3\uff0c\u8fd9\u91cc\u4e0d\u8868\u3002 \u6211\u4eec\u53ef\u4ee5\u5047\u8bbe\u5df2\u7ecf\u5f97\u5230\u4e00\u7ec4\u6700\u4f18\u7684 \\(\\hat{\\alpha}_i\\) \u3002\u4ee3\u5165\u4e0b\u5f0f\u53ef\u4ee5\u6c42\u5f97 \\(\\theta\\) \uff1a \\[ \\mathbf{\\theta} = \\sum_{i=1}^N \\alpha_i y_i \\mathbf{x_i} \\] \u5bf9\u4e8e\u53c2\u6570 \\(\\theta_0\\) \uff0c\u6211\u4eec\u8fd8\u9700\u8981\u5176\u4ed6\u7684 KKT \u6761\u4ef6\u7ea6\u675f\u6c42\u89e3\u3002 \u6761\u4ef6\u4e8c\uff1a\u539f\u95ee\u9898\u53ef\u884c\u6027 \u3002 \\[\\begin{align} y_i(x_i^T \\theta + \\theta_0) &\\geq (1 - \\xi_i) \\\\ \\xi_i &\\geq 0 \\end{align}\\] \u6761\u4ef6\u4e09\uff1a\u5bf9\u5076\u95ee\u9898\u53ef\u884c\u6027 \u3002 \\[\\begin{align} \\alpha_i & \\geq 0 \\\\ \\mu_i & \\geq 0 \\end{align}\\] \u6761\u4ef6\u56db\uff1a\u4e92\u8865\u677e\u5f1b \u3002 \\[\\begin{align} \\alpha_i[y_i(x_i^T \\theta + \\theta_0) - (1 - \\xi_i)] &= 0 \\\\ \\mu_i \\xi_i &= 0 \\end{align}\\] \u901a\u8fc7\u5e73\u7a33\u6027\u6761\u4ef6\uff0c\u6211\u4eec\u5df2\u7ecf\u5f97\u5230\u5173\u7cfb\uff1a \\[ \\hat{\\theta} = \\sum_{i=1}^N \\hat{\\alpha_i} y_i x_i \\] \u53e6\uff0c\u6839\u636e\u4e92\u8865\u677e\u5f1b\u6761\u4ef6\uff0c\u7cfb\u6570 \\(\\hat{\\alpha_i}\\) \u4ec5\u5728\u7ea6\u675f \\(y_i(x_i^T \\theta + \\theta_0) \\geq (1 - \\xi_i)\\) \u7b49\u53f7\u6210\u7acb \u65f6\u53d6\u975e 0\uff0c\u5373\uff1a \\[ y_i(x_i^T \\theta + \\theta_0) = (1 - \\xi_i) \\] \u8fd9\u4e9b\u4f7f\u7b49\u53f7\u6210\u7acb\u7684\u6837\u672c\u70b9\u88ab\u79f0\u4e3a\u201c \u652f\u6301\u5411\u91cf \u201d (support vectors)\uff0c\u56e0\u4e3a\u7cfb\u6570 \\(\\hat{\\theta}\\) \u7684\u53d6\u503c\u53ea\u8ddf\u4ed6\u4eec\u6709\u5173\u3002 \u6839\u636e\u7ea6\u675f\uff1a \\[ \\alpha_i[y_i(x_i^T \\theta + \\theta_0) - (1 - \\xi_i)] = 0 \\] \u652f\u6301\u5411\u91cf\u4e2d\u7684\u4efb\u4f55\u4e00\u4e2a\u6837\u672c\u90fd\u53ef\u4ee5\u7528\u4e8e\u6c42\u89e3 \\(\\theta_0\\) \uff0c\u4e3a\u4e86\u6570\u503c\u7a33\u5b9a\u6027\uff0c\u6211\u4eec\u4f7f\u7528\u6240\u6709\u89e3\u7684 \u5e73\u5747\u503c \u3002 \u6211\u4eec\u518d\u770b\u4ee5\u4e0b\u4e24\u4e2a\u7ea6\u675f\u6761\u4ef6\uff0c\u989d\u5916\u5b9a\u6027\u5206\u6790\u4e00\u4e0b\u8fd9\u4e9b\u652f\u6301\u5411\u91cf\uff1a \\[\\begin{align} \\alpha_i &= C - \\mu_i \\\\ \\mu_i \\xi_i &= 0 \\end{align}\\] \u5728\u8fd9\u4e9b\u6837\u672c\u70b9\u4e2d\uff1a \u5982\u679c \\(\\xi_i = 0\\) \uff0c\u5373\u6837\u672c \\(x_i\\) \u5728 margin \u7684\u8fb9\u754c\u4e0a\u3002\u6b64\u65f6 \\(\\mu_i > 0\\) \u4e14 \\(0 \\leq \\alpha_i \\leq C\\) \u3002 \u5982\u679c \\(\\xi_i > 0\\) \uff0c\u5373\u6837\u672c \\(x_i\\) \u8d8a\u8fc7\u4e86 margin \u8fb9\u754c\uff0c\u5305\u62ec\u88ab\u9519\u8bef\u5206\u7c7b\u7684\u6837\u672c\u3002\u6b64\u65f6 \\(\\mu_i = 0\\) \u4e14 \\(\\alpha_i = C\\) \u3002","title":"12.2.1 Computing the Support Vector Classifier"},{"location":"mathematics/ESL/ESL12_SVM/#kkt","text":"KKT \u65b9\u6cd5\u662f\u5bf9\u62c9\u683c\u6717\u65e5\u4e58\u5b50\u6cd5\u7684\u4e00\u4e2a\u6269\u5c55\u3002\u62c9\u683c\u6717\u65e5\u4e58\u5b50\u6cd5\u53ea\u80fd\u5e94\u7528\u5728\u7b49\u5f0f\u7ea6\u675f\u4e0a\uff0c\u800c KKT\u5141\u8bb8\u4e0d\u7b49\u5f0f\u7ea6\u675f \u3002 \u5bf9\u4e8e\u4f18\u5316\u95ee\u9898\uff1a \\[\\begin{align} &\\text{optimize} & f(x) & \\\\ &\\text{subject to:} & g_i(x) \\leq 0 & (i = 1, \\dots, m)\\\\ & & h_j(x) = 0 & (j = 1, \\dots, n) \\end{align}\\] \u5176\u4e2d \\(f(x)\\) \u662f\u76ee\u6807\u51fd\u6570\uff0c \\(g_i(x)\\) \u662f\u4e0d\u7b49\u5f0f\u7ea6\u675f\uff0c \\(h_j(x)\\) \u662f\u7b49\u5f0f\u7ea6\u675f\u3002\u5bf9\u5e94\u62c9\u683c\u6717\u65e5\u51fd\u6570\uff1a \\[L(x, \\alpha, \\beta) = f(x) + \\sum_{i=1}^m \\alpha_i g_i(x) + \\sum_{j=1}^n \\beta_j h_j(x)\\] \u5047\u8bbe\u5b58\u5728\u5c40\u90e8\u6700\u4f18\u89e3 \\(x^*\\) \uff0c\u5219\u5b83\u5e94\u8be5\u6ee1\u8db3\u4ee5\u4e0b 4 \u7ec4\u7ea6\u675f\uff08\u5373\u53ef\u4ee5\u7528\u4ee5\u4e0b\u7ea6\u675f\u6c42\u89e3\uff09\uff1a \u62c9\u683c\u6717\u65e5\u5e73\u7a33\u6027\u6761\u4ef6(Stationarity) \u8fd9\u662f\u62c9\u683c\u6717\u65e5\u51fd\u6570\u53d6\u6781\u503c\u65f6\u7684\u5fc5\u8981\u6761\u4ef6\uff0c\u8be5\u70b9\u5bfc\u6570\u4e3a0: \\[ \\frac{ \\partial L(x, \\alpha, \\beta) }{\\partial x} |_{x=x^*} = 0 \\] \u539f\u95ee\u9898\u53ef\u884c\u6761\u4ef6(Primal feasibility) \u9700\u8981\u6ee1\u8db3\u539f\u95ee\u9898\u7684\u53ef\u884c\u6027\uff1a \\[\\begin{align} g_i(x^*) \\leq 0 \\\\ h_j(x^*) = 0 \\end{align}\\] \u5bf9\u5076\u95ee\u9898\u53ef\u884c\u6761\u4ef6(Dual feasibility) \u5bf9\u4e8e\u4e0d\u7b49\u5f0f\u7ea6\u675f\uff0c\u4e3a\u4e86\u4f7f \\(g_i(x)\\) \u68af\u5ea6\u65b9\u5411\u603b\u662f\u6307\u5411\u53ef\u884c\u57df\u5185\u90e8 \uff0c\u9700\u8981\u6ee1\u8db3\u7cfb\u6570\u975e\u8d1f\uff1a \\[ \\alpha_i \\geq 0 \\] \u4e92\u8865\u677e\u5f1b\u6761\u4ef6(Complementary slackness) \u6700\u4f18\u89e3\u65e0\u975e\u6709\u4e24\u79cd\u60c5\u51b5\uff0c\u4e00\u79cd\u5728\u4e0d\u7b49\u5f0f\u7ea6\u675f\u6761\u4ef6\u5185\u90e8\uff0c\u5373 \\(g_i(x^*) < 0\\) \uff0c\u6b64\u65f6\u7ea6\u675f\u6761\u4ef6\u4e0d\u8d77\u4f5c\u7528\uff0c\u53ef\u4ee5\u5c06\u5bf9\u5e94\u7684\u677e\u5f1b\u53d8\u91cf\u8bbe\u4e3a \\(\\alpha_i = 0\\) \u3002\u53e6\u4e00\u79cd\u662f\u5728\u8fb9\u754c\u4e0a\uff0c\u5373 \\(g_i(x^*) = 0\\) \uff0c\u6b64\u65f6\u7ea6\u675f\u6761\u4ef6\u6709\u6548\u3002\u65e0\u8bba\u662f\u4ee5\u4e0a\u54ea\u79cd\u60c5\u51b5\uff0c\u90fd\u6709\uff1a \\[ \\alpha_i g_i(x^*) = 0 \\]","title":"KKT \u6761\u4ef6"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/","text":"ESL 3: Linear Methods for Regression \u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u5047\u8bbe\u56de\u5f52\u51fd\u6570 E(Y|X) \u5bf9\u4e8e\u8f93\u5165 X \u662f\u7ebf\u6027\u7684\u3002 \u5b83\u7684\u4f18\u52bf\u5728\u4e8e\uff1a \u7b80\u5355 \u80fd\u591f\u8868\u793a\u6bcf\u4e2a\u8f93\u5165\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd \u8f93\u5165\u53ef\u4ee5\u8fdb\u884c\u53d8\u6362 \u4ed6\u4eec\u6709\u65f6\u5019\u6bd4\u590d\u6742\u7684\u65b9\u6cd5\u66f4\u7cbe\u51c6\uff0c\u5c24\u5176\u662f\u5728\u6837\u672c\u6570\u91cf\u5c11\u3001\u4f4e\u4fe1\u566a\u6bd4\u6216\u8005\u7a00\u758f\u77e9\u9635\u7684\u60c5\u5f62\u3002 3.2 Linear Regression Models and Least Squares \\(p\\) \u7ef4\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u5f62\u5f0f\u5982\u4e0b\uff1a \\[f(X) = \\beta_0 + \\sum_{j=1}^p X_j \\beta_j\\] \u6211\u4eec\u9700\u8981\u4f30\u8ba1\u4e00\u7ec4\u53c2\u6570 \\(\\beta\\) \uff0c\u4f7f\u6b8b\u5dee\u5e73\u65b9\u548c\uff08Residual Sum of Squares\uff09\u6700\u5c0f\uff1a \\[\\begin{align} \\text{RSS}(\\beta) &= (\\textbf{y} - \\textbf{X}\\beta )^T(\\textbf{y} - \\textbf{X}\\beta ) \\\\ &= \\textbf{y}^T\\textbf{y} - \\textbf{y}^T\\textbf{X}\\beta - \\beta^T\\textbf{X}^T\\textbf{y} + \\beta^T\\textbf{X}^T\\textbf{X}\\beta \\end{align}\\] \u5176\u4e2d\uff0c \\(\\textbf{X}\\) \u662f\u4e00\u4e2a \\(N \\times (p+1)\\) \u77e9\u9635\uff0c \\(\\textbf{y}\\) \u662f \\(N \\times 1\\) \u89c2\u6d4b\u503c\u3002 \u5bf9 \\(\\beta\\) \u6c42\u5bfc\u53ef\u4ee5\u5f97\u5230\uff1a \\[ \\frac{\\partial \\text{RSS}(\\beta)}{\\partial \\beta} = -2 \\textbf{X}^T\\textbf{y} + 2\\textbf{X}^T\\textbf{X} \\beta\\] \u7531\u4e8e\u4e8c\u9636\u5bfc\u6570\u6b63\u5b9a\uff0c\u4ee4\u4e00\u9636\u5bfc\u6570\u4e3a 0 \u5411\u91cf\uff0c\u5f97\u51fa\u6781\u503c\u70b9\uff08\u5373\u4f30\u8ba1\u503c\uff09\uff1a \\[ \\hat{\\beta}= (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\textbf{y}\\] \\[\\hat{\\textbf{y}} = \\textbf{X} \\hat{\\beta} = \\textbf{X}(\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\textbf{y}\\] \u6211\u4eec\u79f0 \\(\\textbf{H} = \\textbf{X}(\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\) \u4e3a\u4f30\u8ba1\u77e9\u9635\uff08\"hat\" matrix\uff09\uff0c\u5b83\u6ee1\u8db3\u5bf9\u79f0\u6027\u548c\u5e42\u7b49\u6027\uff1a \\[\\textbf{H}^T = \\textbf{H}\\] \\[\\textbf{H}^T\\textbf{H} = \\textbf{H}\\] \u5f53 \\(\\textbf{X}\\) \u4e2d\u67d0\u4e9b\u5217\u7ebf\u6027\u76f8\u5173\uff08\u5373\u975e\u6ee1\u79e9\u77e9\u9635\uff09\u65f6\uff0c \\((\\textbf{X}^T\\textbf{X})\\) \u662f\u5947\u5f02\u77e9\u9635\uff0c\u5b83\u53ea\u80fd\u6c42\u5e7f\u4e49\u9006\u77e9\u9635\uff0c\u4e0d\u6b62\u4e00\u4e2a\u89e3\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u5c06\u5197\u4f59\u7684\u8f93\u5165\u5254\u9664\u6389\uff0c\u5927\u90e8\u5206\u6c42\u89e3\u8f6f\u4ef6\u90fd\u5b9e\u73b0\u4e86\u8fd9\u4e2a\u529f\u80fd\u3002 \u4f30\u8ba1\u53c2\u6570\u7684\u7edf\u8ba1\u7279\u6027 \u4e3a\u4e86\u786e\u5b9a\u4f30\u8ba1\u7684\u53c2\u6570 \\(\\hat{\\beta}\\) \u7684\u7edf\u8ba1\u7279\u6027\uff0c\u6211\u4eec\u5047\u8bbe\uff1a \u6bcf\u4e2a\u89c2\u6d4b\u503c \\(y_i\\) \u76f8\u4e92\u72ec\u7acb \\(y_i\\) \u6709\u56fa\u5b9a\u7684\u566a\u58f0 \\(\\varepsilon \\sim N(0, \\sigma^2)\\) \u90a3\u4e48\u4f30\u8ba1\u503c \\(\\hat{\\beta}\\) \u7684\u65b9\u5dee\u4e3a\uff1a \\[ \\text{Var}(\\hat{\\beta}) = (\\textbf{X}^T\\textbf{X})^{-1} \\sigma^2\\] where: \\[\\hat{\\sigma}^2 = \\frac{\\text{RSS}}{N-p-1}= \\frac{1}{N-p-1} \\sum_{i=1}^{N} (y_i-\\hat{y})^2\\] \u8bc1\u660e N \u4e2a y \u7684\u89c2\u6d4b\u503c\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\[ \\textbf{y} = \\textbf{X}\\beta + \\varepsilon \\] \u5176\u4e2d \\(\\varepsilon\\) \u662f \\(N \\times 1\\) \u7684\u566a\u58f0\u3002\u56e0\u6b64\u6709\uff1a \\[\\begin{align} \\hat{\\beta} &= (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\textbf{y} \\\\ &= \\beta + (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\varepsilon \\end{align}\\] \u65e0\u504f\u6027\uff08\u671f\u671b\u503c\u4e3a \\(\\beta\\) \uff09\uff1a \\[E(\\hat{\\beta}) = \\beta + (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T E(\\varepsilon) = \\beta\\] \u534f\u65b9\u5dee\u77e9\u9635\uff08\u6ce8\u610f\u662f \\(\\beta \\beta^T\\) \u800c\u975e \\(\\beta^T \\beta\\) \uff0c\u662f\u4e00\u4e2a\u77e9\u9635\uff09\uff1a \\[\\begin{align} \\text{Var}(\\hat{\\beta}) &= E[(\\beta - \\hat{\\beta})(\\beta - \\hat{\\beta})^T] \\\\ &=E[(\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\varepsilon\\varepsilon^T\\textbf{X}(\\textbf{X}^T\\textbf{X})^{-1}] \\\\ &= (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T E(\\varepsilon\\varepsilon^T) \\textbf{X}(\\textbf{X}^T\\textbf{X})^{-1} \\\\ &= \\sigma^2 (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T \\textbf{I} \\textbf{X}(\\textbf{X}^T\\textbf{X})^{-1} \\\\ &= \\sigma^2 (\\textbf{X}^T\\textbf{X})^{-1} \\end{align}\\] \u53ef\u4ee5\u5f97\u5230\uff1a \\[ \\hat{\\beta} \\sim N(\\beta, \\sigma^2 (\\textbf{X}^T\\textbf{X})^{-1})\\] \u4e0b\u9762\u6765\u786e\u5b9a \\(\\sigma^2\\) \u3002 \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u89c2\u6d4b\u503c \\(y\\) \u548c\u9884\u6d4b\u503c \\(\\hat{y}\\) \u7684\u5dee\u6765\u5f97\u5230\u566a\u58f0 \\(\\varepsilon\\) \u3002 \\[\\begin{align} y - \\hat{y} &= \\textbf{X}\\beta + \\varepsilon -\\textbf{X}\\hat{\\beta} \\\\ &= \\textbf{X}\\beta + \\varepsilon - \\textbf{X}(\\beta + (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\varepsilon) \\\\ &= (\\textbf{I -H} )\\varepsilon \\end{align}\\] \\[\\begin{align} \\sum_{i=1}^N(y_i - \\hat{y_i})^2 &= (y - \\hat{y})^T (y - \\hat{y}) \\\\ &= \\varepsilon^T(\\textbf{I - H}) \\varepsilon \\\\ &= \\sum_{k =1}^N \\varepsilon_k^2- \\sum_{i, j = 1}^N \\varepsilon_i \\varepsilon_j H_{ij} \\end{align}\\] \u5176\u671f\u671b\u503c\u4e3a\uff1a \\[\\begin{align} E[\\sum_{i=1}^N(y_i - \\hat{y_i})^2] &= E[\\sum_{k =1}^N \\varepsilon_k^2- \\sum_{i, j = 1}^N \\varepsilon_i \\varepsilon_j H_{ij} ] \\\\ &= N\\sigma^2 - E(\\sum_{i, j = 1}^N \\varepsilon_i \\varepsilon_j H_{ij}) \\end{align}\\] \u7531\u4e8e \\(\\varepsilon_i, \\varepsilon_j\\) \u662f\u72ec\u7acb\u7684\uff0c\u5f53 \\(i \\neq j\\) \u65f6\uff1a \\[\\text{Cov}(\\varepsilon_i, \\varepsilon_j) = E(\\varepsilon_i \\varepsilon_j) - E(\\varepsilon_i)E(\\varepsilon_j) = 0\\] \u56e0\u6b64\uff1a \\[\\begin{align} E[\\sum_{i=1}^N(y_i - \\hat{y_i})^2] &= N\\sigma^2 - E(\\sum_{i, j = 1}^N \\varepsilon_i \\varepsilon_j H_{ij}) \\\\ &= N\\sigma^2 - E(\\sum_{i=1}^{N}\\varepsilon_i^2H_{ii}) \\\\ &= \\sigma^2[N - \\text{trace}(\\textbf{H})] \\end{align}\\] \u8fd9\u91cc\u518d\u5229\u7528\u516c\u5f0f\uff1a \\[\\text{trace}(ABC) = \\text{trace}(CAB)\\] \u5f97\u5230\uff1a \\[\\begin{align} E[\\sum_{i=1}^N(y_i - \\hat{y_i})^2] &= \\sigma^2[N - \\text{trace}(\\textbf{H})] \\\\ &= \\sigma^2[N - \\text{trace}(\\textbf{X}(\\textbf{X}^T \\textbf{X})^{-1} \\textbf{X}^T)] \\\\ &= \\sigma^2[N - \\text{trace}(\\textbf{X}^T \\textbf{X}(\\textbf{X}^T \\textbf{X})^{-1}_{(p+1) \\times (p+1)})] \\\\ &= \\sigma^2[N - \\text{trace}(\\textbf{I}_{(p+1) \\times (p+1)})] \\\\ &= \\sigma^2(N - p -1) \\end{align}\\] \u56e0\u6b64\uff0c\u5bf9 \\(\\sigma^2\\) \u7684\u65e0\u504f\u4f30\u8ba1\u5c31\u662f\uff1a \\[\\hat{\\sigma}^2 = \\frac{1}{N-p-1} \\sum_{i=1}^{N} (y_i-\\hat{y})^2\\] \u6a21\u578b\u8bef\u5dee\u7684\u7edf\u8ba1\u7279\u6027 \u7531\u4e8e\u6211\u4eec\u5bf9\u7b2c i \u4e2a\u6837\u672c\u7684\u566a\u58f0 \\(\\varepsilon_i\\) \u65e0\u504f\u4f30\u8ba1\u5c31\u662f \\(\\hat{\\varepsilon_i} = y_i - \\hat{y_i}\\) \uff0c\u6211\u4eec\u8ba1\u7b97\u5176\u65b9\u5dee\uff1a \\[\\begin{align} \\text{Var}(\\hat{\\varepsilon}) &= \\text{Var}(\\textbf{y} - \\hat{\\textbf{y}}) \\\\ &= \\text{Var}[(\\textbf{I} - \\textbf{H}){\\varepsilon}] \\end{align}\\] \u7531\u4e8e \\(D(AX) = AD(X)A^T\\) \uff1a \\[\\begin{align} \\text{Var}(\\hat{\\varepsilon}) &= \\text{Var}[(\\textbf{I} - \\textbf{H}){\\varepsilon}] \\\\ &= (\\textbf{I} - \\textbf{H}) \\text{Var}(\\varepsilon) (\\textbf{I} - \\textbf{H}) \\end{align}\\] \u7531\u4e8e \\(\\varepsilon \\sim N(0, \\sigma^2)\\) \uff0c\u56e0\u6b64\uff1a \\[\\text{Var}(\\varepsilon) = \\sigma^2 \\textbf{I}_{N \\times N}\\] \u800c \\(\\textbf{H} = \\textbf{X}(\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\) \u6ee1\u8db3\u5bf9\u79f0\u6027\u548c\u5e42\u7b49\u6027\uff1a \\[\\textbf{H}^T = \\textbf{H}\\] \\[\\textbf{H}^T\\textbf{H} = \\textbf{H}\\] \u56e0\u6b64\u6709\u7ed3\u8bba\uff1a \\[\\text{Var}(\\hat{\\varepsilon}) = \\sigma^2 (\\textbf{I} - \\textbf{X}(\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T)\\] \u663e\u8457\u6027\u5206\u6790 \u5f53\u6211\u4eec\u5224\u65ad\u54ea\u4e9b\u53c2\u6570\u53ef\u4ee5\u5ffd\u7565\u4ee5\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 F-statistic \u8fdb\u884c\u663e\u8457\u6027\u5206\u6790\u3002\u5047\u8bbe\u6211\u4eec\u5c06 \\(\\beta\\) \u7ef4\u5ea6\u4ece \\(p_1 + 1\\) \u964d\u4f4e\u5230 \\(p_0 + 1\\) \uff1a \\[ F = \\frac{(\\text{RSS}_0 - \\text{RSS}_1) / (p_1 - p_0)}{\\text{RSS}_1 / (N- p_1 -1)} \\] F-statistic \u63cf\u8ff0\u4e86\u6bcf\u4e2a\u88ab\u5ffd\u7565\u7684\u53c2\u6570\u5bf9 RSS \u7684\u5e73\u5747\u8d21\u732e\uff0c\u7528 \\(\\hat{\\sigma}^2\\) \u8fdb\u884c\u4e86 normalize\u3002 \u5f53 \\(p_1 - p_0 =1\\) \u5373\u4ec5\u53bb\u6389\u4e00\u4e2a\u53c2\u6570\u65f6\uff08\u5047\u8bbe \\(\\beta_j = 0\\) \uff09\uff0c\u8be5\u516c\u5f0f\u53ef\u4ee5\u7b80\u5316\u4e3a\u5bf9\u5e94\u7684 z-score \u7684\u5e73\u65b9\uff0c\u5176\u4e2d z-score \u4e3a\uff1a \\[ z_j = \\frac{\\hat{\\beta}_j}{\\hat{\\sigma} \\sqrt{v_j} }\\] where: \\[\\hat{\\sigma}^2 =\\frac{\\text{RSS}_1}{N-p-1} =\\frac{1}{N-p-1} \\sum_{i=1}^{N} (y_i-\\hat{y})^2\\] \\[v_j = (\\textbf{X}^T\\textbf{X})^{-1}_{jj}\\] \u8bc1\u660e \u8fd9\u4e2a\u8bc1\u660e\u540c\u65f6\u4e5f\u662f\u4e60\u9898 3.1 Ex. 3.1 Show that the F statistic (3.13) for dropping a single coefficient from a model is equal to the square of the corresponding z-score (3.12). \u5b9e\u9645\u4e0a\u6211\u4eec\u9700\u8981\u8bc1\u660e\uff0c\u5728\u53bb\u6389\u6a21\u578b\u7684\u7b2c j \u4e2a\u53c2\u6570\u540e\uff1a \\[ \\text{RSS}_0 - \\text{RSS}_1 = \\frac{\\hat{\\beta}_j^2}{v_j} \\] \u4e0a\u5f0f\u4e2d\u552f\u4e00\u672a\u77e5\u7684\u5c31\u662f \\(\\text{RSS}_0\\) \uff0c\u5b83\u5b9e\u8d28\u4e0a\u662f\u6c42\u4e00\u4e2a\u5e26\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898\uff1a \\[\\begin{align} \\min_{\\beta \\in \\mathbb{R}^{(p+1) \\times 1}} (\\textbf{y} - \\textbf{X}\\beta)^T(\\textbf{y}-\\textbf{X}\\beta) \\\\ \\text{s.t.} ~\\beta_j = 0 \\end{align}\\] \u6211\u4eec\u53ef\u4ee5\u7528\u62c9\u683c\u6717\u65e5\u4e58\u5b50\u6cd5\u6765\u89e3\u51b3\u3002 \\[L(\\beta, \\lambda) = (\\textbf{y} - \\textbf{X}\\beta)^T(\\textbf{y}-\\textbf{X}\\beta) + \\lambda e_j^T \\beta \\] \u5bf9 \\(\\beta\\) \u6c42\u5bfc\uff0c\u5e76\u4ee4\u5bfc\u6570\u4e3a 0\uff0c\u6709\uff1a \\[\\frac{\\partial L(\\beta, \\lambda)}{\\partial \\beta} = - 2\\textbf{X}^T(\\textbf{y} - \\textbf{X}\\beta) + \\lambda e_j = 0\\] \u89e3\u51fa\uff1a \\[\\begin{align} \\beta_0 &= (\\textbf{X}^T\\textbf{X})^{-1} \\textbf{X}^T\\textbf{y} - \\frac{\\lambda}{2}(\\textbf{X}^T \\textbf{X})^{-1} e_j \\\\ &= \\hat{\\beta}- \\frac{\\lambda}{2}(\\textbf{X}^T \\textbf{X})^{-1} e_j \\end{align}\\] \u7b49\u5f0f\u4e24\u8fb9\u4e58\u4ee5 \\(e_j^T\\) \uff0c\u5e76\u5e26\u5165 \\(\\beta_j = 0\\) \uff0c\u6709\uff1a \\[\\begin{align} e_j^T\\beta_0 = 0 &= e_j^T \\hat{\\beta} + \\frac{\\lambda}{2} e_j^T(\\textbf{X}^T \\textbf{X})^{-1} e_j \\\\ &= \\hat{\\beta}_j + \\frac{\\lambda}{2}v_j \\end{align}\\] \u56e0\u6b64\u6709\uff1a \\[\\lambda = - \\frac{2\\hat{\\beta}_j}{v_j}\\] \u5e26\u5165\u53ef\u5f97\uff1a \\[\\begin{align} \\text{RSS}_0 &= (\\textbf{y} - \\textbf{X}\\beta_0)^T(\\textbf{y}-\\textbf{X}\\beta_0) \\\\ &= (\\textbf{y} - \\textbf{X}\\hat{\\beta} + \\frac{\\lambda}{2}\\textbf{X}(\\textbf{X}^T \\textbf{X})^{-1} e_j)^T(\\textbf{y}-\\textbf{X}\\hat{\\beta} + \\frac{\\lambda}{2}\\textbf{X}(\\textbf{X}^T \\textbf{X})^{-1} e_j) \\\\ &= \\text{RSS}_1 + \\frac{\\lambda}{2} [e_j^T(\\textbf{X}^T \\textbf{X})^{-1}\\textbf{X}^T(\\textbf{y} - \\textbf{X}\\hat{\\beta}) + (\\textbf{y} - \\textbf{X}\\hat{\\beta})^T \\textbf{X}(\\textbf{X}^T \\textbf{X})^{-1} e_j)] \\\\ &~~~~ + \\frac{\\lambda^2}{4}e_j^T (\\textbf{X}^T \\textbf{X})^{-1} e_j \\\\ &= \\text{RSS}_1 + \\frac{\\lambda^2}{4}e_j^T (\\textbf{X}^T \\textbf{X})^{-1} e_j \\\\ &= \\text{RSS}_1 + \\frac{\\hat{\\beta}_j^2}{v_j} \\end{align}\\] \u5176\u4e2d\uff0c\u4e2d\u95f4\u9879\u53ef\u4ee5\u6d88\u53bb\u7684\u539f\u56e0\u662f\uff1a \\[\\textbf{X}^T(\\textbf{y} - \\textbf{X}\\hat{\\beta}) = \\textbf{X}^T[\\textbf{y} - \\textbf{X}(\\textbf{X}^T \\textbf{X})^{-1}\\textbf{X}^T\\textbf{y}] = 0 \\] \u76f4\u89c2\u7406\u89e3\uff0c \\(\\textbf{X}\\) \u548c \\(\\textbf{y} - \\textbf{X}\\hat{\\beta}\\) \u662f\u6b63\u4ea4\u7684\uff0c\u56e0\u4e3a \\(\\textbf{X}\\hat{\\beta}\\) \u6b63\u662f \\(\\textbf{y}\\) \u5728 \\(\\textbf{X}\\) \u6240\u5728\u5e73\u9762\u4e0a\u7684\u6295\u5f71\u3002 3.2.2 The Gauss\u2013Markov Theorem \u6700\u5c0f\u4e8c\u4e58\u6cd5\u5f97\u51fa\u7684 \\(\\beta\\) \u5728\u6240\u6709\u7ebf\u6027 \u65e0\u504f \u4f30\u8ba1\u4e2d\u5747\u65b9\u8bef\u5dee\u6700\u5c0f\u3002\u5f53\u7136\uff0c\u5982\u679c\u6211\u4eec\u613f\u610f\u4e3a\u4e86\u8fdb\u4e00\u6b65\u51cf\u5c0f\u8bef\u5dee\u5f15\u5165\u4e00\u70b9 bias\uff0c\u5b8c\u5168\u53ef\u80fd\u627e\u5230\u4e00\u4e2a\u66f4\u5c0f\u5747\u65b9\u8bef\u5dee\u7684 \u6709\u504f \u4f30\u8ba1\u3002 the least squares estimates of the parameters \u03b2 have the smallest variance among all linear unbiased estimates \u73b0\u5728\u6211\u4eec\u6765\u8bc1\u660e\u8fd9\u4e2a\u7ed3\u8bba\u3002\u5bf9\u4e8e\u7ebf\u6027\u4f30\u8ba1\uff1a \\[\\textbf{y} = \\textbf{X}\\beta\\] \\(\\textbf{y}\\) \u4e2d\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\u90fd\u53ef\u4ee5\u770b\u4f5c \\(\\textbf{X}\\) \u4e2d\u7684\u4e00\u884c\u4e0e\u5411\u91cf \\(\\beta\\) \u7684\u7ebf\u6027\u7ec4\u5408\u3002 \u65e0\u504f\u6027 \u90a3\u4e48\uff0c\u9488\u5bf9\u65e0\u504f\u6027\uff0c\u6211\u4eec\u9700\u8981\u8bc1\u660e\u6700\u5c0f\u4e8c\u4e58\u6cd5\u4f30\u8ba1\u51fa\u7684 \\(\\hat{\\beta}\\) \u6ee1\u8db3\uff1a \\[ E(\\alpha^T \\hat{\\beta}) = \\alpha^T\\beta\\] \u5176\u4e2d \\(\\alpha\\) \u662f\u4efb\u610f\u5411\u91cf\u3002 \\[\\begin{align} E(\\alpha^T \\hat{\\beta}) &= E(\\alpha^T (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\textbf{y}) \\\\ &= E(\\alpha^T (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\textbf{X} \\beta) \\\\ &= \\alpha^T \\beta \\end{align} \\] \u5747\u65b9\u8bef\u5dee\u6700\u5c0f Gauss\u2013Markov theorem \u6307\u51fa\uff0c\u5982\u679c\u8fd8\u5b58\u5728\u5176\u4ed6\u7ebf\u6027\u4f30\u8ba1 \\(c^T \\textbf{y}\\) \u6ee1\u8db3\uff1a \\[ E(c^T \\textbf{y}) = \\alpha^T\\beta\\] \u90a3\u4e48\u5fc5\u7136\u6709\uff1a \\[\\text{Var}(\\alpha^T \\hat{\\beta}) \\leq \\text{Var}(c^T \\textbf{y})\\] \u8bc1\u660e\uff1a TBD 3.3 Subset Selection \u6700\u5c0f\u4e8c\u4e58\u6cd5\u7684\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a \u9884\u6d4b\u7cbe\u5ea6\u3002\u867d\u7136\u5b83\u662f\u65e0\u504f\u7684\uff0c\u4f46\u662f\u65b9\u5dee\u5f88\u5927\u3002\u5982\u679c\u6211\u4eec\u5ffd\u7565\u4e00\u90e8\u5206\u6a21\u578b\u53c2\u6570\uff0c\u867d\u7136\u4f1a\u53d8\u6210\u6709\u504f\u4f30\u8ba1\uff0c\u4f46\u662f\u53ef\u80fd\u4f1a\u6781\u5927\u63d0\u9ad8\u7cbe\u5ea6\u3002 \u53ef\u89e3\u91ca\u6027\uff08\u5373\u6a21\u578b\u590d\u6742\u5ea6\uff09\u3002\u5f53\u6a21\u578b\u53c2\u6570\u5f88\u591a\u65f6\uff0c\u6211\u4eec\u60f3\u53bb\u786e\u5b9a\u4e00\u5c0f\u90e8\u5206\u5177\u6709\u6700\u5927\u5f71\u54cd\u7684\u6a21\u578b\u53c2\u6570\uff0c\u4e3a\u6b64\u6211\u4eec\u613f\u610f\u727a\u7272\u4e00\u90e8\u5206\u65e0\u5173\u7d27\u8981\u7684\u53c2\u6570\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u9009\u53d6\u53d8\u91cf\u5b50\u96c6\uff0c\u5373\u201cmodel selection\u201d\u3002 3.3.1 Best-Subset Selection \u6700\u4f73\u5b50\u96c6\u662f\u6307\u4ece\u6240\u6709\u5177\u6709 \\(k (k <= p)\\) \u4e2a\u53d8\u91cf\u7684\u5b50\u96c6\u4e2d\uff0cRSS \u6700\u5c0f\u7684\u90a3\u4e2a\u3002 \u5f53\u7136\uff0c\u6700\u7b80\u5355\u7684\u65b9\u5f0f\u5c31\u662f\u4ece\u904d\u5386\u6240\u6709\u7684\u7ec4\u5408\u3002\u8fd9\u6837\u505a\u7684\u590d\u6742\u5ea6\u662f \\(2^p\\) \uff0c\u53ea\u9002\u7528\u4e8e\u5c0f\u89c4\u6a21\u7684\u95ee\u9898\u3002 3.3.2 Forward- and Backward-Stepwise Selection \u201c\u524d\u5411\u9010\u6b65\u9009\u62e9\u201d\u662f\u4e00\u79cd\u8d2a\u5fc3\u7b97\u6cd5\u3002\u5b83\u6309\u987a\u5e8f\u52a0\u5165\u6700\u80fd\u63d0\u9ad8\u62df\u5408\u5ea6\u7684\u53c2\u6570\u3002\u5b83\u867d\u7136\u4e0d\u4e00\u5b9a\u627e\u5230\u6700\u4f18\u89e3\uff0c\u4f46\u662f\u5b83\u4f18\u52bf\u5728\u4e8e\uff1a \u8fd0\u7b97\u91cf\u5c0f\u3002\u5f53\u7ef4\u5ea6 \\(p >= 40\\) \u65f6\uff0c\u51e0\u4e4e\u65e0\u6cd5\u7b97\u51fa\u6700\u4f18\u89e3\u3002\u4f46\u662f\u4f9d\u65e7\u53ef\u4ee5\u7528 forward stepwise selection \uff08\u5373\u4f7f\u7ef4\u5ea6 p \u5927\u4e8e\u6837\u672c\u6570 N\uff09\u3002 \u65b9\u5dee\u5c0f\u3002\u6700\u4f18\u5b50\u96c6\u65b9\u5dee\u6bd4 forward stepwise selection \u5927\uff0c\u867d\u7136\u540e\u8005\u53ef\u80fd\u4f1a\u6709\u4e00\u5b9a\u7684 bias\u3002 \u90a3\u4e48\u5982\u4f55\u9009\u62e9\u201c\u6700\u80fd\u63d0\u9ad8\u62df\u5408\u5ea6\u201c\u7684\u53c2\u6570\u5462\uff1f\u6211\u4eec\u5728\u4e4b\u524d\u201c\u663e\u8457\u6027\u5206\u6790\u201d\u4e2d\u5df2\u7ecf\u8bc1\u660e\u4e86\uff0c\u53bb\u6389\u4e00\u4e2a\u53c2\u6570\u5bf9\u6b8b\u5dee\u7684\u5f71\u54cd\u4e3a\u5176 z-score \u7684\u5e73\u65b9\u3002\u90a3\u4e48\uff0c\u6211\u4eec\u76f4\u63a5 \u4ece z-score \u6700\u5927\u7684\u53c2\u6570\u5f00\u59cb\u4f9d\u6b21\u52a0\u5165 \u5373\u53ef\u3002\u7b2c \\(j\\) \u4e2a\u53c2\u6570\u7684 z-score \u53ef\u4ee5\u7531\u4e8e\u4e0b\u5f0f\u8ba1\u7b97\uff1a \\[ z_j = \\frac{\\hat{\\beta}_j}{\\hat{\\sigma} \\sqrt{v_j} }\\] where: \\[\\hat{\\sigma}^2 =\\frac{\\text{RSS}_1}{N-p-1} =\\frac{1}{N-p-1} \\sum_{i=1}^{N} (y_i-\\hat{y})^2\\] \\[v_j = (\\textbf{X}^T\\textbf{X})^{-1}_{jj}\\] \u201c\u540e\u5411\u9010\u6b65\u9009\u62e9\u201d \u4e0e \u201c\u524d\u5411\u9010\u6b65\u9009\u62e9\u201c\u76f8\u53cd\u3002\u5b83\u4ece\u5168\u96c6\u5f00\u59cb\uff0c\u4f9d\u6b21\u53bb\u6389\u6700\u65e0\u5173\u7d27\u8981\u7684\u53d8\u91cf\uff08z-score \u6700\u5c0f\u7684\uff09\u3002\u5b83\u53ea\u80fd\u7528\u4e8e\u6837\u672c\u6570 N \u5927\u4e8e\u7ef4\u5ea6 p \u7684\u60c5\u5f62\u3002 3.4 Shrinkage Methods Subset selection \u786e\u5b9e\u53ef\u4ee5\u5e2e\u6211\u4eec\u7b80\u5316\u6a21\u578b\uff0c\u5e76\u4e14\u8fd8\u53ef\u80fd\u964d\u4f4e\u8bef\u5dee\u3002\u4f46\u662f\uff0c\u56e0\u4e3a\u5b83\u662f\u4e00\u4e2a\u79bb\u6563\u7684\u8fc7\u7a0b\uff08\u53c2\u6570\u8981\u4e48\u88ab\u4e22\u5f03\u8981\u4e48\u88ab\u4fdd\u7559\uff0c\u6ca1\u6709\u4e2d\u95f4\u72b6\u6001\uff09\uff0c\u5b83\u901a\u5e38\u5177\u6709\u8f83\u5927\u7684\u65b9\u5dee\u3002Shrinkage methods \u66f4\u52a0\u8fde\u7eed\uff0c\u56e0\u6b64\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002 3.4.1 Ridge Regression Ridge Regression \u901a\u8fc7\u7ed9\u53c2\u6570\u6570\u91cf\u589e\u52a0\u4e00\u4e2a\u60e9\u7f5a\u9879\u6765\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\u3002\u5b83\u7684\u4f18\u5316\u76ee\u6807\uff1a \\[\\hat{\\beta} = \\mathop{\\arg \\min}_{\\beta} \\sum_{i=1}^N(y_i - \\beta_0 - \\sum_{j=1}^p x_{ij}\\beta_j)^2 + \\lambda \\sum_{j=1}^p \\beta_j^2\\] \u8fd9\u91cc\u7684 \\(\\lambda\\) \u63a7\u5236\u6a21\u578b\u201c\u7f29\u5c0f\u201d\u7684\u7a0b\u5ea6\uff0c \\(\\lambda\\) \u8d8a\u5927\uff0c\u5f97\u5230\u7684\u6a21\u578b\u590d\u6742\u5ea6\u8d8a\u4f4e\u3002 \u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c \u60e9\u7f5a\u9879\u4e2d\u4e0d\u5305\u542b\u5e38\u6570\u9879 \\(\\beta_0\\) \uff0c\u5426\u5219\u6a21\u578b\u4e0d\u7a33\u5b9a\u3002\u5f53\u9009\u53d6 \\(y_i = y_i + c\\) \u65f6\uff0c\u9884\u6d4b\u503c \\(\\hat{y}_i\\) \u7684\u53d8\u5316\u91cf\u4e0d\u662f \\(c\\) \u3002 \u4e0e\u7ecf\u5178\u7684 Linear Regression \u4e0d\u540c\uff0cRidge Regression \u8981\u6c42\u8f93\u5165 \\(\\textbf{X}, \\textbf{y}\\) \u662f\u7ecf\u8fc7\u4e86 \u4e2d\u5fc3\u5316 (centering) \u7684\u3002\u5e76\u4e14\uff0c\u8fd9\u91cc\u7684\u6a21\u578b\u53c2\u6570 \\(\\beta\\) \u662f \\(p\\) \u7ef4\u800c\u4e0d\u662f \\(p+1\\) \u7ef4\u7684\u3002 \u4e0b\u9762\u6211\u4eec\u6765\u8bc1\u660e\u8fd9\u4e00\u70b9\u3002 \\(\\beta_0\\) \u7531\u4e8e\u4e0d\u542b \\(\\lambda\\) \uff0c\u53ef\u4ee5\u5355\u72ec\u4f18\u5316\u3002\u6211\u4eec\u5148\u5bf9 \\(\\beta_0\\) \u6c42\u5bfc\uff0c\u5e76\u4ee4\u5bfc\u6570\u4e3a0: \\[\\sum_{i=1}^N(y_i - \\beta_0 - \\sum_{j=1}^p x_{ij}\\beta_j) = 0\\] \u5f97\u5230\uff1a \\[\\beta_0 = \\frac{1}{N}(\\sum_{i=1}^N y_i - \\sum_{i=1}^N \\sum_{j=1}^{p} x_{ij}\\beta_j) \\] \u4ee4 \\(\\overline{x_j} = \\frac{1}{N} \\sum_{i=1}^N x_{ij}\\) \uff0c\u6709\uff1a \\[\\beta_0 = \\frac{1}{N}\\sum_{i=1}^N y_i - \\sum_{j=1}^{p} \\overline{x_{j}} \\beta_j \\] \u6211\u4eec\u4ee5\u4e0b\u7684\u53d8\u5f62\u4e3b\u8981\u662f\u4e3a\u4e86\u5c06\u4f18\u5316\u76ee\u6807\u51fd\u6570\u5199\u6210\u77e9\u9635\u4e58\u6cd5\u5f62\u5f0f\uff0c\u4ee5\u8fdb\u884c\u8fd0\u7b97\u3002 \\[\\begin{align} \\hat{\\beta} &= \\mathop{\\arg \\min}_{\\beta} \\sum_{i=1}^N(y_i - \\beta_0 - \\sum_{j=1}^p x_{ij}\\beta_j)^2 + \\lambda \\sum_{j=1}^p \\beta_j^2 \\\\ &= \\mathop{\\arg \\min}_{\\beta} \\sum_{i=1}^N(y_i - \\beta_0 - \\sum_{j=1}^p \\overline{x_j}\\beta_j - \\sum_{j=1}^p (x_{ij} - \\overline{x_j}) \\beta_j)^2 + \\lambda \\sum_{j=1}^p \\beta_j^2 \\end{align}\\] \u73b0\u5728\u6211\u4eec\u4ee4\uff1a \\[\\begin{align} \\beta_0^c &= \\beta_0 + \\sum_{j=1}^p \\overline{x_j}\\beta_j =\\frac{1}{N} \\sum_{i=1}^N y_{i} \\\\ \\beta_j^c&= \\beta_j & (j>=1) \\end{align}\\] \u53ef\u4ee5\u5f97\u51fa\uff1a \\[\\begin{align} \\hat{\\beta} &= \\mathop{\\arg \\min}_{\\beta^c} \\sum_{i=1}^N(y_i - \\beta_0^c - \\sum_{j=1}^p (x_{ij} - \\overline{x_j}) \\beta_j^c)^2 + \\lambda \\sum_{j=1}^p {\\beta_j^c}^2 \\end{align}\\] \u6211\u4eec\u518d\u4ee4\uff1a \\[\\begin{align} y_i^c &= y_i - \\beta_0^c = y_i - \\frac{1}{N} \\sum_{i=1}^N y_i \\\\ x_{ij}^c&= x_{ij} - \\overline{x_j} & (j >=1) \\end{align}\\] \u6709\uff1a \\[\\begin{align} \\hat{\\beta} &= \\mathop{\\arg \\min}_{\\beta^c} \\sum_{i=1}^N(y_i^c - \\sum_{j=1}^p (x_{ij}^c \\beta_j^c)^2) + \\lambda \\sum_{j=1}^p {\\beta_j^c}^2 \\\\ &=\\mathop{\\arg \\min}_{\\beta} (\\textbf{y} - \\textbf{X}\\beta)^T(\\textbf{y} - \\textbf{X}\\beta) + \\lambda(\\beta^T\\beta) \\end{align}\\] \u5176\u4e2d\uff0c \\(\\textbf{X}, \\textbf{y}, \\beta\\) \u90fd\u7ecf\u8fc7\u4e86\u4e2d\u5fc3\u5316\uff0c\u5e76\u4e14\u662f \\(p\\) \u7ef4\u7684\u3002 \u8be5\u5f0f\u5bf9 \\(\\beta\\) \u6c42\u5bfc\u5e76\u4ee4\u5bfc\u6570\u4e3a 0\uff0c\u6709\uff1a \\[ -\\textbf{X}^T(\\textbf{y} - \\textbf{X}\\beta) + \\lambda \\beta = 0\\] \u89e3\u5f97\uff1a \\[ \\beta = (\\textbf{X}^T\\textbf{X} + \\lambda \\textbf{I})^{-1} \\textbf{X}^T \\textbf{y}\\] \u6211\u4eec\u770b\u5230\uff0c\u5373\u4f7f \\(\\textbf{X}^T\\textbf{X}\\) \u662f\u975e\u6ee1\u79e9\u7684\uff0c\u7531\u4e8e\u591a\u52a0\u4e86\u4e00\u4e2a \\(\\lambda \\textbf{I}\\) \uff0c\u5b83\u4ecd\u662f\u4e00\u4e2a\u53ef\u9006\u77e9\u9635\u3002\u8fd9\u4e5f\u662f ridge regression \u7684\u53e6\u4e00\u4e2a\u4f18\u52bf\u3002 Ridge Regression and SVD \u5947\u5f02\u503c\u5206\u89e3 (singular value decomposition, SVD) \u5c06\u4e00\u4e2a\u77e9\u9635\u5206\u89e3\u4e3a\u4e09\u4e2a\u77e9\u9635\u7684\u4e58\u79ef\uff1a \\[ \\textbf{X}_{N \\times p} = \\textbf{U}_{N \\times N} \\mathbf{\\Sigma}_{N \\times p} \\textbf{V}^T_{p \\times p} \\] \u5176\u4e2d\uff1a \\(\\textbf{U}_{N \\times N}\\) \u662f\u4e00\u4e2a\u5355\u4f4d\u6b63\u4ea4\u77e9\u9635\uff0c\u5728 \\(\\mathbb{R}^{N \\times N}\\) \u7a7a\u95f4\u3002\u5b83\u4ee3\u8868\u4e86\u65cb\u8f6c(rotation) \\(\\mathbf{\\Sigma}_{N \\times p}\\) \u662f\u4e00\u4e2a\u5bf9\u89d2\u77e9\u9635\uff0c\u4f46\u662f\u4e0d\u4e00\u5b9a\u662f\u65b9\u9635\u3002\u5b83\u4ee3\u8868\u62c9\u4f38(scaling) \\(\\textbf{V}^T_{p \\times p}\\) \u662f\u4e00\u4e2a\u5355\u4f4d\u6b63\u4ea4\u77e9\u9635\uff0c\u5728 \\(\\mathbb{R}^{p \\times p}\\) \u7a7a\u95f4\u3002\u5b83\u4ee3\u8868\u65cb\u8f6c(rotation) \u5bf9\u4e8e\u666e\u901a\u7684\u7ebf\u6027\u56de\u5f52\uff0c\u6709\uff1a \\[\\begin{align} \\hat{y} = \\textbf{H}y &= \\textbf{X}(\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^Ty \\\\ &= \\textbf{U}\\mathbf{\\Sigma}\\textbf{V}^T(\\textbf{V}\\mathbf{\\Sigma}^T\\mathbf{\\Sigma}\\textbf{V}^T)^{-1} \\textbf{V}\\mathbf{\\Sigma}^T\\textbf{U}^T y \\\\ &= \\textbf{U}\\mathbf{\\Sigma} (\\mathbf{\\Sigma}^T\\mathbf{\\Sigma})^{-1} \\mathbf{\\Sigma}^T\\textbf{U}^T y \\\\ &= \\textbf{U}\\textbf{U}^T y \\end{align}\\] \u800c\u5bf9\u4e8e ridge regression\uff0c\u6709\uff1a \\[\\begin{align} \\hat{y} &= \\textbf{X}(\\textbf{X}^T\\textbf{X} + \\lambda \\textbf{I})^{-1} \\textbf{X}^T \\textbf{y} \\\\ &= \\textbf{U}\\mathbf{\\Sigma}(\\mathbf{\\Sigma}^T\\mathbf{\\Sigma} + \\lambda \\textbf{I})^{-1} \\mathbf{\\Sigma}^T\\textbf{U}^T y \\end{align}\\] \u5047\u8bbe SVD \u5206\u89e3\u7684\u5947\u5f02\u503c\u4e3a \\(\\sigma_1, \\sigma_2, ... , \\sigma_p\\) \uff0c\u6211\u4eec\u6709\uff1a \\[\\begin{align} \\hat{y} &= \\textbf{U}\\mathbf{\\Sigma}(\\mathbf{\\Sigma}^T\\mathbf{\\Sigma} + \\lambda \\textbf{I})^{-1} \\mathbf{\\Sigma}^T\\textbf{U}^T y \\\\ &= \\sum_{j=1}^p \\textbf{u}_j \\frac{\\sigma_j^2}{\\sigma_j^2 + \\lambda} \\textbf{u}_j^T \\textbf{y} \\end{align}\\] \u5176\u4e2d \\(\\textbf{u}_j\\) \u8868\u793a\u77e9\u9635 \\(\\textbf{U}\\) \u7684\u7b2c \\(j\\) \u5217\u3002 \u56e0\u6b64\uff0c\u4ece\u76f4\u89c2\u610f\u4e49\u4e0a\u7406\u89e3\uff0cridge regression \u76f8\u6bd4\u666e\u901a\u7684 regression \u5c31\u662f\u5bf9 \\(\\textbf{U}\\) \u7684\u6bcf\u4e00\u5217\u9644\u52a0\u4e86\u4e00\u4e2a\u7cfb\u6570 \\(\\frac{\\sigma_j^2}{\\sigma_j^2 + \\lambda} \\leq 1\\) \u3002\u8fd9\u4e2a\u7cfb\u6570\u4e0e\u8be5\u5217\u5bf9\u5e94\u7684\u5947\u5f02\u503c\u76f8\u5173\u3002\u800c\u6211\u4eec\u5728 SVD \u5b9a\u4e49\u4e2d\u77e5\u9053 \\(\\sigma_j\\) \u4ee3\u8868\u4e86\u5728 \\(\\textbf{u}_j\\) \u65b9\u5411\u7684\u7f29\u653e\u7cfb\u6570\u3002\u663e\u7136\uff0c \\(\\frac{\\sigma_j^2}{\\sigma_j^2 + \\lambda}\\) \u5728 \\(\\sigma_j\\) \u8d8a\u5c0f\u65f6\uff0cshrinkage \u8d8a\u5927\u3002\u56e0\u6b64\uff0c\u76f4\u89c2\u7406\u89e3\uff0cridge regression \u4f1a\u503e\u5411\u4e8e\u5ffd\u7565\u8f93\u5165 \\(\\textbf{X}\\) \u65b9\u5dee\u8f83\u5c0f\u7684\u65b9\u5411\u3002 the small singular values correspond to directions in the column space of X having small variance, and ridge regression shrinks these directions the most. \u8fd9\u662f\u4e2a\u6bd4\u8f83\u5408\u7406\u7684\u5047\u8bbe\uff0c\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u5bf9\u4e8e\u6837\u672c\u4e2d\u51e0\u4e4e\u4e00\u6837\u7684\u8f93\u5165\u53c2\u6570\u5e76\u4e0d\u662f\u5f88\u5173\u5fc3. Reference ESL solution ESL Chinese Simple Linear Regression Proofs involving ordinary least squares","title":"ESL 3: Linear Methods for Regression"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#esl-3-linear-methods-for-regression","text":"\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u5047\u8bbe\u56de\u5f52\u51fd\u6570 E(Y|X) \u5bf9\u4e8e\u8f93\u5165 X \u662f\u7ebf\u6027\u7684\u3002 \u5b83\u7684\u4f18\u52bf\u5728\u4e8e\uff1a \u7b80\u5355 \u80fd\u591f\u8868\u793a\u6bcf\u4e2a\u8f93\u5165\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd \u8f93\u5165\u53ef\u4ee5\u8fdb\u884c\u53d8\u6362 \u4ed6\u4eec\u6709\u65f6\u5019\u6bd4\u590d\u6742\u7684\u65b9\u6cd5\u66f4\u7cbe\u51c6\uff0c\u5c24\u5176\u662f\u5728\u6837\u672c\u6570\u91cf\u5c11\u3001\u4f4e\u4fe1\u566a\u6bd4\u6216\u8005\u7a00\u758f\u77e9\u9635\u7684\u60c5\u5f62\u3002","title":"ESL 3: Linear Methods for Regression"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#32-linear-regression-models-and-least-squares","text":"\\(p\\) \u7ef4\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u5f62\u5f0f\u5982\u4e0b\uff1a \\[f(X) = \\beta_0 + \\sum_{j=1}^p X_j \\beta_j\\] \u6211\u4eec\u9700\u8981\u4f30\u8ba1\u4e00\u7ec4\u53c2\u6570 \\(\\beta\\) \uff0c\u4f7f\u6b8b\u5dee\u5e73\u65b9\u548c\uff08Residual Sum of Squares\uff09\u6700\u5c0f\uff1a \\[\\begin{align} \\text{RSS}(\\beta) &= (\\textbf{y} - \\textbf{X}\\beta )^T(\\textbf{y} - \\textbf{X}\\beta ) \\\\ &= \\textbf{y}^T\\textbf{y} - \\textbf{y}^T\\textbf{X}\\beta - \\beta^T\\textbf{X}^T\\textbf{y} + \\beta^T\\textbf{X}^T\\textbf{X}\\beta \\end{align}\\] \u5176\u4e2d\uff0c \\(\\textbf{X}\\) \u662f\u4e00\u4e2a \\(N \\times (p+1)\\) \u77e9\u9635\uff0c \\(\\textbf{y}\\) \u662f \\(N \\times 1\\) \u89c2\u6d4b\u503c\u3002 \u5bf9 \\(\\beta\\) \u6c42\u5bfc\u53ef\u4ee5\u5f97\u5230\uff1a \\[ \\frac{\\partial \\text{RSS}(\\beta)}{\\partial \\beta} = -2 \\textbf{X}^T\\textbf{y} + 2\\textbf{X}^T\\textbf{X} \\beta\\] \u7531\u4e8e\u4e8c\u9636\u5bfc\u6570\u6b63\u5b9a\uff0c\u4ee4\u4e00\u9636\u5bfc\u6570\u4e3a 0 \u5411\u91cf\uff0c\u5f97\u51fa\u6781\u503c\u70b9\uff08\u5373\u4f30\u8ba1\u503c\uff09\uff1a \\[ \\hat{\\beta}= (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\textbf{y}\\] \\[\\hat{\\textbf{y}} = \\textbf{X} \\hat{\\beta} = \\textbf{X}(\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\textbf{y}\\] \u6211\u4eec\u79f0 \\(\\textbf{H} = \\textbf{X}(\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\) \u4e3a\u4f30\u8ba1\u77e9\u9635\uff08\"hat\" matrix\uff09\uff0c\u5b83\u6ee1\u8db3\u5bf9\u79f0\u6027\u548c\u5e42\u7b49\u6027\uff1a \\[\\textbf{H}^T = \\textbf{H}\\] \\[\\textbf{H}^T\\textbf{H} = \\textbf{H}\\] \u5f53 \\(\\textbf{X}\\) \u4e2d\u67d0\u4e9b\u5217\u7ebf\u6027\u76f8\u5173\uff08\u5373\u975e\u6ee1\u79e9\u77e9\u9635\uff09\u65f6\uff0c \\((\\textbf{X}^T\\textbf{X})\\) \u662f\u5947\u5f02\u77e9\u9635\uff0c\u5b83\u53ea\u80fd\u6c42\u5e7f\u4e49\u9006\u77e9\u9635\uff0c\u4e0d\u6b62\u4e00\u4e2a\u89e3\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u5c06\u5197\u4f59\u7684\u8f93\u5165\u5254\u9664\u6389\uff0c\u5927\u90e8\u5206\u6c42\u89e3\u8f6f\u4ef6\u90fd\u5b9e\u73b0\u4e86\u8fd9\u4e2a\u529f\u80fd\u3002","title":"3.2 Linear Regression Models and Least Squares"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#_1","text":"\u4e3a\u4e86\u786e\u5b9a\u4f30\u8ba1\u7684\u53c2\u6570 \\(\\hat{\\beta}\\) \u7684\u7edf\u8ba1\u7279\u6027\uff0c\u6211\u4eec\u5047\u8bbe\uff1a \u6bcf\u4e2a\u89c2\u6d4b\u503c \\(y_i\\) \u76f8\u4e92\u72ec\u7acb \\(y_i\\) \u6709\u56fa\u5b9a\u7684\u566a\u58f0 \\(\\varepsilon \\sim N(0, \\sigma^2)\\) \u90a3\u4e48\u4f30\u8ba1\u503c \\(\\hat{\\beta}\\) \u7684\u65b9\u5dee\u4e3a\uff1a \\[ \\text{Var}(\\hat{\\beta}) = (\\textbf{X}^T\\textbf{X})^{-1} \\sigma^2\\] where: \\[\\hat{\\sigma}^2 = \\frac{\\text{RSS}}{N-p-1}= \\frac{1}{N-p-1} \\sum_{i=1}^{N} (y_i-\\hat{y})^2\\]","title":"\u4f30\u8ba1\u53c2\u6570\u7684\u7edf\u8ba1\u7279\u6027"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#_2","text":"N \u4e2a y \u7684\u89c2\u6d4b\u503c\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\[ \\textbf{y} = \\textbf{X}\\beta + \\varepsilon \\] \u5176\u4e2d \\(\\varepsilon\\) \u662f \\(N \\times 1\\) \u7684\u566a\u58f0\u3002\u56e0\u6b64\u6709\uff1a \\[\\begin{align} \\hat{\\beta} &= (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\textbf{y} \\\\ &= \\beta + (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\varepsilon \\end{align}\\] \u65e0\u504f\u6027\uff08\u671f\u671b\u503c\u4e3a \\(\\beta\\) \uff09\uff1a \\[E(\\hat{\\beta}) = \\beta + (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T E(\\varepsilon) = \\beta\\] \u534f\u65b9\u5dee\u77e9\u9635\uff08\u6ce8\u610f\u662f \\(\\beta \\beta^T\\) \u800c\u975e \\(\\beta^T \\beta\\) \uff0c\u662f\u4e00\u4e2a\u77e9\u9635\uff09\uff1a \\[\\begin{align} \\text{Var}(\\hat{\\beta}) &= E[(\\beta - \\hat{\\beta})(\\beta - \\hat{\\beta})^T] \\\\ &=E[(\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\varepsilon\\varepsilon^T\\textbf{X}(\\textbf{X}^T\\textbf{X})^{-1}] \\\\ &= (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T E(\\varepsilon\\varepsilon^T) \\textbf{X}(\\textbf{X}^T\\textbf{X})^{-1} \\\\ &= \\sigma^2 (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T \\textbf{I} \\textbf{X}(\\textbf{X}^T\\textbf{X})^{-1} \\\\ &= \\sigma^2 (\\textbf{X}^T\\textbf{X})^{-1} \\end{align}\\] \u53ef\u4ee5\u5f97\u5230\uff1a \\[ \\hat{\\beta} \\sim N(\\beta, \\sigma^2 (\\textbf{X}^T\\textbf{X})^{-1})\\] \u4e0b\u9762\u6765\u786e\u5b9a \\(\\sigma^2\\) \u3002 \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u89c2\u6d4b\u503c \\(y\\) \u548c\u9884\u6d4b\u503c \\(\\hat{y}\\) \u7684\u5dee\u6765\u5f97\u5230\u566a\u58f0 \\(\\varepsilon\\) \u3002 \\[\\begin{align} y - \\hat{y} &= \\textbf{X}\\beta + \\varepsilon -\\textbf{X}\\hat{\\beta} \\\\ &= \\textbf{X}\\beta + \\varepsilon - \\textbf{X}(\\beta + (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\varepsilon) \\\\ &= (\\textbf{I -H} )\\varepsilon \\end{align}\\] \\[\\begin{align} \\sum_{i=1}^N(y_i - \\hat{y_i})^2 &= (y - \\hat{y})^T (y - \\hat{y}) \\\\ &= \\varepsilon^T(\\textbf{I - H}) \\varepsilon \\\\ &= \\sum_{k =1}^N \\varepsilon_k^2- \\sum_{i, j = 1}^N \\varepsilon_i \\varepsilon_j H_{ij} \\end{align}\\] \u5176\u671f\u671b\u503c\u4e3a\uff1a \\[\\begin{align} E[\\sum_{i=1}^N(y_i - \\hat{y_i})^2] &= E[\\sum_{k =1}^N \\varepsilon_k^2- \\sum_{i, j = 1}^N \\varepsilon_i \\varepsilon_j H_{ij} ] \\\\ &= N\\sigma^2 - E(\\sum_{i, j = 1}^N \\varepsilon_i \\varepsilon_j H_{ij}) \\end{align}\\] \u7531\u4e8e \\(\\varepsilon_i, \\varepsilon_j\\) \u662f\u72ec\u7acb\u7684\uff0c\u5f53 \\(i \\neq j\\) \u65f6\uff1a \\[\\text{Cov}(\\varepsilon_i, \\varepsilon_j) = E(\\varepsilon_i \\varepsilon_j) - E(\\varepsilon_i)E(\\varepsilon_j) = 0\\] \u56e0\u6b64\uff1a \\[\\begin{align} E[\\sum_{i=1}^N(y_i - \\hat{y_i})^2] &= N\\sigma^2 - E(\\sum_{i, j = 1}^N \\varepsilon_i \\varepsilon_j H_{ij}) \\\\ &= N\\sigma^2 - E(\\sum_{i=1}^{N}\\varepsilon_i^2H_{ii}) \\\\ &= \\sigma^2[N - \\text{trace}(\\textbf{H})] \\end{align}\\] \u8fd9\u91cc\u518d\u5229\u7528\u516c\u5f0f\uff1a \\[\\text{trace}(ABC) = \\text{trace}(CAB)\\] \u5f97\u5230\uff1a \\[\\begin{align} E[\\sum_{i=1}^N(y_i - \\hat{y_i})^2] &= \\sigma^2[N - \\text{trace}(\\textbf{H})] \\\\ &= \\sigma^2[N - \\text{trace}(\\textbf{X}(\\textbf{X}^T \\textbf{X})^{-1} \\textbf{X}^T)] \\\\ &= \\sigma^2[N - \\text{trace}(\\textbf{X}^T \\textbf{X}(\\textbf{X}^T \\textbf{X})^{-1}_{(p+1) \\times (p+1)})] \\\\ &= \\sigma^2[N - \\text{trace}(\\textbf{I}_{(p+1) \\times (p+1)})] \\\\ &= \\sigma^2(N - p -1) \\end{align}\\] \u56e0\u6b64\uff0c\u5bf9 \\(\\sigma^2\\) \u7684\u65e0\u504f\u4f30\u8ba1\u5c31\u662f\uff1a \\[\\hat{\\sigma}^2 = \\frac{1}{N-p-1} \\sum_{i=1}^{N} (y_i-\\hat{y})^2\\]","title":"\u8bc1\u660e"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#_3","text":"\u7531\u4e8e\u6211\u4eec\u5bf9\u7b2c i \u4e2a\u6837\u672c\u7684\u566a\u58f0 \\(\\varepsilon_i\\) \u65e0\u504f\u4f30\u8ba1\u5c31\u662f \\(\\hat{\\varepsilon_i} = y_i - \\hat{y_i}\\) \uff0c\u6211\u4eec\u8ba1\u7b97\u5176\u65b9\u5dee\uff1a \\[\\begin{align} \\text{Var}(\\hat{\\varepsilon}) &= \\text{Var}(\\textbf{y} - \\hat{\\textbf{y}}) \\\\ &= \\text{Var}[(\\textbf{I} - \\textbf{H}){\\varepsilon}] \\end{align}\\] \u7531\u4e8e \\(D(AX) = AD(X)A^T\\) \uff1a \\[\\begin{align} \\text{Var}(\\hat{\\varepsilon}) &= \\text{Var}[(\\textbf{I} - \\textbf{H}){\\varepsilon}] \\\\ &= (\\textbf{I} - \\textbf{H}) \\text{Var}(\\varepsilon) (\\textbf{I} - \\textbf{H}) \\end{align}\\] \u7531\u4e8e \\(\\varepsilon \\sim N(0, \\sigma^2)\\) \uff0c\u56e0\u6b64\uff1a \\[\\text{Var}(\\varepsilon) = \\sigma^2 \\textbf{I}_{N \\times N}\\] \u800c \\(\\textbf{H} = \\textbf{X}(\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\) \u6ee1\u8db3\u5bf9\u79f0\u6027\u548c\u5e42\u7b49\u6027\uff1a \\[\\textbf{H}^T = \\textbf{H}\\] \\[\\textbf{H}^T\\textbf{H} = \\textbf{H}\\] \u56e0\u6b64\u6709\u7ed3\u8bba\uff1a \\[\\text{Var}(\\hat{\\varepsilon}) = \\sigma^2 (\\textbf{I} - \\textbf{X}(\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T)\\]","title":"\u6a21\u578b\u8bef\u5dee\u7684\u7edf\u8ba1\u7279\u6027"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#_4","text":"\u5f53\u6211\u4eec\u5224\u65ad\u54ea\u4e9b\u53c2\u6570\u53ef\u4ee5\u5ffd\u7565\u4ee5\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 F-statistic \u8fdb\u884c\u663e\u8457\u6027\u5206\u6790\u3002\u5047\u8bbe\u6211\u4eec\u5c06 \\(\\beta\\) \u7ef4\u5ea6\u4ece \\(p_1 + 1\\) \u964d\u4f4e\u5230 \\(p_0 + 1\\) \uff1a \\[ F = \\frac{(\\text{RSS}_0 - \\text{RSS}_1) / (p_1 - p_0)}{\\text{RSS}_1 / (N- p_1 -1)} \\] F-statistic \u63cf\u8ff0\u4e86\u6bcf\u4e2a\u88ab\u5ffd\u7565\u7684\u53c2\u6570\u5bf9 RSS \u7684\u5e73\u5747\u8d21\u732e\uff0c\u7528 \\(\\hat{\\sigma}^2\\) \u8fdb\u884c\u4e86 normalize\u3002 \u5f53 \\(p_1 - p_0 =1\\) \u5373\u4ec5\u53bb\u6389\u4e00\u4e2a\u53c2\u6570\u65f6\uff08\u5047\u8bbe \\(\\beta_j = 0\\) \uff09\uff0c\u8be5\u516c\u5f0f\u53ef\u4ee5\u7b80\u5316\u4e3a\u5bf9\u5e94\u7684 z-score \u7684\u5e73\u65b9\uff0c\u5176\u4e2d z-score \u4e3a\uff1a \\[ z_j = \\frac{\\hat{\\beta}_j}{\\hat{\\sigma} \\sqrt{v_j} }\\] where: \\[\\hat{\\sigma}^2 =\\frac{\\text{RSS}_1}{N-p-1} =\\frac{1}{N-p-1} \\sum_{i=1}^{N} (y_i-\\hat{y})^2\\] \\[v_j = (\\textbf{X}^T\\textbf{X})^{-1}_{jj}\\]","title":"\u663e\u8457\u6027\u5206\u6790"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#_5","text":"\u8fd9\u4e2a\u8bc1\u660e\u540c\u65f6\u4e5f\u662f\u4e60\u9898 3.1 Ex. 3.1 Show that the F statistic (3.13) for dropping a single coefficient from a model is equal to the square of the corresponding z-score (3.12). \u5b9e\u9645\u4e0a\u6211\u4eec\u9700\u8981\u8bc1\u660e\uff0c\u5728\u53bb\u6389\u6a21\u578b\u7684\u7b2c j \u4e2a\u53c2\u6570\u540e\uff1a \\[ \\text{RSS}_0 - \\text{RSS}_1 = \\frac{\\hat{\\beta}_j^2}{v_j} \\] \u4e0a\u5f0f\u4e2d\u552f\u4e00\u672a\u77e5\u7684\u5c31\u662f \\(\\text{RSS}_0\\) \uff0c\u5b83\u5b9e\u8d28\u4e0a\u662f\u6c42\u4e00\u4e2a\u5e26\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898\uff1a \\[\\begin{align} \\min_{\\beta \\in \\mathbb{R}^{(p+1) \\times 1}} (\\textbf{y} - \\textbf{X}\\beta)^T(\\textbf{y}-\\textbf{X}\\beta) \\\\ \\text{s.t.} ~\\beta_j = 0 \\end{align}\\] \u6211\u4eec\u53ef\u4ee5\u7528\u62c9\u683c\u6717\u65e5\u4e58\u5b50\u6cd5\u6765\u89e3\u51b3\u3002 \\[L(\\beta, \\lambda) = (\\textbf{y} - \\textbf{X}\\beta)^T(\\textbf{y}-\\textbf{X}\\beta) + \\lambda e_j^T \\beta \\] \u5bf9 \\(\\beta\\) \u6c42\u5bfc\uff0c\u5e76\u4ee4\u5bfc\u6570\u4e3a 0\uff0c\u6709\uff1a \\[\\frac{\\partial L(\\beta, \\lambda)}{\\partial \\beta} = - 2\\textbf{X}^T(\\textbf{y} - \\textbf{X}\\beta) + \\lambda e_j = 0\\] \u89e3\u51fa\uff1a \\[\\begin{align} \\beta_0 &= (\\textbf{X}^T\\textbf{X})^{-1} \\textbf{X}^T\\textbf{y} - \\frac{\\lambda}{2}(\\textbf{X}^T \\textbf{X})^{-1} e_j \\\\ &= \\hat{\\beta}- \\frac{\\lambda}{2}(\\textbf{X}^T \\textbf{X})^{-1} e_j \\end{align}\\] \u7b49\u5f0f\u4e24\u8fb9\u4e58\u4ee5 \\(e_j^T\\) \uff0c\u5e76\u5e26\u5165 \\(\\beta_j = 0\\) \uff0c\u6709\uff1a \\[\\begin{align} e_j^T\\beta_0 = 0 &= e_j^T \\hat{\\beta} + \\frac{\\lambda}{2} e_j^T(\\textbf{X}^T \\textbf{X})^{-1} e_j \\\\ &= \\hat{\\beta}_j + \\frac{\\lambda}{2}v_j \\end{align}\\] \u56e0\u6b64\u6709\uff1a \\[\\lambda = - \\frac{2\\hat{\\beta}_j}{v_j}\\] \u5e26\u5165\u53ef\u5f97\uff1a \\[\\begin{align} \\text{RSS}_0 &= (\\textbf{y} - \\textbf{X}\\beta_0)^T(\\textbf{y}-\\textbf{X}\\beta_0) \\\\ &= (\\textbf{y} - \\textbf{X}\\hat{\\beta} + \\frac{\\lambda}{2}\\textbf{X}(\\textbf{X}^T \\textbf{X})^{-1} e_j)^T(\\textbf{y}-\\textbf{X}\\hat{\\beta} + \\frac{\\lambda}{2}\\textbf{X}(\\textbf{X}^T \\textbf{X})^{-1} e_j) \\\\ &= \\text{RSS}_1 + \\frac{\\lambda}{2} [e_j^T(\\textbf{X}^T \\textbf{X})^{-1}\\textbf{X}^T(\\textbf{y} - \\textbf{X}\\hat{\\beta}) + (\\textbf{y} - \\textbf{X}\\hat{\\beta})^T \\textbf{X}(\\textbf{X}^T \\textbf{X})^{-1} e_j)] \\\\ &~~~~ + \\frac{\\lambda^2}{4}e_j^T (\\textbf{X}^T \\textbf{X})^{-1} e_j \\\\ &= \\text{RSS}_1 + \\frac{\\lambda^2}{4}e_j^T (\\textbf{X}^T \\textbf{X})^{-1} e_j \\\\ &= \\text{RSS}_1 + \\frac{\\hat{\\beta}_j^2}{v_j} \\end{align}\\] \u5176\u4e2d\uff0c\u4e2d\u95f4\u9879\u53ef\u4ee5\u6d88\u53bb\u7684\u539f\u56e0\u662f\uff1a \\[\\textbf{X}^T(\\textbf{y} - \\textbf{X}\\hat{\\beta}) = \\textbf{X}^T[\\textbf{y} - \\textbf{X}(\\textbf{X}^T \\textbf{X})^{-1}\\textbf{X}^T\\textbf{y}] = 0 \\] \u76f4\u89c2\u7406\u89e3\uff0c \\(\\textbf{X}\\) \u548c \\(\\textbf{y} - \\textbf{X}\\hat{\\beta}\\) \u662f\u6b63\u4ea4\u7684\uff0c\u56e0\u4e3a \\(\\textbf{X}\\hat{\\beta}\\) \u6b63\u662f \\(\\textbf{y}\\) \u5728 \\(\\textbf{X}\\) \u6240\u5728\u5e73\u9762\u4e0a\u7684\u6295\u5f71\u3002","title":"\u8bc1\u660e"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#322-the-gaussmarkov-theorem","text":"\u6700\u5c0f\u4e8c\u4e58\u6cd5\u5f97\u51fa\u7684 \\(\\beta\\) \u5728\u6240\u6709\u7ebf\u6027 \u65e0\u504f \u4f30\u8ba1\u4e2d\u5747\u65b9\u8bef\u5dee\u6700\u5c0f\u3002\u5f53\u7136\uff0c\u5982\u679c\u6211\u4eec\u613f\u610f\u4e3a\u4e86\u8fdb\u4e00\u6b65\u51cf\u5c0f\u8bef\u5dee\u5f15\u5165\u4e00\u70b9 bias\uff0c\u5b8c\u5168\u53ef\u80fd\u627e\u5230\u4e00\u4e2a\u66f4\u5c0f\u5747\u65b9\u8bef\u5dee\u7684 \u6709\u504f \u4f30\u8ba1\u3002 the least squares estimates of the parameters \u03b2 have the smallest variance among all linear unbiased estimates \u73b0\u5728\u6211\u4eec\u6765\u8bc1\u660e\u8fd9\u4e2a\u7ed3\u8bba\u3002\u5bf9\u4e8e\u7ebf\u6027\u4f30\u8ba1\uff1a \\[\\textbf{y} = \\textbf{X}\\beta\\] \\(\\textbf{y}\\) \u4e2d\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\u90fd\u53ef\u4ee5\u770b\u4f5c \\(\\textbf{X}\\) \u4e2d\u7684\u4e00\u884c\u4e0e\u5411\u91cf \\(\\beta\\) \u7684\u7ebf\u6027\u7ec4\u5408\u3002","title":"3.2.2 The Gauss\u2013Markov Theorem"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#_6","text":"\u90a3\u4e48\uff0c\u9488\u5bf9\u65e0\u504f\u6027\uff0c\u6211\u4eec\u9700\u8981\u8bc1\u660e\u6700\u5c0f\u4e8c\u4e58\u6cd5\u4f30\u8ba1\u51fa\u7684 \\(\\hat{\\beta}\\) \u6ee1\u8db3\uff1a \\[ E(\\alpha^T \\hat{\\beta}) = \\alpha^T\\beta\\] \u5176\u4e2d \\(\\alpha\\) \u662f\u4efb\u610f\u5411\u91cf\u3002 \\[\\begin{align} E(\\alpha^T \\hat{\\beta}) &= E(\\alpha^T (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\textbf{y}) \\\\ &= E(\\alpha^T (\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\textbf{X} \\beta) \\\\ &= \\alpha^T \\beta \\end{align} \\]","title":"\u65e0\u504f\u6027"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#_7","text":"Gauss\u2013Markov theorem \u6307\u51fa\uff0c\u5982\u679c\u8fd8\u5b58\u5728\u5176\u4ed6\u7ebf\u6027\u4f30\u8ba1 \\(c^T \\textbf{y}\\) \u6ee1\u8db3\uff1a \\[ E(c^T \\textbf{y}) = \\alpha^T\\beta\\] \u90a3\u4e48\u5fc5\u7136\u6709\uff1a \\[\\text{Var}(\\alpha^T \\hat{\\beta}) \\leq \\text{Var}(c^T \\textbf{y})\\] \u8bc1\u660e\uff1a TBD","title":"\u5747\u65b9\u8bef\u5dee\u6700\u5c0f"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#33-subset-selection","text":"\u6700\u5c0f\u4e8c\u4e58\u6cd5\u7684\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a \u9884\u6d4b\u7cbe\u5ea6\u3002\u867d\u7136\u5b83\u662f\u65e0\u504f\u7684\uff0c\u4f46\u662f\u65b9\u5dee\u5f88\u5927\u3002\u5982\u679c\u6211\u4eec\u5ffd\u7565\u4e00\u90e8\u5206\u6a21\u578b\u53c2\u6570\uff0c\u867d\u7136\u4f1a\u53d8\u6210\u6709\u504f\u4f30\u8ba1\uff0c\u4f46\u662f\u53ef\u80fd\u4f1a\u6781\u5927\u63d0\u9ad8\u7cbe\u5ea6\u3002 \u53ef\u89e3\u91ca\u6027\uff08\u5373\u6a21\u578b\u590d\u6742\u5ea6\uff09\u3002\u5f53\u6a21\u578b\u53c2\u6570\u5f88\u591a\u65f6\uff0c\u6211\u4eec\u60f3\u53bb\u786e\u5b9a\u4e00\u5c0f\u90e8\u5206\u5177\u6709\u6700\u5927\u5f71\u54cd\u7684\u6a21\u578b\u53c2\u6570\uff0c\u4e3a\u6b64\u6211\u4eec\u613f\u610f\u727a\u7272\u4e00\u90e8\u5206\u65e0\u5173\u7d27\u8981\u7684\u53c2\u6570\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u9009\u53d6\u53d8\u91cf\u5b50\u96c6\uff0c\u5373\u201cmodel selection\u201d\u3002","title":"3.3 Subset Selection"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#331-best-subset-selection","text":"\u6700\u4f73\u5b50\u96c6\u662f\u6307\u4ece\u6240\u6709\u5177\u6709 \\(k (k <= p)\\) \u4e2a\u53d8\u91cf\u7684\u5b50\u96c6\u4e2d\uff0cRSS \u6700\u5c0f\u7684\u90a3\u4e2a\u3002 \u5f53\u7136\uff0c\u6700\u7b80\u5355\u7684\u65b9\u5f0f\u5c31\u662f\u4ece\u904d\u5386\u6240\u6709\u7684\u7ec4\u5408\u3002\u8fd9\u6837\u505a\u7684\u590d\u6742\u5ea6\u662f \\(2^p\\) \uff0c\u53ea\u9002\u7528\u4e8e\u5c0f\u89c4\u6a21\u7684\u95ee\u9898\u3002","title":"3.3.1 Best-Subset Selection"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#332-forward-and-backward-stepwise-selection","text":"\u201c\u524d\u5411\u9010\u6b65\u9009\u62e9\u201d\u662f\u4e00\u79cd\u8d2a\u5fc3\u7b97\u6cd5\u3002\u5b83\u6309\u987a\u5e8f\u52a0\u5165\u6700\u80fd\u63d0\u9ad8\u62df\u5408\u5ea6\u7684\u53c2\u6570\u3002\u5b83\u867d\u7136\u4e0d\u4e00\u5b9a\u627e\u5230\u6700\u4f18\u89e3\uff0c\u4f46\u662f\u5b83\u4f18\u52bf\u5728\u4e8e\uff1a \u8fd0\u7b97\u91cf\u5c0f\u3002\u5f53\u7ef4\u5ea6 \\(p >= 40\\) \u65f6\uff0c\u51e0\u4e4e\u65e0\u6cd5\u7b97\u51fa\u6700\u4f18\u89e3\u3002\u4f46\u662f\u4f9d\u65e7\u53ef\u4ee5\u7528 forward stepwise selection \uff08\u5373\u4f7f\u7ef4\u5ea6 p \u5927\u4e8e\u6837\u672c\u6570 N\uff09\u3002 \u65b9\u5dee\u5c0f\u3002\u6700\u4f18\u5b50\u96c6\u65b9\u5dee\u6bd4 forward stepwise selection \u5927\uff0c\u867d\u7136\u540e\u8005\u53ef\u80fd\u4f1a\u6709\u4e00\u5b9a\u7684 bias\u3002 \u90a3\u4e48\u5982\u4f55\u9009\u62e9\u201c\u6700\u80fd\u63d0\u9ad8\u62df\u5408\u5ea6\u201c\u7684\u53c2\u6570\u5462\uff1f\u6211\u4eec\u5728\u4e4b\u524d\u201c\u663e\u8457\u6027\u5206\u6790\u201d\u4e2d\u5df2\u7ecf\u8bc1\u660e\u4e86\uff0c\u53bb\u6389\u4e00\u4e2a\u53c2\u6570\u5bf9\u6b8b\u5dee\u7684\u5f71\u54cd\u4e3a\u5176 z-score \u7684\u5e73\u65b9\u3002\u90a3\u4e48\uff0c\u6211\u4eec\u76f4\u63a5 \u4ece z-score \u6700\u5927\u7684\u53c2\u6570\u5f00\u59cb\u4f9d\u6b21\u52a0\u5165 \u5373\u53ef\u3002\u7b2c \\(j\\) \u4e2a\u53c2\u6570\u7684 z-score \u53ef\u4ee5\u7531\u4e8e\u4e0b\u5f0f\u8ba1\u7b97\uff1a \\[ z_j = \\frac{\\hat{\\beta}_j}{\\hat{\\sigma} \\sqrt{v_j} }\\] where: \\[\\hat{\\sigma}^2 =\\frac{\\text{RSS}_1}{N-p-1} =\\frac{1}{N-p-1} \\sum_{i=1}^{N} (y_i-\\hat{y})^2\\] \\[v_j = (\\textbf{X}^T\\textbf{X})^{-1}_{jj}\\] \u201c\u540e\u5411\u9010\u6b65\u9009\u62e9\u201d \u4e0e \u201c\u524d\u5411\u9010\u6b65\u9009\u62e9\u201c\u76f8\u53cd\u3002\u5b83\u4ece\u5168\u96c6\u5f00\u59cb\uff0c\u4f9d\u6b21\u53bb\u6389\u6700\u65e0\u5173\u7d27\u8981\u7684\u53d8\u91cf\uff08z-score \u6700\u5c0f\u7684\uff09\u3002\u5b83\u53ea\u80fd\u7528\u4e8e\u6837\u672c\u6570 N \u5927\u4e8e\u7ef4\u5ea6 p \u7684\u60c5\u5f62\u3002","title":"3.3.2 Forward- and Backward-Stepwise Selection"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#34-shrinkage-methods","text":"Subset selection \u786e\u5b9e\u53ef\u4ee5\u5e2e\u6211\u4eec\u7b80\u5316\u6a21\u578b\uff0c\u5e76\u4e14\u8fd8\u53ef\u80fd\u964d\u4f4e\u8bef\u5dee\u3002\u4f46\u662f\uff0c\u56e0\u4e3a\u5b83\u662f\u4e00\u4e2a\u79bb\u6563\u7684\u8fc7\u7a0b\uff08\u53c2\u6570\u8981\u4e48\u88ab\u4e22\u5f03\u8981\u4e48\u88ab\u4fdd\u7559\uff0c\u6ca1\u6709\u4e2d\u95f4\u72b6\u6001\uff09\uff0c\u5b83\u901a\u5e38\u5177\u6709\u8f83\u5927\u7684\u65b9\u5dee\u3002Shrinkage methods \u66f4\u52a0\u8fde\u7eed\uff0c\u56e0\u6b64\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002","title":"3.4 Shrinkage Methods"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#341-ridge-regression","text":"Ridge Regression \u901a\u8fc7\u7ed9\u53c2\u6570\u6570\u91cf\u589e\u52a0\u4e00\u4e2a\u60e9\u7f5a\u9879\u6765\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\u3002\u5b83\u7684\u4f18\u5316\u76ee\u6807\uff1a \\[\\hat{\\beta} = \\mathop{\\arg \\min}_{\\beta} \\sum_{i=1}^N(y_i - \\beta_0 - \\sum_{j=1}^p x_{ij}\\beta_j)^2 + \\lambda \\sum_{j=1}^p \\beta_j^2\\] \u8fd9\u91cc\u7684 \\(\\lambda\\) \u63a7\u5236\u6a21\u578b\u201c\u7f29\u5c0f\u201d\u7684\u7a0b\u5ea6\uff0c \\(\\lambda\\) \u8d8a\u5927\uff0c\u5f97\u5230\u7684\u6a21\u578b\u590d\u6742\u5ea6\u8d8a\u4f4e\u3002 \u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c \u60e9\u7f5a\u9879\u4e2d\u4e0d\u5305\u542b\u5e38\u6570\u9879 \\(\\beta_0\\) \uff0c\u5426\u5219\u6a21\u578b\u4e0d\u7a33\u5b9a\u3002\u5f53\u9009\u53d6 \\(y_i = y_i + c\\) \u65f6\uff0c\u9884\u6d4b\u503c \\(\\hat{y}_i\\) \u7684\u53d8\u5316\u91cf\u4e0d\u662f \\(c\\) \u3002 \u4e0e\u7ecf\u5178\u7684 Linear Regression \u4e0d\u540c\uff0cRidge Regression \u8981\u6c42\u8f93\u5165 \\(\\textbf{X}, \\textbf{y}\\) \u662f\u7ecf\u8fc7\u4e86 \u4e2d\u5fc3\u5316 (centering) \u7684\u3002\u5e76\u4e14\uff0c\u8fd9\u91cc\u7684\u6a21\u578b\u53c2\u6570 \\(\\beta\\) \u662f \\(p\\) \u7ef4\u800c\u4e0d\u662f \\(p+1\\) \u7ef4\u7684\u3002 \u4e0b\u9762\u6211\u4eec\u6765\u8bc1\u660e\u8fd9\u4e00\u70b9\u3002 \\(\\beta_0\\) \u7531\u4e8e\u4e0d\u542b \\(\\lambda\\) \uff0c\u53ef\u4ee5\u5355\u72ec\u4f18\u5316\u3002\u6211\u4eec\u5148\u5bf9 \\(\\beta_0\\) \u6c42\u5bfc\uff0c\u5e76\u4ee4\u5bfc\u6570\u4e3a0: \\[\\sum_{i=1}^N(y_i - \\beta_0 - \\sum_{j=1}^p x_{ij}\\beta_j) = 0\\] \u5f97\u5230\uff1a \\[\\beta_0 = \\frac{1}{N}(\\sum_{i=1}^N y_i - \\sum_{i=1}^N \\sum_{j=1}^{p} x_{ij}\\beta_j) \\] \u4ee4 \\(\\overline{x_j} = \\frac{1}{N} \\sum_{i=1}^N x_{ij}\\) \uff0c\u6709\uff1a \\[\\beta_0 = \\frac{1}{N}\\sum_{i=1}^N y_i - \\sum_{j=1}^{p} \\overline{x_{j}} \\beta_j \\] \u6211\u4eec\u4ee5\u4e0b\u7684\u53d8\u5f62\u4e3b\u8981\u662f\u4e3a\u4e86\u5c06\u4f18\u5316\u76ee\u6807\u51fd\u6570\u5199\u6210\u77e9\u9635\u4e58\u6cd5\u5f62\u5f0f\uff0c\u4ee5\u8fdb\u884c\u8fd0\u7b97\u3002 \\[\\begin{align} \\hat{\\beta} &= \\mathop{\\arg \\min}_{\\beta} \\sum_{i=1}^N(y_i - \\beta_0 - \\sum_{j=1}^p x_{ij}\\beta_j)^2 + \\lambda \\sum_{j=1}^p \\beta_j^2 \\\\ &= \\mathop{\\arg \\min}_{\\beta} \\sum_{i=1}^N(y_i - \\beta_0 - \\sum_{j=1}^p \\overline{x_j}\\beta_j - \\sum_{j=1}^p (x_{ij} - \\overline{x_j}) \\beta_j)^2 + \\lambda \\sum_{j=1}^p \\beta_j^2 \\end{align}\\] \u73b0\u5728\u6211\u4eec\u4ee4\uff1a \\[\\begin{align} \\beta_0^c &= \\beta_0 + \\sum_{j=1}^p \\overline{x_j}\\beta_j =\\frac{1}{N} \\sum_{i=1}^N y_{i} \\\\ \\beta_j^c&= \\beta_j & (j>=1) \\end{align}\\] \u53ef\u4ee5\u5f97\u51fa\uff1a \\[\\begin{align} \\hat{\\beta} &= \\mathop{\\arg \\min}_{\\beta^c} \\sum_{i=1}^N(y_i - \\beta_0^c - \\sum_{j=1}^p (x_{ij} - \\overline{x_j}) \\beta_j^c)^2 + \\lambda \\sum_{j=1}^p {\\beta_j^c}^2 \\end{align}\\] \u6211\u4eec\u518d\u4ee4\uff1a \\[\\begin{align} y_i^c &= y_i - \\beta_0^c = y_i - \\frac{1}{N} \\sum_{i=1}^N y_i \\\\ x_{ij}^c&= x_{ij} - \\overline{x_j} & (j >=1) \\end{align}\\] \u6709\uff1a \\[\\begin{align} \\hat{\\beta} &= \\mathop{\\arg \\min}_{\\beta^c} \\sum_{i=1}^N(y_i^c - \\sum_{j=1}^p (x_{ij}^c \\beta_j^c)^2) + \\lambda \\sum_{j=1}^p {\\beta_j^c}^2 \\\\ &=\\mathop{\\arg \\min}_{\\beta} (\\textbf{y} - \\textbf{X}\\beta)^T(\\textbf{y} - \\textbf{X}\\beta) + \\lambda(\\beta^T\\beta) \\end{align}\\] \u5176\u4e2d\uff0c \\(\\textbf{X}, \\textbf{y}, \\beta\\) \u90fd\u7ecf\u8fc7\u4e86\u4e2d\u5fc3\u5316\uff0c\u5e76\u4e14\u662f \\(p\\) \u7ef4\u7684\u3002 \u8be5\u5f0f\u5bf9 \\(\\beta\\) \u6c42\u5bfc\u5e76\u4ee4\u5bfc\u6570\u4e3a 0\uff0c\u6709\uff1a \\[ -\\textbf{X}^T(\\textbf{y} - \\textbf{X}\\beta) + \\lambda \\beta = 0\\] \u89e3\u5f97\uff1a \\[ \\beta = (\\textbf{X}^T\\textbf{X} + \\lambda \\textbf{I})^{-1} \\textbf{X}^T \\textbf{y}\\] \u6211\u4eec\u770b\u5230\uff0c\u5373\u4f7f \\(\\textbf{X}^T\\textbf{X}\\) \u662f\u975e\u6ee1\u79e9\u7684\uff0c\u7531\u4e8e\u591a\u52a0\u4e86\u4e00\u4e2a \\(\\lambda \\textbf{I}\\) \uff0c\u5b83\u4ecd\u662f\u4e00\u4e2a\u53ef\u9006\u77e9\u9635\u3002\u8fd9\u4e5f\u662f ridge regression \u7684\u53e6\u4e00\u4e2a\u4f18\u52bf\u3002","title":"3.4.1 Ridge Regression"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#ridge-regression-and-svd","text":"\u5947\u5f02\u503c\u5206\u89e3 (singular value decomposition, SVD) \u5c06\u4e00\u4e2a\u77e9\u9635\u5206\u89e3\u4e3a\u4e09\u4e2a\u77e9\u9635\u7684\u4e58\u79ef\uff1a \\[ \\textbf{X}_{N \\times p} = \\textbf{U}_{N \\times N} \\mathbf{\\Sigma}_{N \\times p} \\textbf{V}^T_{p \\times p} \\] \u5176\u4e2d\uff1a \\(\\textbf{U}_{N \\times N}\\) \u662f\u4e00\u4e2a\u5355\u4f4d\u6b63\u4ea4\u77e9\u9635\uff0c\u5728 \\(\\mathbb{R}^{N \\times N}\\) \u7a7a\u95f4\u3002\u5b83\u4ee3\u8868\u4e86\u65cb\u8f6c(rotation) \\(\\mathbf{\\Sigma}_{N \\times p}\\) \u662f\u4e00\u4e2a\u5bf9\u89d2\u77e9\u9635\uff0c\u4f46\u662f\u4e0d\u4e00\u5b9a\u662f\u65b9\u9635\u3002\u5b83\u4ee3\u8868\u62c9\u4f38(scaling) \\(\\textbf{V}^T_{p \\times p}\\) \u662f\u4e00\u4e2a\u5355\u4f4d\u6b63\u4ea4\u77e9\u9635\uff0c\u5728 \\(\\mathbb{R}^{p \\times p}\\) \u7a7a\u95f4\u3002\u5b83\u4ee3\u8868\u65cb\u8f6c(rotation) \u5bf9\u4e8e\u666e\u901a\u7684\u7ebf\u6027\u56de\u5f52\uff0c\u6709\uff1a \\[\\begin{align} \\hat{y} = \\textbf{H}y &= \\textbf{X}(\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^Ty \\\\ &= \\textbf{U}\\mathbf{\\Sigma}\\textbf{V}^T(\\textbf{V}\\mathbf{\\Sigma}^T\\mathbf{\\Sigma}\\textbf{V}^T)^{-1} \\textbf{V}\\mathbf{\\Sigma}^T\\textbf{U}^T y \\\\ &= \\textbf{U}\\mathbf{\\Sigma} (\\mathbf{\\Sigma}^T\\mathbf{\\Sigma})^{-1} \\mathbf{\\Sigma}^T\\textbf{U}^T y \\\\ &= \\textbf{U}\\textbf{U}^T y \\end{align}\\] \u800c\u5bf9\u4e8e ridge regression\uff0c\u6709\uff1a \\[\\begin{align} \\hat{y} &= \\textbf{X}(\\textbf{X}^T\\textbf{X} + \\lambda \\textbf{I})^{-1} \\textbf{X}^T \\textbf{y} \\\\ &= \\textbf{U}\\mathbf{\\Sigma}(\\mathbf{\\Sigma}^T\\mathbf{\\Sigma} + \\lambda \\textbf{I})^{-1} \\mathbf{\\Sigma}^T\\textbf{U}^T y \\end{align}\\] \u5047\u8bbe SVD \u5206\u89e3\u7684\u5947\u5f02\u503c\u4e3a \\(\\sigma_1, \\sigma_2, ... , \\sigma_p\\) \uff0c\u6211\u4eec\u6709\uff1a \\[\\begin{align} \\hat{y} &= \\textbf{U}\\mathbf{\\Sigma}(\\mathbf{\\Sigma}^T\\mathbf{\\Sigma} + \\lambda \\textbf{I})^{-1} \\mathbf{\\Sigma}^T\\textbf{U}^T y \\\\ &= \\sum_{j=1}^p \\textbf{u}_j \\frac{\\sigma_j^2}{\\sigma_j^2 + \\lambda} \\textbf{u}_j^T \\textbf{y} \\end{align}\\] \u5176\u4e2d \\(\\textbf{u}_j\\) \u8868\u793a\u77e9\u9635 \\(\\textbf{U}\\) \u7684\u7b2c \\(j\\) \u5217\u3002 \u56e0\u6b64\uff0c\u4ece\u76f4\u89c2\u610f\u4e49\u4e0a\u7406\u89e3\uff0cridge regression \u76f8\u6bd4\u666e\u901a\u7684 regression \u5c31\u662f\u5bf9 \\(\\textbf{U}\\) \u7684\u6bcf\u4e00\u5217\u9644\u52a0\u4e86\u4e00\u4e2a\u7cfb\u6570 \\(\\frac{\\sigma_j^2}{\\sigma_j^2 + \\lambda} \\leq 1\\) \u3002\u8fd9\u4e2a\u7cfb\u6570\u4e0e\u8be5\u5217\u5bf9\u5e94\u7684\u5947\u5f02\u503c\u76f8\u5173\u3002\u800c\u6211\u4eec\u5728 SVD \u5b9a\u4e49\u4e2d\u77e5\u9053 \\(\\sigma_j\\) \u4ee3\u8868\u4e86\u5728 \\(\\textbf{u}_j\\) \u65b9\u5411\u7684\u7f29\u653e\u7cfb\u6570\u3002\u663e\u7136\uff0c \\(\\frac{\\sigma_j^2}{\\sigma_j^2 + \\lambda}\\) \u5728 \\(\\sigma_j\\) \u8d8a\u5c0f\u65f6\uff0cshrinkage \u8d8a\u5927\u3002\u56e0\u6b64\uff0c\u76f4\u89c2\u7406\u89e3\uff0cridge regression \u4f1a\u503e\u5411\u4e8e\u5ffd\u7565\u8f93\u5165 \\(\\textbf{X}\\) \u65b9\u5dee\u8f83\u5c0f\u7684\u65b9\u5411\u3002 the small singular values correspond to directions in the column space of X having small variance, and ridge regression shrinks these directions the most. \u8fd9\u662f\u4e2a\u6bd4\u8f83\u5408\u7406\u7684\u5047\u8bbe\uff0c\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u5bf9\u4e8e\u6837\u672c\u4e2d\u51e0\u4e4e\u4e00\u6837\u7684\u8f93\u5165\u53c2\u6570\u5e76\u4e0d\u662f\u5f88\u5173\u5fc3.","title":"Ridge Regression and SVD"},{"location":"mathematics/ESL/ESL3_LinearMethodsForRegression/#reference","text":"ESL solution ESL Chinese Simple Linear Regression Proofs involving ordinary least squares","title":"Reference"},{"location":"mathematics/ESL/ESL4_LinearMethodsForClassification/","text":"ESL 4: Linear Methods for Classification 4.2 Linear Regression of an Indicator Matrix \u5bf9\u4e8e\u5206\u7c7b\u95ee\u9898\uff0c\u6211\u4eec\u53ef\u4ee5\u628a\u6bcf\u4e2a\u5206\u7c7b\u7528 indicator variable \u6765\u7f16\u7801\u3002 \u4f8b\u5982\uff0c\u5982\u679c\u6709 \\(K\\) \u4e2a\u7c7b\u578b\uff0c\u6211\u4eec\u53ef\u4ee5\u5b9a\u4e49\uff1a \\[ \\textbf{y} = [y_1, ..., y_K]^T \\] \u5f53\u6837\u672c\u662f\u7b2c \\(i\\) \u7c7b\u65f6\uff0c \\(y_i = 1\\) \uff0c\u5176\u5b83\u503c\u4e3a 0\u3002 \u5f53\u6211\u4eec\u6709 N \u4e2a\u6837\u672c\u65f6\uff0c\u53ef\u4ee5\u5199\u6210\u4e00\u4e2a \\(N \\times K\\) \u77e9\u9635\uff08indicator response matrix\uff09\uff1a \\[ \\textbf{Y} = [\\textbf{y}_1, ..., \\textbf{y}_N]^T \\] \u8fd9\u4e2a\u77e9\u9635\u6bcf\u4e00\u884c\u4ec5\u6709\u4e00\u4e2a 1\uff0c\u5176\u4f59\u503c\u4e3a 0\u3002\u8fd9\u4e2a 1 \u4ee3\u8868\u8be5\u884c\u6837\u672c\u7684\u7c7b\u578b\u3002 \u8fd9\u5b9e\u9645\u4e0a\u5c31\u662f one-hot \u7f16\u7801\uff0c\u8fd9\u79cd\u7f16\u7801\u76f8\u5bf9\u4e8e\u76f4\u63a5\u4f7f\u7528\u6574\u6570 \\(1, ..., K\\) \u6765\u8868\u793a\u7684\u6709\u4f18\u52bf\u5728\u4e8e \u7c7b\u578b\u95f4\u7684\u8ddd\u79bb\u90fd\u662f\u4e00\u6837\u7684 \u3002 \u5229\u7528\u7b2c\u4e09\u7ae0\u7684 Linear Regression\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u51fa\u7cfb\u6570\u77e9\u9635 \\(\\hat{\\textbf{B}}\\) \uff1a \\[ \\hat{\\textbf{B}} = \\textbf{X}(\\textbf{X}^T \\textbf{X})^{-1} \\textbf{X}^T \\textbf{Y} \\] \\(\\hat{\\textbf{B}}\\) \u662f\u4e00\u4e2a \\((p+1) \\times K\\) \u7684\u77e9\u9635\u3002 \\(\\textbf{X}\\) \u662f \\(N \\times (p+1)\\) \u77e9\u9635\u3002 \u5f97\u5230\u4f30\u8ba1\u503c\uff1a \\[ \\hat{\\textbf{Y}} = \\textbf{X}(\\textbf{X}^T \\textbf{X})^{-1} \\textbf{X}^T \\textbf{Y}\\] \u8be5\u65b9\u6cd5\u7684\u6b65\u9aa4\u662f\uff1a \u5bf9\u7c7b\u578b\u8fdb\u884c one-hot \u7f16\u7801\u5f97\u5230 \\(\\textbf{Y}\\) \u5c06\u95ee\u9898\u89c6\u4f5c\u4e00\u4e2a\u591a\u53d8\u91cf\u7684\u7ebf\u6027\u56de\u5f52\u95ee\u9898\uff0c\u5bf9 one-hot \u7f16\u7801\u540e\u7684\u6bcf\u4e2a bit \u8fdb\u884c\u62df\u5408\u5f97\u5230 \\(\\hat{\\textbf{B}}\\) \u5728\u5224\u65ad\u7c7b\u522b\u65f6\uff0c\u9009\u62e9 \\(\\textbf{X}\\hat{\\textbf{B}}\\) \u6bcf\u884c\u7684\u6700\u5927\u503c\u6240\u8868\u793a\u7684\u7c7b\u578b \u4f7f\u7528 Linear Regression \u89e3\u51b3\u5206\u7c7b\u95ee\u9898\u7684\u6700\u5927\u95ee\u9898\u5728\u4e8e\uff0c\u5f53\u7c7b\u522b\u6570 \\(K \\leq 3\\) \u65f6\uff0c\u53ef\u80fd\u4f1a\u51fa\u73b0\u67d0\u4e2a\u7c7b\u88ab\u63a9\u76d6\uff08mask\uff09\u7684\u60c5\u51b5\u3002\u5176\u672c\u8d28\u539f\u56e0\u662f Linear Regression \u7684\u201c\u521a\u6027\u201d\u7279\u8d28\uff0c\u5373\u5b83\u7684\u5206\u754c\u9762\u662f\u4e0d\u591f\u7075\u6d3b\u7684\u3002 \u4e3e\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\uff0c\u5bf9\u4e8e\u4ee5\u4e0b\u4e09\u4e2a 1 \u7ef4\u6b63\u6001\u5206\u5e03\uff1a class1: \\(x \\sim N(1, 1)\\) class2: \\(x \\sim N(5, 1)\\) class3: \\(x \\sim N(9, 1)\\) \u5206\u5e03\u5982\u4e0b\uff1a \u5982\u679c\u6211\u4eec\u7528 Linear Regression \u62df\u5408\uff0c\u90a3\u6211\u4eec\u53ef\u4ee5\u5f97\u5230 3 \u7ec4 \\(\\beta_0, \\beta_1\\) \uff0c\u5206\u522b\u5bf9\u5e94\u7b2c \\(i\\) \u7ec4\uff0c\u53ef\u4ee5\u7528\u6765\u8ba1\u7b97 \\(y_i\\) \u7684\u503c\uff1a \\[ y_i = \\beta_0 + \\beta_1 x \\] \u53ef\u4ee5\u770b\u5230\uff0c \\(y_1\\) \uff08\u5bf9\u5e94class2\uff09\u4ece\u6765\u4e0d\u662f\u6700\u5927\u503c\u3002\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u7684\u5206\u7c7b\u7ed3\u679c\u4e2d\u53ea\u6709 class1 \u548c class3 \u4e86\uff0cclass2 \u88ab mask \u4e86\u3002\u53ef\u4ee5\u901a\u8fc7\u7ed3\u679c\u9a8c\u8bc1\uff1a pd . DataFrame ( X * B ) . T . idxmax () . value_counts () # 2 1505 # 0 1495 # dtype: int64 \u4ee3\u7801\uff1a import numpy as np import pandas as pd def generate_nd_sample ( name , mu_array , sigma , N ): xx = {} for i in range ( 1 , len ( mu_array ) + 1 ): xi = np . random . normal ( mu_array [ i - 1 ], sigma , N ) xx [ f \"x { i } \" ] = xi xx [ \"name\" ] = name return pd . DataFrame ( xx ) . astype ({ \"name\" : \"category\" }) s1 = generate_nd_sample ( \"class1\" , [ 1 ], 1 , 1000 ) s2 = generate_nd_sample ( \"class2\" , [ 5 ], 1 , 1000 ) s3 = generate_nd_sample ( \"class3\" , [ 9 ], 1 , 1000 ) s = pd . concat ([ s1 , s2 , s3 ]) . reset_index ( drop = True ) # Linear Regression tmp = s . copy () tmp . insert ( 0 , \"ones\" , np . ones ( s . shape [ 0 ])) X = np . matrix ( tmp . drop ( \"name\" , axis = 1 ) . to_numpy () . T ) . T Y = np . matrix ( pd . get_dummies ( s . name )) def LR_beta ( X , Y ): # class count K = Y . shape [ 1 ] return ( X . T * X ) . I * X . T * Y B = LR_beta ( X , Y ) # Plot from bokeh.io import output_notebook output_notebook () from bokeh.palettes import viridis from bokeh.plotting import figure , show import itertools def create_histogram_figure ( sample_data ): # sample data must be like: # | x | category | assert sample_data . shape [ 1 ] == 2 , \"input must be of shape (N, 2)\" x = sample_data . iloc [:, 0 ] categories = sample_data . iloc [:, 1 ] . unique () fig = figure ( x_axis_label = x . name , y_axis_label = \"counts\" ) color_gen = itertools . cycle ( viridis ( len ( categories ))) for ( category , color ) in zip ( categories , color_gen ): data = sample_data [ sample_data . iloc [:, 1 ] == category ] counts , bins = np . histogram ( data . iloc [:, 0 ], bins = 'auto' ) fig . quad ( top = counts , bottom = 0 , left = bins [: - 1 ], right = bins [ 1 :], alpha = 0.5 , color = color , legend_label = str ( category )) return fig def create_line_figure ( lines , x_start , x_end ): fig = figure ( x_axis_label = \"x\" , y_axis_label = \"y\" ) color_gen = itertools . cycle ( viridis ( lines . shape [ 0 ])) for i in range ( lines . shape [ 0 ]): b0 , b1 = lines [ i , 0 ], lines [ i , 1 ] fig . line ( x = [ x_start , x_end ], y = [ b0 + b1 * x_start , b0 + b1 * x_end ], line_width = 2 , alpha = 0.5 , color = next ( color_gen ), legend_label = f \"y { i } = { b0 : .6f } + { b1 : .6f } x\" ) return fig hist_fig = create_histogram_figure ( s ) line_fig = create_line_figure ( B . T , s . x1 . min (), s . x1 . max ()) from bokeh import layouts show ( layouts . column ( hist_fig , line_fig )) 4.3 Linear discriminant analysis \u4e3a\u4e86\u83b7\u5f97\u6700\u4f18\u7684\u5206\u7c7b\u7ed3\u679c\uff0c\u6211\u4eec\u9700\u8981\u77e5\u9053\u540e\u9a8c\u6982\u7387\uff08 \\(X = x\\) \u65f6\u5c5e\u4e8e\u7b2c \\(k\\) \u7c7b\u7684\u6982\u7387\uff09\uff1a \\[ \\text{Pr}(G=k | X=x) = \\frac{f_k(x) \\pi_k}{\\sum_{i=1}^K f_i(x) \\pi_i}\\] \u56e0\u4e3a\u672c\u8d28\u4e0a\uff0c\u6211\u4eec\u662f\u5728\u627e\u5230\u4e00\u4e2a k \u4f7f\u5f97\u540e\u9a8c\u6982\u7387\u6700\u5927\uff0c\u5373\uff1a \\[\\begin{align} \\hat{k} &= \\mathop{\\arg \\max}_{k} \\text{Pr}(G=k | X=x) \\\\ &= \\mathop{\\arg \\max}_{k} f_k(x) \\pi_k \\\\ &= \\mathop{\\arg \\max}_{k} [\\ln(f_k(x)) + \\ln(\\pi_k)] \\end{align}\\] \u8fd9\u88ab\u79f0\u4e3a \u5224\u522b\u51fd\u6570 \uff08discriminant function\uff09\uff0c\u5176\u4e2d\uff1a \\(f_i(x)\\) \u662f\u7b2c i \u7c7b\u6837\u672c\u53d6 x \u7684\u6982\u7387 \\(\\pi_i\\) \u662f\u5c5e\u4e8e\u7b2c i \u7c7b\u7684\u5148\u9a8c\u6982\u7387 \u8fd9\u91cc\u7684\u96be\u70b9\u5728\u4e8e\u786e\u5b9a \\(f_i(x)\\) \uff0c\u663e\u7136 \\(\\pi_i\\) \u7684\u4f30\u8ba1\u662f\u53ef\u4ee5\u901a\u8fc7\u6837\u672c\u6570\u636e\u76f4\u63a5\u5f97\u5230\u7684\u3002 \u7ebf\u6027\u5224\u522b\u5206\u6790\uff08Linear Discriminant Analysis, LDA\uff09 \u5047\u8bbe\u53d8\u91cf X \u670d\u4ece\u591a\u7ef4\u9ad8\u65af\u5206\u5e03 \uff08X \u5305\u542b\u591a\u7ef4\uff09\uff1a \\[ f_k(x) = \\frac{1}{(2 \\pi)^{p/2} |\\mathbf{\\Sigma}_k|^{1/2}} e^{-\\frac{1}{2}(x - \\mu_k)^T \\mathbf{\\Sigma}_k^{-1} (x - \\mu_k)} \\] \u5e26\u5165\u6700\u4f18\u5206\u7c7b\u7684\u5f0f\u5b50, \u9010\u6b65\u53bb\u6389\u4e0e \\(k\\) \u65e0\u5173\u7684\u90e8\u5206\uff1a \\[\\begin{align} \\hat{k} &= \\mathop{\\arg \\max}_{k} [\\ln(f_k(x)) + \\ln(\\pi_k)] \\\\ &= \\mathop{\\arg \\max}_{k} [- \\ln((2 \\pi)^{p/2} |\\mathbf{ \\Sigma }_k|^{1/2}) - \\frac{1}{2}(x - \\mu_k)^T \\mathbf{ \\Sigma }_k^{-1} (x - \\mu_k) + \\ln(\\pi_k)] \\\\ &= \\mathop{\\arg \\max}_{k} [- \\frac{1}{2} \\ln |\\mathbf{ \\Sigma }_k| - \\frac{1}{2}(x - \\mu_k)^T \\mathbf{\\Sigma}_k^{-1} (x - \\mu_k) + \\ln(\\pi_k)] \\\\ \\end{align}\\] \u6b64\u65f6\uff0c\u5224\u522b\u51fd\u6570\u4e3a\uff1a \\[\\delta_k(x) = - \\frac{1}{2} \\ln |\\mathbf{ \\Sigma }_k| - \\frac{1}{2}(x - \\mu_k)^T \\mathbf{\\Sigma}_k^{-1} (x - \\mu_k) + \\ln(\\pi_k)\\] \u662f \\(x\\) \u7684\u4e8c\u6b21\u51fd\u6570\u3002\u56e0\u6b64\u79f0\u4e3a\u4e8c\u6b21\u5224\u522b\u5206\u6790(Quadratic Discriminant Analysis, QDA)\u3002 \u6211\u4eec\u518d \u5047\u8bbe\u6bcf\u4e2a\u7c7b\u4e2d\u53d8\u91cf X \u5206\u5e03\u7684\u65b9\u5dee\u662f\u76f8\u7b49\u7684 \uff0c\u5219 \\(\\mathbf{\\Sigma}\\) \u4e5f\u4e0e \\(k\\) \u65e0\u5173\u4e86\uff0c\u53ef\u4ee5\u8fdb\u6b65\u4e00\u5316\u7b80\u5224\u522b\u51fd\u6570\u4e3a\uff1a \\[\\delta_k(x) = x^T\\mathbf{\\Sigma}^{-1}\\mu_k - \\frac{1}{2}\\mu_k^T\\mathbf{\\Sigma}^{-1} \\mu_k + \\ln(\\pi_k)\\] \u6211\u4eec\u53ef\u4ee5\u770b\u51fa\uff0c\u5316\u7b80\u540e\u5224\u522b\u51fd\u6570\u5bf9\u4e8e \\(x\\) \u662f \u7ebf\u6027 \u7684\u3002\u8fd9\u8bf4\u660e\u4e24\u4e2a\u7c7b\u7684\u5206\u754c\u9762\uff08\u5373\u5224\u522b\u51fd\u6570\u76f8\u7b49\u65f6\uff09\u4e5f\u662f\u7ebf\u6027\u7684\u3002\u56e0\u6b64\u53eb\u505a\u7ebf\u6027\u5224\u522b\u5206\u6790(Linear Discriminant Analysis, LDA)\u3002 \u5b9e\u9645\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u6837\u672c\u4f30\u8ba1\u9ad8\u65af\u5206\u5e03\u7684\u53c2\u6570\uff1a \\(\\hat{\\pi}_k = N_k / N\\) \uff0c\u5373\u7b2c k \u7c7b\u7684\u6837\u672c\u6570\u5360\u603b\u6837\u672c\u6570\u7684\u6bd4\u4f8b \\(\\hat{\\mu}_k = \\sum_{g_i = k} x_i / N_k\\) \uff0c\u5373\u7b2c k \u7c7b\u6837\u672c X \u7684\u5e73\u5747\u503c \\(\\hat{\\mathbf{\\Sigma}} = \\sum_{k=1}^K \\sum_{g_i = k} (x_i - \\hat{\\mu}_k)(x_i - \\hat{\\mu}_k)^T / (N - K)\\) \uff0c\u5bf9\u534f\u65b9\u5dee\u77e9\u9635\u7684\u65e0\u504f\u4f30\u8ba1\uff0c\u8bc1\u660e\u5728 ESL3 \u4e2d \u6709\u4e86\u5224\u522b\u51fd\u6570\u7684\u8868\u8fbe\u5f0f \\(\\delta_k(x)\\) \uff0c\u6211\u4eec\u53ea\u9700\u8981\u4f9d\u6b21\u5e26\u5165 \\(k = 1, ..., K\\) , \u5f53\u5f97\u5230\u7684 \\(\\delta_k(x)\\) \u6700\u5927\u65f6\u7684 \\(k\\) \u5373\u4e3a\u6700\u4f73\u5206\u7c7b\u3002 4.3.2 Computation of LDA \u534f\u65b9\u5dee\u77e9\u9635 \\(\\mathbf{\\Sigma}\\) \u662f\u4e00\u4e2a\u5bf9\u79f0\u77e9\u9635\uff0c\u53ef\u4ee5\u8fdb\u884c\u7279\u5f81\u503c\u5206\u89e3\uff1a \\[ \\mathbf{\\Sigma} = \\mathbf{Q}\\mathbf{\\Lambda}\\mathbf{Q}^T \\] \u5176\u4e2d\uff1a \\(\\mathbf{Q}\\) \u662f\u5355\u4f4d\u6b63\u4ea4\u77e9\u9635\uff0c \\(\\mathbf{\\Lambda}\\) \u662f\u5bf9\u89d2\u9635\u3002\u5e26\u5165\u5224\u522b\u51fd\u6570\u6709\uff1a \\[\\begin{align} \\delta_k(x) &= x^T\\mathbf{\\Sigma}^{-1}\\mu_k - \\frac{1}{2}\\mu_k^T\\mathbf{\\Sigma}^{-1} \\mu_k + \\ln(\\pi_k) \\\\ &= x^T\\mathbf{Q}^{T}\\mathbf{\\Lambda}^{-1}\\mathbf{Q}\\mu_k - \\frac{1}{2}\\mu_k^T\\mathbf{Q}^{T}\\mathbf{\\Lambda}^{-1}\\mathbf{Q}\\mu_k + \\ln(\\pi_k) \\end{align}\\] \u4ee4\uff1a \\[ x^{*} = \\mathbf{\\Lambda}^{-\\frac{1}{2}}\\mathbf{Q}x \\] \\[ \\mu^{*} = \\mathbf{\\Lambda}^{-\\frac{1}{2}}\\mathbf{Q} \\mu \\] \u6709\uff1a \\[ \\delta_k(x^{*}) = x^{* T}\\mu_k^{*} - \\frac{1}{2}\\mu_k^{* T} \\mu_k^{*} + \\ln(\\pi_k) \\] \u5f53\u6211\u4eec\u5224\u65ad\u67d0\u4e2a\u6837\u672c \\(x_1\\) \u5c5e\u4e8e m \u548c n \u4e2d\u7684\u54ea\u4e00\u4e2a\u7c7b\u65f6\uff0c\u53ef\u4ee5\u6bd4\u8f83\u5176\u5224\u522b\u51fd\u6570\uff0c\u6211\u4eec\u5224\u65ad\u5b83\u662f m \u7c7b\u5982\u679c\u6ee1\u8db3\uff1a \\[ \\delta_m(x_1^*) > \\delta_n(x_1^*) \\] \u5e26\u5165\u8868\u8fbe\u5f0f\u6709\uff1a \\[ x^{*T} (\\mu^*_m - \\mu^*_n) > \\frac{1}{2} (\\mu^*_m + \\mu^*_n)^T(\\mu^*_m - \\mu^*_n) - \\ln(\\pi_m/\\pi_n)\\] \u8fd9\u6837\u770b\u8d77\u6765\u5c31\u975e\u5e38\u76f4\u89c2\u4e86\u3002 LDA \u662f\u5c06\u6837\u672c\u6295\u5f71\u5728\u4e24\u4e2a\u7c7b\u4e2d\u5fc3\u7684\u8fde\u7ebf\u4e0a\uff0c\u5e76\u4e14\u6bd4\u8f83\u5b83\u66f4\u9760\u8fd1\u54ea\u4e00\u8fb9\uff0c\u4ee5\u6b64\u51b3\u5b9a\u5b83\u5c5e\u4e8e\u54ea\u4e2a\u7c7b \u3002\u5f53\u7136\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u8fd8\u8003\u8651\u4e86\u4e24\u4e2a\u7c7b\u7684\u5148\u9a8c\u6982\u7387\uff08 \\(\\ln(\\pi_m/\\pi_n)\\) \u9879\uff09\u3002 4.3.3 Reduced-Rank Linear Discriminant Analysis LDA \u4e5f\u662f\u4e00\u79cd\u964d\u7ef4\u7684\u624b\u6bb5\u3002\u5047\u8bbe\u6211\u4eec\u6709 \\(p\\) \u7ef4\u7279\u5f81\uff0c \\(K\\) \u4e2a\u7c7b\u522b\u3002\u6839\u636e 4.3.2 \u4e2d\u4ecb\u7ecd\u7684\u8ba1\u7b97\u65b9\u5f0f\uff0c\u6211\u4eec\u4e00\u5171\u6709 \\(K\\) \u4e2a\u7c7b\u4e2d\u5fc3\u70b9\u3002\u4ed6\u4eec\u4e00\u5b9a\u5728\u4e00\u4e2a\u6700\u9ad8 \\(K-1\\) \u7ef4\u7684\u7a7a\u95f4\u91cc\u3002 \u4f8b\uff1a\u7ea2\u9152\u5206\u7c7b \u4f8b\u5982\uff0c\u5bf9\u4e8e 2 \u4e2a\u7c7b\u7684\u5206\u7c7b\u95ee\u9898\uff0c \u65e0\u8bba\u7279\u5f81\u662f\u591a\u5c11\u7ef4 \uff0c\u6211\u4eec\u53ea\u6709 2 \u4e2a\u7c7b\u4e2d\u5fc3\u70b9\u3002\u4ed6\u4eec\u5fc5\u5b9a\u5728\u4e00\u6761\u76f4\u7ebf\uff081\u7ef4\uff09\u4e0a\u3002\u540c\u7406\uff0c\u5bf9\u4e8e 3 \u4e2a\u7c7b\u7684\u5206\u7c7b\u95ee\u9898\uff0c\u6211\u4eec\u53ea\u6709 3 \u4e2a\u7c7b\u4e2d\u5fc3\u70b9\u3002\u4ed6\u4eec\u5fc5\u5b9a\u5728\u4e00\u4e2a\u5e73\u9762\uff082\u7ef4\uff09\u5185\uff0c\u5982\u679c\u7279\u5f81\u7ef4\u5ea6\u5927\u4e8e\u7b49\u4e8e 2\u3002 \u56e0\u6b64\uff0c\u7ecf\u8fc7 LDA\uff0c\u539f\u59cb\u6570\u636e\u603b\u80fd\u88ab\u6295\u5f71\u5230\u4e00\u4e2a\u8d85\u5e73\u9762\u4e0a\uff0c\u5176\u7ef4\u5ea6\u4e3a\uff08\u5bf9\u5e94 sklearn LDA \u65b9\u6cd5\u4e2d\u7684 n_components \u53c2\u6570\uff09\uff1a \\[ L = \\min(p, K-1) \\] \u8fd9\u8bf4\u660e\uff0c \u5728 \\(p \\gg K\\) \u65f6\uff0c\u4f7f\u7528 LDA \u53ef\u4ee5\u5c06\u4e00\u4e2a \\(p\\) \u7ef4\u7684\u8f93\u5165\u964d\u7ef4\u5230 \\(K-1\\) \u7ef4 \u3002 \u6211\u4eec\u4ee5 sklearn \u4e2d\u7684 wine \u6570\u636e\u96c6\u4e3a\u4f8b\u3002\u5b83\u5177\u6709 13 \u7ef4\u7279\u5f81\uff0c3 \u4e2a\u7c7b\u522b\u3002\u6211\u4eec\u4f7f\u7528 LDA \u53ef\u4ee5\u5c06\u8fd9\u4e9b\u6570\u636e\u6295\u5f71\u5230\u4e00\u4e2a 2 \u7ef4\u7684\u5e73\u9762\u4e0a\u3002 \u4ee3\u7801\uff1a import pandas as pd import numpy as np from sklearn import datasets wine = datasets . load_wine () X = pd . DataFrame ( wine . data , columns = wine . feature_names ) y = wine . target # LDA projection from sklearn.discriminant_analysis import LinearDiscriminantAnalysis model = LinearDiscriminantAnalysis ( n_components = 2 ) . fit ( X , y ) model . transform ( X ) # plot data_to_plot = pd . DataFrame ( np . insert ( model . transform ( X ), 2 , y , axis = 1 ), columns = [ \"x1\" , \"x2\" , \"class\" ]) show ( create_scatter_figure ( \"LDA projection for wine data\" , data_to_plot )) Find the optimal subspace \u5728\u5b9e\u9645\u4e2d\uff0c\u5982\u679c \\(K\\) \u4e5f\u5f88\u5927\uff0c\u90a3\u8fd8\u9700\u8981\u8fdb\u4e00\u6b65\u964d\u4f4e\u7ef4\u5ea6\u3002\u5047\u8bbe\u6211\u4eec\u76ee\u6807\u662f\u964d\u4f4e\u5230 \\(L\\) \u7ef4\uff08 \\(L \\ll K-1\\) )\uff0c\u5373\u5bfb\u627e\u8d85\u5e73\u9762 \\(H_{K-1}\\) \u7684\u6700\u4f18\u5b50\u7a7a\u95f4 \\(H_L\\) \u3002 Fisher \u5c06\u8fd9\u4e2a\u95ee\u9898\u63d0\u70bc\u4e3a\uff1a \u627e\u5230\u7ebf\u6027\u7ec4\u5408 \\(Z = a^T X\\) \u4f7f\u5f97\u7c7b\u95f4\u7684\u65b9\u5dee\u76f8\u5bf9\u4e8e\u7c7b\u5185\u65b9\u5dee\u6700\u5927 \\(X\\) \u7684\u7c7b\u5185(Within)\u65b9\u5dee\u4e3a\uff1a \\[ \\textbf{W} = \\sum_{k=1}^K \\sum_{g_i=k} (x_i - \\mu_k)(x_i - \\mu_k)^T \\] \\(X\\) \u7684\u7c7b\u95f4(Between)\u65b9\u5dee\u4e3a\uff1a \\[ \\textbf{B} = \\sum_{k=1}^K (\\mu - \\mu_k)(\\mu - \\mu_k)^T \\] \u6839\u636e\u5411\u91cf\u7684\u7edf\u8ba1\u7279\u6027\uff0c\u6709 \\(Z\\) \u7684\u7c7b\u5185\u65b9\u5dee\u4e3a \\(a^T \\textbf{W} a\\) \uff0c\u7c7b\u95f4\u65b9\u5dee\u4e3a \\(a^T \\textbf{B} a\\) \u3002 \u4e8e\u662f\uff0cFisher \u5b9e\u9645\u4e0a\u662f\u5728\u89e3\u51b3\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\uff1a \\[ \\mathop{\\arg \\max}_a \\frac{a^T \\textbf{B} a}{a^T \\textbf{W} a} \\] \u7531\u4e8e\u6211\u4eec\u603b\u53ef\u4ee5\u901a\u8fc7\u8c03\u8282\u6c42\u5f97\u7684 \\(a\\) \u7684\u7cfb\u6570\u4f7f\u5f97 \\(a^T \\textbf{W} a = 1\\) \uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u6539\u5199\u4e3a\uff1a \\[\\begin{align} \\mathop{\\arg \\max}_a & ~ a^T \\textbf{B} a \\\\ \\text{s.t.} & ~ a^T \\textbf{W} a = 1 \\end{align}\\] \u5047\u8bbe \\(\\mathbf{W}\\) \u53ef\u9006 \uff0c\u4ee4 \\(u = \\mathbf{W}^{\\frac{1}{2}} a\\) \uff0c\u7531\u4e8e \\(\\textbf{W}\\) \u662f\u5bf9\u79f0\u77e9\u9635\uff0c\u6709\uff1a \\[\\begin{align} \\mathop{\\arg \\max}_u & ~ u^T \\mathbf{W}^{-\\frac{1}{2}}\\textbf{B}\\mathbf{W}^{-\\frac{1}{2}} u \\\\ \\text{s.t.} & ~ u^Tu = 1 \\end{align}\\] \\(\\mathbf{W}^{-\\frac{1}{2}}\\textbf{B}\\mathbf{W}^{-\\frac{1}{2}}\\) \u4e5f\u662f\u5bf9\u79f0\u77e9\u9635\uff0c\u5fc5\u5b9a\u5b58\u5728\u7279\u5f81\u503c\u5206\u89e3\uff1a \\[ \\mathbf{W}^{-\\frac{1}{2}}\\textbf{B}\\mathbf{W}^{-\\frac{1}{2}} = \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^T \\] \u56e0\u6b64\u5316\u7b80\u4e3a\uff1a \\[\\begin{align} \\mathop{\\arg \\max}_u & ~ u^T \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^T u \\\\ \\text{s.t.} & ~ u^Tu = 1 \\end{align}\\] \u518d\u4ee4 \\(v = \\mathbf{Q}^T u\\) \uff0c\u7531\u4e8e \\(\\mathbf{Q}\\) \u662f\u5355\u4f4d\u6b63\u4ea4\u77e9\u9635\uff0c \\(v^T v = 1\\) \u4f9d\u7136\u6210\u7acb\uff1a \\[\\begin{align} \\mathop{\\arg \\max}_v & ~ v^T \\mathbf{\\Lambda} v \\\\ \\text{s.t.} & ~ v^Tv = 1 \\end{align}\\] \\(\\mathbf{\\Lambda}\\) \u662f\u5bf9\u89d2\u77e9\u9635\uff0c\u6240\u4ee5 \u8be5\u4f18\u5316\u95ee\u9898\u672c\u8d28\u662f\u6c42\u6700\u5927\u7279\u5f81\u503c \u3002\u5047\u8bbe \\(\\lambda_i\\) \u6700\u5927\uff0c\u663e\u7136\u5728 \\(v_i = 1\\) \u65f6\u53d6\u5f97\u6700\u5927\u503c \\(\\lambda_i^2\\) \u3002 \u7531\u4e8e \\(\\mathbf{\\Lambda}\\) \u662f \\(\\mathbf{W}^{-\\frac{1}{2}}\\textbf{B}\\mathbf{W}^{-\\frac{1}{2}}\\) \u7684\u7279\u5f81\u503c\uff0c\u4e3a\u4e86\u7b80\u5316\u6c42\u89e3\uff0c\u6211\u4eec\u5229\u7528\u5b9a\u7406\uff1a \\(\\mathbf{AB}\\) \u4e0e \\(\\mathbf{BA}\\) \u5177\u6709\u540c\u6837\u7684\u7279\u5f81\u503c\uff0c\u5982\u679c \\(x\\) \u662f \\(\\mathbf{AB}\\) \u7684\u67d0\u4e2a\u7279\u5f81\u5411\u91cf\uff0c\u5219\u5bf9\u5e94\u7684 \\(\\mathbf{BA}\\) \u7684\u7279\u5f81\u5411\u91cf\u662f \\(y = \\mathbf{B}x\\) \u53ef\u4ee5\u5f97\u5230 \\(\\mathbf{\\Lambda}\\) \u4e5f\u662f \\(\\mathbf{W}^{-1}\\textbf{B}\\) \u7684\u7279\u5f81\u503c\u3002 \u5047\u8bbe \\(\\mathbf{W}^{-1}\\textbf{B}\\) \u7684\u6700\u5927\u7279\u5f81\u503c\u4e3a \\(\\lambda_i\\) \uff0c\u5bf9\u5e94\u7684\u7279\u5f81\u5411\u91cf\u4e3a \\(\\xi\\) \uff0c\u5219\u6240\u6c42\u7684\u7ebf\u6027\u53d8\u6362\u4e3a\uff1a \\[ a = \\mathbf{W}^{-\\frac{1}{2}} \\xi \\] \u8fd9\u6837\u5c31\u627e\u5230\u4e86 \\(H_L\\) \u7684 1 \u4e2a\u7ef4\u5ea6\uff0c\u540c\u7406\uff0c\u6211\u4eec\u9009\u53d6 top L \u4e2a\u7ef4\u5ea6\uff0c\u5373\u5f97\u5230\u4e86 \\(H_L\\) \u3002 \u5b9a\u7406\u8bc1\u660e \u5047\u8bbe \\(\\lambda\\) \u662f \\(\\mathbf{AB}\\) \u7684\u4efb\u610f\u7279\u5f81\u503c\u3002 \\[ \\mathbf{AB}x = \\lambda x \\] \u4ee4 \\(y = \\mathbf{B}x\\) \uff0c\u5219\u6709\uff1a \\[ \\mathbf{A}y = \\lambda x \\] \u540c\u65f6\u5de6\u4e58 \\(\\mathbf{B}\\) \uff1a \\[ \\mathbf{BA}y = \\lambda \\mathbf{B}x = \\lambda y \\] \u4f8b\uff1a\u624b\u5199\u6570\u5b57\u5206\u7c7b \u624b\u5199\u6570\u5b57\u5206\u7c7b\u662f\u901a\u8fc7 8x8 \u7684\u624b\u5199\u6570\u5b57\u56fe\u7247\u5224\u65ad\u662f 0-9 \u4e2d\u7684\u54ea\u4e2a\u6570\u5b57\u3002\u663e\u7136\uff0c\u8fd9\u662f\u4e00\u4e2a\u5177\u6709 \\(p = 8 \\times 8 = 64\\) \u7ef4\u7279\u5f81\uff0c \\(K = 10\\) \u4e2a\u7c7b\u522b\u7684\u5206\u7c7b\u4efb\u52a1\u3002\u6211\u4eec\u53ef\u4ee5\u7528 sklearn \u5e93\u7684 LDA \u5f97\u5230\u4e0b\u9762\u7684\u7ed3\u679c\uff08\u964d\u81f3 2 \u7ef4 plot\uff09\uff1a import pandas as pd import numpy as np import scipy from sklearn import datasets digits = datasets . load_digits () X = pd . DataFrame ( digits . data , columns = digits . feature_names ) y = digits . target trainX = X [: len ( X ) // 2 ] trainY = y [: len ( y ) // 2 ] from sklearn.discriminant_analysis import LinearDiscriminantAnalysis model = LinearDiscriminantAnalysis ( n_components = 2 , solver = \"eigen\" , shrinkage = 0.01 ) . fit ( trainX , trainY ) # reduce rank to 2 dimension data reduceRankX = model . transform ( trainX ) \u663e\u7136\uff0c\u76f4\u63a5\u8c03\u5305\u9690\u85cf\u4e86\u592a\u591a\u7ec6\u8282\uff0c\u4e3a\u4e86\u52a0\u6df1\u7406\u89e3\uff0c\u6211\u4eec\u6839\u636e\u516c\u5f0f\u63a8\u5bfc\u81ea\u5df1\u624b\u52a8\u5b9e\u73b0\u4e00\u4e2a\uff1a def shrink ( cov , shrinkage ): dimensions = cov . shape [ 0 ] return ( 1 - shrinkage ) * cov + shrinkage * np . trace ( cov ) / dimensions * np . identity ( dimensions ) def my_lda ( X , y , n_components , shrinkage ): T = X . cov () W = X . groupby ( y ) . apply ( lambda g : g . cov () * ( len ( g ) - 1 ) ) . groupby ( level = 1 ) . sum () / X . shape [ 0 ] shrunkW = shrink ( W , shrinkage ) invShrunkW = np . linalg . inv ( shrunkW ) shrunkB = shrink ( T , shrinkage ) - shrunkW # eigen values is ascending eigenvalues , eigenvectors = np . linalg . eigh ( invShrunkW . dot ( shrunkB )) # eigen vectors with greatest eigen values xi = eigenvectors [:,:: - 1 ][:,: n_components ] # L = np.linalg.cholesky(invShrunkW) # return L.dot(xi) # W^{-1/2}, not Cholesky return scipy . linalg . sqrtm ( invShrunkW ) . dot ( xi ) \u5176\u4e2d\uff0c shrink \u51fd\u6570\u662f\u4e3a\u4e86\u5904\u7406\u5f53 \\(\\mathbf{W}\\) \u662f \u5947\u5f02\u77e9\u9635 (\u4e0d\u53ef\u9006)\u7684\u60c5\u5f62\u3002\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 shrunk covariance \u6765\u4f7f\u5176\u53d8\u4e3a\u53ef\u9006\u77e9\u9635\u518d\u5904\u7406\u3002\u8fd9\u5728\u8f93\u5165 \\(X\\) \u662f\u7a00\u758f\u77e9\u9635\u65f6\u5f88\u5e38\u89c1\uff0c\u4f8b\u5982\u624b\u5199\u6570\u5b57\u5206\u7c7b\u3002 \\[ \\mathbf{\\Sigma}_{\\text{shrunk}} = (1 - \\alpha) \\hat{\\mathbf{\\Sigma}} + \\alpha \\frac{\\mathop{tr} \\hat{\\mathbf{\\Sigma}}}{p} \\mathbf{I}\\] \u5176\u4e2d \\(\\alpha\\) \u662f shrinkage\uff0c \\(p\\) \u662f\u7279\u5f81\u7ef4\u5ea6\u3002 \u53e6\u5916\u8fd8\u9700\u8981\u6ce8\u610f\u533a\u5206\u77e9\u9635\u5e73\u65b9\u6839 sqrtm \u4e0e Cholesky Decomposition\u3002 \u77e9\u9635\u5e73\u65b9\u6839\u6307 \\(\\mathbf{B} \\mathbf{B} = \\mathbf{B}^T \\mathbf{B} = \\mathbf{A}\\) \uff0c\u8981\u6c42 \\(\\mathbf{B}\\) \u662f\u5bf9\u79f0\u77e9\u9635\u3002 Cholesky Decomposition \u6307 \\(\\mathbf{L}^T \\mathbf{L} = \\mathbf{A}\\) \uff0c\u8981\u6c42 \\(\\mathbf{L}\\) \u662f\u4e09\u89d2\u77e9\u9635\u3002 \u4f7f\u7528\u81ea\u5df1\u5b9e\u73b0\u7684 LDA \u5f97\u5230\u4e0e sklearn \u5b9e\u73b0\u7c7b\u4f3c\u7684\u7ed3\u679c\uff1a \u53ef\u4ee5\u770b\u51fa\uff0c\u5728\u964d\u5230 2 \u7ef4\u540e\uff0cLDA \u8fd8\u662f\u80fd\u591f\u6e05\u695a\u533a\u5206\u51fa\u6570\u5b57 0, 1, 2, 3, 4, 6\uff0c\u4f46\u662f\u5b58\u5728\u4e00\u4e9b\u6570\u5b57\u7684\u7c7b\u522b\u91cd\u53e0\u5728\u4e00\u8d77\u7684\u60c5\u51b5\u3002\u6b64\u65f6\u53ef\u4ee5 \u589e\u52a0\u7ef4\u5ea6 \\(L\\) \u89e3\u51b3\u3002 \u4e0b\u9762\u662f\u7b2c3\u30014 \u7ef4\uff1a \u53ef\u4ee5\u770b\u51fa\uff0c\u5b83\u8f83\u597d\u7684\u8865\u8db3\u4e86 1\u30012 \u7ef4\u65e0\u6cd5\u6b63\u786e\u5206\u7c7b\u7684\u6570\u5b57\u3002\u5bf9\u4e8e\u6570\u5b57 5\u30017 \u6709\u4e86\u6e05\u695a\u7684\u5206\u7c7b\u3002 4.4 Logistic regression \u903b\u8f91\u56de\u5f52\u5e0c\u671b\u7528\u8f93\u5165 \\(x\\) \u7684\u7ebf\u6027\u7ec4\u5408\u5efa\u6a21\u5c5e\u4e8e k \u7c7b\u7684\u540e\u9a8c\u6982\u7387\uff0c\u5e76\u4e14\u8981\u6c42\u6240\u6709\u6982\u7387\u4e4b\u548c\u4e3a 1\u3002 \u4ee5\u6700\u540e\u4e00\u4e2a\u7c7b\uff08K \u7c7b\uff09\u7684\u540e\u9a8c\u6982\u7387 \\(\\text{Pr} (G = K | X = x)\\) \u4e3a\u6bd4\u8f83\u57fa\u51c6\uff0c\u6709\uff1a \\[ \\ln \\frac{\\text{Pr} (G = k | X = x)}{\\text{Pr} (G = K | X = x)} = \\beta_{k0} + \\beta_{k1}^T x\\] \u53ef\u4ee5\u5199\u4e3a\uff1a \\[ \\text{Pr} (G = k | X = x) = \\begin{cases} \\dfrac{e^{\\beta_{k0} + \\beta_{k1}^Tx}}{1 + \\sum_{l=1}^{K-1} e^{\\beta_{l0} + \\beta_{l1}^Tx}}, & k = 1, 2, ..., K-1 \\\\ \\dfrac{1}{1 + \\sum_{l=1}^{K-1} e^{\\beta_{l0} + \\beta_{l1}^Tx}}, & k = K \\end{cases}\\] \u4e3a\u4ec0\u4e48\u4e0d\u76f4\u63a5\u5bf9\u6982\u7387\u8fdb\u884c\u5efa\u6a21\uff0c\u800c\u8981\u5bf9 logit \u51fd\u6570\u5efa\u6a21\u5462\uff1f\u8fd9\u662f\u56e0\u4e3a\u6982\u7387\u7684\u53d6\u503c\u8303\u56f4\u662f \\([0, 1]\\) \u800c\u7b49\u5f0f\u53f3\u8fb9\u7684\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u7684\u53d6\u503c\u8303\u56f4\u662f \\((-\\inf, +\\inf)\\) \u3002\u800c\u7531\u4e8e logit \u7684\u4e00\u4e2a\u91cd\u8981\u7279\u6027\u5c31\u662f\u6ca1\u6709\u4e0a\u4e0b\u9650\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5c1d\u8bd5\u7528\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u62df\u5408 logit\u3002 4.4.1 Fitting Logistic Regression Models \u5bf9\u4e8e\u7b2c k \u7c7b\u7684\u67d0\u4e2a\u6837\u672c i\uff0c\u6211\u4eec\u5e0c\u671b\u627e\u5230\u4e00\u7ec4\u6a21\u578b\u53c2\u6570 \\(\\theta\\) \uff0c\u4f7f\u6a21\u578b\u8ba4\u4e3a\u8be5\u6837\u672c\u5c5e\u4e8e k \u7684\u6982\u7387\uff08\u5373 \u6b63\u786e\u5206\u7c7b\u6982\u7387 \uff09\u5c3d\u91cf\u5927\u3002\u6211\u4eec\u5c06\u8fd9\u4e2a\u6982\u7387\u8ba1\u4f5c\uff1a \\[\\text{Pr} (G = k | X = x) = p_{k} (x; \\theta)\\] \u5219\u8be5\u4f18\u5316\u95ee\u9898\u662f\uff1a \\[\\begin{align} \\hat{\\theta} = \\mathop{\\arg \\max}_{\\theta} ~ p_{k} (x; \\theta) \\end{align}\\] \u5bf9\u4e8e\u6240\u6709\u6837\u672c\uff0c\u6211\u4eec\u76ee\u6807\u662f\u4ee4\u4ed6\u4eec \u88ab\u6b63\u786e\u5206\u7c7b\u7684\u6982\u7387\u548c\u6700\u5927 \uff1a \\[ \\ell (\\theta) = \\sum_{i=1}^N \\ln p_{g_i} (x_i; \\theta) \\] \u4e3a\u4e86\u7b80\u5316\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u53ea\u8003\u8651\u800c \\(K=2\\) \u5373 \u4e8c\u5206\u7c7b \u95ee\u9898\u60c5\u51b5\u3002\u6b64\u65f6\u6837\u672c\u8981\u4e48\u5c5e\u4e8e 1 \u7c7b\u8981\u4e48\u5c5e\u4e8e 2 \u7c7b\u3002 \u4e3a\u4e86\u7b80\u5355\u8868\u793a\uff1a \\[p_{k} (x; \\theta) = \\begin{cases} p_1 (x; \\theta), & k = 1 \\\\ 1 - p_1(x; \\theta), & k = 2 \\end{cases}\\] \u6211\u4eec\u53ef\u4ee5\u5047\u8bbe\u6837\u672c\u89c2\u6d4b\u503c \\(y_i = 1\\) \u4ee3\u8868\u5c5e\u4e8e\u7b2c 1 \u7c7b\uff0c \\(y_i = 0\\) \u4ee3\u8868 \u4e0d\u5c5e\u4e8e \u7b2c 1 \u7c7b\uff08\u90a3\u4e48\u80af\u5b9a\u5c5e\u4e8e\u7b2c 2 \u7c7b\uff09\u3002\u5219 \\[p_{k} (x_i; \\theta) = y_i p_1 (x_i; \\theta) + (1-y_i)(1-p_1(x_i; \\theta))\\] \u5219\u6709\uff1a \\[ \\begin{align} \\ell (\\theta) &= \\sum_{i=1}^N \\ln p_{g_i} (x_i; \\theta) \\\\ &= \\sum_{i=1}^N {y_i \\ln p_1 (x_i; \\theta) + (1-y_i) \\ln (1-p_1(x_i; \\theta))} \\\\ &= \\sum_{i=1}^N {\\ln(1 - p_1(x_i; \\theta)) + y_i \\ln \\frac{ p_1 (x_i; \\theta)}{1 - p_1 (x_i; \\theta)} } \\\\ &= \\sum_{i=1}^N {\\ln(1 - p_1(x_i; \\theta)) + y_i \\mathbf{\\beta}^Tx_i } \\\\ &= \\sum_{i=1}^N {y_i \\mathbf{\\beta}^Tx_i - \\ln(1 + e^{\\mathbf{\\beta}^Tx_i}) } \\end{align}\\] \u5176\u4e2d \\(\\mathbf{\\beta} = [ \\beta_{10}, \\beta_{11}, ... \\beta_{1p} ]\\) \uff0c\u5bf9\u5e94 \\(x = [1, x_1, x_2, ... x_p]\\) \u3002 \u6c42\u89e3\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u53ef\u4ee5\u4ee4\u5176\u5bf9 \\(\\beta\\) \u7684\u5bfc\u6570\u4e3a 0: \\[ \\frac{\\partial \\ell(\\beta)}{\\partial \\beta} = \\sum_{i=1}^N x_i(y_i - p_1(x_i; \\beta)) = 0, \\] \u4e3a\u4e86\u6c42\u89e3 \\(\\dfrac{\\partial \\ell(\\beta)}{\\partial \\beta} = 0\\) \uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u51f8\u4f18\u5316\u4e2d\u7684 Newton-Raphson \u6cd5\u3002\u5373\u9009\u53d6\u4e00\u4e2a\u4efb\u610f\u521d\u59cb \\(x_n\\) \uff08\u4e0d\u662f\u521d\u59cb\u89e3\uff0c\u56e0\u4e3a\u8981\u6c42\u7684\u5c31\u662f\u89e3\uff09\uff0c\u5e76\u53d6\u5176\u5207\u7ebf\u4e0e x \u8f74\u4ea4\u70b9 \\(x_{n+1}\\) \uff1a \\[ \\beta^{\\text{new}} = \\beta - (\\frac{\\partial^2 \\ell(\\beta)}{\\partial \\beta \\partial \\beta^T})^{-1} \\frac{\\partial \\ell(\\beta)}{\\partial \\beta}\\] \u5176\u4e2d \\((p+1) \\times (p+1)\\) \u7ef4 Hessian \u77e9\u9635\uff1a \\[\\begin{align} \\frac{\\partial^2 \\ell(\\beta)}{\\partial \\beta \\partial \\beta^T} &= - \\sum_{i=1}^N x_i \\frac{\\partial p_1(x_i; \\beta)}{\\partial \\beta^T} \\\\ &= - \\sum_{i=1}^N x_i \\dfrac{\\partial \\dfrac{e^{\\beta^T x_i}}{1 + e^{\\beta^T x_i}} }{\\partial \\beta^T} \\\\ &= - \\sum_{i=1}^N x_i \\frac{x_i^T e^{\\beta^T x_i}}{(1 + e^{\\beta^T x_i})^2} \\\\ &= -\\sum_{i=1}^N x_i x_i^T p_1(x_i; \\beta) (1 - p_1(x_i; \\beta)) \\end{align}\\] \u6211\u4eec\u5c06\u4ed6\u4eec\u5199\u6210\u77e9\u9635\u5f62\u5f0f\uff1a \\[ \\frac{\\partial \\ell(\\beta)}{\\partial \\beta} = \\mathbf{X}^T(\\mathbf{y} - \\mathbf{p})\\] \\[ \\frac{\\partial^2 \\ell(\\beta)}{\\partial \\beta \\partial \\beta^T} = \\mathbf{X}^T \\mathbf{W} \\mathbf{X} \\] \u5176\u4e2d \\(\\mathbf{X}\\) \u662f \\(N \\times (p+1)\\) \u77e9\u9635\uff0c \\(\\mathbf{y} - \\mathbf{p}\\) \u662f \\(N\\) \u7ef4\u5217\u5411\u91cf\uff0c \\(\\mathbf{W}\\) \u662f \\(N \\times N\\) \u5bf9\u89d2\u77e9\u9635\uff0c\u7b2c i \u4e2a\u5143\u7d20\u662f \\(p_1(x_i; \\beta) (1 - p_1(x_i; \\beta))\\) \u3002 \u5e26\u5165 Newton-Raphson \u516c\u5f0f\uff1a \\[\\begin{align} \\beta^{\\text{new}} &= \\beta - (\\frac{\\partial^2 \\ell(\\beta)}{\\partial \\beta \\partial \\beta^T})^{-1} \\frac{\\partial \\ell(\\beta)}{\\partial \\beta} \\\\ &= \\beta + (\\mathbf{X}^T \\mathbf{W} \\mathbf{X})^{-1} \\mathbf{X}^T(\\mathbf{y} - \\mathbf{p}) \\\\ &= (\\mathbf{X}^T \\mathbf{W} \\mathbf{X})^{-1}\\mathbf{X}^T \\mathbf{W}(\\mathbf{X}\\beta + \\mathbf{W}^{-1}(\\mathbf{y} - \\mathbf{p})) \\\\ &= (\\mathbf{X}^T \\mathbf{W} \\mathbf{X})^{-1}\\mathbf{X}^T \\mathbf{W}\\mathbf{z} \\end{align}\\] \u8fd9\u5c31\u662f \u8fed\u4ee3\u66f4\u65b0 \u7684\u8ba1\u7b97\u516c\u5f0f\u3002\u7531\u4e8e \\(\\mathbf{p}\\) \u548c \\(\\mathbf{W}\\) \u90fd\u968f \\(\\beta\\) \u53d8\u5316\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u5728\u6bcf\u8f6e\u8fed\u4ee3\u91cd\u65b0\u8ba1\u7b97\u4ed6\u4eec\u7684\u503c\u3002 \u4e0a\u5f0f\u4e2d\uff0c\u6211\u4eec\u5b9a\u4e49\u4e86\uff1a \\[ \\mathbf{z} = \\mathbf{X}\\beta + \\mathbf{W}^{-1}(\\mathbf{y} - \\mathbf{p}) \\] \u56de\u60f3 \u6700\u5c0f\u4e8c\u4e58\u6cd5 \u7684\u516c\u5f0f\uff1a \\[ \\hat{\\beta} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y} \\] \u53ef\u4ee5\u53d1\u73b0\u4e24\u8005\u975e\u5e38\u76f8\u4f3c\uff0c\u533a\u522b\u5728\u4e8e\u903b\u8f91\u56de\u5f52\u4e2d\u591a\u4e86\u4e00\u4e2a\u6743\u91cd\u5bf9\u89d2\u77e9\u9635 \\(\\mathbf{W}\\) \u3002\u56e0\u6b64\u8fd9\u4e2a\u7b97\u6cd5\u4e5f\u79f0\u4e3a iteratively reweighted least squares \uff08\u91cd\u65b0\u52a0\u6743\u8fed\u4ee3\u6700\u5c0f\u4e8c\u4e58\u6cd5\uff09\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u8fd8\u9700\u8981\u4e00\u4e2a \\(\\beta\\) \u7684 \u521d\u59cb\u503c \u3002\u4e00\u822c\u60c5\u51b5\u4e0b\u53ef\u4ee5\u9009 \\(\\beta = 0\\) \u3002\u8be5\u7b97\u6cd5 \u4e0d\u4fdd\u8bc1\u6536\u655b \u3002 \u4f8b\uff1a\u4e73\u817a\u764c\u8bca\u65ad \u8be5\u6848\u4f8b\u901a\u8fc7 30 \u7ef4\u7279\u5f81\u6765\u5224\u65ad\u4e73\u817a\u764c\u662f\u6076\u6027\u8fd8\u662f\u826f\u6027\uff0c\u662f\u4e00\u4e2a\u5178\u578b\u7684 2 \u5206\u7c7b\u95ee\u9898\u3002 import pandas as pd import numpy as np from sklearn import datasets , model_selection def load_sklearn_data ( sk_data ): X = pd . DataFrame ( sk_data . data , columns = sk_data . feature_names ) y = pd . Series ( sk_data . target , name = \"target\" ) . apply ( lambda index : sk_data . target_names [ index ]) . astype ( \"category\" ) return X , y X , y = load_sklearn_data ( datasets . load_breast_cancer ()) X_train , X_test , y_train , y_test = model_selection . train_test_split ( X , y , test_size = 0.2 ) from sklearn.metrics import accuracy_score from sklearn.linear_model import LogisticRegression model = LogisticRegression ( solver = \"newton-cg\" ) . fit ( X_train , y_train ) accuracy_score ( model . predict ( X_test ), y_test ) \u7ed3\u679c\u662f 0.9385964912280702 \u3002\u6211\u4eec\u518d\u7528\u81ea\u5df1\u5b9e\u73b0\u7684 LR \u8fdb\u884c\u5224\u65ad\uff1a def sigmoid ( x , beta ): tmp = np . exp ( x . dot ( beta )) return tmp / ( 1 + tmp ) class MyLogisticRegression : def __init__ ( self , max_iter , tolerance = 0.01 ): self . max_iter_ = max_iter self . tolerance_ = tolerance self . beta = None def fit ( self , train_X , train_y ): N , p = train_X . shape X = train_X . to_numpy () X = np . concatenate (( np . atleast_2d ( np . ones ( N )) . T , train_X . to_numpy ()), axis = 1 ) self . beta = np . zeros ( p + 1 ) beta = self . beta for i in range ( self . max_iter_ ): prob = np . apply_along_axis ( sigmoid , 1 , X , beta ) W = np . diag ( prob * ( 1 - prob )) z = X . dot ( beta ) + np . linalg . inv ( W ) . dot ( train_y . cat . codes - prob ) new_beta = np . linalg . inv ( X . T @ W @ X ) @ X . T @ W . dot ( z ) beta = new_beta self . beta = beta def predict ( self , test_X ): X = test_X . copy () X . insert ( 0 , \"x_0\" , np . ones ( test_X . shape [ 0 ])) prob = X . apply ( lambda row : sigmoid ( row , self . beta ), axis = 1 ) return prob . apply ( lambda x : 1 if x >= 0.5 else 0 ) \u6839\u636e\u516c\u5f0f\u5199\u4ee3\u7801\uff0c\u6ce8\u610f \\(\\beta\\) \u7684\u8fed\u4ee3\u66f4\u65b0\u5373\u53ef\u3002\u6700\u5927\u7684\u96be\u5ea6\u662f\u7ec8\u6b62\u6761\u4ef6\uff0c\u56e0\u4e3a\u8fed\u4ee3\u6570\u6b21\u4e4b\u540e\u4f1a\u9047\u5230 Hessian \u77e9\u9635 \\(\\mathbf{X}^T \\mathbf{W} \\mathbf{X}\\) \u6210\u4e86\u5947\u5f02\u77e9\u9635\u7684\u95ee\u9898\u3002 \u8fd0\u884c\u7684\u7ed3\u679c\u8868\u660e\u5206\u7c7b\u6b63\u786e\u7387\u53ef\u4ee5\u8fbe\u5230 0.9473684210526315 \u3002 TODO: how to find a stopping criteria? 4.4.5 Logistic Regression or LDA? \u5728 4.3 \u4e2d\u6211\u4eec\u4ecb\u7ecd\u4e86 LDA\uff0c\u56de\u5fc6\u5176\u5224\u65ad\u67d0\u4e2a\u6837\u672c\u5c5e\u4e8e \\(k\\) \u8fd8\u662f \\(l\\) \u7684\u51fd\u6570\uff08\u5f53\u8be5\u5f0f\u5927\u4e8e 0 \u65f6\u5c5e\u4e8e \\(k\\) \u7c7b\uff09\uff1a \\[\\begin{align} \\ln \\frac{\\text{Pr}(G=k | X=x)}{\\text{Pr}(G=l | X=x)} &= \\ln \\frac{f_k(x) \\pi_k}{ f_l(x) \\pi_l} \\\\ &= \\ln \\frac{\\pi_k}{\\pi_l} - \\frac{1}{2}(\\mu_k + \\mu_l) \\mathbf{\\Sigma}^{-1} (\\mu_k - \\mu_l) + x^T \\mathbf{\\Sigma}^{-1} (\\mu_k - \\mu_l) \\\\ &= \\alpha_{k0} + \\alpha_{k1}^T x \\end{align}\\] \u53ef\u4ee5\u770b\u51fa\u5176\u5f62\u5f0f\u4e0e logistic regression \u4e00\u81f4\uff1a \\[\\ln \\frac{\\text{Pr}(G=k | X=x)}{\\text{Pr}(G=l | X=x)} = \\beta_{k0} + \\beta_{k1}^T x\\] \u90a3\u4e48\u4ed6\u4eec\u4fe9\u662f\u4e0d\u662f\u4e00\u6837\u7684\u65b9\u6cd5\u5462\uff1f\u5e76\u4e0d\u662f\u3002\u4ed6\u4eec\u7684\u4e3b\u8981\u533a\u522b\u662f\uff1a \u5047\u8bbe\u4e0d\u540c\u3002LDA \u5047\u8bbe\u4e86 \\(x\\) \u670d\u4ece\u6b63\u6001\u5206\u5e03\uff0c\u4e14\u5404\u4e2a\u7c7b\u7684\u534f\u65b9\u5dee\u77e9\u9635\u76f8\u540c\u3002LR \u6ca1\u6709\u9650\u5b9a \\(x\\) \u7684\u5206\u5e03\u3002\u7531\u4e8e LDA \u5047\u8bbe\u4e86\u6b63\u6001\u5206\u5e03\uff0c\u5b83\u5bf9\u4e8e\u6781\u7aef\u7684 outlier \u9c81\u68d2\u6027\u5dee\uff08\u4f1a\u5f71\u54cd\u5206\u5e03\u51fd\u6570)\u3002 \u4f18\u5316\u76ee\u6807\u4e0d\u540c\u3002LDA \u6700\u5927\u5316 full log-likelihood\uff0c\u9700\u8981\u8003\u8651 \\(x\\) \u7684\u8fb9\u7f18\u5206\u5e03\u51fd\u6570\u3002LR \u6700\u5927\u5316 conditional likelihood\uff0c\u4e0d\u9700\u8981\u8003\u8651 \\(x\\) \u7684\u8fb9\u7f18\u5206\u5e03\u51fd\u6570\u3002 \u6bd4\u8f83\u96be\u7406\u89e3\u7684\u662f\u7b2c\u4e8c\u70b9\u3002 \u9996\u5148\uff0c\u6839\u636e Bayes \u516c\u5f0f\uff0c\u5728\u5df2\u77e5 B \u53d1\u751f\u65f6\uff0cA \u7684\u6761\u4ef6\u6982\u7387\u4e3a\uff1a \\[ P(A|B) = \\frac{P( A \\cap B ) }{P(B)} \\] \u56e0\u6b64\u5bf9\u4e8e\u5206\u7c7b\u95ee\u9898\uff0c \u6761\u4ef6\u6982\u7387(conditional likelihood) \u662f \u5728\u5df2\u77e5 \\(X = x\\) \u65f6\uff0c\u6837\u672c\u7c7b\u522b \\(G = k\\) \u7c7b\u7684\u6982\u7387 \u3002\u5b83\u4e0e \u5168\u6982\u7387(full likelihood) \u4e4b\u95f4\u5b58\u5728\u5173\u7cfb\uff1a \\[\\begin{align} \\text{Pr}(G=k | X=x) &= \\frac{\\text{Pr}(X, G=k)}{\\text{Pr}(X)} \\\\ &= \\frac{\\text{Pr}(X, G=k)}{\\sum_{l=1}^K \\text{Pr}(X, G=l)} \\\\ \\end{align}\\] LDA \u7684\u76ee\u6807\u662f\u627e\u5230\u4e00\u4e2a\u7c7b\u522b \\(k\\) \u4f7f\u5f97\u540e\u9a8c\u6982\u7387\u6700\u5927\uff0c\u5373\uff1a \\[\\begin{align} \\hat{k} &= \\mathop{\\arg \\max}_{k} \\text{Pr}(G=k | X=x) \\\\ &= \\mathop{\\arg \\max}_{k} \\frac{\\text{Pr}(X, G=k)}{\\sum_{l=1}^K \\text{Pr}(X, G=l)} \\end{align}\\] LDA \u9009\u62e9 \u5bf9\u5168\u6982\u7387\u5efa\u6a21 \uff0c\u9700\u8981\u77e5\u9053 \\(x\\) \u7684\u5728\u6bcf\u4e2a\u7c7b\u7684\u5bc6\u5ea6\u51fd\u6570 \\(f_i(x)\\) \uff0cLDA \u5047\u8bbe\u5176\u4e3a\u6b63\u6001\u5206\u5e03\uff0c\u4e14\u534f\u65b9\u5dee\u76f8\u7b49\u3002\u5168\u6982\u7387\u4e3a\uff1a \\[ \\text{Pr}(X, G=k) = f_k(x) \\pi_k = \\phi(x; \\mu_k, \\mathbf{\\Sigma}) \\pi_k \\] \u6240\u4ee5\u8bf4\u5b83\u8003\u8651\u7684\u662f full log-likelihood\u3002 \u5bf9\u4e8e LR\uff0c\u5b83\u76f4\u63a5 \u5bf9\u6761\u4ef6\u6982\u7387\u5efa\u6a21 \u3002\u5373\u5047\u8bbe\u5b58\u5728\u4e00\u7ec4 \\(\\beta\\) \u80fd\u591f\u4f7f\u6761\u4ef6\u6982\u7387\u7684 log ratio \u548c \\(x\\) \u6709\u5982\u4e0b\u7ebf\u6027\u5173\u7cfb\uff1a \\[\\ln \\frac{\\text{Pr}(G=k | X=x)}{\\text{Pr}(G=l | X=x)} = \\beta_{k0} + \\beta_{k1}^T x\\] \u5e76\u4e14\uff0c\u8fd9\u4e00\u7ec4 \\(\\beta\\) \u4f7f \u6240\u6709\u6837\u672c\u6b63\u786e\u5206\u7c7b\u7684\u6982\u7387\u548c \u6700\u5927\uff1a \\[\\begin{align} \\hat{\\theta} &= \\mathop{\\arg \\max}_{\\theta} ~ \\ell (\\theta) \\\\ &= \\mathop{\\arg \\max}_{\\theta} ~ \\sum_{i=1}^N \\ln p_{g_i} (x_i; \\theta) \\\\ &= \\sum_{i=1}^N y_i \\mathbf{\\beta}^Tx_i - \\ln(1 + e^{\\mathbf{\\beta}^Tx_i}) \\end{align}\\] \u5176\u4e2d\u4e0d\u5305\u542b\u4efb\u4f55\u4e0e\u8fb9\u7f18\u5bc6\u5ea6\u51fd\u6570 \\(\\text{Pr}(X)\\) \u76f8\u5173\u7684\u90e8\u5206\uff0c\u4e5f\u6ca1\u6709\u5047\u8bbe \\(x\\) \u7684\u5206\u5e03\u3002\u56e0\u6b64\u8bf4\u5b83\u53ea\u8003\u8651 conditional likelihood\u3002 Reference masking in linear regression for multiple classes Linear discriminant analysis, explained shrunk covariance between-class scatter matrix calculation \u903b\u8f91\u56de\u5f52 Implementing logistic regression from scratch in Python","title":"ESL 4: Linear Methods for Classification"},{"location":"mathematics/ESL/ESL4_LinearMethodsForClassification/#esl-4-linear-methods-for-classification","text":"","title":"ESL 4: Linear Methods for Classification"},{"location":"mathematics/ESL/ESL4_LinearMethodsForClassification/#42-linear-regression-of-an-indicator-matrix","text":"\u5bf9\u4e8e\u5206\u7c7b\u95ee\u9898\uff0c\u6211\u4eec\u53ef\u4ee5\u628a\u6bcf\u4e2a\u5206\u7c7b\u7528 indicator variable \u6765\u7f16\u7801\u3002 \u4f8b\u5982\uff0c\u5982\u679c\u6709 \\(K\\) \u4e2a\u7c7b\u578b\uff0c\u6211\u4eec\u53ef\u4ee5\u5b9a\u4e49\uff1a \\[ \\textbf{y} = [y_1, ..., y_K]^T \\] \u5f53\u6837\u672c\u662f\u7b2c \\(i\\) \u7c7b\u65f6\uff0c \\(y_i = 1\\) \uff0c\u5176\u5b83\u503c\u4e3a 0\u3002 \u5f53\u6211\u4eec\u6709 N \u4e2a\u6837\u672c\u65f6\uff0c\u53ef\u4ee5\u5199\u6210\u4e00\u4e2a \\(N \\times K\\) \u77e9\u9635\uff08indicator response matrix\uff09\uff1a \\[ \\textbf{Y} = [\\textbf{y}_1, ..., \\textbf{y}_N]^T \\] \u8fd9\u4e2a\u77e9\u9635\u6bcf\u4e00\u884c\u4ec5\u6709\u4e00\u4e2a 1\uff0c\u5176\u4f59\u503c\u4e3a 0\u3002\u8fd9\u4e2a 1 \u4ee3\u8868\u8be5\u884c\u6837\u672c\u7684\u7c7b\u578b\u3002 \u8fd9\u5b9e\u9645\u4e0a\u5c31\u662f one-hot \u7f16\u7801\uff0c\u8fd9\u79cd\u7f16\u7801\u76f8\u5bf9\u4e8e\u76f4\u63a5\u4f7f\u7528\u6574\u6570 \\(1, ..., K\\) \u6765\u8868\u793a\u7684\u6709\u4f18\u52bf\u5728\u4e8e \u7c7b\u578b\u95f4\u7684\u8ddd\u79bb\u90fd\u662f\u4e00\u6837\u7684 \u3002 \u5229\u7528\u7b2c\u4e09\u7ae0\u7684 Linear Regression\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u51fa\u7cfb\u6570\u77e9\u9635 \\(\\hat{\\textbf{B}}\\) \uff1a \\[ \\hat{\\textbf{B}} = \\textbf{X}(\\textbf{X}^T \\textbf{X})^{-1} \\textbf{X}^T \\textbf{Y} \\] \\(\\hat{\\textbf{B}}\\) \u662f\u4e00\u4e2a \\((p+1) \\times K\\) \u7684\u77e9\u9635\u3002 \\(\\textbf{X}\\) \u662f \\(N \\times (p+1)\\) \u77e9\u9635\u3002 \u5f97\u5230\u4f30\u8ba1\u503c\uff1a \\[ \\hat{\\textbf{Y}} = \\textbf{X}(\\textbf{X}^T \\textbf{X})^{-1} \\textbf{X}^T \\textbf{Y}\\] \u8be5\u65b9\u6cd5\u7684\u6b65\u9aa4\u662f\uff1a \u5bf9\u7c7b\u578b\u8fdb\u884c one-hot \u7f16\u7801\u5f97\u5230 \\(\\textbf{Y}\\) \u5c06\u95ee\u9898\u89c6\u4f5c\u4e00\u4e2a\u591a\u53d8\u91cf\u7684\u7ebf\u6027\u56de\u5f52\u95ee\u9898\uff0c\u5bf9 one-hot \u7f16\u7801\u540e\u7684\u6bcf\u4e2a bit \u8fdb\u884c\u62df\u5408\u5f97\u5230 \\(\\hat{\\textbf{B}}\\) \u5728\u5224\u65ad\u7c7b\u522b\u65f6\uff0c\u9009\u62e9 \\(\\textbf{X}\\hat{\\textbf{B}}\\) \u6bcf\u884c\u7684\u6700\u5927\u503c\u6240\u8868\u793a\u7684\u7c7b\u578b \u4f7f\u7528 Linear Regression \u89e3\u51b3\u5206\u7c7b\u95ee\u9898\u7684\u6700\u5927\u95ee\u9898\u5728\u4e8e\uff0c\u5f53\u7c7b\u522b\u6570 \\(K \\leq 3\\) \u65f6\uff0c\u53ef\u80fd\u4f1a\u51fa\u73b0\u67d0\u4e2a\u7c7b\u88ab\u63a9\u76d6\uff08mask\uff09\u7684\u60c5\u51b5\u3002\u5176\u672c\u8d28\u539f\u56e0\u662f Linear Regression \u7684\u201c\u521a\u6027\u201d\u7279\u8d28\uff0c\u5373\u5b83\u7684\u5206\u754c\u9762\u662f\u4e0d\u591f\u7075\u6d3b\u7684\u3002 \u4e3e\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\uff0c\u5bf9\u4e8e\u4ee5\u4e0b\u4e09\u4e2a 1 \u7ef4\u6b63\u6001\u5206\u5e03\uff1a class1: \\(x \\sim N(1, 1)\\) class2: \\(x \\sim N(5, 1)\\) class3: \\(x \\sim N(9, 1)\\) \u5206\u5e03\u5982\u4e0b\uff1a \u5982\u679c\u6211\u4eec\u7528 Linear Regression \u62df\u5408\uff0c\u90a3\u6211\u4eec\u53ef\u4ee5\u5f97\u5230 3 \u7ec4 \\(\\beta_0, \\beta_1\\) \uff0c\u5206\u522b\u5bf9\u5e94\u7b2c \\(i\\) \u7ec4\uff0c\u53ef\u4ee5\u7528\u6765\u8ba1\u7b97 \\(y_i\\) \u7684\u503c\uff1a \\[ y_i = \\beta_0 + \\beta_1 x \\] \u53ef\u4ee5\u770b\u5230\uff0c \\(y_1\\) \uff08\u5bf9\u5e94class2\uff09\u4ece\u6765\u4e0d\u662f\u6700\u5927\u503c\u3002\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u7684\u5206\u7c7b\u7ed3\u679c\u4e2d\u53ea\u6709 class1 \u548c class3 \u4e86\uff0cclass2 \u88ab mask \u4e86\u3002\u53ef\u4ee5\u901a\u8fc7\u7ed3\u679c\u9a8c\u8bc1\uff1a pd . DataFrame ( X * B ) . T . idxmax () . value_counts () # 2 1505 # 0 1495 # dtype: int64 \u4ee3\u7801\uff1a import numpy as np import pandas as pd def generate_nd_sample ( name , mu_array , sigma , N ): xx = {} for i in range ( 1 , len ( mu_array ) + 1 ): xi = np . random . normal ( mu_array [ i - 1 ], sigma , N ) xx [ f \"x { i } \" ] = xi xx [ \"name\" ] = name return pd . DataFrame ( xx ) . astype ({ \"name\" : \"category\" }) s1 = generate_nd_sample ( \"class1\" , [ 1 ], 1 , 1000 ) s2 = generate_nd_sample ( \"class2\" , [ 5 ], 1 , 1000 ) s3 = generate_nd_sample ( \"class3\" , [ 9 ], 1 , 1000 ) s = pd . concat ([ s1 , s2 , s3 ]) . reset_index ( drop = True ) # Linear Regression tmp = s . copy () tmp . insert ( 0 , \"ones\" , np . ones ( s . shape [ 0 ])) X = np . matrix ( tmp . drop ( \"name\" , axis = 1 ) . to_numpy () . T ) . T Y = np . matrix ( pd . get_dummies ( s . name )) def LR_beta ( X , Y ): # class count K = Y . shape [ 1 ] return ( X . T * X ) . I * X . T * Y B = LR_beta ( X , Y ) # Plot from bokeh.io import output_notebook output_notebook () from bokeh.palettes import viridis from bokeh.plotting import figure , show import itertools def create_histogram_figure ( sample_data ): # sample data must be like: # | x | category | assert sample_data . shape [ 1 ] == 2 , \"input must be of shape (N, 2)\" x = sample_data . iloc [:, 0 ] categories = sample_data . iloc [:, 1 ] . unique () fig = figure ( x_axis_label = x . name , y_axis_label = \"counts\" ) color_gen = itertools . cycle ( viridis ( len ( categories ))) for ( category , color ) in zip ( categories , color_gen ): data = sample_data [ sample_data . iloc [:, 1 ] == category ] counts , bins = np . histogram ( data . iloc [:, 0 ], bins = 'auto' ) fig . quad ( top = counts , bottom = 0 , left = bins [: - 1 ], right = bins [ 1 :], alpha = 0.5 , color = color , legend_label = str ( category )) return fig def create_line_figure ( lines , x_start , x_end ): fig = figure ( x_axis_label = \"x\" , y_axis_label = \"y\" ) color_gen = itertools . cycle ( viridis ( lines . shape [ 0 ])) for i in range ( lines . shape [ 0 ]): b0 , b1 = lines [ i , 0 ], lines [ i , 1 ] fig . line ( x = [ x_start , x_end ], y = [ b0 + b1 * x_start , b0 + b1 * x_end ], line_width = 2 , alpha = 0.5 , color = next ( color_gen ), legend_label = f \"y { i } = { b0 : .6f } + { b1 : .6f } x\" ) return fig hist_fig = create_histogram_figure ( s ) line_fig = create_line_figure ( B . T , s . x1 . min (), s . x1 . max ()) from bokeh import layouts show ( layouts . column ( hist_fig , line_fig ))","title":"4.2 Linear Regression of an Indicator Matrix"},{"location":"mathematics/ESL/ESL4_LinearMethodsForClassification/#43-linear-discriminant-analysis","text":"\u4e3a\u4e86\u83b7\u5f97\u6700\u4f18\u7684\u5206\u7c7b\u7ed3\u679c\uff0c\u6211\u4eec\u9700\u8981\u77e5\u9053\u540e\u9a8c\u6982\u7387\uff08 \\(X = x\\) \u65f6\u5c5e\u4e8e\u7b2c \\(k\\) \u7c7b\u7684\u6982\u7387\uff09\uff1a \\[ \\text{Pr}(G=k | X=x) = \\frac{f_k(x) \\pi_k}{\\sum_{i=1}^K f_i(x) \\pi_i}\\] \u56e0\u4e3a\u672c\u8d28\u4e0a\uff0c\u6211\u4eec\u662f\u5728\u627e\u5230\u4e00\u4e2a k \u4f7f\u5f97\u540e\u9a8c\u6982\u7387\u6700\u5927\uff0c\u5373\uff1a \\[\\begin{align} \\hat{k} &= \\mathop{\\arg \\max}_{k} \\text{Pr}(G=k | X=x) \\\\ &= \\mathop{\\arg \\max}_{k} f_k(x) \\pi_k \\\\ &= \\mathop{\\arg \\max}_{k} [\\ln(f_k(x)) + \\ln(\\pi_k)] \\end{align}\\] \u8fd9\u88ab\u79f0\u4e3a \u5224\u522b\u51fd\u6570 \uff08discriminant function\uff09\uff0c\u5176\u4e2d\uff1a \\(f_i(x)\\) \u662f\u7b2c i \u7c7b\u6837\u672c\u53d6 x \u7684\u6982\u7387 \\(\\pi_i\\) \u662f\u5c5e\u4e8e\u7b2c i \u7c7b\u7684\u5148\u9a8c\u6982\u7387 \u8fd9\u91cc\u7684\u96be\u70b9\u5728\u4e8e\u786e\u5b9a \\(f_i(x)\\) \uff0c\u663e\u7136 \\(\\pi_i\\) \u7684\u4f30\u8ba1\u662f\u53ef\u4ee5\u901a\u8fc7\u6837\u672c\u6570\u636e\u76f4\u63a5\u5f97\u5230\u7684\u3002 \u7ebf\u6027\u5224\u522b\u5206\u6790\uff08Linear Discriminant Analysis, LDA\uff09 \u5047\u8bbe\u53d8\u91cf X \u670d\u4ece\u591a\u7ef4\u9ad8\u65af\u5206\u5e03 \uff08X \u5305\u542b\u591a\u7ef4\uff09\uff1a \\[ f_k(x) = \\frac{1}{(2 \\pi)^{p/2} |\\mathbf{\\Sigma}_k|^{1/2}} e^{-\\frac{1}{2}(x - \\mu_k)^T \\mathbf{\\Sigma}_k^{-1} (x - \\mu_k)} \\] \u5e26\u5165\u6700\u4f18\u5206\u7c7b\u7684\u5f0f\u5b50, \u9010\u6b65\u53bb\u6389\u4e0e \\(k\\) \u65e0\u5173\u7684\u90e8\u5206\uff1a \\[\\begin{align} \\hat{k} &= \\mathop{\\arg \\max}_{k} [\\ln(f_k(x)) + \\ln(\\pi_k)] \\\\ &= \\mathop{\\arg \\max}_{k} [- \\ln((2 \\pi)^{p/2} |\\mathbf{ \\Sigma }_k|^{1/2}) - \\frac{1}{2}(x - \\mu_k)^T \\mathbf{ \\Sigma }_k^{-1} (x - \\mu_k) + \\ln(\\pi_k)] \\\\ &= \\mathop{\\arg \\max}_{k} [- \\frac{1}{2} \\ln |\\mathbf{ \\Sigma }_k| - \\frac{1}{2}(x - \\mu_k)^T \\mathbf{\\Sigma}_k^{-1} (x - \\mu_k) + \\ln(\\pi_k)] \\\\ \\end{align}\\] \u6b64\u65f6\uff0c\u5224\u522b\u51fd\u6570\u4e3a\uff1a \\[\\delta_k(x) = - \\frac{1}{2} \\ln |\\mathbf{ \\Sigma }_k| - \\frac{1}{2}(x - \\mu_k)^T \\mathbf{\\Sigma}_k^{-1} (x - \\mu_k) + \\ln(\\pi_k)\\] \u662f \\(x\\) \u7684\u4e8c\u6b21\u51fd\u6570\u3002\u56e0\u6b64\u79f0\u4e3a\u4e8c\u6b21\u5224\u522b\u5206\u6790(Quadratic Discriminant Analysis, QDA)\u3002 \u6211\u4eec\u518d \u5047\u8bbe\u6bcf\u4e2a\u7c7b\u4e2d\u53d8\u91cf X \u5206\u5e03\u7684\u65b9\u5dee\u662f\u76f8\u7b49\u7684 \uff0c\u5219 \\(\\mathbf{\\Sigma}\\) \u4e5f\u4e0e \\(k\\) \u65e0\u5173\u4e86\uff0c\u53ef\u4ee5\u8fdb\u6b65\u4e00\u5316\u7b80\u5224\u522b\u51fd\u6570\u4e3a\uff1a \\[\\delta_k(x) = x^T\\mathbf{\\Sigma}^{-1}\\mu_k - \\frac{1}{2}\\mu_k^T\\mathbf{\\Sigma}^{-1} \\mu_k + \\ln(\\pi_k)\\] \u6211\u4eec\u53ef\u4ee5\u770b\u51fa\uff0c\u5316\u7b80\u540e\u5224\u522b\u51fd\u6570\u5bf9\u4e8e \\(x\\) \u662f \u7ebf\u6027 \u7684\u3002\u8fd9\u8bf4\u660e\u4e24\u4e2a\u7c7b\u7684\u5206\u754c\u9762\uff08\u5373\u5224\u522b\u51fd\u6570\u76f8\u7b49\u65f6\uff09\u4e5f\u662f\u7ebf\u6027\u7684\u3002\u56e0\u6b64\u53eb\u505a\u7ebf\u6027\u5224\u522b\u5206\u6790(Linear Discriminant Analysis, LDA)\u3002 \u5b9e\u9645\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u6837\u672c\u4f30\u8ba1\u9ad8\u65af\u5206\u5e03\u7684\u53c2\u6570\uff1a \\(\\hat{\\pi}_k = N_k / N\\) \uff0c\u5373\u7b2c k \u7c7b\u7684\u6837\u672c\u6570\u5360\u603b\u6837\u672c\u6570\u7684\u6bd4\u4f8b \\(\\hat{\\mu}_k = \\sum_{g_i = k} x_i / N_k\\) \uff0c\u5373\u7b2c k \u7c7b\u6837\u672c X \u7684\u5e73\u5747\u503c \\(\\hat{\\mathbf{\\Sigma}} = \\sum_{k=1}^K \\sum_{g_i = k} (x_i - \\hat{\\mu}_k)(x_i - \\hat{\\mu}_k)^T / (N - K)\\) \uff0c\u5bf9\u534f\u65b9\u5dee\u77e9\u9635\u7684\u65e0\u504f\u4f30\u8ba1\uff0c\u8bc1\u660e\u5728 ESL3 \u4e2d \u6709\u4e86\u5224\u522b\u51fd\u6570\u7684\u8868\u8fbe\u5f0f \\(\\delta_k(x)\\) \uff0c\u6211\u4eec\u53ea\u9700\u8981\u4f9d\u6b21\u5e26\u5165 \\(k = 1, ..., K\\) , \u5f53\u5f97\u5230\u7684 \\(\\delta_k(x)\\) \u6700\u5927\u65f6\u7684 \\(k\\) \u5373\u4e3a\u6700\u4f73\u5206\u7c7b\u3002","title":"4.3 Linear discriminant analysis"},{"location":"mathematics/ESL/ESL4_LinearMethodsForClassification/#432-computation-of-lda","text":"\u534f\u65b9\u5dee\u77e9\u9635 \\(\\mathbf{\\Sigma}\\) \u662f\u4e00\u4e2a\u5bf9\u79f0\u77e9\u9635\uff0c\u53ef\u4ee5\u8fdb\u884c\u7279\u5f81\u503c\u5206\u89e3\uff1a \\[ \\mathbf{\\Sigma} = \\mathbf{Q}\\mathbf{\\Lambda}\\mathbf{Q}^T \\] \u5176\u4e2d\uff1a \\(\\mathbf{Q}\\) \u662f\u5355\u4f4d\u6b63\u4ea4\u77e9\u9635\uff0c \\(\\mathbf{\\Lambda}\\) \u662f\u5bf9\u89d2\u9635\u3002\u5e26\u5165\u5224\u522b\u51fd\u6570\u6709\uff1a \\[\\begin{align} \\delta_k(x) &= x^T\\mathbf{\\Sigma}^{-1}\\mu_k - \\frac{1}{2}\\mu_k^T\\mathbf{\\Sigma}^{-1} \\mu_k + \\ln(\\pi_k) \\\\ &= x^T\\mathbf{Q}^{T}\\mathbf{\\Lambda}^{-1}\\mathbf{Q}\\mu_k - \\frac{1}{2}\\mu_k^T\\mathbf{Q}^{T}\\mathbf{\\Lambda}^{-1}\\mathbf{Q}\\mu_k + \\ln(\\pi_k) \\end{align}\\] \u4ee4\uff1a \\[ x^{*} = \\mathbf{\\Lambda}^{-\\frac{1}{2}}\\mathbf{Q}x \\] \\[ \\mu^{*} = \\mathbf{\\Lambda}^{-\\frac{1}{2}}\\mathbf{Q} \\mu \\] \u6709\uff1a \\[ \\delta_k(x^{*}) = x^{* T}\\mu_k^{*} - \\frac{1}{2}\\mu_k^{* T} \\mu_k^{*} + \\ln(\\pi_k) \\] \u5f53\u6211\u4eec\u5224\u65ad\u67d0\u4e2a\u6837\u672c \\(x_1\\) \u5c5e\u4e8e m \u548c n \u4e2d\u7684\u54ea\u4e00\u4e2a\u7c7b\u65f6\uff0c\u53ef\u4ee5\u6bd4\u8f83\u5176\u5224\u522b\u51fd\u6570\uff0c\u6211\u4eec\u5224\u65ad\u5b83\u662f m \u7c7b\u5982\u679c\u6ee1\u8db3\uff1a \\[ \\delta_m(x_1^*) > \\delta_n(x_1^*) \\] \u5e26\u5165\u8868\u8fbe\u5f0f\u6709\uff1a \\[ x^{*T} (\\mu^*_m - \\mu^*_n) > \\frac{1}{2} (\\mu^*_m + \\mu^*_n)^T(\\mu^*_m - \\mu^*_n) - \\ln(\\pi_m/\\pi_n)\\] \u8fd9\u6837\u770b\u8d77\u6765\u5c31\u975e\u5e38\u76f4\u89c2\u4e86\u3002 LDA \u662f\u5c06\u6837\u672c\u6295\u5f71\u5728\u4e24\u4e2a\u7c7b\u4e2d\u5fc3\u7684\u8fde\u7ebf\u4e0a\uff0c\u5e76\u4e14\u6bd4\u8f83\u5b83\u66f4\u9760\u8fd1\u54ea\u4e00\u8fb9\uff0c\u4ee5\u6b64\u51b3\u5b9a\u5b83\u5c5e\u4e8e\u54ea\u4e2a\u7c7b \u3002\u5f53\u7136\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u8fd8\u8003\u8651\u4e86\u4e24\u4e2a\u7c7b\u7684\u5148\u9a8c\u6982\u7387\uff08 \\(\\ln(\\pi_m/\\pi_n)\\) \u9879\uff09\u3002","title":"4.3.2 Computation of LDA"},{"location":"mathematics/ESL/ESL4_LinearMethodsForClassification/#433-reduced-rank-linear-discriminant-analysis","text":"LDA \u4e5f\u662f\u4e00\u79cd\u964d\u7ef4\u7684\u624b\u6bb5\u3002\u5047\u8bbe\u6211\u4eec\u6709 \\(p\\) \u7ef4\u7279\u5f81\uff0c \\(K\\) \u4e2a\u7c7b\u522b\u3002\u6839\u636e 4.3.2 \u4e2d\u4ecb\u7ecd\u7684\u8ba1\u7b97\u65b9\u5f0f\uff0c\u6211\u4eec\u4e00\u5171\u6709 \\(K\\) \u4e2a\u7c7b\u4e2d\u5fc3\u70b9\u3002\u4ed6\u4eec\u4e00\u5b9a\u5728\u4e00\u4e2a\u6700\u9ad8 \\(K-1\\) \u7ef4\u7684\u7a7a\u95f4\u91cc\u3002","title":"4.3.3 Reduced-Rank Linear Discriminant Analysis"},{"location":"mathematics/ESL/ESL4_LinearMethodsForClassification/#_1","text":"\u4f8b\u5982\uff0c\u5bf9\u4e8e 2 \u4e2a\u7c7b\u7684\u5206\u7c7b\u95ee\u9898\uff0c \u65e0\u8bba\u7279\u5f81\u662f\u591a\u5c11\u7ef4 \uff0c\u6211\u4eec\u53ea\u6709 2 \u4e2a\u7c7b\u4e2d\u5fc3\u70b9\u3002\u4ed6\u4eec\u5fc5\u5b9a\u5728\u4e00\u6761\u76f4\u7ebf\uff081\u7ef4\uff09\u4e0a\u3002\u540c\u7406\uff0c\u5bf9\u4e8e 3 \u4e2a\u7c7b\u7684\u5206\u7c7b\u95ee\u9898\uff0c\u6211\u4eec\u53ea\u6709 3 \u4e2a\u7c7b\u4e2d\u5fc3\u70b9\u3002\u4ed6\u4eec\u5fc5\u5b9a\u5728\u4e00\u4e2a\u5e73\u9762\uff082\u7ef4\uff09\u5185\uff0c\u5982\u679c\u7279\u5f81\u7ef4\u5ea6\u5927\u4e8e\u7b49\u4e8e 2\u3002 \u56e0\u6b64\uff0c\u7ecf\u8fc7 LDA\uff0c\u539f\u59cb\u6570\u636e\u603b\u80fd\u88ab\u6295\u5f71\u5230\u4e00\u4e2a\u8d85\u5e73\u9762\u4e0a\uff0c\u5176\u7ef4\u5ea6\u4e3a\uff08\u5bf9\u5e94 sklearn LDA \u65b9\u6cd5\u4e2d\u7684 n_components \u53c2\u6570\uff09\uff1a \\[ L = \\min(p, K-1) \\] \u8fd9\u8bf4\u660e\uff0c \u5728 \\(p \\gg K\\) \u65f6\uff0c\u4f7f\u7528 LDA \u53ef\u4ee5\u5c06\u4e00\u4e2a \\(p\\) \u7ef4\u7684\u8f93\u5165\u964d\u7ef4\u5230 \\(K-1\\) \u7ef4 \u3002 \u6211\u4eec\u4ee5 sklearn \u4e2d\u7684 wine \u6570\u636e\u96c6\u4e3a\u4f8b\u3002\u5b83\u5177\u6709 13 \u7ef4\u7279\u5f81\uff0c3 \u4e2a\u7c7b\u522b\u3002\u6211\u4eec\u4f7f\u7528 LDA \u53ef\u4ee5\u5c06\u8fd9\u4e9b\u6570\u636e\u6295\u5f71\u5230\u4e00\u4e2a 2 \u7ef4\u7684\u5e73\u9762\u4e0a\u3002 \u4ee3\u7801\uff1a import pandas as pd import numpy as np from sklearn import datasets wine = datasets . load_wine () X = pd . DataFrame ( wine . data , columns = wine . feature_names ) y = wine . target # LDA projection from sklearn.discriminant_analysis import LinearDiscriminantAnalysis model = LinearDiscriminantAnalysis ( n_components = 2 ) . fit ( X , y ) model . transform ( X ) # plot data_to_plot = pd . DataFrame ( np . insert ( model . transform ( X ), 2 , y , axis = 1 ), columns = [ \"x1\" , \"x2\" , \"class\" ]) show ( create_scatter_figure ( \"LDA projection for wine data\" , data_to_plot ))","title":"\u4f8b\uff1a\u7ea2\u9152\u5206\u7c7b"},{"location":"mathematics/ESL/ESL4_LinearMethodsForClassification/#find-the-optimal-subspace","text":"\u5728\u5b9e\u9645\u4e2d\uff0c\u5982\u679c \\(K\\) \u4e5f\u5f88\u5927\uff0c\u90a3\u8fd8\u9700\u8981\u8fdb\u4e00\u6b65\u964d\u4f4e\u7ef4\u5ea6\u3002\u5047\u8bbe\u6211\u4eec\u76ee\u6807\u662f\u964d\u4f4e\u5230 \\(L\\) \u7ef4\uff08 \\(L \\ll K-1\\) )\uff0c\u5373\u5bfb\u627e\u8d85\u5e73\u9762 \\(H_{K-1}\\) \u7684\u6700\u4f18\u5b50\u7a7a\u95f4 \\(H_L\\) \u3002 Fisher \u5c06\u8fd9\u4e2a\u95ee\u9898\u63d0\u70bc\u4e3a\uff1a \u627e\u5230\u7ebf\u6027\u7ec4\u5408 \\(Z = a^T X\\) \u4f7f\u5f97\u7c7b\u95f4\u7684\u65b9\u5dee\u76f8\u5bf9\u4e8e\u7c7b\u5185\u65b9\u5dee\u6700\u5927 \\(X\\) \u7684\u7c7b\u5185(Within)\u65b9\u5dee\u4e3a\uff1a \\[ \\textbf{W} = \\sum_{k=1}^K \\sum_{g_i=k} (x_i - \\mu_k)(x_i - \\mu_k)^T \\] \\(X\\) \u7684\u7c7b\u95f4(Between)\u65b9\u5dee\u4e3a\uff1a \\[ \\textbf{B} = \\sum_{k=1}^K (\\mu - \\mu_k)(\\mu - \\mu_k)^T \\] \u6839\u636e\u5411\u91cf\u7684\u7edf\u8ba1\u7279\u6027\uff0c\u6709 \\(Z\\) \u7684\u7c7b\u5185\u65b9\u5dee\u4e3a \\(a^T \\textbf{W} a\\) \uff0c\u7c7b\u95f4\u65b9\u5dee\u4e3a \\(a^T \\textbf{B} a\\) \u3002 \u4e8e\u662f\uff0cFisher \u5b9e\u9645\u4e0a\u662f\u5728\u89e3\u51b3\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\uff1a \\[ \\mathop{\\arg \\max}_a \\frac{a^T \\textbf{B} a}{a^T \\textbf{W} a} \\] \u7531\u4e8e\u6211\u4eec\u603b\u53ef\u4ee5\u901a\u8fc7\u8c03\u8282\u6c42\u5f97\u7684 \\(a\\) \u7684\u7cfb\u6570\u4f7f\u5f97 \\(a^T \\textbf{W} a = 1\\) \uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u6539\u5199\u4e3a\uff1a \\[\\begin{align} \\mathop{\\arg \\max}_a & ~ a^T \\textbf{B} a \\\\ \\text{s.t.} & ~ a^T \\textbf{W} a = 1 \\end{align}\\] \u5047\u8bbe \\(\\mathbf{W}\\) \u53ef\u9006 \uff0c\u4ee4 \\(u = \\mathbf{W}^{\\frac{1}{2}} a\\) \uff0c\u7531\u4e8e \\(\\textbf{W}\\) \u662f\u5bf9\u79f0\u77e9\u9635\uff0c\u6709\uff1a \\[\\begin{align} \\mathop{\\arg \\max}_u & ~ u^T \\mathbf{W}^{-\\frac{1}{2}}\\textbf{B}\\mathbf{W}^{-\\frac{1}{2}} u \\\\ \\text{s.t.} & ~ u^Tu = 1 \\end{align}\\] \\(\\mathbf{W}^{-\\frac{1}{2}}\\textbf{B}\\mathbf{W}^{-\\frac{1}{2}}\\) \u4e5f\u662f\u5bf9\u79f0\u77e9\u9635\uff0c\u5fc5\u5b9a\u5b58\u5728\u7279\u5f81\u503c\u5206\u89e3\uff1a \\[ \\mathbf{W}^{-\\frac{1}{2}}\\textbf{B}\\mathbf{W}^{-\\frac{1}{2}} = \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^T \\] \u56e0\u6b64\u5316\u7b80\u4e3a\uff1a \\[\\begin{align} \\mathop{\\arg \\max}_u & ~ u^T \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^T u \\\\ \\text{s.t.} & ~ u^Tu = 1 \\end{align}\\] \u518d\u4ee4 \\(v = \\mathbf{Q}^T u\\) \uff0c\u7531\u4e8e \\(\\mathbf{Q}\\) \u662f\u5355\u4f4d\u6b63\u4ea4\u77e9\u9635\uff0c \\(v^T v = 1\\) \u4f9d\u7136\u6210\u7acb\uff1a \\[\\begin{align} \\mathop{\\arg \\max}_v & ~ v^T \\mathbf{\\Lambda} v \\\\ \\text{s.t.} & ~ v^Tv = 1 \\end{align}\\] \\(\\mathbf{\\Lambda}\\) \u662f\u5bf9\u89d2\u77e9\u9635\uff0c\u6240\u4ee5 \u8be5\u4f18\u5316\u95ee\u9898\u672c\u8d28\u662f\u6c42\u6700\u5927\u7279\u5f81\u503c \u3002\u5047\u8bbe \\(\\lambda_i\\) \u6700\u5927\uff0c\u663e\u7136\u5728 \\(v_i = 1\\) \u65f6\u53d6\u5f97\u6700\u5927\u503c \\(\\lambda_i^2\\) \u3002 \u7531\u4e8e \\(\\mathbf{\\Lambda}\\) \u662f \\(\\mathbf{W}^{-\\frac{1}{2}}\\textbf{B}\\mathbf{W}^{-\\frac{1}{2}}\\) \u7684\u7279\u5f81\u503c\uff0c\u4e3a\u4e86\u7b80\u5316\u6c42\u89e3\uff0c\u6211\u4eec\u5229\u7528\u5b9a\u7406\uff1a \\(\\mathbf{AB}\\) \u4e0e \\(\\mathbf{BA}\\) \u5177\u6709\u540c\u6837\u7684\u7279\u5f81\u503c\uff0c\u5982\u679c \\(x\\) \u662f \\(\\mathbf{AB}\\) \u7684\u67d0\u4e2a\u7279\u5f81\u5411\u91cf\uff0c\u5219\u5bf9\u5e94\u7684 \\(\\mathbf{BA}\\) \u7684\u7279\u5f81\u5411\u91cf\u662f \\(y = \\mathbf{B}x\\) \u53ef\u4ee5\u5f97\u5230 \\(\\mathbf{\\Lambda}\\) \u4e5f\u662f \\(\\mathbf{W}^{-1}\\textbf{B}\\) \u7684\u7279\u5f81\u503c\u3002 \u5047\u8bbe \\(\\mathbf{W}^{-1}\\textbf{B}\\) \u7684\u6700\u5927\u7279\u5f81\u503c\u4e3a \\(\\lambda_i\\) \uff0c\u5bf9\u5e94\u7684\u7279\u5f81\u5411\u91cf\u4e3a \\(\\xi\\) \uff0c\u5219\u6240\u6c42\u7684\u7ebf\u6027\u53d8\u6362\u4e3a\uff1a \\[ a = \\mathbf{W}^{-\\frac{1}{2}} \\xi \\] \u8fd9\u6837\u5c31\u627e\u5230\u4e86 \\(H_L\\) \u7684 1 \u4e2a\u7ef4\u5ea6\uff0c\u540c\u7406\uff0c\u6211\u4eec\u9009\u53d6 top L \u4e2a\u7ef4\u5ea6\uff0c\u5373\u5f97\u5230\u4e86 \\(H_L\\) \u3002","title":"Find the optimal subspace"},{"location":"mathematics/ESL/ESL4_LinearMethodsForClassification/#_2","text":"\u5047\u8bbe \\(\\lambda\\) \u662f \\(\\mathbf{AB}\\) \u7684\u4efb\u610f\u7279\u5f81\u503c\u3002 \\[ \\mathbf{AB}x = \\lambda x \\] \u4ee4 \\(y = \\mathbf{B}x\\) \uff0c\u5219\u6709\uff1a \\[ \\mathbf{A}y = \\lambda x \\] \u540c\u65f6\u5de6\u4e58 \\(\\mathbf{B}\\) \uff1a \\[ \\mathbf{BA}y = \\lambda \\mathbf{B}x = \\lambda y \\]","title":"\u5b9a\u7406\u8bc1\u660e"},{"location":"mathematics/ESL/ESL4_LinearMethodsForClassification/#_3","text":"\u624b\u5199\u6570\u5b57\u5206\u7c7b\u662f\u901a\u8fc7 8x8 \u7684\u624b\u5199\u6570\u5b57\u56fe\u7247\u5224\u65ad\u662f 0-9 \u4e2d\u7684\u54ea\u4e2a\u6570\u5b57\u3002\u663e\u7136\uff0c\u8fd9\u662f\u4e00\u4e2a\u5177\u6709 \\(p = 8 \\times 8 = 64\\) \u7ef4\u7279\u5f81\uff0c \\(K = 10\\) \u4e2a\u7c7b\u522b\u7684\u5206\u7c7b\u4efb\u52a1\u3002\u6211\u4eec\u53ef\u4ee5\u7528 sklearn \u5e93\u7684 LDA \u5f97\u5230\u4e0b\u9762\u7684\u7ed3\u679c\uff08\u964d\u81f3 2 \u7ef4 plot\uff09\uff1a import pandas as pd import numpy as np import scipy from sklearn import datasets digits = datasets . load_digits () X = pd . DataFrame ( digits . data , columns = digits . feature_names ) y = digits . target trainX = X [: len ( X ) // 2 ] trainY = y [: len ( y ) // 2 ] from sklearn.discriminant_analysis import LinearDiscriminantAnalysis model = LinearDiscriminantAnalysis ( n_components = 2 , solver = \"eigen\" , shrinkage = 0.01 ) . fit ( trainX , trainY ) # reduce rank to 2 dimension data reduceRankX = model . transform ( trainX ) \u663e\u7136\uff0c\u76f4\u63a5\u8c03\u5305\u9690\u85cf\u4e86\u592a\u591a\u7ec6\u8282\uff0c\u4e3a\u4e86\u52a0\u6df1\u7406\u89e3\uff0c\u6211\u4eec\u6839\u636e\u516c\u5f0f\u63a8\u5bfc\u81ea\u5df1\u624b\u52a8\u5b9e\u73b0\u4e00\u4e2a\uff1a def shrink ( cov , shrinkage ): dimensions = cov . shape [ 0 ] return ( 1 - shrinkage ) * cov + shrinkage * np . trace ( cov ) / dimensions * np . identity ( dimensions ) def my_lda ( X , y , n_components , shrinkage ): T = X . cov () W = X . groupby ( y ) . apply ( lambda g : g . cov () * ( len ( g ) - 1 ) ) . groupby ( level = 1 ) . sum () / X . shape [ 0 ] shrunkW = shrink ( W , shrinkage ) invShrunkW = np . linalg . inv ( shrunkW ) shrunkB = shrink ( T , shrinkage ) - shrunkW # eigen values is ascending eigenvalues , eigenvectors = np . linalg . eigh ( invShrunkW . dot ( shrunkB )) # eigen vectors with greatest eigen values xi = eigenvectors [:,:: - 1 ][:,: n_components ] # L = np.linalg.cholesky(invShrunkW) # return L.dot(xi) # W^{-1/2}, not Cholesky return scipy . linalg . sqrtm ( invShrunkW ) . dot ( xi ) \u5176\u4e2d\uff0c shrink \u51fd\u6570\u662f\u4e3a\u4e86\u5904\u7406\u5f53 \\(\\mathbf{W}\\) \u662f \u5947\u5f02\u77e9\u9635 (\u4e0d\u53ef\u9006)\u7684\u60c5\u5f62\u3002\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 shrunk covariance \u6765\u4f7f\u5176\u53d8\u4e3a\u53ef\u9006\u77e9\u9635\u518d\u5904\u7406\u3002\u8fd9\u5728\u8f93\u5165 \\(X\\) \u662f\u7a00\u758f\u77e9\u9635\u65f6\u5f88\u5e38\u89c1\uff0c\u4f8b\u5982\u624b\u5199\u6570\u5b57\u5206\u7c7b\u3002 \\[ \\mathbf{\\Sigma}_{\\text{shrunk}} = (1 - \\alpha) \\hat{\\mathbf{\\Sigma}} + \\alpha \\frac{\\mathop{tr} \\hat{\\mathbf{\\Sigma}}}{p} \\mathbf{I}\\] \u5176\u4e2d \\(\\alpha\\) \u662f shrinkage\uff0c \\(p\\) \u662f\u7279\u5f81\u7ef4\u5ea6\u3002 \u53e6\u5916\u8fd8\u9700\u8981\u6ce8\u610f\u533a\u5206\u77e9\u9635\u5e73\u65b9\u6839 sqrtm \u4e0e Cholesky Decomposition\u3002 \u77e9\u9635\u5e73\u65b9\u6839\u6307 \\(\\mathbf{B} \\mathbf{B} = \\mathbf{B}^T \\mathbf{B} = \\mathbf{A}\\) \uff0c\u8981\u6c42 \\(\\mathbf{B}\\) \u662f\u5bf9\u79f0\u77e9\u9635\u3002 Cholesky Decomposition \u6307 \\(\\mathbf{L}^T \\mathbf{L} = \\mathbf{A}\\) \uff0c\u8981\u6c42 \\(\\mathbf{L}\\) \u662f\u4e09\u89d2\u77e9\u9635\u3002 \u4f7f\u7528\u81ea\u5df1\u5b9e\u73b0\u7684 LDA \u5f97\u5230\u4e0e sklearn \u5b9e\u73b0\u7c7b\u4f3c\u7684\u7ed3\u679c\uff1a \u53ef\u4ee5\u770b\u51fa\uff0c\u5728\u964d\u5230 2 \u7ef4\u540e\uff0cLDA \u8fd8\u662f\u80fd\u591f\u6e05\u695a\u533a\u5206\u51fa\u6570\u5b57 0, 1, 2, 3, 4, 6\uff0c\u4f46\u662f\u5b58\u5728\u4e00\u4e9b\u6570\u5b57\u7684\u7c7b\u522b\u91cd\u53e0\u5728\u4e00\u8d77\u7684\u60c5\u51b5\u3002\u6b64\u65f6\u53ef\u4ee5 \u589e\u52a0\u7ef4\u5ea6 \\(L\\) \u89e3\u51b3\u3002 \u4e0b\u9762\u662f\u7b2c3\u30014 \u7ef4\uff1a \u53ef\u4ee5\u770b\u51fa\uff0c\u5b83\u8f83\u597d\u7684\u8865\u8db3\u4e86 1\u30012 \u7ef4\u65e0\u6cd5\u6b63\u786e\u5206\u7c7b\u7684\u6570\u5b57\u3002\u5bf9\u4e8e\u6570\u5b57 5\u30017 \u6709\u4e86\u6e05\u695a\u7684\u5206\u7c7b\u3002","title":"\u4f8b\uff1a\u624b\u5199\u6570\u5b57\u5206\u7c7b"},{"location":"mathematics/ESL/ESL4_LinearMethodsForClassification/#44-logistic-regression","text":"\u903b\u8f91\u56de\u5f52\u5e0c\u671b\u7528\u8f93\u5165 \\(x\\) \u7684\u7ebf\u6027\u7ec4\u5408\u5efa\u6a21\u5c5e\u4e8e k \u7c7b\u7684\u540e\u9a8c\u6982\u7387\uff0c\u5e76\u4e14\u8981\u6c42\u6240\u6709\u6982\u7387\u4e4b\u548c\u4e3a 1\u3002 \u4ee5\u6700\u540e\u4e00\u4e2a\u7c7b\uff08K \u7c7b\uff09\u7684\u540e\u9a8c\u6982\u7387 \\(\\text{Pr} (G = K | X = x)\\) \u4e3a\u6bd4\u8f83\u57fa\u51c6\uff0c\u6709\uff1a \\[ \\ln \\frac{\\text{Pr} (G = k | X = x)}{\\text{Pr} (G = K | X = x)} = \\beta_{k0} + \\beta_{k1}^T x\\] \u53ef\u4ee5\u5199\u4e3a\uff1a \\[ \\text{Pr} (G = k | X = x) = \\begin{cases} \\dfrac{e^{\\beta_{k0} + \\beta_{k1}^Tx}}{1 + \\sum_{l=1}^{K-1} e^{\\beta_{l0} + \\beta_{l1}^Tx}}, & k = 1, 2, ..., K-1 \\\\ \\dfrac{1}{1 + \\sum_{l=1}^{K-1} e^{\\beta_{l0} + \\beta_{l1}^Tx}}, & k = K \\end{cases}\\] \u4e3a\u4ec0\u4e48\u4e0d\u76f4\u63a5\u5bf9\u6982\u7387\u8fdb\u884c\u5efa\u6a21\uff0c\u800c\u8981\u5bf9 logit \u51fd\u6570\u5efa\u6a21\u5462\uff1f\u8fd9\u662f\u56e0\u4e3a\u6982\u7387\u7684\u53d6\u503c\u8303\u56f4\u662f \\([0, 1]\\) \u800c\u7b49\u5f0f\u53f3\u8fb9\u7684\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u7684\u53d6\u503c\u8303\u56f4\u662f \\((-\\inf, +\\inf)\\) \u3002\u800c\u7531\u4e8e logit \u7684\u4e00\u4e2a\u91cd\u8981\u7279\u6027\u5c31\u662f\u6ca1\u6709\u4e0a\u4e0b\u9650\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5c1d\u8bd5\u7528\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u62df\u5408 logit\u3002","title":"4.4 Logistic regression"},{"location":"mathematics/ESL/ESL4_LinearMethodsForClassification/#441-fitting-logistic-regression-models","text":"\u5bf9\u4e8e\u7b2c k \u7c7b\u7684\u67d0\u4e2a\u6837\u672c i\uff0c\u6211\u4eec\u5e0c\u671b\u627e\u5230\u4e00\u7ec4\u6a21\u578b\u53c2\u6570 \\(\\theta\\) \uff0c\u4f7f\u6a21\u578b\u8ba4\u4e3a\u8be5\u6837\u672c\u5c5e\u4e8e k \u7684\u6982\u7387\uff08\u5373 \u6b63\u786e\u5206\u7c7b\u6982\u7387 \uff09\u5c3d\u91cf\u5927\u3002\u6211\u4eec\u5c06\u8fd9\u4e2a\u6982\u7387\u8ba1\u4f5c\uff1a \\[\\text{Pr} (G = k | X = x) = p_{k} (x; \\theta)\\] \u5219\u8be5\u4f18\u5316\u95ee\u9898\u662f\uff1a \\[\\begin{align} \\hat{\\theta} = \\mathop{\\arg \\max}_{\\theta} ~ p_{k} (x; \\theta) \\end{align}\\] \u5bf9\u4e8e\u6240\u6709\u6837\u672c\uff0c\u6211\u4eec\u76ee\u6807\u662f\u4ee4\u4ed6\u4eec \u88ab\u6b63\u786e\u5206\u7c7b\u7684\u6982\u7387\u548c\u6700\u5927 \uff1a \\[ \\ell (\\theta) = \\sum_{i=1}^N \\ln p_{g_i} (x_i; \\theta) \\] \u4e3a\u4e86\u7b80\u5316\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u53ea\u8003\u8651\u800c \\(K=2\\) \u5373 \u4e8c\u5206\u7c7b \u95ee\u9898\u60c5\u51b5\u3002\u6b64\u65f6\u6837\u672c\u8981\u4e48\u5c5e\u4e8e 1 \u7c7b\u8981\u4e48\u5c5e\u4e8e 2 \u7c7b\u3002 \u4e3a\u4e86\u7b80\u5355\u8868\u793a\uff1a \\[p_{k} (x; \\theta) = \\begin{cases} p_1 (x; \\theta), & k = 1 \\\\ 1 - p_1(x; \\theta), & k = 2 \\end{cases}\\] \u6211\u4eec\u53ef\u4ee5\u5047\u8bbe\u6837\u672c\u89c2\u6d4b\u503c \\(y_i = 1\\) \u4ee3\u8868\u5c5e\u4e8e\u7b2c 1 \u7c7b\uff0c \\(y_i = 0\\) \u4ee3\u8868 \u4e0d\u5c5e\u4e8e \u7b2c 1 \u7c7b\uff08\u90a3\u4e48\u80af\u5b9a\u5c5e\u4e8e\u7b2c 2 \u7c7b\uff09\u3002\u5219 \\[p_{k} (x_i; \\theta) = y_i p_1 (x_i; \\theta) + (1-y_i)(1-p_1(x_i; \\theta))\\] \u5219\u6709\uff1a \\[ \\begin{align} \\ell (\\theta) &= \\sum_{i=1}^N \\ln p_{g_i} (x_i; \\theta) \\\\ &= \\sum_{i=1}^N {y_i \\ln p_1 (x_i; \\theta) + (1-y_i) \\ln (1-p_1(x_i; \\theta))} \\\\ &= \\sum_{i=1}^N {\\ln(1 - p_1(x_i; \\theta)) + y_i \\ln \\frac{ p_1 (x_i; \\theta)}{1 - p_1 (x_i; \\theta)} } \\\\ &= \\sum_{i=1}^N {\\ln(1 - p_1(x_i; \\theta)) + y_i \\mathbf{\\beta}^Tx_i } \\\\ &= \\sum_{i=1}^N {y_i \\mathbf{\\beta}^Tx_i - \\ln(1 + e^{\\mathbf{\\beta}^Tx_i}) } \\end{align}\\] \u5176\u4e2d \\(\\mathbf{\\beta} = [ \\beta_{10}, \\beta_{11}, ... \\beta_{1p} ]\\) \uff0c\u5bf9\u5e94 \\(x = [1, x_1, x_2, ... x_p]\\) \u3002 \u6c42\u89e3\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u53ef\u4ee5\u4ee4\u5176\u5bf9 \\(\\beta\\) \u7684\u5bfc\u6570\u4e3a 0: \\[ \\frac{\\partial \\ell(\\beta)}{\\partial \\beta} = \\sum_{i=1}^N x_i(y_i - p_1(x_i; \\beta)) = 0, \\] \u4e3a\u4e86\u6c42\u89e3 \\(\\dfrac{\\partial \\ell(\\beta)}{\\partial \\beta} = 0\\) \uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u51f8\u4f18\u5316\u4e2d\u7684 Newton-Raphson \u6cd5\u3002\u5373\u9009\u53d6\u4e00\u4e2a\u4efb\u610f\u521d\u59cb \\(x_n\\) \uff08\u4e0d\u662f\u521d\u59cb\u89e3\uff0c\u56e0\u4e3a\u8981\u6c42\u7684\u5c31\u662f\u89e3\uff09\uff0c\u5e76\u53d6\u5176\u5207\u7ebf\u4e0e x \u8f74\u4ea4\u70b9 \\(x_{n+1}\\) \uff1a \\[ \\beta^{\\text{new}} = \\beta - (\\frac{\\partial^2 \\ell(\\beta)}{\\partial \\beta \\partial \\beta^T})^{-1} \\frac{\\partial \\ell(\\beta)}{\\partial \\beta}\\] \u5176\u4e2d \\((p+1) \\times (p+1)\\) \u7ef4 Hessian \u77e9\u9635\uff1a \\[\\begin{align} \\frac{\\partial^2 \\ell(\\beta)}{\\partial \\beta \\partial \\beta^T} &= - \\sum_{i=1}^N x_i \\frac{\\partial p_1(x_i; \\beta)}{\\partial \\beta^T} \\\\ &= - \\sum_{i=1}^N x_i \\dfrac{\\partial \\dfrac{e^{\\beta^T x_i}}{1 + e^{\\beta^T x_i}} }{\\partial \\beta^T} \\\\ &= - \\sum_{i=1}^N x_i \\frac{x_i^T e^{\\beta^T x_i}}{(1 + e^{\\beta^T x_i})^2} \\\\ &= -\\sum_{i=1}^N x_i x_i^T p_1(x_i; \\beta) (1 - p_1(x_i; \\beta)) \\end{align}\\] \u6211\u4eec\u5c06\u4ed6\u4eec\u5199\u6210\u77e9\u9635\u5f62\u5f0f\uff1a \\[ \\frac{\\partial \\ell(\\beta)}{\\partial \\beta} = \\mathbf{X}^T(\\mathbf{y} - \\mathbf{p})\\] \\[ \\frac{\\partial^2 \\ell(\\beta)}{\\partial \\beta \\partial \\beta^T} = \\mathbf{X}^T \\mathbf{W} \\mathbf{X} \\] \u5176\u4e2d \\(\\mathbf{X}\\) \u662f \\(N \\times (p+1)\\) \u77e9\u9635\uff0c \\(\\mathbf{y} - \\mathbf{p}\\) \u662f \\(N\\) \u7ef4\u5217\u5411\u91cf\uff0c \\(\\mathbf{W}\\) \u662f \\(N \\times N\\) \u5bf9\u89d2\u77e9\u9635\uff0c\u7b2c i \u4e2a\u5143\u7d20\u662f \\(p_1(x_i; \\beta) (1 - p_1(x_i; \\beta))\\) \u3002 \u5e26\u5165 Newton-Raphson \u516c\u5f0f\uff1a \\[\\begin{align} \\beta^{\\text{new}} &= \\beta - (\\frac{\\partial^2 \\ell(\\beta)}{\\partial \\beta \\partial \\beta^T})^{-1} \\frac{\\partial \\ell(\\beta)}{\\partial \\beta} \\\\ &= \\beta + (\\mathbf{X}^T \\mathbf{W} \\mathbf{X})^{-1} \\mathbf{X}^T(\\mathbf{y} - \\mathbf{p}) \\\\ &= (\\mathbf{X}^T \\mathbf{W} \\mathbf{X})^{-1}\\mathbf{X}^T \\mathbf{W}(\\mathbf{X}\\beta + \\mathbf{W}^{-1}(\\mathbf{y} - \\mathbf{p})) \\\\ &= (\\mathbf{X}^T \\mathbf{W} \\mathbf{X})^{-1}\\mathbf{X}^T \\mathbf{W}\\mathbf{z} \\end{align}\\] \u8fd9\u5c31\u662f \u8fed\u4ee3\u66f4\u65b0 \u7684\u8ba1\u7b97\u516c\u5f0f\u3002\u7531\u4e8e \\(\\mathbf{p}\\) \u548c \\(\\mathbf{W}\\) \u90fd\u968f \\(\\beta\\) \u53d8\u5316\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u5728\u6bcf\u8f6e\u8fed\u4ee3\u91cd\u65b0\u8ba1\u7b97\u4ed6\u4eec\u7684\u503c\u3002 \u4e0a\u5f0f\u4e2d\uff0c\u6211\u4eec\u5b9a\u4e49\u4e86\uff1a \\[ \\mathbf{z} = \\mathbf{X}\\beta + \\mathbf{W}^{-1}(\\mathbf{y} - \\mathbf{p}) \\] \u56de\u60f3 \u6700\u5c0f\u4e8c\u4e58\u6cd5 \u7684\u516c\u5f0f\uff1a \\[ \\hat{\\beta} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y} \\] \u53ef\u4ee5\u53d1\u73b0\u4e24\u8005\u975e\u5e38\u76f8\u4f3c\uff0c\u533a\u522b\u5728\u4e8e\u903b\u8f91\u56de\u5f52\u4e2d\u591a\u4e86\u4e00\u4e2a\u6743\u91cd\u5bf9\u89d2\u77e9\u9635 \\(\\mathbf{W}\\) \u3002\u56e0\u6b64\u8fd9\u4e2a\u7b97\u6cd5\u4e5f\u79f0\u4e3a iteratively reweighted least squares \uff08\u91cd\u65b0\u52a0\u6743\u8fed\u4ee3\u6700\u5c0f\u4e8c\u4e58\u6cd5\uff09\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u8fd8\u9700\u8981\u4e00\u4e2a \\(\\beta\\) \u7684 \u521d\u59cb\u503c \u3002\u4e00\u822c\u60c5\u51b5\u4e0b\u53ef\u4ee5\u9009 \\(\\beta = 0\\) \u3002\u8be5\u7b97\u6cd5 \u4e0d\u4fdd\u8bc1\u6536\u655b \u3002","title":"4.4.1 Fitting Logistic Regression Models"},{"location":"mathematics/ESL/ESL4_LinearMethodsForClassification/#_4","text":"\u8be5\u6848\u4f8b\u901a\u8fc7 30 \u7ef4\u7279\u5f81\u6765\u5224\u65ad\u4e73\u817a\u764c\u662f\u6076\u6027\u8fd8\u662f\u826f\u6027\uff0c\u662f\u4e00\u4e2a\u5178\u578b\u7684 2 \u5206\u7c7b\u95ee\u9898\u3002 import pandas as pd import numpy as np from sklearn import datasets , model_selection def load_sklearn_data ( sk_data ): X = pd . DataFrame ( sk_data . data , columns = sk_data . feature_names ) y = pd . Series ( sk_data . target , name = \"target\" ) . apply ( lambda index : sk_data . target_names [ index ]) . astype ( \"category\" ) return X , y X , y = load_sklearn_data ( datasets . load_breast_cancer ()) X_train , X_test , y_train , y_test = model_selection . train_test_split ( X , y , test_size = 0.2 ) from sklearn.metrics import accuracy_score from sklearn.linear_model import LogisticRegression model = LogisticRegression ( solver = \"newton-cg\" ) . fit ( X_train , y_train ) accuracy_score ( model . predict ( X_test ), y_test ) \u7ed3\u679c\u662f 0.9385964912280702 \u3002\u6211\u4eec\u518d\u7528\u81ea\u5df1\u5b9e\u73b0\u7684 LR \u8fdb\u884c\u5224\u65ad\uff1a def sigmoid ( x , beta ): tmp = np . exp ( x . dot ( beta )) return tmp / ( 1 + tmp ) class MyLogisticRegression : def __init__ ( self , max_iter , tolerance = 0.01 ): self . max_iter_ = max_iter self . tolerance_ = tolerance self . beta = None def fit ( self , train_X , train_y ): N , p = train_X . shape X = train_X . to_numpy () X = np . concatenate (( np . atleast_2d ( np . ones ( N )) . T , train_X . to_numpy ()), axis = 1 ) self . beta = np . zeros ( p + 1 ) beta = self . beta for i in range ( self . max_iter_ ): prob = np . apply_along_axis ( sigmoid , 1 , X , beta ) W = np . diag ( prob * ( 1 - prob )) z = X . dot ( beta ) + np . linalg . inv ( W ) . dot ( train_y . cat . codes - prob ) new_beta = np . linalg . inv ( X . T @ W @ X ) @ X . T @ W . dot ( z ) beta = new_beta self . beta = beta def predict ( self , test_X ): X = test_X . copy () X . insert ( 0 , \"x_0\" , np . ones ( test_X . shape [ 0 ])) prob = X . apply ( lambda row : sigmoid ( row , self . beta ), axis = 1 ) return prob . apply ( lambda x : 1 if x >= 0.5 else 0 ) \u6839\u636e\u516c\u5f0f\u5199\u4ee3\u7801\uff0c\u6ce8\u610f \\(\\beta\\) \u7684\u8fed\u4ee3\u66f4\u65b0\u5373\u53ef\u3002\u6700\u5927\u7684\u96be\u5ea6\u662f\u7ec8\u6b62\u6761\u4ef6\uff0c\u56e0\u4e3a\u8fed\u4ee3\u6570\u6b21\u4e4b\u540e\u4f1a\u9047\u5230 Hessian \u77e9\u9635 \\(\\mathbf{X}^T \\mathbf{W} \\mathbf{X}\\) \u6210\u4e86\u5947\u5f02\u77e9\u9635\u7684\u95ee\u9898\u3002 \u8fd0\u884c\u7684\u7ed3\u679c\u8868\u660e\u5206\u7c7b\u6b63\u786e\u7387\u53ef\u4ee5\u8fbe\u5230 0.9473684210526315 \u3002 TODO: how to find a stopping criteria?","title":"\u4f8b\uff1a\u4e73\u817a\u764c\u8bca\u65ad"},{"location":"mathematics/ESL/ESL4_LinearMethodsForClassification/#445-logistic-regression-or-lda","text":"\u5728 4.3 \u4e2d\u6211\u4eec\u4ecb\u7ecd\u4e86 LDA\uff0c\u56de\u5fc6\u5176\u5224\u65ad\u67d0\u4e2a\u6837\u672c\u5c5e\u4e8e \\(k\\) \u8fd8\u662f \\(l\\) \u7684\u51fd\u6570\uff08\u5f53\u8be5\u5f0f\u5927\u4e8e 0 \u65f6\u5c5e\u4e8e \\(k\\) \u7c7b\uff09\uff1a \\[\\begin{align} \\ln \\frac{\\text{Pr}(G=k | X=x)}{\\text{Pr}(G=l | X=x)} &= \\ln \\frac{f_k(x) \\pi_k}{ f_l(x) \\pi_l} \\\\ &= \\ln \\frac{\\pi_k}{\\pi_l} - \\frac{1}{2}(\\mu_k + \\mu_l) \\mathbf{\\Sigma}^{-1} (\\mu_k - \\mu_l) + x^T \\mathbf{\\Sigma}^{-1} (\\mu_k - \\mu_l) \\\\ &= \\alpha_{k0} + \\alpha_{k1}^T x \\end{align}\\] \u53ef\u4ee5\u770b\u51fa\u5176\u5f62\u5f0f\u4e0e logistic regression \u4e00\u81f4\uff1a \\[\\ln \\frac{\\text{Pr}(G=k | X=x)}{\\text{Pr}(G=l | X=x)} = \\beta_{k0} + \\beta_{k1}^T x\\] \u90a3\u4e48\u4ed6\u4eec\u4fe9\u662f\u4e0d\u662f\u4e00\u6837\u7684\u65b9\u6cd5\u5462\uff1f\u5e76\u4e0d\u662f\u3002\u4ed6\u4eec\u7684\u4e3b\u8981\u533a\u522b\u662f\uff1a \u5047\u8bbe\u4e0d\u540c\u3002LDA \u5047\u8bbe\u4e86 \\(x\\) \u670d\u4ece\u6b63\u6001\u5206\u5e03\uff0c\u4e14\u5404\u4e2a\u7c7b\u7684\u534f\u65b9\u5dee\u77e9\u9635\u76f8\u540c\u3002LR \u6ca1\u6709\u9650\u5b9a \\(x\\) \u7684\u5206\u5e03\u3002\u7531\u4e8e LDA \u5047\u8bbe\u4e86\u6b63\u6001\u5206\u5e03\uff0c\u5b83\u5bf9\u4e8e\u6781\u7aef\u7684 outlier \u9c81\u68d2\u6027\u5dee\uff08\u4f1a\u5f71\u54cd\u5206\u5e03\u51fd\u6570)\u3002 \u4f18\u5316\u76ee\u6807\u4e0d\u540c\u3002LDA \u6700\u5927\u5316 full log-likelihood\uff0c\u9700\u8981\u8003\u8651 \\(x\\) \u7684\u8fb9\u7f18\u5206\u5e03\u51fd\u6570\u3002LR \u6700\u5927\u5316 conditional likelihood\uff0c\u4e0d\u9700\u8981\u8003\u8651 \\(x\\) \u7684\u8fb9\u7f18\u5206\u5e03\u51fd\u6570\u3002 \u6bd4\u8f83\u96be\u7406\u89e3\u7684\u662f\u7b2c\u4e8c\u70b9\u3002 \u9996\u5148\uff0c\u6839\u636e Bayes \u516c\u5f0f\uff0c\u5728\u5df2\u77e5 B \u53d1\u751f\u65f6\uff0cA \u7684\u6761\u4ef6\u6982\u7387\u4e3a\uff1a \\[ P(A|B) = \\frac{P( A \\cap B ) }{P(B)} \\] \u56e0\u6b64\u5bf9\u4e8e\u5206\u7c7b\u95ee\u9898\uff0c \u6761\u4ef6\u6982\u7387(conditional likelihood) \u662f \u5728\u5df2\u77e5 \\(X = x\\) \u65f6\uff0c\u6837\u672c\u7c7b\u522b \\(G = k\\) \u7c7b\u7684\u6982\u7387 \u3002\u5b83\u4e0e \u5168\u6982\u7387(full likelihood) \u4e4b\u95f4\u5b58\u5728\u5173\u7cfb\uff1a \\[\\begin{align} \\text{Pr}(G=k | X=x) &= \\frac{\\text{Pr}(X, G=k)}{\\text{Pr}(X)} \\\\ &= \\frac{\\text{Pr}(X, G=k)}{\\sum_{l=1}^K \\text{Pr}(X, G=l)} \\\\ \\end{align}\\] LDA \u7684\u76ee\u6807\u662f\u627e\u5230\u4e00\u4e2a\u7c7b\u522b \\(k\\) \u4f7f\u5f97\u540e\u9a8c\u6982\u7387\u6700\u5927\uff0c\u5373\uff1a \\[\\begin{align} \\hat{k} &= \\mathop{\\arg \\max}_{k} \\text{Pr}(G=k | X=x) \\\\ &= \\mathop{\\arg \\max}_{k} \\frac{\\text{Pr}(X, G=k)}{\\sum_{l=1}^K \\text{Pr}(X, G=l)} \\end{align}\\] LDA \u9009\u62e9 \u5bf9\u5168\u6982\u7387\u5efa\u6a21 \uff0c\u9700\u8981\u77e5\u9053 \\(x\\) \u7684\u5728\u6bcf\u4e2a\u7c7b\u7684\u5bc6\u5ea6\u51fd\u6570 \\(f_i(x)\\) \uff0cLDA \u5047\u8bbe\u5176\u4e3a\u6b63\u6001\u5206\u5e03\uff0c\u4e14\u534f\u65b9\u5dee\u76f8\u7b49\u3002\u5168\u6982\u7387\u4e3a\uff1a \\[ \\text{Pr}(X, G=k) = f_k(x) \\pi_k = \\phi(x; \\mu_k, \\mathbf{\\Sigma}) \\pi_k \\] \u6240\u4ee5\u8bf4\u5b83\u8003\u8651\u7684\u662f full log-likelihood\u3002 \u5bf9\u4e8e LR\uff0c\u5b83\u76f4\u63a5 \u5bf9\u6761\u4ef6\u6982\u7387\u5efa\u6a21 \u3002\u5373\u5047\u8bbe\u5b58\u5728\u4e00\u7ec4 \\(\\beta\\) \u80fd\u591f\u4f7f\u6761\u4ef6\u6982\u7387\u7684 log ratio \u548c \\(x\\) \u6709\u5982\u4e0b\u7ebf\u6027\u5173\u7cfb\uff1a \\[\\ln \\frac{\\text{Pr}(G=k | X=x)}{\\text{Pr}(G=l | X=x)} = \\beta_{k0} + \\beta_{k1}^T x\\] \u5e76\u4e14\uff0c\u8fd9\u4e00\u7ec4 \\(\\beta\\) \u4f7f \u6240\u6709\u6837\u672c\u6b63\u786e\u5206\u7c7b\u7684\u6982\u7387\u548c \u6700\u5927\uff1a \\[\\begin{align} \\hat{\\theta} &= \\mathop{\\arg \\max}_{\\theta} ~ \\ell (\\theta) \\\\ &= \\mathop{\\arg \\max}_{\\theta} ~ \\sum_{i=1}^N \\ln p_{g_i} (x_i; \\theta) \\\\ &= \\sum_{i=1}^N y_i \\mathbf{\\beta}^Tx_i - \\ln(1 + e^{\\mathbf{\\beta}^Tx_i}) \\end{align}\\] \u5176\u4e2d\u4e0d\u5305\u542b\u4efb\u4f55\u4e0e\u8fb9\u7f18\u5bc6\u5ea6\u51fd\u6570 \\(\\text{Pr}(X)\\) \u76f8\u5173\u7684\u90e8\u5206\uff0c\u4e5f\u6ca1\u6709\u5047\u8bbe \\(x\\) \u7684\u5206\u5e03\u3002\u56e0\u6b64\u8bf4\u5b83\u53ea\u8003\u8651 conditional likelihood\u3002","title":"4.4.5 Logistic Regression or LDA?"},{"location":"mathematics/ESL/ESL4_LinearMethodsForClassification/#reference","text":"masking in linear regression for multiple classes Linear discriminant analysis, explained shrunk covariance between-class scatter matrix calculation \u903b\u8f91\u56de\u5f52 Implementing logistic regression from scratch in Python","title":"Reference"},{"location":"mathematics/ESL/ESL6_KernelSmoothingMethods/","text":"ESL 6: Kernel Smoothing Methods \u672c\u7ae0\u6211\u4eec\u4ecb\u7ecd \u6838\u5e73\u6ed1\u65b9\u6cd5 \u3002\u5b83\u4ec5\u5229\u7528\u76ee\u6807\u70b9 \\(x_0\\) \u5468\u56f4\u7684\u89c2\u6d4b\u70b9\u6765\u62df\u5408\u6a21\u578b \\(f(X)\\) \uff0c\u5f97\u5230 \\(\\hat{f}(X)\\) \u3002\u76f8\u8f83\u4e8e\u6700\u8fd1\u90bb\u6cd5\uff0c\u5b83\u6240\u5f97\u5230\u7684 \\(\\hat{f}(X)\\) \u662f\u5e73\u6ed1 (smooth) \u540e\u7684\u3002 \u5b83\u5e73\u6ed1\u66f2\u7ebf\u7684\u539f\u7406\u662f\u5229\u7528\u4e00\u4e2a\u6838\u51fd\u6570 \\(K_\\lambda (x_0, x_i)\\) \u6839\u636e\u76ee\u6807\u70b9 \\(x_0\\) \u548c\u5468\u56f4\u70b9 \\(x_i\\) \u7684\u8ddd\u79bb\u8d4b\u4e88\u6743\u91cd\u3002 \u8fd9\u4e00\u7c7b\u65b9\u6cd5\u51e0\u4e4e\u4e0d\u9700\u8981\u8bad\u7ec3\uff0c\u53c2\u6570\u4e5f\u5f88\u7b80\u5355\uff0c\u53ea\u6709\u4e00\u4e2a\u8d85\u53c2\u6570 \\(\\lambda\\) \uff0c\u7528\u6765\u8bbe\u7f6e\u201c\u5468\u56f4\u201d\u7684\u5177\u4f53\u8303\u56f4\u3002\u4ed6\u4eec\u4e5f\u88ab\u79f0\u4e3a \"memory-based\" \u65b9\u6cd5\uff0c\u5176\u6a21\u578b\u5c31\u662f\u6240\u6709\u8bad\u7ec3\u6837\u672c\u672c\u8eab\uff0c\u62df\u5408\u5b9e\u65f6\u8fdb\u884c\u3002\u56e0\u6b64\uff0c\u5bf9\u4e8e\u67d0\u4e9b\u8981\u6c42\u8fd0\u7b97\u901f\u5ea6\uff0c\u6216\u8005\u5b58\u50a8\u6709\u9650\u7684\u573a\u5408\uff0c\u8fd9\u7c7b\u65b9\u6cd5\u5e76\u4e0d\u9002\u7528\u3002 \u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c \u6838\u5e73\u6ed1\u65b9\u6cd5 \u548c \u6838\u65b9\u6cd5 \u662f\u4e0d\u540c\u7684\u6982\u5ff5\u3002 \u6838\u65b9\u6cd5 \u4f1a\u5728\u9ad8\u7ef4\u7279\u5f81\u7a7a\u95f4\u8ba1\u7b97\u5185\u79ef\uff0c\u7528\u4e8e\u6b63\u5219\u5316\u7684\u975e\u7ebf\u6027\u5efa\u6a21\u3002 6.1 One-Dimensional Kernel Smoothers \u76f8\u5bf9\u4e8e\u6700\u8fd1\u90bb\u6cd5\uff0c\u6838\u5e73\u6ed1\u6cd5\u5bf9\u76ee\u6807\u70b9\u9644\u8fd1\u9009\u53d6\u7684\u6837\u672c\u70b9\u8bbe\u7f6e\u4e86 \u6839\u636e\u8ddd\u79bb\u8870\u51cf\u7684\u6743\u91cd \uff0c\u518d\u8fdb\u884c\u52a0\u6743\u5e73\u5747\u3002\u8fd9\u6837\u505a\u7684\u6700\u5927\u597d\u5904\u662f\u4f7f\u66f2\u7ebf\u66f4\u52a0\u5e73\u6ed1\u4e86\uff08\u4f46\u662f\u4e0d\u4e00\u5b9a\u53ef\u5bfc\uff0c\u89c1\u6587\u672b exercise\uff09 \\[ \\hat{f}(x_0) = \\dfrac{\\sum_{i=1}^N K_\\lambda(x_0, x_i)y_i}{\\sum_{i=1}^N K_\\lambda(x_0, x_i) } \\] \u6837\u672c\u70b9 \\(x\\) \u7684\u6743\u91cd\u51fd\u6570\uff08\u4e5f\u79f0\u4e3a\u6838\u51fd\u6570\uff09\u5b9a\u4e49\u4e3a\u5176\u4e0e\u76ee\u6807\u70b9 \\(x_0\\) \u8ddd\u79bb\u76f8\u5173\u7684\u51fd\u6570\uff1a \\[ K_\\lambda(x_0, x) = D( \\dfrac{|x - x_0|}{h_\\lambda(x_0)} ) \\] \u5176\u4e2d \\(h_\\lambda(x_0)\\) \u8868\u793a\u9009\u53d6\u7a97\u53e3\u7684\u5927\u5c0f\u53ef\u4ee5\u6839\u636e\u76ee\u6807\u70b9\u7684\u53d6\u503c\u53d8\u5316\u3002 \u53ef\u4ee5\u770b\u51fa\uff0c\u53f3\u56fe\u4f7f\u7528\u6838\u51fd\u6570\u5e73\u6ed1\u540e\uff0c\u76f8\u6bd4\u5de6\u56fe\u7684\u6700\u8fd1\u90bb\u6cd5\u83b7\u5f97\u7684\u4f30\u8ba1\u503c\u66f4\u4e3a\u5e73\u6ed1\u3002 6.1.1 Local Linear Regression \u6211\u4eec\u901a\u8fc7\u5f15\u5165\u6838\u51fd\u6570\u89e3\u51b3\u4e86\u5e73\u6ed1\u6027\u95ee\u9898\uff0c\u4f46\u662f\uff0c\u6211\u4eec\u53d1\u73b0\u5728\u4e34\u8fd1\u8fb9\u754c\u7684\u5730\u65b9\uff0c\u66f2\u7ebf\u51fa\u73b0\u4e86\u8f83\u5927\u7684 bias\uff0c\u8fd9\u662f\u7531\u4e8e\u8fb9\u754c\u533a\u57df\u6837\u672c\u70b9\u5206\u5e03\u4e0d\u5747\u5300\u3002 \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7 \u5c40\u90e8\u7ebf\u6027\u56de\u5f52 \u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u5b83\u5728 \u6bcf\u4e2a \u76ee\u6807\u70b9 \\(x_0\\) \u6c42\u89e3\u4e00\u4e2a \u6700\u5c0f\u4e8c\u4e58 \u95ee\u9898\uff1a \\[ \\mathop{\\arg \\min}_{\\alpha(x_0), \\beta(x_0)} \\sum_{i=1}^{N} K_\\lambda(x_0, x_i)[y_i - \\alpha(x_0) -\\beta(x_0)x_i]^2 \\] \u5373\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u76ee\u6807\u70b9\u5468\u56f4\u9009\u53d6\u7684\u6837\u672c\u70b9\uff0c\u7528\u7ebf\u6027\u51fd\u6570\u53bb\u62df\u5408\uff0c\u5f97\u5230\u7ebf\u6027\u65b9\u7a0b\uff1a \\[ \\hat{f}(x) = \\alpha(x_0) + \\beta(x_0)x \\] \u518d\u4ee3\u5165 \\(x_0\\) \u5f97\u5230\u4f30\u8ba1\u503c\u3002\u8be5\u65b9\u6cd5\u53ef\u4ee5 \u9664\u53bb 1 \u9636\u7684 bias\uff0c\u53ea\u4fdd\u7559 2 \u9636\u53ca\u66f4\u9ad8\u9636\u7684 bias \u3002 \u5bf9\u4e8e\u67d0\u4e00\u4e2a\u76ee\u6807\u70b9 \\(x_0\\) \uff0c\u5047\u8bbe\u5176\u5468\u56f4\u9009\u53d6\u4e86 \\(N\\) \u4e2a\u6837\u672c\u70b9\uff0c\u5176\u4f30\u8ba1\u7ed3\u679c\u53ef\u4ee5\u5199\u6210\u77e9\u9635\u5f62\u5f0f\uff1a \\[\\begin{align} \\hat{f}(x_0) &= b(x_0)^T (\\mathbf{B}^T \\mathbf{W}(x_0) \\mathbf{B})^{-1} \\mathbf{B}^T \\mathbf{W}(x_0) \\mathbf{y} \\\\ &= \\sum_{i=1}^{N} l_i(x_0)y_i \\end{align}\\] \u5176\u4e2d \\(b(x_0)^T = (1, x_0)\\) \uff0c\u77e9\u9635\uff1a \\[ \\mathbf{B} = \\left[ \\begin{array}{cc} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_N \\end{array} \\right]_{N \\times 2}\\] \\[ \\mathbf{W}(x_0) = \\left[ \\begin{array}{cccc} K_\\lambda(x_0, x_1) & & &\\\\ & K_\\lambda(x_0, x_2) & &\\\\ & & & \\ddots & \\\\ & & & & K_\\lambda(x_0, x_N) \\\\ \\end{array} \\right]_{N \\times N}\\] \u5176\u6548\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u53ef\u4ee5\u770b\u51fa\u5728\u5b9a\u4e49\u57df\u8fb9\u7f18\u4f4d\u7f6e\uff0c\u4f7f\u7528\u5c40\u90e8\u7ebf\u6027\u56de\u5f52\uff08\u53f3\u56fe\uff09\u62df\u5408\u6548\u679c\u66f4\u597d\u3002 6.2 Selecting the Width of the Kernel \u51e0\u79cd\u5e38\u7528\u7684 kernel: \u5bf9\u4e8e Epanechnikov \u548c tri-cube kernel\uff0c \\(\\lambda\\) \u662f\u201c\u5468\u56f4\u201d\u7684\u534a\u5f84\u3002\u5bf9\u4e8e Gaussian kernel\uff0c \\(\\lambda\\) \u662f\u5176\u6807\u51c6\u5dee \\(\\sigma\\) \u3002 \u9009\u53d6 \\(\\lambda\\) \u5b9e\u9645\u4e0a\u662f bias-variance \u7684 tradeoff\u3002\u5f53\u9009\u53d6\u7a97\u53e3\u5f88\u5c0f\u65f6\uff0c\u7531\u4e8e\u91c7\u7528\u7684\u6837\u672c\u70b9\u8f83\u5c11\uff0c\u5f97\u5230\u7684\u76ee\u6807\u70b9\u7684\u4f30\u8ba1\u503c variance \u4f1a\u5f88\u5927\u3002\u4f46\u662f\u540c\u65f6\uff0c\u7531\u4e8e\u9009\u53d6\u7684\u70b9\u90fd\u662f\u79bb\u76ee\u6807\u70b9\u6700\u8fd1\u7684\u70b9\uff0c\u5b83\u7684 bias \u5f88\u5c0f\u3002 6.3 Multi-dimensional Local Regression \u6211\u4eec\u53ef\u4ee5\u81ea\u7136\u5730\u5c06\u5c40\u90e8\u7ebf\u6027\u56de\u5f52\u6269\u5c55\u5230\u591a\u7ef4\uff0c\u7528\u4e8e\u62df\u5408\u4e00\u4e2a\u8d85\u5e73\u9762\u3002 \u5f53\u7ef4\u5ea6 \\(p = 2\\) \uff0c\u9636\u6b21 \\(d = 1\\) \u65f6\uff0c\u6211\u4eec\u6709\uff1a \\[ b(X) = (1, X_1, X_2) \\] \u5f53\u7ef4\u5ea6 \\(p = 2\\) \uff0c\u9636\u6b21 \\(d = 2\\) \u65f6\uff0c\u6211\u4eec\u6709\uff1a \\[ b(X) = (1, X_1, X_2, X_1^2, X_2^2, X_1X_2) \\] \u9700\u8981\u6c42\u89e3\u7684\u4f18\u5316\u95ee\u9898\u53d8\u4e3a\uff1a \\[ \\mathop{\\arg \\min}_{\\beta(x_0)} \\sum_{i=1}^{N} K_\\lambda(x_0, x_i)[y_i - b(x_i)^T \\beta(x_0)]^2 \\] \u62df\u5408\u7684\u51fd\u6570\u4e3a \\(\\hat{f}(x_0) = b(x_0)^T \\hat{\\beta}(x_0)\\) \u3002 \u7ef4\u5ea6\u53d8\u5927\u65f6\uff0c\u7531\u4e8e\u8fb9\u754c\u4e0a\u7684\u70b9\u5360\u603b\u4f53\u6837\u672c\u7684\u6bd4\u4f8b\u66f4\u5927\uff08\u8d8a\u6765\u8d8a\u8d8b\u8fd1\u4e8e 100%\uff09\uff0c\u5728\u8fb9\u754c\u4e0a\u5f88\u96be\u4fdd\u6301\u4e00\u4e2a\u597d\u7684 bias-variance tradeoff\u3002\u56e0\u6b64\uff0c\u5c40\u90e8\u7ebf\u6027\u56de\u5f52\u5728 3 \u7ef4\u4ee5\u4e0a\u7684\u60c5\u5f62\u65f6\u5bf9\u8fb9\u754c bias \u7684\u4fee\u6b63\u4f5c\u7528\u4e0d\u4f73\u3002 Exercises Show that the Nadaraya-Watson kernel smooth with fixed metric bandwidth \\(\\lambda\\) and a Gaussian kernel is differentiable. What can be said for the Epanechnikov kernel? What can be said for the Epanechnikov kernel with adaptive nearest-neighbor bandwidth \\(\\lambda(x_0)\\) ? Nadaraya-Watson \u5b9a\u4e49\u7684\u4f30\u8ba1\u503c\u4e3a\uff1a \\[ \\hat{f}(x_0) = \\dfrac{\\sum_{i=1}^N K_\\lambda(x_0, x_i)y_i}{\\sum_{i=1}^N K_\\lambda(x_0, x_i) } \\] \u5f53\u6211\u4eec\u9009\u62e9\u9ad8\u65af\u6838\u65f6\uff1a \\[ K_\\lambda(x_0, x) = \\dfrac{1}{\\sqrt{2 \\pi} \\lambda} e^{- \\dfrac{(x-x_0)^2}{2\\lambda^2}} \\] \u65e0\u8bba \\(x_0\\) \u5982\u4f55\u9009\u53d6\uff0c\u9ad8\u65af\u6838\u51fd\u6570\u59cb\u7ec8\u53ef\u5bfc\u3002\u56e0\u6b64 \\(\\hat{f}(x_0)\\) \u4e5f\u59cb\u7ec8\u53ef\u5bfc\u3002 \u800c\u5bf9\u4e8e Epanechnikov \u6838\uff1a \\[ K_\\lambda(x_0, x) = \\begin{cases} \\dfrac{3}{4} (1 - \\dfrac{(x-x_0)^2}{\\lambda^2}), & \\text{if } |x - x_0| \\leq \\lambda \\\\ 0, & \\text{otherwise} \\end{cases} \\] \u7531\u4e8e Epanechnikov \u6838\u51fd\u6570\u662f\u4e00\u4e2a\u5206\u6bb5\u51fd\u6570\uff0c\u867d\u7136\u8fde\u7eed\u4f46\u662f\u4e0d\u53ef\u5bfc\uff0c\u56e0\u6b64 \\(\\hat{f}(x_0)\\) \u4e5f\u4e0d\u53ef\u5bfc\u3002","title":"ESL 6: Kernel Smoothing Methods"},{"location":"mathematics/ESL/ESL6_KernelSmoothingMethods/#esl-6-kernel-smoothing-methods","text":"\u672c\u7ae0\u6211\u4eec\u4ecb\u7ecd \u6838\u5e73\u6ed1\u65b9\u6cd5 \u3002\u5b83\u4ec5\u5229\u7528\u76ee\u6807\u70b9 \\(x_0\\) \u5468\u56f4\u7684\u89c2\u6d4b\u70b9\u6765\u62df\u5408\u6a21\u578b \\(f(X)\\) \uff0c\u5f97\u5230 \\(\\hat{f}(X)\\) \u3002\u76f8\u8f83\u4e8e\u6700\u8fd1\u90bb\u6cd5\uff0c\u5b83\u6240\u5f97\u5230\u7684 \\(\\hat{f}(X)\\) \u662f\u5e73\u6ed1 (smooth) \u540e\u7684\u3002 \u5b83\u5e73\u6ed1\u66f2\u7ebf\u7684\u539f\u7406\u662f\u5229\u7528\u4e00\u4e2a\u6838\u51fd\u6570 \\(K_\\lambda (x_0, x_i)\\) \u6839\u636e\u76ee\u6807\u70b9 \\(x_0\\) \u548c\u5468\u56f4\u70b9 \\(x_i\\) \u7684\u8ddd\u79bb\u8d4b\u4e88\u6743\u91cd\u3002 \u8fd9\u4e00\u7c7b\u65b9\u6cd5\u51e0\u4e4e\u4e0d\u9700\u8981\u8bad\u7ec3\uff0c\u53c2\u6570\u4e5f\u5f88\u7b80\u5355\uff0c\u53ea\u6709\u4e00\u4e2a\u8d85\u53c2\u6570 \\(\\lambda\\) \uff0c\u7528\u6765\u8bbe\u7f6e\u201c\u5468\u56f4\u201d\u7684\u5177\u4f53\u8303\u56f4\u3002\u4ed6\u4eec\u4e5f\u88ab\u79f0\u4e3a \"memory-based\" \u65b9\u6cd5\uff0c\u5176\u6a21\u578b\u5c31\u662f\u6240\u6709\u8bad\u7ec3\u6837\u672c\u672c\u8eab\uff0c\u62df\u5408\u5b9e\u65f6\u8fdb\u884c\u3002\u56e0\u6b64\uff0c\u5bf9\u4e8e\u67d0\u4e9b\u8981\u6c42\u8fd0\u7b97\u901f\u5ea6\uff0c\u6216\u8005\u5b58\u50a8\u6709\u9650\u7684\u573a\u5408\uff0c\u8fd9\u7c7b\u65b9\u6cd5\u5e76\u4e0d\u9002\u7528\u3002 \u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c \u6838\u5e73\u6ed1\u65b9\u6cd5 \u548c \u6838\u65b9\u6cd5 \u662f\u4e0d\u540c\u7684\u6982\u5ff5\u3002 \u6838\u65b9\u6cd5 \u4f1a\u5728\u9ad8\u7ef4\u7279\u5f81\u7a7a\u95f4\u8ba1\u7b97\u5185\u79ef\uff0c\u7528\u4e8e\u6b63\u5219\u5316\u7684\u975e\u7ebf\u6027\u5efa\u6a21\u3002","title":"ESL 6: Kernel Smoothing Methods"},{"location":"mathematics/ESL/ESL6_KernelSmoothingMethods/#61-one-dimensional-kernel-smoothers","text":"\u76f8\u5bf9\u4e8e\u6700\u8fd1\u90bb\u6cd5\uff0c\u6838\u5e73\u6ed1\u6cd5\u5bf9\u76ee\u6807\u70b9\u9644\u8fd1\u9009\u53d6\u7684\u6837\u672c\u70b9\u8bbe\u7f6e\u4e86 \u6839\u636e\u8ddd\u79bb\u8870\u51cf\u7684\u6743\u91cd \uff0c\u518d\u8fdb\u884c\u52a0\u6743\u5e73\u5747\u3002\u8fd9\u6837\u505a\u7684\u6700\u5927\u597d\u5904\u662f\u4f7f\u66f2\u7ebf\u66f4\u52a0\u5e73\u6ed1\u4e86\uff08\u4f46\u662f\u4e0d\u4e00\u5b9a\u53ef\u5bfc\uff0c\u89c1\u6587\u672b exercise\uff09 \\[ \\hat{f}(x_0) = \\dfrac{\\sum_{i=1}^N K_\\lambda(x_0, x_i)y_i}{\\sum_{i=1}^N K_\\lambda(x_0, x_i) } \\] \u6837\u672c\u70b9 \\(x\\) \u7684\u6743\u91cd\u51fd\u6570\uff08\u4e5f\u79f0\u4e3a\u6838\u51fd\u6570\uff09\u5b9a\u4e49\u4e3a\u5176\u4e0e\u76ee\u6807\u70b9 \\(x_0\\) \u8ddd\u79bb\u76f8\u5173\u7684\u51fd\u6570\uff1a \\[ K_\\lambda(x_0, x) = D( \\dfrac{|x - x_0|}{h_\\lambda(x_0)} ) \\] \u5176\u4e2d \\(h_\\lambda(x_0)\\) \u8868\u793a\u9009\u53d6\u7a97\u53e3\u7684\u5927\u5c0f\u53ef\u4ee5\u6839\u636e\u76ee\u6807\u70b9\u7684\u53d6\u503c\u53d8\u5316\u3002 \u53ef\u4ee5\u770b\u51fa\uff0c\u53f3\u56fe\u4f7f\u7528\u6838\u51fd\u6570\u5e73\u6ed1\u540e\uff0c\u76f8\u6bd4\u5de6\u56fe\u7684\u6700\u8fd1\u90bb\u6cd5\u83b7\u5f97\u7684\u4f30\u8ba1\u503c\u66f4\u4e3a\u5e73\u6ed1\u3002","title":"6.1 One-Dimensional Kernel Smoothers"},{"location":"mathematics/ESL/ESL6_KernelSmoothingMethods/#611-local-linear-regression","text":"\u6211\u4eec\u901a\u8fc7\u5f15\u5165\u6838\u51fd\u6570\u89e3\u51b3\u4e86\u5e73\u6ed1\u6027\u95ee\u9898\uff0c\u4f46\u662f\uff0c\u6211\u4eec\u53d1\u73b0\u5728\u4e34\u8fd1\u8fb9\u754c\u7684\u5730\u65b9\uff0c\u66f2\u7ebf\u51fa\u73b0\u4e86\u8f83\u5927\u7684 bias\uff0c\u8fd9\u662f\u7531\u4e8e\u8fb9\u754c\u533a\u57df\u6837\u672c\u70b9\u5206\u5e03\u4e0d\u5747\u5300\u3002 \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7 \u5c40\u90e8\u7ebf\u6027\u56de\u5f52 \u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u5b83\u5728 \u6bcf\u4e2a \u76ee\u6807\u70b9 \\(x_0\\) \u6c42\u89e3\u4e00\u4e2a \u6700\u5c0f\u4e8c\u4e58 \u95ee\u9898\uff1a \\[ \\mathop{\\arg \\min}_{\\alpha(x_0), \\beta(x_0)} \\sum_{i=1}^{N} K_\\lambda(x_0, x_i)[y_i - \\alpha(x_0) -\\beta(x_0)x_i]^2 \\] \u5373\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u76ee\u6807\u70b9\u5468\u56f4\u9009\u53d6\u7684\u6837\u672c\u70b9\uff0c\u7528\u7ebf\u6027\u51fd\u6570\u53bb\u62df\u5408\uff0c\u5f97\u5230\u7ebf\u6027\u65b9\u7a0b\uff1a \\[ \\hat{f}(x) = \\alpha(x_0) + \\beta(x_0)x \\] \u518d\u4ee3\u5165 \\(x_0\\) \u5f97\u5230\u4f30\u8ba1\u503c\u3002\u8be5\u65b9\u6cd5\u53ef\u4ee5 \u9664\u53bb 1 \u9636\u7684 bias\uff0c\u53ea\u4fdd\u7559 2 \u9636\u53ca\u66f4\u9ad8\u9636\u7684 bias \u3002 \u5bf9\u4e8e\u67d0\u4e00\u4e2a\u76ee\u6807\u70b9 \\(x_0\\) \uff0c\u5047\u8bbe\u5176\u5468\u56f4\u9009\u53d6\u4e86 \\(N\\) \u4e2a\u6837\u672c\u70b9\uff0c\u5176\u4f30\u8ba1\u7ed3\u679c\u53ef\u4ee5\u5199\u6210\u77e9\u9635\u5f62\u5f0f\uff1a \\[\\begin{align} \\hat{f}(x_0) &= b(x_0)^T (\\mathbf{B}^T \\mathbf{W}(x_0) \\mathbf{B})^{-1} \\mathbf{B}^T \\mathbf{W}(x_0) \\mathbf{y} \\\\ &= \\sum_{i=1}^{N} l_i(x_0)y_i \\end{align}\\] \u5176\u4e2d \\(b(x_0)^T = (1, x_0)\\) \uff0c\u77e9\u9635\uff1a \\[ \\mathbf{B} = \\left[ \\begin{array}{cc} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_N \\end{array} \\right]_{N \\times 2}\\] \\[ \\mathbf{W}(x_0) = \\left[ \\begin{array}{cccc} K_\\lambda(x_0, x_1) & & &\\\\ & K_\\lambda(x_0, x_2) & &\\\\ & & & \\ddots & \\\\ & & & & K_\\lambda(x_0, x_N) \\\\ \\end{array} \\right]_{N \\times N}\\] \u5176\u6548\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u53ef\u4ee5\u770b\u51fa\u5728\u5b9a\u4e49\u57df\u8fb9\u7f18\u4f4d\u7f6e\uff0c\u4f7f\u7528\u5c40\u90e8\u7ebf\u6027\u56de\u5f52\uff08\u53f3\u56fe\uff09\u62df\u5408\u6548\u679c\u66f4\u597d\u3002","title":"6.1.1 Local Linear Regression"},{"location":"mathematics/ESL/ESL6_KernelSmoothingMethods/#62-selecting-the-width-of-the-kernel","text":"\u51e0\u79cd\u5e38\u7528\u7684 kernel: \u5bf9\u4e8e Epanechnikov \u548c tri-cube kernel\uff0c \\(\\lambda\\) \u662f\u201c\u5468\u56f4\u201d\u7684\u534a\u5f84\u3002\u5bf9\u4e8e Gaussian kernel\uff0c \\(\\lambda\\) \u662f\u5176\u6807\u51c6\u5dee \\(\\sigma\\) \u3002 \u9009\u53d6 \\(\\lambda\\) \u5b9e\u9645\u4e0a\u662f bias-variance \u7684 tradeoff\u3002\u5f53\u9009\u53d6\u7a97\u53e3\u5f88\u5c0f\u65f6\uff0c\u7531\u4e8e\u91c7\u7528\u7684\u6837\u672c\u70b9\u8f83\u5c11\uff0c\u5f97\u5230\u7684\u76ee\u6807\u70b9\u7684\u4f30\u8ba1\u503c variance \u4f1a\u5f88\u5927\u3002\u4f46\u662f\u540c\u65f6\uff0c\u7531\u4e8e\u9009\u53d6\u7684\u70b9\u90fd\u662f\u79bb\u76ee\u6807\u70b9\u6700\u8fd1\u7684\u70b9\uff0c\u5b83\u7684 bias \u5f88\u5c0f\u3002","title":"6.2 Selecting the Width of the Kernel"},{"location":"mathematics/ESL/ESL6_KernelSmoothingMethods/#63-multi-dimensional-local-regression","text":"\u6211\u4eec\u53ef\u4ee5\u81ea\u7136\u5730\u5c06\u5c40\u90e8\u7ebf\u6027\u56de\u5f52\u6269\u5c55\u5230\u591a\u7ef4\uff0c\u7528\u4e8e\u62df\u5408\u4e00\u4e2a\u8d85\u5e73\u9762\u3002 \u5f53\u7ef4\u5ea6 \\(p = 2\\) \uff0c\u9636\u6b21 \\(d = 1\\) \u65f6\uff0c\u6211\u4eec\u6709\uff1a \\[ b(X) = (1, X_1, X_2) \\] \u5f53\u7ef4\u5ea6 \\(p = 2\\) \uff0c\u9636\u6b21 \\(d = 2\\) \u65f6\uff0c\u6211\u4eec\u6709\uff1a \\[ b(X) = (1, X_1, X_2, X_1^2, X_2^2, X_1X_2) \\] \u9700\u8981\u6c42\u89e3\u7684\u4f18\u5316\u95ee\u9898\u53d8\u4e3a\uff1a \\[ \\mathop{\\arg \\min}_{\\beta(x_0)} \\sum_{i=1}^{N} K_\\lambda(x_0, x_i)[y_i - b(x_i)^T \\beta(x_0)]^2 \\] \u62df\u5408\u7684\u51fd\u6570\u4e3a \\(\\hat{f}(x_0) = b(x_0)^T \\hat{\\beta}(x_0)\\) \u3002 \u7ef4\u5ea6\u53d8\u5927\u65f6\uff0c\u7531\u4e8e\u8fb9\u754c\u4e0a\u7684\u70b9\u5360\u603b\u4f53\u6837\u672c\u7684\u6bd4\u4f8b\u66f4\u5927\uff08\u8d8a\u6765\u8d8a\u8d8b\u8fd1\u4e8e 100%\uff09\uff0c\u5728\u8fb9\u754c\u4e0a\u5f88\u96be\u4fdd\u6301\u4e00\u4e2a\u597d\u7684 bias-variance tradeoff\u3002\u56e0\u6b64\uff0c\u5c40\u90e8\u7ebf\u6027\u56de\u5f52\u5728 3 \u7ef4\u4ee5\u4e0a\u7684\u60c5\u5f62\u65f6\u5bf9\u8fb9\u754c bias \u7684\u4fee\u6b63\u4f5c\u7528\u4e0d\u4f73\u3002","title":"6.3 Multi-dimensional Local Regression"},{"location":"mathematics/ESL/ESL6_KernelSmoothingMethods/#exercises","text":"Show that the Nadaraya-Watson kernel smooth with fixed metric bandwidth \\(\\lambda\\) and a Gaussian kernel is differentiable. What can be said for the Epanechnikov kernel? What can be said for the Epanechnikov kernel with adaptive nearest-neighbor bandwidth \\(\\lambda(x_0)\\) ? Nadaraya-Watson \u5b9a\u4e49\u7684\u4f30\u8ba1\u503c\u4e3a\uff1a \\[ \\hat{f}(x_0) = \\dfrac{\\sum_{i=1}^N K_\\lambda(x_0, x_i)y_i}{\\sum_{i=1}^N K_\\lambda(x_0, x_i) } \\] \u5f53\u6211\u4eec\u9009\u62e9\u9ad8\u65af\u6838\u65f6\uff1a \\[ K_\\lambda(x_0, x) = \\dfrac{1}{\\sqrt{2 \\pi} \\lambda} e^{- \\dfrac{(x-x_0)^2}{2\\lambda^2}} \\] \u65e0\u8bba \\(x_0\\) \u5982\u4f55\u9009\u53d6\uff0c\u9ad8\u65af\u6838\u51fd\u6570\u59cb\u7ec8\u53ef\u5bfc\u3002\u56e0\u6b64 \\(\\hat{f}(x_0)\\) \u4e5f\u59cb\u7ec8\u53ef\u5bfc\u3002 \u800c\u5bf9\u4e8e Epanechnikov \u6838\uff1a \\[ K_\\lambda(x_0, x) = \\begin{cases} \\dfrac{3}{4} (1 - \\dfrac{(x-x_0)^2}{\\lambda^2}), & \\text{if } |x - x_0| \\leq \\lambda \\\\ 0, & \\text{otherwise} \\end{cases} \\] \u7531\u4e8e Epanechnikov \u6838\u51fd\u6570\u662f\u4e00\u4e2a\u5206\u6bb5\u51fd\u6570\uff0c\u867d\u7136\u8fde\u7eed\u4f46\u662f\u4e0d\u53ef\u5bfc\uff0c\u56e0\u6b64 \\(\\hat{f}(x_0)\\) \u4e5f\u4e0d\u53ef\u5bfc\u3002","title":"Exercises"},{"location":"mathematics/ESL/ESL9_AdditiveModels/","text":"ESL 9.1: Generalized Additive Models \u5b9e\u9645\u4e2d\u7684\u5f88\u591a\u6a21\u578b\u5e76\u975e\u7ebf\u6027\uff0c\u4f20\u7edf\u7ebf\u6027\u6a21\u578b\u6548\u679c\u5e76\u4e0d\u597d\u3002\u672c\u8282\u4ecb\u7ecd\u4e86\u4e00\u79cd\u66f4\u52a0\u7075\u6d3b\u7684\u7edf\u8ba1\u6a21\u578b\uff0c\u53ef\u4ee5\u5efa\u6a21\u975e\u7ebf\u6027\u7684\u5f71\u54cd\u3002\u5b83\u5c06\u6a21\u578b\u5b9a\u4e49\u4e3a\uff1a \\[ E(Y|X_1, X_2, ..., X_p) = \\alpha + f_1(X_1) + f_2(X_2) + \\cdots + f_p(X_p)\\] \u5176\u4e2d\uff0c \\(X_i\\) \u662f\u7b2c \\(i\\) \u4e2a\u7279\u5f81\uff0c \\(Y\\) \u662f\u9884\u6d4b\u503c\uff0c \\(f_i\\) \u662f\u7b2c \\(i\\) \u4e2a\u7279\u5f81\u7684 \"smoother\"\uff0c\u5b83\u53ef\u4ee5\u662f\u4e00\u4e2a cubic spline\uff0c\u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a kernel smoother\u3002 \u4f8b\u5982\uff0c\u5728\u903b\u8f91\u56de\u5f52\u4e2d\uff0c\u5bf9\u4e8e\u4e8c\u5206\u7c7b\u95ee\u9898\u6211\u4eec\u5047\u8bbe Y=1 \u7684\u6982\u7387 \\(\\mu(X) = \\text{Pr}(Y=1|X)\\) \uff0c\u6211\u4eec\u53ef\u4ee5\u5c06 logit \u51fd\u6570\u8868\u793a\u4e3a\u7279\u5f81\u7684 \u7ebf\u6027 \u7ec4\u5408\uff1a \\[ \\ln(\\dfrac{\\mu(X)}{1-\\mu(X)}) = \\alpha + \\beta_1 X_1 + \\cdots + \\beta_p X_p \\] \u5728 additive model \u4e2d\uff0c\u6211\u4eec\u4e0d\u4f5c\u7ebf\u6027\u5047\u8bbe\uff0c\u4e0a\u5f0f\u5199\u4e3a\u66f4\u901a\u7528\u7684\u5f62\u5f0f\uff1a \\[ \\ln(\\dfrac{\\mu(X)}{1-\\mu(X)}) = \\alpha + f_1(X_1) + \\cdots + f_p(X_p) \\] \u4e0a\u5f0f\u7684\u6bcf\u4e2a\u4f30\u8ba1\u51fd\u6570 \\(f_i\\) \u662f\u57fa\u4e8e scatterplot smoother \u7684\uff0c\u56e0\u6b64\u53ef\u4ee5\u4f53\u73b0 \\(X_i\\) \u7684\u975e\u7ebf\u6027\u7279\u5f81\u3002 9.1.1 Fitting Additive Models \u672c\u8282\u6211\u4eec\u7528 cubic spline \u4f5c\u4e3a scatterplot smoother \u6765\u62df\u5408\u4e00\u4e2a additive model\u3002\u8fd9\u4e2a additive model \u5f62\u5f0f\u4e3a\uff1a \\[ Y = \\alpha + \\sum_{j=1}^p f_j(X_j) + \\varepsilon \\] \u5176\u4e2d \\(\\varepsilon\\) \u662f\u5747\u503c\u4e3a 0 \u7684\u8bef\u5dee\u9879\u3002 \u6211\u4eec\u7684\u76ee\u6807\u662f\u786e\u5b9a \\(\\alpha\\) \u4ee5\u53ca \\(f_j\\) \uff0c\u4e3a\u4e86\u63cf\u8ff0\u975e\u7ebf\u6027\uff0c\u6211\u4eec\u5047\u8bbe \\(f_j\\) \u662f \u4ee5\u6bcf\u4e2a\u6837\u672c\u70b9\u4e3a\u8282\u70b9\u7684 cubic spline \u3002 Unique Solution \u5982\u679c\u6211\u4eec\u4e0d\u9644\u52a0\u9650\u5236\u6761\u4ef6\uff0c\u5e38\u6570\u9879 \\(\\alpha\\) \u4e0d\u662f\u552f\u4e00\u7684\u3002\u56e0\u4e3a\u6211\u4eec\u53ef\u4ee5\u5728\u51fd\u6570 \\(f_j\\) \u7684\u5e38\u719f\u9879\u4e2d\u4efb\u610f\u8fdb\u884c\u52a0\u51cf\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u589e\u52a0\u4e86\u4e00\u6761\u9650\u5236\u6761\u4ef6\u4ee5\u83b7\u5f97 \u552f\u4e00\u89e3 : \\[ \\sum_i^N f_j(x_{ij}) = 0 \\] \u5373\u9650\u5236\u6bcf\u4e2a\u51fd\u6570\u7684\u4f30\u8ba1\u503c\u76f8\u52a0\u4e3a 0\u3002\u6b64\u65f6\u5fc5\u7136\u6709\u4e00\u4e2a\u786e\u5b9a\u7684 \\(\\hat{\\alpha} = \\text{ave} (y_i)\\) \u3002 \u4e0a\u9762\u7b97\u6cd5\u9700\u8981\u6ce8\u610f\u7684\u91cd\u70b9\uff1a \\(\\alpha\\) \u521d\u59cb\u503c\u4e3a \\(\\hat{\\alpha} = \\text{ave} (y_i)\\) \uff0c\u5e76\u4fdd\u6301\u4e0d\u53d8 \\(f_j\\) \u521d\u59cb\u5316\u5168\u7cfb\u6570\u4e3a 0 \u5faa\u73af\u7684\u601d\u8def\u662f\u4e0d\u65ad\u5730\u7528 \\(f_j\\) \u53bb\u62df\u5408 \u6b8b\u5dee \uff0c\u76f4\u5230\u6536\u655b\uff0c\u6b8b\u5dee\u7531 y \u51cf\u53bb \u5176\u5b83 \u6240\u6709\u7279\u5f81\u7684\u9884\u6d4b\u503c\u4e4b\u548c\u5f97\u5230\u3002 9.1.2 Example: Additive Logistic Regression Additive model \u53ef\u4ee5\u5e94\u7528\u5230\u5206\u7c7b\u95ee\u9898\u4e2d\u3002\u901a\u7528\u7684 additive logistic model \u7684\u5f62\u5f0f\u4e3a\uff1a \\[ \\ln \\frac{\\text{Pr}(Y=1 | X)}{\\text{Pr}(Y=0 | X)} = \\alpha + f_1(X_1) + \\cdots + f_p(X_p) \\] \u5176\u4e2d, \\(f_1, f_2, \\dots, f_p\\) \u7528 Newton-Raphson \u6cd5\u4f30\u8ba1\u3002 Example: Predicting Email Spam \u6211\u4eec\u5206\u522b\u7528 logistic regression \u548c additive logistic model \u5bf9\u5783\u573e\u90ae\u4ef6\u8fdb\u884c\u5206\u7c7b\uff0c\u4ee5\u6b64\u6765\u5206\u6790 additive model \u7684\u7279\u70b9\u3002 \u4e0b\u9762\u662f logistic regression \u7684\u4ee3\u7801\uff1a from sklearn.linear_model import LogisticRegression from sklearn.model_selection import KFold for train_index , test_index in KFold ( n_splits = 5 , shuffle = True , random_state = 1 ) . split ( X ): trainX , testX = X . loc [ train_index ], X . loc [ test_index ] trainY , testY = y . loc [ train_index ], y . loc [ test_index ] model = LogisticRegression ( random_state = 0 ) . fit ( trainX , trainY ) print ( f \"LR accuracy: { model . score ( testX , testY ) } \" ) logistic regression \u7684\u7ed3\u679c\u4e3a\uff1a LR accuracy: 0.9283387622149837 LR accuracy: 0.9271739130434783 LR accuracy: 0.9119565217391304 LR accuracy: 0.9206521739130434 LR accuracy: 0.925 \u4e0b\u9762\u662f additive logistic model \u7684\u4ee3\u7801\uff1a from pygam import LogisticGAM for train_index , test_index in KFold ( n_splits = 5 , shuffle = True , random_state = 1 ) . split ( X ): trainX , testX = X . loc [ train_index ], X . loc [ test_index ] trainY , testY = y . loc [ train_index ], y . loc [ test_index ] model = LogisticGAM () . fit ( trainX , trainY ) print ( f \"GAM accuracy: { model . accuracy ( testX , testY ) } \" ) additive model \u7684\u7ed3\u679c\u4e3a\uff1a GAM accuracy: 0.9402823018458197 GAM accuracy: 0.9380434782608695 GAM accuracy: 0.9228260869565217 GAM accuracy: 0.9467391304347826 GAM accuracy: 0.9456521739130435 \u53ef\u4ee5\u770b\u51fa\uff0c\u9ed8\u8ba4\u53c2\u6570\u60c5\u51b5\u4e0b\uff0cGAM \u7684\u7ed3\u679c\u8981\u7565\u597d\u4e8e LR \u7684\u7ed3\u679c\u3002\u901a\u8fc7\u753b\u51fa\u62df\u5408\u51fa\u7684\u6bcf\u4e2a\u7279\u5f81\u7684\u51fd\u6570 \\(f_j(X_j)\\) \uff0c\u53ef\u4ee5\u770b\u51fa\uff0c\u5f88\u591a\u7279\u5f81\u90fd\u5177\u6709\u975e\u7ebf\u6027\u7684\u51fd\u6570\u3002\u800c additive model \u7684\u4e00\u5927\u4f18\u52bf\u5c31\u662f\u80fd\u591f capture non-linear effects. \u7ed8\u56fe\u6240\u7528\u4ee3\u7801\uff1a # Plot to notebook from bokeh.io import output_notebook output_notebook () from bokeh.plotting import figure , show from bokeh import layouts def plot_features ( gam_model , feature_names ): # exclude the intercept feature_count = len ( gam_model . terms ) - 1 figs = [] for i in range ( feature_count ): xx = gam_model . generate_X_grid ( term = i )[:, i ] yy = gam_model . partial_dependence ( term = i ) fig = figure ( title = feature_names [ i ]) fig . line ( x = xx , y = yy ) figs . append ( fig ) show ( layouts . gridplot ( figs , ncols = 2 , width = 400 , height = 200 )) Reference GAM: The Predictive Modeling Silver Bullet","title":"ESL 9.1: Generalized Additive Models"},{"location":"mathematics/ESL/ESL9_AdditiveModels/#esl-91-generalized-additive-models","text":"\u5b9e\u9645\u4e2d\u7684\u5f88\u591a\u6a21\u578b\u5e76\u975e\u7ebf\u6027\uff0c\u4f20\u7edf\u7ebf\u6027\u6a21\u578b\u6548\u679c\u5e76\u4e0d\u597d\u3002\u672c\u8282\u4ecb\u7ecd\u4e86\u4e00\u79cd\u66f4\u52a0\u7075\u6d3b\u7684\u7edf\u8ba1\u6a21\u578b\uff0c\u53ef\u4ee5\u5efa\u6a21\u975e\u7ebf\u6027\u7684\u5f71\u54cd\u3002\u5b83\u5c06\u6a21\u578b\u5b9a\u4e49\u4e3a\uff1a \\[ E(Y|X_1, X_2, ..., X_p) = \\alpha + f_1(X_1) + f_2(X_2) + \\cdots + f_p(X_p)\\] \u5176\u4e2d\uff0c \\(X_i\\) \u662f\u7b2c \\(i\\) \u4e2a\u7279\u5f81\uff0c \\(Y\\) \u662f\u9884\u6d4b\u503c\uff0c \\(f_i\\) \u662f\u7b2c \\(i\\) \u4e2a\u7279\u5f81\u7684 \"smoother\"\uff0c\u5b83\u53ef\u4ee5\u662f\u4e00\u4e2a cubic spline\uff0c\u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a kernel smoother\u3002 \u4f8b\u5982\uff0c\u5728\u903b\u8f91\u56de\u5f52\u4e2d\uff0c\u5bf9\u4e8e\u4e8c\u5206\u7c7b\u95ee\u9898\u6211\u4eec\u5047\u8bbe Y=1 \u7684\u6982\u7387 \\(\\mu(X) = \\text{Pr}(Y=1|X)\\) \uff0c\u6211\u4eec\u53ef\u4ee5\u5c06 logit \u51fd\u6570\u8868\u793a\u4e3a\u7279\u5f81\u7684 \u7ebf\u6027 \u7ec4\u5408\uff1a \\[ \\ln(\\dfrac{\\mu(X)}{1-\\mu(X)}) = \\alpha + \\beta_1 X_1 + \\cdots + \\beta_p X_p \\] \u5728 additive model \u4e2d\uff0c\u6211\u4eec\u4e0d\u4f5c\u7ebf\u6027\u5047\u8bbe\uff0c\u4e0a\u5f0f\u5199\u4e3a\u66f4\u901a\u7528\u7684\u5f62\u5f0f\uff1a \\[ \\ln(\\dfrac{\\mu(X)}{1-\\mu(X)}) = \\alpha + f_1(X_1) + \\cdots + f_p(X_p) \\] \u4e0a\u5f0f\u7684\u6bcf\u4e2a\u4f30\u8ba1\u51fd\u6570 \\(f_i\\) \u662f\u57fa\u4e8e scatterplot smoother \u7684\uff0c\u56e0\u6b64\u53ef\u4ee5\u4f53\u73b0 \\(X_i\\) \u7684\u975e\u7ebf\u6027\u7279\u5f81\u3002","title":"ESL 9.1: Generalized Additive Models"},{"location":"mathematics/ESL/ESL9_AdditiveModels/#911-fitting-additive-models","text":"\u672c\u8282\u6211\u4eec\u7528 cubic spline \u4f5c\u4e3a scatterplot smoother \u6765\u62df\u5408\u4e00\u4e2a additive model\u3002\u8fd9\u4e2a additive model \u5f62\u5f0f\u4e3a\uff1a \\[ Y = \\alpha + \\sum_{j=1}^p f_j(X_j) + \\varepsilon \\] \u5176\u4e2d \\(\\varepsilon\\) \u662f\u5747\u503c\u4e3a 0 \u7684\u8bef\u5dee\u9879\u3002 \u6211\u4eec\u7684\u76ee\u6807\u662f\u786e\u5b9a \\(\\alpha\\) \u4ee5\u53ca \\(f_j\\) \uff0c\u4e3a\u4e86\u63cf\u8ff0\u975e\u7ebf\u6027\uff0c\u6211\u4eec\u5047\u8bbe \\(f_j\\) \u662f \u4ee5\u6bcf\u4e2a\u6837\u672c\u70b9\u4e3a\u8282\u70b9\u7684 cubic spline \u3002","title":"9.1.1 Fitting Additive Models"},{"location":"mathematics/ESL/ESL9_AdditiveModels/#unique-solution","text":"\u5982\u679c\u6211\u4eec\u4e0d\u9644\u52a0\u9650\u5236\u6761\u4ef6\uff0c\u5e38\u6570\u9879 \\(\\alpha\\) \u4e0d\u662f\u552f\u4e00\u7684\u3002\u56e0\u4e3a\u6211\u4eec\u53ef\u4ee5\u5728\u51fd\u6570 \\(f_j\\) \u7684\u5e38\u719f\u9879\u4e2d\u4efb\u610f\u8fdb\u884c\u52a0\u51cf\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u589e\u52a0\u4e86\u4e00\u6761\u9650\u5236\u6761\u4ef6\u4ee5\u83b7\u5f97 \u552f\u4e00\u89e3 : \\[ \\sum_i^N f_j(x_{ij}) = 0 \\] \u5373\u9650\u5236\u6bcf\u4e2a\u51fd\u6570\u7684\u4f30\u8ba1\u503c\u76f8\u52a0\u4e3a 0\u3002\u6b64\u65f6\u5fc5\u7136\u6709\u4e00\u4e2a\u786e\u5b9a\u7684 \\(\\hat{\\alpha} = \\text{ave} (y_i)\\) \u3002 \u4e0a\u9762\u7b97\u6cd5\u9700\u8981\u6ce8\u610f\u7684\u91cd\u70b9\uff1a \\(\\alpha\\) \u521d\u59cb\u503c\u4e3a \\(\\hat{\\alpha} = \\text{ave} (y_i)\\) \uff0c\u5e76\u4fdd\u6301\u4e0d\u53d8 \\(f_j\\) \u521d\u59cb\u5316\u5168\u7cfb\u6570\u4e3a 0 \u5faa\u73af\u7684\u601d\u8def\u662f\u4e0d\u65ad\u5730\u7528 \\(f_j\\) \u53bb\u62df\u5408 \u6b8b\u5dee \uff0c\u76f4\u5230\u6536\u655b\uff0c\u6b8b\u5dee\u7531 y \u51cf\u53bb \u5176\u5b83 \u6240\u6709\u7279\u5f81\u7684\u9884\u6d4b\u503c\u4e4b\u548c\u5f97\u5230\u3002","title":"Unique Solution"},{"location":"mathematics/ESL/ESL9_AdditiveModels/#912-example-additive-logistic-regression","text":"Additive model \u53ef\u4ee5\u5e94\u7528\u5230\u5206\u7c7b\u95ee\u9898\u4e2d\u3002\u901a\u7528\u7684 additive logistic model \u7684\u5f62\u5f0f\u4e3a\uff1a \\[ \\ln \\frac{\\text{Pr}(Y=1 | X)}{\\text{Pr}(Y=0 | X)} = \\alpha + f_1(X_1) + \\cdots + f_p(X_p) \\] \u5176\u4e2d, \\(f_1, f_2, \\dots, f_p\\) \u7528 Newton-Raphson \u6cd5\u4f30\u8ba1\u3002","title":"9.1.2 Example: Additive Logistic Regression"},{"location":"mathematics/ESL/ESL9_AdditiveModels/#example-predicting-email-spam","text":"\u6211\u4eec\u5206\u522b\u7528 logistic regression \u548c additive logistic model \u5bf9\u5783\u573e\u90ae\u4ef6\u8fdb\u884c\u5206\u7c7b\uff0c\u4ee5\u6b64\u6765\u5206\u6790 additive model \u7684\u7279\u70b9\u3002 \u4e0b\u9762\u662f logistic regression \u7684\u4ee3\u7801\uff1a from sklearn.linear_model import LogisticRegression from sklearn.model_selection import KFold for train_index , test_index in KFold ( n_splits = 5 , shuffle = True , random_state = 1 ) . split ( X ): trainX , testX = X . loc [ train_index ], X . loc [ test_index ] trainY , testY = y . loc [ train_index ], y . loc [ test_index ] model = LogisticRegression ( random_state = 0 ) . fit ( trainX , trainY ) print ( f \"LR accuracy: { model . score ( testX , testY ) } \" ) logistic regression \u7684\u7ed3\u679c\u4e3a\uff1a LR accuracy: 0.9283387622149837 LR accuracy: 0.9271739130434783 LR accuracy: 0.9119565217391304 LR accuracy: 0.9206521739130434 LR accuracy: 0.925 \u4e0b\u9762\u662f additive logistic model \u7684\u4ee3\u7801\uff1a from pygam import LogisticGAM for train_index , test_index in KFold ( n_splits = 5 , shuffle = True , random_state = 1 ) . split ( X ): trainX , testX = X . loc [ train_index ], X . loc [ test_index ] trainY , testY = y . loc [ train_index ], y . loc [ test_index ] model = LogisticGAM () . fit ( trainX , trainY ) print ( f \"GAM accuracy: { model . accuracy ( testX , testY ) } \" ) additive model \u7684\u7ed3\u679c\u4e3a\uff1a GAM accuracy: 0.9402823018458197 GAM accuracy: 0.9380434782608695 GAM accuracy: 0.9228260869565217 GAM accuracy: 0.9467391304347826 GAM accuracy: 0.9456521739130435 \u53ef\u4ee5\u770b\u51fa\uff0c\u9ed8\u8ba4\u53c2\u6570\u60c5\u51b5\u4e0b\uff0cGAM \u7684\u7ed3\u679c\u8981\u7565\u597d\u4e8e LR \u7684\u7ed3\u679c\u3002\u901a\u8fc7\u753b\u51fa\u62df\u5408\u51fa\u7684\u6bcf\u4e2a\u7279\u5f81\u7684\u51fd\u6570 \\(f_j(X_j)\\) \uff0c\u53ef\u4ee5\u770b\u51fa\uff0c\u5f88\u591a\u7279\u5f81\u90fd\u5177\u6709\u975e\u7ebf\u6027\u7684\u51fd\u6570\u3002\u800c additive model \u7684\u4e00\u5927\u4f18\u52bf\u5c31\u662f\u80fd\u591f capture non-linear effects. \u7ed8\u56fe\u6240\u7528\u4ee3\u7801\uff1a # Plot to notebook from bokeh.io import output_notebook output_notebook () from bokeh.plotting import figure , show from bokeh import layouts def plot_features ( gam_model , feature_names ): # exclude the intercept feature_count = len ( gam_model . terms ) - 1 figs = [] for i in range ( feature_count ): xx = gam_model . generate_X_grid ( term = i )[:, i ] yy = gam_model . partial_dependence ( term = i ) fig = figure ( title = feature_names [ i ]) fig . line ( x = xx , y = yy ) figs . append ( fig ) show ( layouts . gridplot ( figs , ncols = 2 , width = 400 , height = 200 ))","title":"Example: Predicting Email Spam"},{"location":"mathematics/ESL/ESL9_AdditiveModels/#reference","text":"GAM: The Predictive Modeling Silver Bullet","title":"Reference"},{"location":"mathematics/ESL/ESL9_TreeBasedMethods/","text":"ESL 9.2: Tree-Based Methods 9.2.1 Background \u6811\u65b9\u6cd5\u5c06\u7279\u5f81\u7a7a\u95f4\u5206\u5272\u4e3a\u4e0d\u540c\u533a\u57df\uff0c\u7136\u540e\u7528\u4e00\u4e2a\u7b80\u5355\u7684\u6a21\u578b\uff08\u6bd4\u5982\u5e38\u6570\uff09\u6765\u62df\u5408\u6bcf\u4e2a\u533a\u57df\u3002 \u8003\u8651\u4e00\u4e2a\u7b80\u5355\u7684\u56de\u5f52\u95ee\u9898\u3002\u7279\u5f81\u662f\u4e8c\u7ef4\u7684 \\(X_1\\) \u548c \\(X_2\\) \uff0c\u54cd\u5e94\u662f\u5b9e\u6570 \\(Y\\) \u3002\u6211\u4eec\u53ef\u4ee5\u628a\u7279\u5f81\u7a7a\u95f4\u5206\u533a\uff0c\u6bcf\u4e2a\u533a\u8d4b\u4e88\u4e00\u4e2a\u5e38\u6570\u4f5c\u4e3a\u54cd\u5e94\u7684\u4f30\u8ba1\u503c\u3002 \u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5de6\u4e0a\u89d2\u7684\u5b50\u56fe\u662f\u4e00\u79cd\u590d\u6742\u7684\u60c5\u5f62\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u533a\u57df\u5f88\u96be\u63cf\u8ff0\u3002\u6211\u4eec\u5148\u7814\u7a76\u7c7b\u4f3c\u4e8e\u53f3\u4e0a\u89d2\u7684\u5b50\u56fe\u7684\u7b80\u5355\u60c5\u5f62\uff0c\u5b83\u53ef\u4ee5\u8868\u793a\u6210\u4e00\u4e2a\u7b80\u5355\u7684\u4e8c\u53c9\u6811\uff08\u5de6\u4e0b\uff09\uff0c\u6bcf\u4e2a\u53f6\u5b50\u8282\u70b9\u5c31\u662f\u5176\u5206\u533a\u7ed3\u679c\uff0c\u53ef\u4ee5\u8d4b\u4e88\u4e00\u4e2a\u5e38\u6570\u3002 9.2.2 Regression Trees \u73b0\u5728\u6211\u4eec\u53ef\u4ee5\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u5982\u4f55\u6784\u9020\u4e00\u4e2a regression tree\u3002\u5047\u8bbe\u6211\u4eec\u7684\u7279\u5f81\u6709 \\(p\\) \u7ef4\uff0c\u5171\u6709 \\(N\\) \u4e2a\u89c2\u6d4b\u6837\u672c\u3002\u6211\u4eec\u9700\u8981\u627e\u5230\u4e00\u4e2a\u7b97\u6cd5\u80fd\u591f\u81ea\u52a8\u51b3\u5b9a\u5728\u54ea\u4e9b\u7279\u5f81\u7684\u54ea\u4e9b\u503c\u8fdb\u884c\u5206\u5272\uff0c\u4ee5\u6b64\u51b3\u5b9a regression tree \u7684\u5f62\u72b6\u3002\u5982\u679c\u5206\u652f\u6570\u592a\u591a\uff0c\u663e\u7136\u4f1a\u5b58\u5728\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002\u4f46\u662f\u5206\u652f\u6570\u592a\u5c11\u53c8\u53ef\u80fd\u5ffd\u7565\u6389\u91cd\u8981\u7684\u7ed3\u6784\u3002 \u53ef\u8c03\u53c2\u6570\uff1a \u6bcf\u4e2a\u53f6\u5b50\u8282\u70b9\u6700\u5927\u6837\u672c\u6570\uff08\u7528\u4e8e Step 1 \u7ec8\u6b62\u6761\u4ef6\uff09 Step1. \u9012\u5f52\u6784\u9020\u4e8c\u53c9\u6811 Step 1.1 \u9012\u5f52\u5207\u5206 \u5047\u8bbe\u6211\u4eec\u5bf9\u7b2c \\(j\\) \u4e2a\u7279\u5f81\u9009\u62e9\u4e86\u5206\u5272\u70b9 \\(s\\) \uff0c\u5219\u5206\u5272\u6210\u7684\u4e24\u4e2a\u90e8\u5206\u4e3a\uff1a \\[ R_1(j, s) = \\{ X|X_j \\leq s \\} \\] \\[ R_2(j, s) = \\{ X|X_j \\gt s \\} \\] \u6211\u4eec\u7684\u76ee\u6807\u662f\u9009\u62e9 \\(j\\) \u548c \\(s\\) \u8ba9\u4e24\u4e2a\u90e8\u5206\u7684\u6b8b\u5dee\u5e73\u65b9\u548c (RSS) \u6700\u5c0f\uff0c\u5373\u6c42\u89e3\u5982\u4e0b\u95ee\u9898\uff1a \\[ \\min_{j,s} [ \\sum_{x_i \\in R_1} (y_i - \\hat{c}_1)^2 + \\sum_{x_i \\in R_2} (y_i - \\hat{c}_2)^2 ]\\] \u5176\u4e2d\u9884\u6d4b\u503c\u7684\u4f30\u8ba1 \\(\\hat{c}\\) \u4e3a\u5404\u90e8\u5206 \\(y_i\\) \u7684\u5747\u503c\u3002 \u5047\u8bbe \\(X_j\\) \u5728\u6837\u672c\u4e2d\u4e00\u5171\u6709 k \u4e2a\u4e0d\u540c\u7684\u503c\uff0c\u5219\u663e\u7136\u6700\u591a\u6709 k-1 \u79cd\u5206\u6cd5\u3002\u53ef\u4ee5\u4f9d\u6b21\u5c1d\u8bd5\u627e\u5230 \\(s\\) \u3002\u8fd9\u6837\u6211\u4eec\u5c31\u786e\u5b9a\u4e86\u4e00\u7ec4 \\((j, s)\\) \u7ec4\u5408\u3002\u8be5\u7ec4\u5408\u5c06\u6570\u636e\u5206\u4e3a\u4e24\u90e8\u5206\uff0c\u6211\u4eec\u518d\u5bf9\u6bcf\u4e00\u4e2a\u90e8\u5206\u91cd\u590d\u4e0a\u8ff0\u64cd\u4f5c\u3002 Step1.2 \u7ec8\u6b62\u6761\u4ef6 \u5728 step 1.1 \u7684\u6bcf\u6b21\u5207\u5206\u4e4b\u540e\uff0c\u6211\u4eec\u9700\u8981\u5bf9\u6bcf\u4e2a\u90e8\u5206\u5224\u65ad\u662f\u5426\u505c\u6b62\u5207\u5206\u3002\u5982\u679c\u76f4\u63a5\u7528 sum-of-squares \u53d8\u5c0f\u7684\u5e45\u5ea6\u4f5c\u4e3a\u7ec8\u6b62\u6761\u4ef6\uff0c\u53ef\u80fd\u4f1a\u5bfc\u81f4\u7ed3\u679c\u4e0d\u7406\u60f3\u3002\u56e0\u4e3a\u67d0\u6b21\u5206\u5272\u540e sum-of-squares \u53d8\u5316\u4e0d\u5927\uff0c\u53ef\u80fd\u5b83\u7684\u540e\u7eed\u5206\u5272\u80fd\u6781\u5927\u964d\u4f4e sum-of-squares\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u91c7\u7528 \u9650\u5236\u53f6\u5b50\u8282\u70b9\u6837\u672c\u6570 \u7684\u65b9\u6cd5\u4f5c\u4e3a\u7ec8\u6b62\u6761\u4ef6\u3002\u5982\u679c\u5206\u5272\u540e\u7684\u8282\u70b9\u6837\u672c\u6570\u662f\u5426\u4f4e\u4e8e\u67d0\u4e2a\u7ed9\u5b9a\u7684\u503c\uff08\u4f8b\u5982 5\uff09\u5219\u505c\u6b62\uff0c\u5426\u5219\u91cd\u590d step 1.1 \u9012\u5f52\u5730\u8fdb\u884c\u5207\u5206\u3002 \u8fd9\u6837\u7684\u7ed3\u679c\u662f\u6211\u4eec\u5f97\u5230\u4e86\u4e00\u4e2a\u53ef\u80fd \u8fc7\u62df\u5408 \u7684\u6811\u3002\u6bd4\u5982\uff0c\u67d0\u4e00\u7c7b\u522b\u7684\u6570\u636e\u5b9e\u9645\u6709 8 \u4e2a\uff0c\u4f46\u662f\u6211\u4eec\u53f6\u5b50\u8282\u70b9\u7684\u6837\u672c\u6570\u4e0a\u9650\u8bbe\u4e3a\u4e86 5\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u8fdb\u884c\u526a\u679d\uff0c\u5373\u5408\u5e76\u4e00\u4e9b\u8282\u70b9\u3002 Step2. \u526a\u679d \u526a\u679d\u7684\u76ee\u7684\u662f\u5728\u603b\u8282\u70b9\u6570\u4ee5\u53ca\u6bcf\u4e2a\u8282\u70b9\u7684\u6837\u672c\u7684 RSS \u4e2d\u53d6\u4e00\u4e2a\u8f83\u597d\u7684\u5e73\u8861\u3002\u56e0\u6b64\u6211\u4eec\u5b9a\u4e49\u201c\u590d\u6742\u5ea6\u6210\u672c\u201d (cost-complexity)\uff1a \\[ \\text{RSS}_m = \\sum_{x_i \\in R_m} (y_i - \\hat{c}_m)^2 \\] \\[ C_\\alpha (T) = \\sum_{m=1}^{|T|} \\text{RSS}_m + \\alpha |T|\\] \u5176\u4e2d\uff1a \\(|T|\\) \uff1a\u526a\u679d\u540e\u7684\u6811 T \u7684\u8282\u70b9\u6570 \\(\\text{RSS}_m\\) \uff1a\u7b2c m \u4e2a\u8282\u70b9\u7684\u6b8b\u5dee\u5e73\u65b9\u548c \\(\\alpha\\) \uff1a\u8282\u70b9\u4e2a\u6570\u6743\u91cd\uff0c\u5373\u590d\u6742\u5ea6\u6210\u672c\uff0c\u5982\u679c\u8bbe\u4e3a 0 \u5219\u4e0d\u8fdb\u884c\u526a\u679d \u663e\u7136\uff0c\u5bf9\u6bcf\u4e2a \\(\\alpha\\) \u7684\u53d6\u503c\uff0c\u6211\u4eec\u90fd\u6709\u4e00\u4e2a\u552f\u4e00\u786e\u5b9a\u7684\u6811 \\(T_\\alpha\\) \u4f7f \\(C_\\alpha (T)\\) \u6700\u5c0f\u3002 Step 2.1 \u4ea4\u53c9\u68c0\u9a8c\u6cd5\u786e\u5b9a \\(\\alpha\\) \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u8c03\u8282 \\(\\alpha\\) \u6765\u51b3\u5b9a\u526a\u679d\u540e\u7684\u6a21\u578b\u590d\u6742\u5ea6\uff08\u8282\u70b9\u6570\uff09\u3002 \\(\\alpha\\) \u8d8a\u5927\uff0c\u6a21\u578b\u8d8a\u7b80\u5355\uff0c\u8d8a\u4e0d\u7cbe\u786e\u3002 \\(\\alpha\\) \u592a\u5c0f\u5219\u4f1a\u9020\u6210\u8fc7\u62df\u5408\u3002 \u4e3a\u4e86\u786e\u5b9a\u5408\u9002\u7684 \\(\\alpha\\) \u6211\u4eec\u53ef\u4ee5\u628a\u6570\u636e\u7684 1/5 \u6216\u8005 1/10 \u7559\u4f5c\u68c0\u9a8c\u6570\u636e\uff0c\u5269\u4f59\u6570\u636e\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e\u3002\u7136\u540e\u5bfb\u627e\u4f7f\u68c0\u9a8c\u6570\u636e\u7684\u9884\u6d4b\u8bef\u5dee\u6700\u5c0f\u7684 \\(\\hat{\\alpha}\\) \u3002 Step 2.2 \u6700\u5f31\u8fde\u63a5\u6cd5\u526a\u679d \u6211\u4eec\u4ece\u5bf9\u51cf\u5c11 \\(\\text{RSS}\\) \u8d21\u732e\u6700\u5c0f\u7684\u5206\u53c9\u70b9\u5f00\u59cb\u5408\u5e76\u8282\u70b9\uff0c\u76f4\u5230\u6211\u4eec\u4ec5\u5269\u4e00\u4e2a\u6839\u8282\u70b9\u3002\u6211\u4eec\u8bb0\u5f55\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\u751f\u6210\u7684\u6bcf\u4e00\u4e2a\u6811\uff08\u6709\u9650\u96c6\uff09\uff0c\u5e76\u4e14\u8ba1\u7b97\u5176 \\(C_{\\hat{\\alpha}} (T)\\) \uff0c\u6700\u5c0f\u7684\u6811\u5c31\u662f\u6700\u7ec8\u7ed3\u679c \\(T_{\\hat{\\alpha}}\\) \u3002 9.2.3 Classification Trees \u5bf9\u4e8e\u56de\u5f52\u95ee\u9898\uff0c\u6211\u4eec\u5e0c\u671b\u6700\u5c0f\u5316\u6b8b\u5dee\uff0c\u5373\u6837\u672c\u4e0e\u5747\u503c\u7684\u5dee\u7684\u5e73\u65b9\u548c\uff1a \\[ \\text{RSS}_m = \\sum_{x_i \\in R_m} (y_i - \\hat{c}_m)^2 \\] \u5bf9\u4e8e\u5206\u7c7b\u95ee\u9898\uff0c\u6211\u4eec\u7684\u76ee\u7684\u662f\u4f7f\u6837\u672c\u6b63\u786e\u5206\u7c7b\u7684\u6982\u7387\u6700\u9ad8\u3002\u6211\u4eec\u5b9a\u4e49\u67d0 \u53f6\u5b50\u8282\u70b9 \u6240\u5708\u5b9a\u7684\u533a\u57df\u4e3a \\(R_m\\) \uff0c\u8be5\u8282\u70b9\u4e0a\u5171\u6709 \\(N_m\\) \u4e2a\u6837\u672c\u3002\u6211\u4eec\u5b9a\u4e49\u8282\u70b9\u7684\u201c\u7eaf\u6d01\u5ea6\u201d\u4e3a\uff1a \\[ \\hat{p}_{mk} = \\frac{1}{N_m} \\sum_{x_i \\in R_m} I(y_i = k) \\] \u5b83\u8868\u793a\u5728\u8282\u70b9 m \u4e2d\u7b2c k \u7c7b\u6837\u672c\u7684\u6bd4\u4f8b\u3002\u6211\u4eec\u5c06\u8fd9\u4e2a\u533a\u57df\u5185\u5212\u5206\u7ed9\u5360\u6bd4\u6700\u9ad8\u7684\u7c7b\u578b\uff0c \u5373 \\(k(m) = \\mathop{\\arg \\max_k \\hat{p}_{mk}}\\) \u3002 \u6211\u4eec\u53ef\u4ee5\u5f97\u51fa\u5bf9\u4e8e\u8282\u70b9 m \u7684 loss function\uff1a \uff08\u4e0d\u53ef\u5bfc\uff09\u8bef\u5206\u7c7b\uff0c\u9519\u8bef\u5224\u65ad\u8282\u70b9 m \u7684\u67d0\u4e9b\u6837\u672c\u5c5e\u4e8e k \u7c7b\uff1a \\[ Q_m(T) = \\frac{1}{N_m} \\sum_{x_i \\in R_m} I(y_i != k(m)) = 1 - \\hat{p}_{mk}(m)\\] \u5bf9\u4e8e 2 \u5206\u7c7b\u95ee\u9898\uff0c\u6709 \\(Q_m(T) = 1 - \\max(p, 1-p)\\) \u3002 \uff08\u53ef\u5bfc\uff09Gini \u6307\u6570\uff0c\u8282\u70b9 m \u4e0a\u6240\u6709\u7c7b\u522b\u7684\u4e0d\u7eaf\u5ea6\u4e0e\u7eaf\u6d01\u5ea6\u4e4b\u79ef\u7684\u548c\u3002 \\[ Q_m(T) = \\sum_{k != k'} \\hat{p}_{mk} \\hat{p}_{mk'} = \\sum_{k=1}^K \\hat{p}_{mk}(1 - \\hat{p}_{mk}) \\] \u5bf9\u4e8e 2 \u5206\u7c7b\u95ee\u9898\uff0c\u6709 \\(Q_m(T) = 2p(1-p)\\) \u3002 \uff08\u53ef\u5bfc\uff09Cross-entropy\uff0c\u4ea4\u53c9\u71b5\u3002 \\[ Q_m(T) = \\sum_{k=1}^K \\hat{p}_{mk} \\ln(\\hat{p}_{mk}) \\] \u5bf9\u4e8e 2 \u5206\u7c7b\u95ee\u9898\uff0c\u6709 \\(Q_m(T) = -p \\ln p - (1-p) \\ln(1-p)\\) \u3002 9.2.4 Other Issues CART (Classification And Regression Tree) \u6a21\u578b\u7684\u4f18\u52bf\u5728\u4e8e\uff1a \u6982\u5ff5\u7b80\u5355 \u53ef\u89e3\u91ca\u6027\u5f3a \u5b83\u7684\u7f3a\u9677\u5728\u4e8e\uff1a variance \u6bd4\u8f83\u5927\uff0c\u8bad\u7ec3\u6570\u636e\u4e0a\u5f88\u5c0f\u7684\u6539\u53d8\u53ef\u80fd\u5bfc\u81f4\u6700\u7ec8\u751f\u6210\u7684\u6811\u5dee\u5f02\u5de8\u5927\u3002\u5176\u539f\u56e0\u662f\u7531\u4e8e\u6811\u672c\u8eab\u7684\u5c42\u7ea7\u7ed3\u6784\uff0c\u5bfc\u81f4\u4e0a\u5c42\u7684\u5206\u5272\u4f1a\u5f71\u54cd\u4e0b\u5c42\u6240\u6709\u8282\u70b9\u3002 \u5206\u754c\u9762\u4e0d\u5149\u6ed1\u3002 \u96be\u4ee5\u5efa\u6a21\u52a0\u6027\u7ed3\u6784\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u6709\u4e00\u4e2a\u7b80\u5355\u7684\u51fd\u6570: \\[Y = c_1 I(X_1 < t_1) + c_2 I (X_2 < t_2)\\] \u4e0d\u540c\u4e8e\u52a0\u6027\u6a21\u578b\uff0c\u7531\u4e8e\u6811\u6a21\u578b\u6ca1\u6709\u7ed9\u4e88\u201c\u52a0\u6027\u201d\u7684\u5047\u8bbe\uff0c\u6211\u4eec\u9700\u8981\u8db3\u591f\u591a\u7684\u8bad\u7ec3\u6570\u636e\u624d\u80fd\u4f7f\u5176\u5076\u7136\u6355\u83b7\u5230\u8fd9\u79cd\u52a0\u6027\u7ed3\u6784\u3002 9.2.5 Spam Example \u6211\u4eec\u540c\u6837\u7528\u4e0a\u4e00\u7ae0\u4e2d\u7684\u5783\u573e\u90ae\u4ef6\u5206\u7c7b\u4f5c\u4e3a\u4f8b\u5b50\u3002 for train_index , test_index in KFold ( n_splits = 5 , shuffle = True , random_state = 1 ) . split ( X ): # print(\"TRAIN:\", train_index, \"TEST:\", test_index) trainX , testX = X . loc [ train_index ], X . loc [ test_index ] trainY , testY = y . loc [ train_index ], y . loc [ test_index ] model = tree . DecisionTreeClassifier () . fit ( trainX , trainY ) print ( f \"CART accurracy: { model . score ( testX , testY ) } \" ) pd . DataFrame ( model . feature_importances_ , index = model . feature_names_in_ , columns = [ \"importance\" ]) . sort_values ( by = \"importance\" , ascending = False ) \u5176\u5206\u7c7b\u51c6\u786e\u7387\u4e0e\u7ebf\u6027\u56de\u5f52\u76f8\u4f3c\uff0c\u4e0d\u5982 additive model\u3002 CART accurracy: 0.9196525515743756 CART accurracy: 0.8978260869565218 CART accurracy: 0.9195652173913044 CART accurracy: 0.933695652173913 CART accurracy: 0.9152173913043479 \u6211\u4eec\u53ef\u4ee5\u770b\u5230\u5176\u524d\u5341\u7684 feature importance\uff1a importance char_freq_$ 0.340080 word_freq_remove 0.158076 char_freq_! 0.084968 word_freq_hp 0.058652 capital_run_length_total 0.045410 capital_run_length_longest 0.036924 word_freq_edu 0.024785 word_freq_free 0.024647 word_freq_you 0.021009 word_freq_george 0.019951 \u8fd8\u662f\u975e\u5e38\u7b26\u5408\u76f4\u89c9\u7684\u3002 \u53c2\u8003 \u4f7f\u7528 LightGBM \u524d\u526a\u679d\u8fc7\u7a0b","title":"ESL 9.2: Tree-Based Methods"},{"location":"mathematics/ESL/ESL9_TreeBasedMethods/#esl-92-tree-based-methods","text":"","title":"ESL 9.2: Tree-Based Methods"},{"location":"mathematics/ESL/ESL9_TreeBasedMethods/#921-background","text":"\u6811\u65b9\u6cd5\u5c06\u7279\u5f81\u7a7a\u95f4\u5206\u5272\u4e3a\u4e0d\u540c\u533a\u57df\uff0c\u7136\u540e\u7528\u4e00\u4e2a\u7b80\u5355\u7684\u6a21\u578b\uff08\u6bd4\u5982\u5e38\u6570\uff09\u6765\u62df\u5408\u6bcf\u4e2a\u533a\u57df\u3002 \u8003\u8651\u4e00\u4e2a\u7b80\u5355\u7684\u56de\u5f52\u95ee\u9898\u3002\u7279\u5f81\u662f\u4e8c\u7ef4\u7684 \\(X_1\\) \u548c \\(X_2\\) \uff0c\u54cd\u5e94\u662f\u5b9e\u6570 \\(Y\\) \u3002\u6211\u4eec\u53ef\u4ee5\u628a\u7279\u5f81\u7a7a\u95f4\u5206\u533a\uff0c\u6bcf\u4e2a\u533a\u8d4b\u4e88\u4e00\u4e2a\u5e38\u6570\u4f5c\u4e3a\u54cd\u5e94\u7684\u4f30\u8ba1\u503c\u3002 \u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5de6\u4e0a\u89d2\u7684\u5b50\u56fe\u662f\u4e00\u79cd\u590d\u6742\u7684\u60c5\u5f62\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u533a\u57df\u5f88\u96be\u63cf\u8ff0\u3002\u6211\u4eec\u5148\u7814\u7a76\u7c7b\u4f3c\u4e8e\u53f3\u4e0a\u89d2\u7684\u5b50\u56fe\u7684\u7b80\u5355\u60c5\u5f62\uff0c\u5b83\u53ef\u4ee5\u8868\u793a\u6210\u4e00\u4e2a\u7b80\u5355\u7684\u4e8c\u53c9\u6811\uff08\u5de6\u4e0b\uff09\uff0c\u6bcf\u4e2a\u53f6\u5b50\u8282\u70b9\u5c31\u662f\u5176\u5206\u533a\u7ed3\u679c\uff0c\u53ef\u4ee5\u8d4b\u4e88\u4e00\u4e2a\u5e38\u6570\u3002","title":"9.2.1 Background"},{"location":"mathematics/ESL/ESL9_TreeBasedMethods/#922-regression-trees","text":"\u73b0\u5728\u6211\u4eec\u53ef\u4ee5\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u5982\u4f55\u6784\u9020\u4e00\u4e2a regression tree\u3002\u5047\u8bbe\u6211\u4eec\u7684\u7279\u5f81\u6709 \\(p\\) \u7ef4\uff0c\u5171\u6709 \\(N\\) \u4e2a\u89c2\u6d4b\u6837\u672c\u3002\u6211\u4eec\u9700\u8981\u627e\u5230\u4e00\u4e2a\u7b97\u6cd5\u80fd\u591f\u81ea\u52a8\u51b3\u5b9a\u5728\u54ea\u4e9b\u7279\u5f81\u7684\u54ea\u4e9b\u503c\u8fdb\u884c\u5206\u5272\uff0c\u4ee5\u6b64\u51b3\u5b9a regression tree \u7684\u5f62\u72b6\u3002\u5982\u679c\u5206\u652f\u6570\u592a\u591a\uff0c\u663e\u7136\u4f1a\u5b58\u5728\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002\u4f46\u662f\u5206\u652f\u6570\u592a\u5c11\u53c8\u53ef\u80fd\u5ffd\u7565\u6389\u91cd\u8981\u7684\u7ed3\u6784\u3002 \u53ef\u8c03\u53c2\u6570\uff1a \u6bcf\u4e2a\u53f6\u5b50\u8282\u70b9\u6700\u5927\u6837\u672c\u6570\uff08\u7528\u4e8e Step 1 \u7ec8\u6b62\u6761\u4ef6\uff09","title":"9.2.2 Regression Trees"},{"location":"mathematics/ESL/ESL9_TreeBasedMethods/#step1","text":"","title":"Step1. \u9012\u5f52\u6784\u9020\u4e8c\u53c9\u6811"},{"location":"mathematics/ESL/ESL9_TreeBasedMethods/#step-11","text":"\u5047\u8bbe\u6211\u4eec\u5bf9\u7b2c \\(j\\) \u4e2a\u7279\u5f81\u9009\u62e9\u4e86\u5206\u5272\u70b9 \\(s\\) \uff0c\u5219\u5206\u5272\u6210\u7684\u4e24\u4e2a\u90e8\u5206\u4e3a\uff1a \\[ R_1(j, s) = \\{ X|X_j \\leq s \\} \\] \\[ R_2(j, s) = \\{ X|X_j \\gt s \\} \\] \u6211\u4eec\u7684\u76ee\u6807\u662f\u9009\u62e9 \\(j\\) \u548c \\(s\\) \u8ba9\u4e24\u4e2a\u90e8\u5206\u7684\u6b8b\u5dee\u5e73\u65b9\u548c (RSS) \u6700\u5c0f\uff0c\u5373\u6c42\u89e3\u5982\u4e0b\u95ee\u9898\uff1a \\[ \\min_{j,s} [ \\sum_{x_i \\in R_1} (y_i - \\hat{c}_1)^2 + \\sum_{x_i \\in R_2} (y_i - \\hat{c}_2)^2 ]\\] \u5176\u4e2d\u9884\u6d4b\u503c\u7684\u4f30\u8ba1 \\(\\hat{c}\\) \u4e3a\u5404\u90e8\u5206 \\(y_i\\) \u7684\u5747\u503c\u3002 \u5047\u8bbe \\(X_j\\) \u5728\u6837\u672c\u4e2d\u4e00\u5171\u6709 k \u4e2a\u4e0d\u540c\u7684\u503c\uff0c\u5219\u663e\u7136\u6700\u591a\u6709 k-1 \u79cd\u5206\u6cd5\u3002\u53ef\u4ee5\u4f9d\u6b21\u5c1d\u8bd5\u627e\u5230 \\(s\\) \u3002\u8fd9\u6837\u6211\u4eec\u5c31\u786e\u5b9a\u4e86\u4e00\u7ec4 \\((j, s)\\) \u7ec4\u5408\u3002\u8be5\u7ec4\u5408\u5c06\u6570\u636e\u5206\u4e3a\u4e24\u90e8\u5206\uff0c\u6211\u4eec\u518d\u5bf9\u6bcf\u4e00\u4e2a\u90e8\u5206\u91cd\u590d\u4e0a\u8ff0\u64cd\u4f5c\u3002","title":"Step 1.1 \u9012\u5f52\u5207\u5206"},{"location":"mathematics/ESL/ESL9_TreeBasedMethods/#step12","text":"\u5728 step 1.1 \u7684\u6bcf\u6b21\u5207\u5206\u4e4b\u540e\uff0c\u6211\u4eec\u9700\u8981\u5bf9\u6bcf\u4e2a\u90e8\u5206\u5224\u65ad\u662f\u5426\u505c\u6b62\u5207\u5206\u3002\u5982\u679c\u76f4\u63a5\u7528 sum-of-squares \u53d8\u5c0f\u7684\u5e45\u5ea6\u4f5c\u4e3a\u7ec8\u6b62\u6761\u4ef6\uff0c\u53ef\u80fd\u4f1a\u5bfc\u81f4\u7ed3\u679c\u4e0d\u7406\u60f3\u3002\u56e0\u4e3a\u67d0\u6b21\u5206\u5272\u540e sum-of-squares \u53d8\u5316\u4e0d\u5927\uff0c\u53ef\u80fd\u5b83\u7684\u540e\u7eed\u5206\u5272\u80fd\u6781\u5927\u964d\u4f4e sum-of-squares\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u91c7\u7528 \u9650\u5236\u53f6\u5b50\u8282\u70b9\u6837\u672c\u6570 \u7684\u65b9\u6cd5\u4f5c\u4e3a\u7ec8\u6b62\u6761\u4ef6\u3002\u5982\u679c\u5206\u5272\u540e\u7684\u8282\u70b9\u6837\u672c\u6570\u662f\u5426\u4f4e\u4e8e\u67d0\u4e2a\u7ed9\u5b9a\u7684\u503c\uff08\u4f8b\u5982 5\uff09\u5219\u505c\u6b62\uff0c\u5426\u5219\u91cd\u590d step 1.1 \u9012\u5f52\u5730\u8fdb\u884c\u5207\u5206\u3002 \u8fd9\u6837\u7684\u7ed3\u679c\u662f\u6211\u4eec\u5f97\u5230\u4e86\u4e00\u4e2a\u53ef\u80fd \u8fc7\u62df\u5408 \u7684\u6811\u3002\u6bd4\u5982\uff0c\u67d0\u4e00\u7c7b\u522b\u7684\u6570\u636e\u5b9e\u9645\u6709 8 \u4e2a\uff0c\u4f46\u662f\u6211\u4eec\u53f6\u5b50\u8282\u70b9\u7684\u6837\u672c\u6570\u4e0a\u9650\u8bbe\u4e3a\u4e86 5\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u8fdb\u884c\u526a\u679d\uff0c\u5373\u5408\u5e76\u4e00\u4e9b\u8282\u70b9\u3002","title":"Step1.2 \u7ec8\u6b62\u6761\u4ef6"},{"location":"mathematics/ESL/ESL9_TreeBasedMethods/#step2","text":"\u526a\u679d\u7684\u76ee\u7684\u662f\u5728\u603b\u8282\u70b9\u6570\u4ee5\u53ca\u6bcf\u4e2a\u8282\u70b9\u7684\u6837\u672c\u7684 RSS \u4e2d\u53d6\u4e00\u4e2a\u8f83\u597d\u7684\u5e73\u8861\u3002\u56e0\u6b64\u6211\u4eec\u5b9a\u4e49\u201c\u590d\u6742\u5ea6\u6210\u672c\u201d (cost-complexity)\uff1a \\[ \\text{RSS}_m = \\sum_{x_i \\in R_m} (y_i - \\hat{c}_m)^2 \\] \\[ C_\\alpha (T) = \\sum_{m=1}^{|T|} \\text{RSS}_m + \\alpha |T|\\] \u5176\u4e2d\uff1a \\(|T|\\) \uff1a\u526a\u679d\u540e\u7684\u6811 T \u7684\u8282\u70b9\u6570 \\(\\text{RSS}_m\\) \uff1a\u7b2c m \u4e2a\u8282\u70b9\u7684\u6b8b\u5dee\u5e73\u65b9\u548c \\(\\alpha\\) \uff1a\u8282\u70b9\u4e2a\u6570\u6743\u91cd\uff0c\u5373\u590d\u6742\u5ea6\u6210\u672c\uff0c\u5982\u679c\u8bbe\u4e3a 0 \u5219\u4e0d\u8fdb\u884c\u526a\u679d \u663e\u7136\uff0c\u5bf9\u6bcf\u4e2a \\(\\alpha\\) \u7684\u53d6\u503c\uff0c\u6211\u4eec\u90fd\u6709\u4e00\u4e2a\u552f\u4e00\u786e\u5b9a\u7684\u6811 \\(T_\\alpha\\) \u4f7f \\(C_\\alpha (T)\\) \u6700\u5c0f\u3002","title":"Step2. \u526a\u679d"},{"location":"mathematics/ESL/ESL9_TreeBasedMethods/#step-21-alpha","text":"\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u8c03\u8282 \\(\\alpha\\) \u6765\u51b3\u5b9a\u526a\u679d\u540e\u7684\u6a21\u578b\u590d\u6742\u5ea6\uff08\u8282\u70b9\u6570\uff09\u3002 \\(\\alpha\\) \u8d8a\u5927\uff0c\u6a21\u578b\u8d8a\u7b80\u5355\uff0c\u8d8a\u4e0d\u7cbe\u786e\u3002 \\(\\alpha\\) \u592a\u5c0f\u5219\u4f1a\u9020\u6210\u8fc7\u62df\u5408\u3002 \u4e3a\u4e86\u786e\u5b9a\u5408\u9002\u7684 \\(\\alpha\\) \u6211\u4eec\u53ef\u4ee5\u628a\u6570\u636e\u7684 1/5 \u6216\u8005 1/10 \u7559\u4f5c\u68c0\u9a8c\u6570\u636e\uff0c\u5269\u4f59\u6570\u636e\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e\u3002\u7136\u540e\u5bfb\u627e\u4f7f\u68c0\u9a8c\u6570\u636e\u7684\u9884\u6d4b\u8bef\u5dee\u6700\u5c0f\u7684 \\(\\hat{\\alpha}\\) \u3002","title":"Step 2.1 \u4ea4\u53c9\u68c0\u9a8c\u6cd5\u786e\u5b9a \\(\\alpha\\)"},{"location":"mathematics/ESL/ESL9_TreeBasedMethods/#step-22","text":"\u6211\u4eec\u4ece\u5bf9\u51cf\u5c11 \\(\\text{RSS}\\) \u8d21\u732e\u6700\u5c0f\u7684\u5206\u53c9\u70b9\u5f00\u59cb\u5408\u5e76\u8282\u70b9\uff0c\u76f4\u5230\u6211\u4eec\u4ec5\u5269\u4e00\u4e2a\u6839\u8282\u70b9\u3002\u6211\u4eec\u8bb0\u5f55\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\u751f\u6210\u7684\u6bcf\u4e00\u4e2a\u6811\uff08\u6709\u9650\u96c6\uff09\uff0c\u5e76\u4e14\u8ba1\u7b97\u5176 \\(C_{\\hat{\\alpha}} (T)\\) \uff0c\u6700\u5c0f\u7684\u6811\u5c31\u662f\u6700\u7ec8\u7ed3\u679c \\(T_{\\hat{\\alpha}}\\) \u3002","title":"Step 2.2 \u6700\u5f31\u8fde\u63a5\u6cd5\u526a\u679d"},{"location":"mathematics/ESL/ESL9_TreeBasedMethods/#923-classification-trees","text":"\u5bf9\u4e8e\u56de\u5f52\u95ee\u9898\uff0c\u6211\u4eec\u5e0c\u671b\u6700\u5c0f\u5316\u6b8b\u5dee\uff0c\u5373\u6837\u672c\u4e0e\u5747\u503c\u7684\u5dee\u7684\u5e73\u65b9\u548c\uff1a \\[ \\text{RSS}_m = \\sum_{x_i \\in R_m} (y_i - \\hat{c}_m)^2 \\] \u5bf9\u4e8e\u5206\u7c7b\u95ee\u9898\uff0c\u6211\u4eec\u7684\u76ee\u7684\u662f\u4f7f\u6837\u672c\u6b63\u786e\u5206\u7c7b\u7684\u6982\u7387\u6700\u9ad8\u3002\u6211\u4eec\u5b9a\u4e49\u67d0 \u53f6\u5b50\u8282\u70b9 \u6240\u5708\u5b9a\u7684\u533a\u57df\u4e3a \\(R_m\\) \uff0c\u8be5\u8282\u70b9\u4e0a\u5171\u6709 \\(N_m\\) \u4e2a\u6837\u672c\u3002\u6211\u4eec\u5b9a\u4e49\u8282\u70b9\u7684\u201c\u7eaf\u6d01\u5ea6\u201d\u4e3a\uff1a \\[ \\hat{p}_{mk} = \\frac{1}{N_m} \\sum_{x_i \\in R_m} I(y_i = k) \\] \u5b83\u8868\u793a\u5728\u8282\u70b9 m \u4e2d\u7b2c k \u7c7b\u6837\u672c\u7684\u6bd4\u4f8b\u3002\u6211\u4eec\u5c06\u8fd9\u4e2a\u533a\u57df\u5185\u5212\u5206\u7ed9\u5360\u6bd4\u6700\u9ad8\u7684\u7c7b\u578b\uff0c \u5373 \\(k(m) = \\mathop{\\arg \\max_k \\hat{p}_{mk}}\\) \u3002 \u6211\u4eec\u53ef\u4ee5\u5f97\u51fa\u5bf9\u4e8e\u8282\u70b9 m \u7684 loss function\uff1a \uff08\u4e0d\u53ef\u5bfc\uff09\u8bef\u5206\u7c7b\uff0c\u9519\u8bef\u5224\u65ad\u8282\u70b9 m \u7684\u67d0\u4e9b\u6837\u672c\u5c5e\u4e8e k \u7c7b\uff1a \\[ Q_m(T) = \\frac{1}{N_m} \\sum_{x_i \\in R_m} I(y_i != k(m)) = 1 - \\hat{p}_{mk}(m)\\] \u5bf9\u4e8e 2 \u5206\u7c7b\u95ee\u9898\uff0c\u6709 \\(Q_m(T) = 1 - \\max(p, 1-p)\\) \u3002 \uff08\u53ef\u5bfc\uff09Gini \u6307\u6570\uff0c\u8282\u70b9 m \u4e0a\u6240\u6709\u7c7b\u522b\u7684\u4e0d\u7eaf\u5ea6\u4e0e\u7eaf\u6d01\u5ea6\u4e4b\u79ef\u7684\u548c\u3002 \\[ Q_m(T) = \\sum_{k != k'} \\hat{p}_{mk} \\hat{p}_{mk'} = \\sum_{k=1}^K \\hat{p}_{mk}(1 - \\hat{p}_{mk}) \\] \u5bf9\u4e8e 2 \u5206\u7c7b\u95ee\u9898\uff0c\u6709 \\(Q_m(T) = 2p(1-p)\\) \u3002 \uff08\u53ef\u5bfc\uff09Cross-entropy\uff0c\u4ea4\u53c9\u71b5\u3002 \\[ Q_m(T) = \\sum_{k=1}^K \\hat{p}_{mk} \\ln(\\hat{p}_{mk}) \\] \u5bf9\u4e8e 2 \u5206\u7c7b\u95ee\u9898\uff0c\u6709 \\(Q_m(T) = -p \\ln p - (1-p) \\ln(1-p)\\) \u3002","title":"9.2.3 Classification Trees"},{"location":"mathematics/ESL/ESL9_TreeBasedMethods/#924-other-issues","text":"CART (Classification And Regression Tree) \u6a21\u578b\u7684\u4f18\u52bf\u5728\u4e8e\uff1a \u6982\u5ff5\u7b80\u5355 \u53ef\u89e3\u91ca\u6027\u5f3a \u5b83\u7684\u7f3a\u9677\u5728\u4e8e\uff1a variance \u6bd4\u8f83\u5927\uff0c\u8bad\u7ec3\u6570\u636e\u4e0a\u5f88\u5c0f\u7684\u6539\u53d8\u53ef\u80fd\u5bfc\u81f4\u6700\u7ec8\u751f\u6210\u7684\u6811\u5dee\u5f02\u5de8\u5927\u3002\u5176\u539f\u56e0\u662f\u7531\u4e8e\u6811\u672c\u8eab\u7684\u5c42\u7ea7\u7ed3\u6784\uff0c\u5bfc\u81f4\u4e0a\u5c42\u7684\u5206\u5272\u4f1a\u5f71\u54cd\u4e0b\u5c42\u6240\u6709\u8282\u70b9\u3002 \u5206\u754c\u9762\u4e0d\u5149\u6ed1\u3002 \u96be\u4ee5\u5efa\u6a21\u52a0\u6027\u7ed3\u6784\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u6709\u4e00\u4e2a\u7b80\u5355\u7684\u51fd\u6570: \\[Y = c_1 I(X_1 < t_1) + c_2 I (X_2 < t_2)\\] \u4e0d\u540c\u4e8e\u52a0\u6027\u6a21\u578b\uff0c\u7531\u4e8e\u6811\u6a21\u578b\u6ca1\u6709\u7ed9\u4e88\u201c\u52a0\u6027\u201d\u7684\u5047\u8bbe\uff0c\u6211\u4eec\u9700\u8981\u8db3\u591f\u591a\u7684\u8bad\u7ec3\u6570\u636e\u624d\u80fd\u4f7f\u5176\u5076\u7136\u6355\u83b7\u5230\u8fd9\u79cd\u52a0\u6027\u7ed3\u6784\u3002","title":"9.2.4 Other Issues"},{"location":"mathematics/ESL/ESL9_TreeBasedMethods/#925-spam-example","text":"\u6211\u4eec\u540c\u6837\u7528\u4e0a\u4e00\u7ae0\u4e2d\u7684\u5783\u573e\u90ae\u4ef6\u5206\u7c7b\u4f5c\u4e3a\u4f8b\u5b50\u3002 for train_index , test_index in KFold ( n_splits = 5 , shuffle = True , random_state = 1 ) . split ( X ): # print(\"TRAIN:\", train_index, \"TEST:\", test_index) trainX , testX = X . loc [ train_index ], X . loc [ test_index ] trainY , testY = y . loc [ train_index ], y . loc [ test_index ] model = tree . DecisionTreeClassifier () . fit ( trainX , trainY ) print ( f \"CART accurracy: { model . score ( testX , testY ) } \" ) pd . DataFrame ( model . feature_importances_ , index = model . feature_names_in_ , columns = [ \"importance\" ]) . sort_values ( by = \"importance\" , ascending = False ) \u5176\u5206\u7c7b\u51c6\u786e\u7387\u4e0e\u7ebf\u6027\u56de\u5f52\u76f8\u4f3c\uff0c\u4e0d\u5982 additive model\u3002 CART accurracy: 0.9196525515743756 CART accurracy: 0.8978260869565218 CART accurracy: 0.9195652173913044 CART accurracy: 0.933695652173913 CART accurracy: 0.9152173913043479 \u6211\u4eec\u53ef\u4ee5\u770b\u5230\u5176\u524d\u5341\u7684 feature importance\uff1a importance char_freq_$ 0.340080 word_freq_remove 0.158076 char_freq_! 0.084968 word_freq_hp 0.058652 capital_run_length_total 0.045410 capital_run_length_longest 0.036924 word_freq_edu 0.024785 word_freq_free 0.024647 word_freq_you 0.021009 word_freq_george 0.019951 \u8fd8\u662f\u975e\u5e38\u7b26\u5408\u76f4\u89c9\u7684\u3002","title":"9.2.5 Spam Example"},{"location":"mathematics/ESL/ESL9_TreeBasedMethods/#_1","text":"\u4f7f\u7528 LightGBM \u524d\u526a\u679d\u8fc7\u7a0b","title":"\u53c2\u8003"},{"location":"mathematics/matrix/MatrixCalculus/","text":"\u5411\u91cf\u548c\u77e9\u9635\u6c42\u5bfc \u5411\u91cf\u3001\u77e9\u9635\u6c42\u5bfc\u5176\u5b9e\u5c31\u4e24\u4e2a\u5185\u5bb9 \u5206\u5b50\u6bcf\u4e2a\u5143\u7d20\u5bf9\u5206\u6bcd\u6bcf\u4e2a\u5143\u7d20\u6c42\u5bfc \u5c06\u7ed3\u679c\u4ee5\u4e00\u5b9a\u65b9\u5f0f\u5e03\u5c40 \u5bf9\u4e8e 1\uff0c\u6ca1\u4ec0\u4e48\u7279\u522b\u7684\uff0c\u5c31\u662f\u6807\u91cf\u4e4b\u95f4\u7684\u6c42\u5bfc\u3002 \u5bf9\u4e8e 2\uff0c\u6211\u4eec\u9700\u8981\u5206\u60c5\u51b5\u8ba8\u8bba\u3002 \u6c42\u5bfc\u5e03\u5c40 \u6c42\u5bfc\u7ed3\u679c\u7684\u5e03\u5c40\u6839\u636e\u5b9a\u4e49\u4e0d\u540c\u6709\u6240\u4e0d\u540c\uff0c\u6ca1\u6709\u7edf\u4e00\u3002\u6240\u4ee5\u7ecf\u5e38\u5728\u4e0d\u540c\u7684\u4e66\u4e0a\u770b\u5230\u4e0d\u4e00\u6837\u7684\u516c\u5f0f\uff0c\u4f7f\u4eba\u4ea7\u751f\u56f0\u60d1\u3002 \u5e38\u89c1\u7684\u6c42\u5bfc\u7c7b\u578b\u5982\u4e0b\uff1a \u5206\u6bcd \\ \u5206\u5b50 \u6807\u91cf \u5411\u91cf \u77e9\u9635 \u6807\u91cf \\(\\dfrac{\\partial y}{ \\partial x}\\) \\(\\dfrac{ \\partial \\textbf{y} }{ \\partial x }\\) \\(\\dfrac{\\partial \\textbf{Y}}{\\partial x}\\) \u5411\u91cf \\(\\dfrac{\\partial y}{ \\partial \\textbf{x}}\\) \\(\\dfrac{\\partial \\textbf{y} }{ \\partial \\textbf{x}}\\) / \u77e9\u9635 \\(\\dfrac{ \\partial y }{ \\partial \\textbf{X} }\\) / / \u6211\u4eec\u5212\u6389\u7684\u7c7b\u578b\u662f\u56e0\u4e3a\u5176\u7ed3\u679c\u65e0\u6cd5\u5728\u4e8c\u7ef4\u77e9\u9635\u4e2d\u5f88\u597d\u5730\u8868\u793a\uff0c\u5728\u4f18\u5316\u95ee\u9898\u4e2d\u4e5f\u4e0d\u5e38\u89c1\u3002 \u672a\u5212\u6389\u7684\u7c7b\u578b\u4e2d\uff0c\u552f\u4e00\u5e03\u5c40\u6709\u6b67\u4e49\u7684\u5c31\u662f\u5411\u91cf\u5bf9\u5411\u91cf\u7684\u6c42\u5bfc\uff1a \\(\\dfrac{ \\partial \\textbf{y} }{ \\partial \\textbf{x} }\\) \u5411\u91cf\u5bf9\u5411\u91cf\u6c42\u5bfc \u6b67\u4e49\u5728\u4e8e\uff0c\u5047\u8bbe \\(\\textbf{y}\\) \u662f\u4e00\u4e2a \\(m\\) \u7ef4\u5411\u91cf\uff0c \\(\\textbf{x}\\) \u662f\u4e00\u4e2a \\(n\\) \u7ef4\u5411\u91cf\uff0c\u90a3\u6c42\u5bfc\u7ed3\u679c\u662f\u4e00\u4e2a \\(m \\times n\\) \u77e9\u9635\u8fd8\u662f \\(n \\times m\\) \u77e9\u9635\u5462\uff1f \u5206\u5b50\u5e03\u5c40\uff0c\u5373\u4ee5\u5206\u5b50 \\(\\textbf{y}\\) \u7684\u5143\u7d20\u6570\u4f5c\u4e3a\u884c\u6570\u3002\u7ed3\u679c\u662f\u4e00\u4e2a \\(m \\times n\\) \u77e9\u9635\uff0c\u4e5f\u79f0\u4e3a\u96c5\u53ef\u6bd4\uff08Jacobian\uff09\u77e9\u9635\u3002 \\[ \\frac{ \\partial \\textbf{ y } }{ \\partial \\textbf{ x } } = \\begin{bmatrix} \\frac{ \\partial {y_1} }{ \\partial {x_1} } & \\frac{\\partial {y_1} }{\\partial {x_2} } & \\cdots &\\frac{\\partial {y_1} }{\\partial {x_n} } \\\\ \\frac{\\partial {y_2} }{\\partial {x_1} } & \\frac{\\partial {y_2} }{\\partial {x_2} } & \\cdots &\\frac{\\partial {y_2} }{\\partial {x_n} } \\\\ \\vdots & \\vdots & & \\vdots \\\\ \\frac{\\partial {y_m} }{\\partial {x_1} } & \\frac{\\partial {y_m} }{\\partial {x_2} } & \\cdots &\\frac{\\partial {y_m} }{\\partial {x_n} } \\\\ \\end{bmatrix}_{m \\times n} \\] \u5206\u6bcd\u5e03\u5c40\uff0c\u5373\u4ee5\u5206\u6bcd \\(\\textbf{x}\\) \u7684\u5143\u7d20\u6570\u4f5c\u4e3a\u884c\u6570\u3002\u7ed3\u679c\u662f\u4e00\u4e2a \\(n \\times m\\) \u77e9\u9635\uff0c\u4e5f\u79f0\u4e3a\u68af\u5ea6(Gradient)\u77e9\u9635\u3002 \\[ \\frac{\\partial \\textbf{ y }}{\\partial \\textbf{ x } } = \\begin{bmatrix} \\frac{\\partial {y_1} }{\\partial {x_1} } & \\frac{\\partial {y_2} }{\\partial {x_1} } & \\cdots &\\frac{\\partial {y_m} }{\\partial {x_1} } \\\\ \\frac{\\partial {y_1} }{\\partial {x_2} } & \\frac{\\partial {y_2} }{\\partial {x_2} } & \\cdots &\\frac{\\partial {y_m } }{\\partial {x_2} } \\\\ \\vdots & \\vdots & & \\vdots \\\\ \\frac{\\partial {y_1} }{\\partial {x_n} } & \\frac{\\partial {y_2} }{\\partial {x_n} } & \\cdots &\\frac{\\partial {y_m} }{\\partial {x_n} } \\\\ \\end{bmatrix}_{n \\times m} \\] \u4e24\u79cd\u5e03\u5c40\u5747\u53ef\uff0c\u5728\u4e00\u672c\u4e66\u4e2d\u4e00\u822c\u662f\u4e00\u81f4\u7684\u3002 \u6807\u91cf\u5bf9\u5411\u91cf\u6c42\u5bfc \u6807\u91cf\u5e38\u89c1\u7684\u6709\u4ee5\u4e0b\u51e0\u79cd\u5f62\u5f0f\uff1a \\(a^T x\\) \\(x^T a\\) \\(x^T A x\\) \u4ece\u5b9a\u4e49\u4e0a\u770b\uff0c1 \u548c 2 \u7c7b\u4f3c\uff1a \u9996\u5148\u5b9a\u4e49\uff1a \\[S = a^T x = x^T a = \\sum_{i=1}^n a_ix_i\\] \u5f97\u51fa\uff1a \\[ \\frac{\\partial S}{\\partial x_i} = a_i\\] \u56e0\u6b64\uff1a \\[\\frac{\\partial a^Tx}{\\partial x} = \\frac{\\partial x^Ta}{\\partial x} = [ \\frac{\\partial S}{\\partial x_1}, \\frac{\\partial S}{\\partial x_2}, \\cdots, \\frac{\\partial S}{\\partial x_n}]^T = a\\] 3 \u7a0d\u5fae\u590d\u6742\uff1a \\[ S = \\sum_{i=1}^n \\sum_{j=1}^n x_iA_{i,j}x_j\\] \\[ \\frac{\\partial S}{\\partial x_k} = \\sum_{j=1}^n A_{k,j}x_j + \\sum_{i=1}^n x_iA_{i,k} = (A_{k,i} + A_{i,k})x_i\\] \u5373\u6c42\u5bfc\u540e\u5411\u91cf\u7684\u7b2c k \u4e2a\u5143\u7d20\u662f A \u7684\u7b2c k \u884c\u4e0e x \u7684\u5185\u79ef + \u7b2c k \u5217\u4e0e x \u7684\u5185\u79ef\u3002\u8fd9\u5176\u5b9e\u5c31\u662f\u77e9\u9635\u4e0e\u5411\u91cf\u4e58\u6cd5\u7684\u5b9a\u4e49\u3002 \\[\\frac{\\partial x^TAx}{\\partial x} = [ \\frac{\\partial S}{\\partial x_1}, \\frac{\\partial S}{\\partial x_2}, \\cdots, \\frac{\\partial S}{\\partial x_n}]^T = Ax + A^Tx \\] \u4f8b\uff1a\u6700\u5c0f\u4e8c\u4e58\u6cd5 \u6700\u5c0f\u4e8c\u4e58\u6cd5\u662f\u6700\u6d41\u884c\u7684\u7ebf\u6027\u6a21\u578b\u62df\u5408\u65b9\u6cd5\u3002\u5b83\u7684\u76ee\u7684\u662f\u627e\u51fa\u7cfb\u6570 \\(\\mathbf{\\beta}\\) \u4f7f \\(||Y-\\hat Y||_2\\) \uff08residual sum of squares, RSS\uff09\u6700\u5c0f\uff1a \\[\\text{RSS}(\\mathbf{\\beta} ) = \\sum_{j=1}^N (y_j - X_j^T\\mathbf{\\beta} )^2 \\] \u5176\u4e2d \\(j\\) \u4ee3\u8868\u8bad\u7ec3\u6570\u636e\u7684\u5e8f\u53f7\u3002\u4e00\u5171\u6709 \\(N\\) \u7ec4\u8bad\u7ec3\u6570\u636e\u3002 \u7528\u77e9\u9635\u5f62\u5f0f\u8868\u793a\u4e3a\uff1a \\[\\text{RSS}(\\mathbf{\\beta}) = (\\textbf{y} - \\textbf{X}\\mathbf{\\beta} )^T(\\textbf{y} - \\textbf{X}\\mathbf{\\beta} )\\] \u8fd9\u91cc\u9700\u8981\u7528 \\(\\text{RSS}(\\mathbf{\\beta})\\) \u5bf9 \\(\\mathbf{\\beta}\\) \u6c42\u5bfc\uff0c\u5f97\u51fa\u4e8c\u6b21\u51fd\u6570\u6700\u503c\u70b9\u3002 \\[\\text{RSS}(\\mathbf{\\beta}) = \\textbf{y}^T\\textbf{y} -\\textbf{y}^T \\textbf{X} \\mathbf{\\beta} - \\mathbf{\\beta}^T \\textbf{X}^T \\textbf{y} + \\mathbf{\\beta}^T \\textbf{X}^T \\textbf{X}\\mathbf{\\beta}\\] \u5957\u7528\u4e0a\u9762\u7684\u7ed3\u8bba\uff0c\u53ef\u4ee5\u5f97\u5230\uff1a \\[ \\frac{ \\partial \\text{RSS}(\\mathbf{\\beta})}{\\partial \\mathbf{\\beta}} = - 2\\textbf{X}^T\\textbf{y} + 2\\textbf{X}^T\\textbf{X}\\mathbf{\\beta}\\] \u4ee4\u5176\u4e3a 0 \u53ef\u4ee5\u89e3\u51fa\uff1a \\[\\hat{\\mathbf{\\beta}} = (\\textbf{X}^T \\textbf{X})^{-1} \\textbf{X}^T \\textbf{y}\\]","title":"\u5411\u91cf\u548c\u77e9\u9635\u6c42\u5bfc"},{"location":"mathematics/matrix/MatrixCalculus/#_1","text":"\u5411\u91cf\u3001\u77e9\u9635\u6c42\u5bfc\u5176\u5b9e\u5c31\u4e24\u4e2a\u5185\u5bb9 \u5206\u5b50\u6bcf\u4e2a\u5143\u7d20\u5bf9\u5206\u6bcd\u6bcf\u4e2a\u5143\u7d20\u6c42\u5bfc \u5c06\u7ed3\u679c\u4ee5\u4e00\u5b9a\u65b9\u5f0f\u5e03\u5c40 \u5bf9\u4e8e 1\uff0c\u6ca1\u4ec0\u4e48\u7279\u522b\u7684\uff0c\u5c31\u662f\u6807\u91cf\u4e4b\u95f4\u7684\u6c42\u5bfc\u3002 \u5bf9\u4e8e 2\uff0c\u6211\u4eec\u9700\u8981\u5206\u60c5\u51b5\u8ba8\u8bba\u3002","title":"\u5411\u91cf\u548c\u77e9\u9635\u6c42\u5bfc"},{"location":"mathematics/matrix/MatrixCalculus/#_2","text":"\u6c42\u5bfc\u7ed3\u679c\u7684\u5e03\u5c40\u6839\u636e\u5b9a\u4e49\u4e0d\u540c\u6709\u6240\u4e0d\u540c\uff0c\u6ca1\u6709\u7edf\u4e00\u3002\u6240\u4ee5\u7ecf\u5e38\u5728\u4e0d\u540c\u7684\u4e66\u4e0a\u770b\u5230\u4e0d\u4e00\u6837\u7684\u516c\u5f0f\uff0c\u4f7f\u4eba\u4ea7\u751f\u56f0\u60d1\u3002 \u5e38\u89c1\u7684\u6c42\u5bfc\u7c7b\u578b\u5982\u4e0b\uff1a \u5206\u6bcd \\ \u5206\u5b50 \u6807\u91cf \u5411\u91cf \u77e9\u9635 \u6807\u91cf \\(\\dfrac{\\partial y}{ \\partial x}\\) \\(\\dfrac{ \\partial \\textbf{y} }{ \\partial x }\\) \\(\\dfrac{\\partial \\textbf{Y}}{\\partial x}\\) \u5411\u91cf \\(\\dfrac{\\partial y}{ \\partial \\textbf{x}}\\) \\(\\dfrac{\\partial \\textbf{y} }{ \\partial \\textbf{x}}\\) / \u77e9\u9635 \\(\\dfrac{ \\partial y }{ \\partial \\textbf{X} }\\) / / \u6211\u4eec\u5212\u6389\u7684\u7c7b\u578b\u662f\u56e0\u4e3a\u5176\u7ed3\u679c\u65e0\u6cd5\u5728\u4e8c\u7ef4\u77e9\u9635\u4e2d\u5f88\u597d\u5730\u8868\u793a\uff0c\u5728\u4f18\u5316\u95ee\u9898\u4e2d\u4e5f\u4e0d\u5e38\u89c1\u3002 \u672a\u5212\u6389\u7684\u7c7b\u578b\u4e2d\uff0c\u552f\u4e00\u5e03\u5c40\u6709\u6b67\u4e49\u7684\u5c31\u662f\u5411\u91cf\u5bf9\u5411\u91cf\u7684\u6c42\u5bfc\uff1a \\(\\dfrac{ \\partial \\textbf{y} }{ \\partial \\textbf{x} }\\)","title":"\u6c42\u5bfc\u5e03\u5c40"},{"location":"mathematics/matrix/MatrixCalculus/#_3","text":"\u6b67\u4e49\u5728\u4e8e\uff0c\u5047\u8bbe \\(\\textbf{y}\\) \u662f\u4e00\u4e2a \\(m\\) \u7ef4\u5411\u91cf\uff0c \\(\\textbf{x}\\) \u662f\u4e00\u4e2a \\(n\\) \u7ef4\u5411\u91cf\uff0c\u90a3\u6c42\u5bfc\u7ed3\u679c\u662f\u4e00\u4e2a \\(m \\times n\\) \u77e9\u9635\u8fd8\u662f \\(n \\times m\\) \u77e9\u9635\u5462\uff1f \u5206\u5b50\u5e03\u5c40\uff0c\u5373\u4ee5\u5206\u5b50 \\(\\textbf{y}\\) \u7684\u5143\u7d20\u6570\u4f5c\u4e3a\u884c\u6570\u3002\u7ed3\u679c\u662f\u4e00\u4e2a \\(m \\times n\\) \u77e9\u9635\uff0c\u4e5f\u79f0\u4e3a\u96c5\u53ef\u6bd4\uff08Jacobian\uff09\u77e9\u9635\u3002 \\[ \\frac{ \\partial \\textbf{ y } }{ \\partial \\textbf{ x } } = \\begin{bmatrix} \\frac{ \\partial {y_1} }{ \\partial {x_1} } & \\frac{\\partial {y_1} }{\\partial {x_2} } & \\cdots &\\frac{\\partial {y_1} }{\\partial {x_n} } \\\\ \\frac{\\partial {y_2} }{\\partial {x_1} } & \\frac{\\partial {y_2} }{\\partial {x_2} } & \\cdots &\\frac{\\partial {y_2} }{\\partial {x_n} } \\\\ \\vdots & \\vdots & & \\vdots \\\\ \\frac{\\partial {y_m} }{\\partial {x_1} } & \\frac{\\partial {y_m} }{\\partial {x_2} } & \\cdots &\\frac{\\partial {y_m} }{\\partial {x_n} } \\\\ \\end{bmatrix}_{m \\times n} \\] \u5206\u6bcd\u5e03\u5c40\uff0c\u5373\u4ee5\u5206\u6bcd \\(\\textbf{x}\\) \u7684\u5143\u7d20\u6570\u4f5c\u4e3a\u884c\u6570\u3002\u7ed3\u679c\u662f\u4e00\u4e2a \\(n \\times m\\) \u77e9\u9635\uff0c\u4e5f\u79f0\u4e3a\u68af\u5ea6(Gradient)\u77e9\u9635\u3002 \\[ \\frac{\\partial \\textbf{ y }}{\\partial \\textbf{ x } } = \\begin{bmatrix} \\frac{\\partial {y_1} }{\\partial {x_1} } & \\frac{\\partial {y_2} }{\\partial {x_1} } & \\cdots &\\frac{\\partial {y_m} }{\\partial {x_1} } \\\\ \\frac{\\partial {y_1} }{\\partial {x_2} } & \\frac{\\partial {y_2} }{\\partial {x_2} } & \\cdots &\\frac{\\partial {y_m } }{\\partial {x_2} } \\\\ \\vdots & \\vdots & & \\vdots \\\\ \\frac{\\partial {y_1} }{\\partial {x_n} } & \\frac{\\partial {y_2} }{\\partial {x_n} } & \\cdots &\\frac{\\partial {y_m} }{\\partial {x_n} } \\\\ \\end{bmatrix}_{n \\times m} \\] \u4e24\u79cd\u5e03\u5c40\u5747\u53ef\uff0c\u5728\u4e00\u672c\u4e66\u4e2d\u4e00\u822c\u662f\u4e00\u81f4\u7684\u3002","title":"\u5411\u91cf\u5bf9\u5411\u91cf\u6c42\u5bfc"},{"location":"mathematics/matrix/MatrixCalculus/#_4","text":"\u6807\u91cf\u5e38\u89c1\u7684\u6709\u4ee5\u4e0b\u51e0\u79cd\u5f62\u5f0f\uff1a \\(a^T x\\) \\(x^T a\\) \\(x^T A x\\) \u4ece\u5b9a\u4e49\u4e0a\u770b\uff0c1 \u548c 2 \u7c7b\u4f3c\uff1a \u9996\u5148\u5b9a\u4e49\uff1a \\[S = a^T x = x^T a = \\sum_{i=1}^n a_ix_i\\] \u5f97\u51fa\uff1a \\[ \\frac{\\partial S}{\\partial x_i} = a_i\\] \u56e0\u6b64\uff1a \\[\\frac{\\partial a^Tx}{\\partial x} = \\frac{\\partial x^Ta}{\\partial x} = [ \\frac{\\partial S}{\\partial x_1}, \\frac{\\partial S}{\\partial x_2}, \\cdots, \\frac{\\partial S}{\\partial x_n}]^T = a\\] 3 \u7a0d\u5fae\u590d\u6742\uff1a \\[ S = \\sum_{i=1}^n \\sum_{j=1}^n x_iA_{i,j}x_j\\] \\[ \\frac{\\partial S}{\\partial x_k} = \\sum_{j=1}^n A_{k,j}x_j + \\sum_{i=1}^n x_iA_{i,k} = (A_{k,i} + A_{i,k})x_i\\] \u5373\u6c42\u5bfc\u540e\u5411\u91cf\u7684\u7b2c k \u4e2a\u5143\u7d20\u662f A \u7684\u7b2c k \u884c\u4e0e x \u7684\u5185\u79ef + \u7b2c k \u5217\u4e0e x \u7684\u5185\u79ef\u3002\u8fd9\u5176\u5b9e\u5c31\u662f\u77e9\u9635\u4e0e\u5411\u91cf\u4e58\u6cd5\u7684\u5b9a\u4e49\u3002 \\[\\frac{\\partial x^TAx}{\\partial x} = [ \\frac{\\partial S}{\\partial x_1}, \\frac{\\partial S}{\\partial x_2}, \\cdots, \\frac{\\partial S}{\\partial x_n}]^T = Ax + A^Tx \\]","title":"\u6807\u91cf\u5bf9\u5411\u91cf\u6c42\u5bfc"},{"location":"mathematics/matrix/MatrixCalculus/#_5","text":"\u6700\u5c0f\u4e8c\u4e58\u6cd5\u662f\u6700\u6d41\u884c\u7684\u7ebf\u6027\u6a21\u578b\u62df\u5408\u65b9\u6cd5\u3002\u5b83\u7684\u76ee\u7684\u662f\u627e\u51fa\u7cfb\u6570 \\(\\mathbf{\\beta}\\) \u4f7f \\(||Y-\\hat Y||_2\\) \uff08residual sum of squares, RSS\uff09\u6700\u5c0f\uff1a \\[\\text{RSS}(\\mathbf{\\beta} ) = \\sum_{j=1}^N (y_j - X_j^T\\mathbf{\\beta} )^2 \\] \u5176\u4e2d \\(j\\) \u4ee3\u8868\u8bad\u7ec3\u6570\u636e\u7684\u5e8f\u53f7\u3002\u4e00\u5171\u6709 \\(N\\) \u7ec4\u8bad\u7ec3\u6570\u636e\u3002 \u7528\u77e9\u9635\u5f62\u5f0f\u8868\u793a\u4e3a\uff1a \\[\\text{RSS}(\\mathbf{\\beta}) = (\\textbf{y} - \\textbf{X}\\mathbf{\\beta} )^T(\\textbf{y} - \\textbf{X}\\mathbf{\\beta} )\\] \u8fd9\u91cc\u9700\u8981\u7528 \\(\\text{RSS}(\\mathbf{\\beta})\\) \u5bf9 \\(\\mathbf{\\beta}\\) \u6c42\u5bfc\uff0c\u5f97\u51fa\u4e8c\u6b21\u51fd\u6570\u6700\u503c\u70b9\u3002 \\[\\text{RSS}(\\mathbf{\\beta}) = \\textbf{y}^T\\textbf{y} -\\textbf{y}^T \\textbf{X} \\mathbf{\\beta} - \\mathbf{\\beta}^T \\textbf{X}^T \\textbf{y} + \\mathbf{\\beta}^T \\textbf{X}^T \\textbf{X}\\mathbf{\\beta}\\] \u5957\u7528\u4e0a\u9762\u7684\u7ed3\u8bba\uff0c\u53ef\u4ee5\u5f97\u5230\uff1a \\[ \\frac{ \\partial \\text{RSS}(\\mathbf{\\beta})}{\\partial \\mathbf{\\beta}} = - 2\\textbf{X}^T\\textbf{y} + 2\\textbf{X}^T\\textbf{X}\\mathbf{\\beta}\\] \u4ee4\u5176\u4e3a 0 \u53ef\u4ee5\u89e3\u51fa\uff1a \\[\\hat{\\mathbf{\\beta}} = (\\textbf{X}^T \\textbf{X})^{-1} \\textbf{X}^T \\textbf{y}\\]","title":"\u4f8b\uff1a\u6700\u5c0f\u4e8c\u4e58\u6cd5"},{"location":"mathematics/probability/RigidBalls/","text":"\u5c0f\u7403\u78b0\u649e\u95ee\u9898\u4e2d\u7684\u7edf\u8ba1\u5b66 \u670b\u53cb\u7ed9\u6211\u53d1\u4e86\u4e00\u9053\u7b14\u8bd5\u9898\u8ba9\u6211\u5e2e\u5fd9\u505a\u3002\u9898\u76ee\u5927\u6982\u662f\u8fd9\u6837\uff1a (1) \u6709 1 \u4e2a\u5c0f\u7403\u653e\u5728\u4e00\u4e2a 1m \u957f\u7684\u5149\u6ed1\u51f9\u69fd\u91cc\uff0c\u5c0f\u7403\u521d\u59cb\u4f4d\u7f6e\u968f\u673a\uff08\u5747\u5300\u5206\u5e03\uff09\uff0c\u521d\u59cb\u901f\u5ea6 1m/s\uff0c\u65b9\u5411\u968f\u673a\u3002\u6c42\u5c0f\u7403\u6ed1\u51fa\u51f9\u69fd\u7684\u671f\u671b\u503c\u3002 (2) \u5982\u679c\u6709 2 \u4e2a\u5c0f\u7403\uff0c\u4e14\u5c0f\u7403\u78b0\u649e\u4e3a\u521a\u6027\u78b0\u649e\uff0c\u6c42\u4e24\u4e2a\u5c0f\u7403\u5168\u90e8\u4ece\u51f9\u69fd\u6389\u843d\u7684\u65f6\u95f4\u671f\u671b\u503c\u3002 (3) \u5982\u679c\u6709 n \u4e2a\u5c0f\u7403\u5462\uff1f \u8fd9\u9053\u9898\u5176\u5b9e\u7528\u76f4\u89c9\u505a\u5f88\u7b80\u5355\u3002\u4e3b\u8981\u6709\u4e24\u4e2a\u5173\u7a8d\uff1a 1. \u521a\u6027\u78b0\u649e\u540e\uff0c\u5c0f\u7403\u4ea4\u6362\u901f\u5ea6 \u52a8\u91cf\u5b88\u6052+\u80fd\u91cf\u5b88\u6052 2. n \u4e2a\u5c0f\u7403\u5728\u8f68\u9053\u4e0a\u5747\u5300\u5206\u5e03\u5927\u6982\u662f\u4ec0\u4e48\u6837\uff1f \u5176\u671f\u671b\u5c31\u662f\u5747\u5300\u628a\u8f68\u9053\u5206\u6210 n + 1 \u4efd\u3002 \u56e0\u6b64\u7b54\u6848\u662f\uff1a1/2\uff0c2/3\uff0c\u548c n/(n+1) \u5f53\u7136\uff0c\u8fd9\u5b8c\u5168\u4e0d\u591f\u4e25\u8c28\u3002\u4e0b\u9762\u8fdb\u5165\u6570\u5b66\u90e8\u5206\u3002 N \u4e2a\u72ec\u7acb\u540c\u5206\u5e03\u6700\u5927\u503c\u7684\u671f\u671b \u8fd9\u9053\u9898\u53ef\u4ee5\u63d0\u70bc\u51fa\u4e00\u4e2a\u6570\u5b66\u95ee\u9898\uff0c\u5373\u6c42 N \u4e2a\u72ec\u7acb\u540c\u5206\u5e03\u6700\u5927\u503c\u7684\u671f\u671b\u3002 \u5047\u8bbe \\(Y\\) \u662f N \u4e2a\u968f\u673a\u53d8\u91cf\u7684\u6700\u5927\u503c\uff0c\u5219 \\(Y\\) \u7684\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\uff08Cumulative Distribution Function\uff09\u4e3a\uff1a \\[G(y) = P(Y \\leq y) = P( \\max(X_1, X_2, ..., X_n) \\leq y)\\] \u7531\u4e8e X \u76f8\u4e92\u72ec\u7acb\uff0c\u4e0a\u5f0f\u7b49\u4ef7\u4e8e\uff1a \\[\\begin{align} G(y) &= P(X_1 \\leq y) P( X_2 \\leq y) P(X_n \\leq y) \\\\ &= F^n(y) \\end{align}\\] \u5176\u4e2d \\(F\\) \u8868\u793a \\(X\\) \u7684\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\u3002 \u90a3\u4e48 \\(Y\\) \u7684\u671f\u671b\u503c\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\[\\begin{align} E(Y) &= \\int_a^b y G'(y) dy \\\\ &= yG(y)|_a^b - \\int_a^bG(y)dy \\\\ &= b - \\int_a^bF^n(y)dy \\end{align}\\] \u5747\u5300\u5206\u5e03\u60c5\u5f62 \u5bf9\u4e8e \\((a, b)\\) \u533a\u95f4\u4e0a\u7684\u5747\u5300\u5206\u5e03\u6709\uff1a \\[F(x) = \\frac{x-a}{b-a}\\] \u6545 \\[\\begin{align} E(Y) &= b - \\int_a^bF^n(y)dy \\\\ &= b - \\frac{1}{(b-a)^n} \\int_a^b(y-a)^n dy \\\\ &= b - \\frac{b-a}{n+1} \\\\ &= \\frac{a + nb}{n+1} \\end{align}\\] \u5e26\u5165\u9898\u76ee\u4e2d\u7684\u533a\u95f4 \\((0,1)\\) \u5f97\u5230\uff1a \\[E(Y) = \\frac{n}{n+1}\\]","title":"\u5c0f\u7403\u78b0\u649e\u95ee\u9898\u4e2d\u7684\u7edf\u8ba1\u5b66"},{"location":"mathematics/probability/RigidBalls/#_1","text":"\u670b\u53cb\u7ed9\u6211\u53d1\u4e86\u4e00\u9053\u7b14\u8bd5\u9898\u8ba9\u6211\u5e2e\u5fd9\u505a\u3002\u9898\u76ee\u5927\u6982\u662f\u8fd9\u6837\uff1a (1) \u6709 1 \u4e2a\u5c0f\u7403\u653e\u5728\u4e00\u4e2a 1m \u957f\u7684\u5149\u6ed1\u51f9\u69fd\u91cc\uff0c\u5c0f\u7403\u521d\u59cb\u4f4d\u7f6e\u968f\u673a\uff08\u5747\u5300\u5206\u5e03\uff09\uff0c\u521d\u59cb\u901f\u5ea6 1m/s\uff0c\u65b9\u5411\u968f\u673a\u3002\u6c42\u5c0f\u7403\u6ed1\u51fa\u51f9\u69fd\u7684\u671f\u671b\u503c\u3002 (2) \u5982\u679c\u6709 2 \u4e2a\u5c0f\u7403\uff0c\u4e14\u5c0f\u7403\u78b0\u649e\u4e3a\u521a\u6027\u78b0\u649e\uff0c\u6c42\u4e24\u4e2a\u5c0f\u7403\u5168\u90e8\u4ece\u51f9\u69fd\u6389\u843d\u7684\u65f6\u95f4\u671f\u671b\u503c\u3002 (3) \u5982\u679c\u6709 n \u4e2a\u5c0f\u7403\u5462\uff1f \u8fd9\u9053\u9898\u5176\u5b9e\u7528\u76f4\u89c9\u505a\u5f88\u7b80\u5355\u3002\u4e3b\u8981\u6709\u4e24\u4e2a\u5173\u7a8d\uff1a 1. \u521a\u6027\u78b0\u649e\u540e\uff0c\u5c0f\u7403\u4ea4\u6362\u901f\u5ea6 \u52a8\u91cf\u5b88\u6052+\u80fd\u91cf\u5b88\u6052 2. n \u4e2a\u5c0f\u7403\u5728\u8f68\u9053\u4e0a\u5747\u5300\u5206\u5e03\u5927\u6982\u662f\u4ec0\u4e48\u6837\uff1f \u5176\u671f\u671b\u5c31\u662f\u5747\u5300\u628a\u8f68\u9053\u5206\u6210 n + 1 \u4efd\u3002 \u56e0\u6b64\u7b54\u6848\u662f\uff1a1/2\uff0c2/3\uff0c\u548c n/(n+1) \u5f53\u7136\uff0c\u8fd9\u5b8c\u5168\u4e0d\u591f\u4e25\u8c28\u3002\u4e0b\u9762\u8fdb\u5165\u6570\u5b66\u90e8\u5206\u3002","title":"\u5c0f\u7403\u78b0\u649e\u95ee\u9898\u4e2d\u7684\u7edf\u8ba1\u5b66"},{"location":"mathematics/probability/RigidBalls/#n","text":"\u8fd9\u9053\u9898\u53ef\u4ee5\u63d0\u70bc\u51fa\u4e00\u4e2a\u6570\u5b66\u95ee\u9898\uff0c\u5373\u6c42 N \u4e2a\u72ec\u7acb\u540c\u5206\u5e03\u6700\u5927\u503c\u7684\u671f\u671b\u3002 \u5047\u8bbe \\(Y\\) \u662f N \u4e2a\u968f\u673a\u53d8\u91cf\u7684\u6700\u5927\u503c\uff0c\u5219 \\(Y\\) \u7684\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\uff08Cumulative Distribution Function\uff09\u4e3a\uff1a \\[G(y) = P(Y \\leq y) = P( \\max(X_1, X_2, ..., X_n) \\leq y)\\] \u7531\u4e8e X \u76f8\u4e92\u72ec\u7acb\uff0c\u4e0a\u5f0f\u7b49\u4ef7\u4e8e\uff1a \\[\\begin{align} G(y) &= P(X_1 \\leq y) P( X_2 \\leq y) P(X_n \\leq y) \\\\ &= F^n(y) \\end{align}\\] \u5176\u4e2d \\(F\\) \u8868\u793a \\(X\\) \u7684\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\u3002 \u90a3\u4e48 \\(Y\\) \u7684\u671f\u671b\u503c\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\[\\begin{align} E(Y) &= \\int_a^b y G'(y) dy \\\\ &= yG(y)|_a^b - \\int_a^bG(y)dy \\\\ &= b - \\int_a^bF^n(y)dy \\end{align}\\]","title":"N \u4e2a\u72ec\u7acb\u540c\u5206\u5e03\u6700\u5927\u503c\u7684\u671f\u671b"},{"location":"mathematics/probability/RigidBalls/#_2","text":"\u5bf9\u4e8e \\((a, b)\\) \u533a\u95f4\u4e0a\u7684\u5747\u5300\u5206\u5e03\u6709\uff1a \\[F(x) = \\frac{x-a}{b-a}\\] \u6545 \\[\\begin{align} E(Y) &= b - \\int_a^bF^n(y)dy \\\\ &= b - \\frac{1}{(b-a)^n} \\int_a^b(y-a)^n dy \\\\ &= b - \\frac{b-a}{n+1} \\\\ &= \\frac{a + nb}{n+1} \\end{align}\\] \u5e26\u5165\u9898\u76ee\u4e2d\u7684\u533a\u95f4 \\((0,1)\\) \u5f97\u5230\uff1a \\[E(Y) = \\frac{n}{n+1}\\]","title":"\u5747\u5300\u5206\u5e03\u60c5\u5f62"},{"location":"mathematics/probability/martingale/","text":"Martingale Definition Process X is a martingale if for all n: \\[ E[X_{n+1}|F_n] = X_n \\] Where Fn is the history of Xn (called filtration) Which means, on the n+1 step, the expectation of X shall be the same as any step before. A martingale may be thought of as a \u201cfair game\u201d, because given the information in current and previous plays (Fn), you don't expect to change your total winning (X). Example Here are two practical example to help you understand it. Partial sum process A simple coin game, in \\(i\\) turn we bet \\(X_i\\) , and \\(S_n\\) is our winning money after n turn. Let Xi be independent, define the partial sum process: \\[\\begin{aligned} S_0 &= 0, \\\\ S_n &= \\sum_{ i=1 }^n X_i, n=1, 2,... \\end{aligned}\\] Sn is a martingale iff: \\[E(X_i) = 0\\] Proof With Xi being independent, and E(Xi) = 0, we have: \\[\\begin{aligned} E[S_{n+1}|X_1,...X_n] &= E[S_n + X_{n+1} | X_1,...X_n] \\\\ &= S_n + E[X_{n+1} | X_1,...X_n] \\\\ &= S_n + E[X_{n+1}] \\\\ &= S_n \\end{aligned}\\] Gambler's Ruin Problem A classic problem on martingale. Consider a gambler who starts with an initial fortune of $1 and then on each successive gamble either wins $1 or loses $1 independent of the past with probabilities p and q = 1\u2212p respectively. Let Rn denote the total fortune after the n th gamble. The gambler\u2019s objective is to reach a total fortune of $N, without first getting ruined (running out of money). If the gambler succeeds, then the gambler is said to win the game. Let \\(P_i\\) denote the probability that the gambler wins when the initial money \\(R_0 = i\\) , we have: \\[P_i = pP_{i+1} + qP_{i-1}\\] This is because P_i can only lead to two states: Winning $1 with probability p to state \\(P_{i+1}\\) Losing $1 with probability q to state \\(P_{i-1}\\) Subtract P_{i-1} from both sides of the equation, we get: \\[P_i = (p + q) P_i = pP_{i+1} + qP_{i-1}\\] i.e., \\[{P_{i+1} - P_i}= \\frac{ q }{ p }(P_i - P_{i-1})\\] Thus \\[\\begin{aligned} P_{i+1} - P_1 &= \\sum_{k=1}^i (P_{k+1} - P_k) \\\\ &= \\sum_{k=1}^i (\\frac{q}{p})^k P_1 \\end{aligned}\\] We have \\[P_{i+1}= \\begin{cases} P_1 \\frac{1-(q/p)^{i+1}}{1-(q/p)} &, p \\neq q\\\\ P_1 (i+1) &, p=q \\end{cases}\\] To solve P_1, pick i = N-1 and use the fact that P_N = 1 \\[P_1= \\begin{cases} \\frac{1-(q/p)}{1-(q/p)^N} &, p \\neq q\\\\ 1/N &, p=q \\end{cases}\\] Substitute P_1 and we have: \\[P_i= \\begin{cases} \\frac{ 1-(q/p)^i}{ 1-(q/p)^N } &, p \\neq q \\\\ i/N &, p=q \\end{cases}\\] Reference martingales.dvi (rice.edu) 4700-07-Notes-GR.pdf (columbia.edu)","title":"Martingale"},{"location":"mathematics/probability/martingale/#martingale","text":"","title":"Martingale"},{"location":"mathematics/probability/martingale/#definition","text":"Process X is a martingale if for all n: \\[ E[X_{n+1}|F_n] = X_n \\] Where Fn is the history of Xn (called filtration) Which means, on the n+1 step, the expectation of X shall be the same as any step before. A martingale may be thought of as a \u201cfair game\u201d, because given the information in current and previous plays (Fn), you don't expect to change your total winning (X).","title":"Definition"},{"location":"mathematics/probability/martingale/#example","text":"Here are two practical example to help you understand it.","title":"Example"},{"location":"mathematics/probability/martingale/#partial-sum-process","text":"A simple coin game, in \\(i\\) turn we bet \\(X_i\\) , and \\(S_n\\) is our winning money after n turn. Let Xi be independent, define the partial sum process: \\[\\begin{aligned} S_0 &= 0, \\\\ S_n &= \\sum_{ i=1 }^n X_i, n=1, 2,... \\end{aligned}\\] Sn is a martingale iff: \\[E(X_i) = 0\\]","title":"Partial sum process"},{"location":"mathematics/probability/martingale/#proof","text":"With Xi being independent, and E(Xi) = 0, we have: \\[\\begin{aligned} E[S_{n+1}|X_1,...X_n] &= E[S_n + X_{n+1} | X_1,...X_n] \\\\ &= S_n + E[X_{n+1} | X_1,...X_n] \\\\ &= S_n + E[X_{n+1}] \\\\ &= S_n \\end{aligned}\\]","title":"Proof"},{"location":"mathematics/probability/martingale/#gamblers-ruin-problem","text":"A classic problem on martingale. Consider a gambler who starts with an initial fortune of $1 and then on each successive gamble either wins $1 or loses $1 independent of the past with probabilities p and q = 1\u2212p respectively. Let Rn denote the total fortune after the n th gamble. The gambler\u2019s objective is to reach a total fortune of $N, without first getting ruined (running out of money). If the gambler succeeds, then the gambler is said to win the game. Let \\(P_i\\) denote the probability that the gambler wins when the initial money \\(R_0 = i\\) , we have: \\[P_i = pP_{i+1} + qP_{i-1}\\] This is because P_i can only lead to two states: Winning $1 with probability p to state \\(P_{i+1}\\) Losing $1 with probability q to state \\(P_{i-1}\\) Subtract P_{i-1} from both sides of the equation, we get: \\[P_i = (p + q) P_i = pP_{i+1} + qP_{i-1}\\] i.e., \\[{P_{i+1} - P_i}= \\frac{ q }{ p }(P_i - P_{i-1})\\] Thus \\[\\begin{aligned} P_{i+1} - P_1 &= \\sum_{k=1}^i (P_{k+1} - P_k) \\\\ &= \\sum_{k=1}^i (\\frac{q}{p})^k P_1 \\end{aligned}\\] We have \\[P_{i+1}= \\begin{cases} P_1 \\frac{1-(q/p)^{i+1}}{1-(q/p)} &, p \\neq q\\\\ P_1 (i+1) &, p=q \\end{cases}\\] To solve P_1, pick i = N-1 and use the fact that P_N = 1 \\[P_1= \\begin{cases} \\frac{1-(q/p)}{1-(q/p)^N} &, p \\neq q\\\\ 1/N &, p=q \\end{cases}\\] Substitute P_1 and we have: \\[P_i= \\begin{cases} \\frac{ 1-(q/p)^i}{ 1-(q/p)^N } &, p \\neq q \\\\ i/N &, p=q \\end{cases}\\]","title":"Gambler's Ruin Problem"},{"location":"mathematics/probability/martingale/#reference","text":"martingales.dvi (rice.edu) 4700-07-Notes-GR.pdf (columbia.edu)","title":"Reference"},{"location":"trading/option/BSM/","text":"The Black-Scholes-Merton model \u5728 1970 \u5e74\u4ee3\uff0cFischer Black, Myron Scholes, Robert Merton \u63d0\u51fa\u4e86\u4e00\u4e2a\u91cd\u8981\u7684\u6b27\u5f0f\u671f\u6743\u5b9a\u4ef7\u6a21\u578b\u3002\u8fd9\u4e2a\u6a21\u578b\u57fa\u4e8e\u4ee5\u4e0b 7 \u6761\u5047\u8bbe\uff1a \u80a1\u7968\u4ef7\u683c\u7b26\u5408\u4f0a\u85e4\u8fc7\u7a0b \\(\\frac{ dS }{ S } = \\mu ~dt + \\sigma ~dz\\) \u5141\u8bb8\u5356\u7a7a\u8bc1\u5238\u5e76\u5145\u5206\u5229\u7528\u6536\u76ca \u6ca1\u6709\u4ea4\u6613\u8d39\u7528\u548c\u7a0e\uff0c\u6240\u6709\u8bc1\u5238\u5b8c\u5168\u53ef\u5206\u5272 \u5728\u671f\u6743\u671f\u9650\u5185\uff0c\u80a1\u7968\u4e0d\u652f\u4ed8\u80a1\u606f \u4e0d\u5b58\u5728\u65e0\u98ce\u9669\u5957\u5229\u673a\u4f1a \u8bc1\u5238\u4ea4\u6613\u8fde\u7eed\u8fdb\u884c \u65e0\u98ce\u9669\u5229\u7387 \\(r\\) \u662f\u5e38\u6570\u5e76\u4e14\u5bf9\u6240\u6709\u671f\u9650\u76f8\u540c \u6ce8\u610f\uff0c\u8fd9\u5176\u4e2d\u5e76\u4e0d\u5305\u542b\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u3002\u4ece\u6839\u672c\u4e0a\u8bb2\uff0c\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u53ea\u662f\u4e00\u4e2a\u6570\u5b66\u4e0a\u7684\u6c42\u89e3\u6280\u5de7\uff0c\u5373\u4f7f\u4e0d\u4f7f\u7528\u8fd9\u4e2a\u6280\u5de7\uff0c\u4e00\u6837\u53ef\u4ee5\u901a\u8fc7\u66b4\u529b\u6c42\u89e3 PDE \u5f97\u5230\u540c\u6837\u7684\u7ed3\u679c\uff08Feynman-Kac Theorem\uff09\u3002\u8fd9\u4e00\u70b9\u975e\u5e38\u91cd\u8981\uff0c\u56e0\u4e3a\u771f\u5b9e\u4e16\u754c\u660e\u663e\u4e0d\u662f\u98ce\u9669\u4e2d\u6027\u7684\uff0cBSM \u516c\u5f0f\u4e5f\u4e0d\u53ef\u80fd\u57fa\u4e8e\u8fd9\u4e48\u4e00\u4e2a\u4e0d\u9760\u8c31\u7684\u5047\u8bbe\u3002 14.6 Black-Scholes-Merton \u5fae\u5206\u65b9\u7a0b \u6839\u636e\u5047\u8bbe\uff0c\u80a1\u7968\u7684\u4ef7\u683c\u670d\u4ece\u4ee5\u4e0b\u4f0a\u85e4\u8fc7\u7a0b\uff1a \\[\\frac{ dS }{ S } = \\mu ~dt + \\sigma ~dz\\] \u6211\u4eec\u7684\u76ee\u6807\uff0c\u4e5f\u5c31\u662f\u4ee5\u8be5\u80a1\u7968\u4e3a\u6807\u7684\u7269\u7684\u770b\u6da8\u671f\u6743\u7684\u4ef7\u683c \\(C\\) \u80af\u5b9a\u662f \\(S\\) \u548c \\(t\\) \u7684\u51fd\u6570\u3002\u6839\u636e\u4f0a\u85e4\u5f15\u7406\uff0c\u5f97\u5230\uff1a \\[dC = (\\frac{ \\partial C}{ \\partial S} \\mu S + \\frac{ \\partial C}{ \\partial t} + \\frac{1}{2} \\frac{ \\partial^2 C}{ \\partial S^2} \\sigma^2 S^2)~dt + \\frac{ \\partial C}{ \\partial S}\\sigma S~dz\\] \u8fd9\u662f\u4e00\u4e2a\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff0c\u6211\u4eec\u5f88\u96be\u76f4\u63a5\u6c42\u89e3\u3002\u4e8e\u662f\u6211\u4eec\u5e0c\u671b\u5229\u7528 \\(S\\) \u548c \\(C\\) \u7684\u7ebf\u6027\u7ec4\u5408\u6d88\u53bb\u5176\u968f\u673a\u9879\u3002 \u6784\u9020\u4e00\u4e2a portfolio \\(V = Q_S S + Q_C C\\) \uff0c\u5176\u4e2d \\(Q_S\\) \u548c \\(Q_C\\) \u5206\u522b\u662f\u80a1\u7968\u548c\u770b\u6da8\u671f\u6743\u7684\u6570\u91cf\u3002\u4e3a\u4e86\u6d88\u9664\u968f\u673a\u9879 \\(dz\\) \uff0c\u6211\u4eec\u9700\u8981\uff1a \\[Q_S \\sigma S + Q_C \\frac{\\partial C}{\\partial S}\\sigma S = 0\\] \u6211\u4eec\u53ef\u4ee5\u4ee4 \\(Q_S = \\frac{\\partial C}{\\partial S}\\) \uff0c \\(Q_C = -1\\) \u3002 \u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c \u6211\u4eec\u901a\u8fc7\u8fd9\u6837\u5b9e\u9645\u6784\u9020\u4e86\u4e00\u4e2a\u65e0\u98ce\u9669\u7684 portfolio\uff0c\u540c\u65f6\uff0c\u80a1\u7968\u7684\u6570\u91cf\u4e5f\u662f Greeks \u91cc\u9762\u7684 delta\u3002 \u7531\u4e8e\u8fd9\u662f\u4e00\u4e2a\u65e0\u98ce\u9669\u7684 portfolio\uff0c\u5176\u6ce2\u52a8\u7387\u4e3a 0\uff0c\u671f\u671b\u6536\u76ca\u7b49\u4e8e\u65e0\u98ce\u9669\u5229\u7387 \\(r\\) \u3002\u56e0\u6b64\uff1a \\[dV = rVdt\\] \u5e76\u4e14 \\[dV = Q_S~dS +Q_C~dC\\] \u5e26\u5165\u5f97\uff1a \\[\\frac{\\partial C}{\\partial S} rS + \\frac{\\partial C}{\\partial t} + \\frac{1}{2}\\frac{\\partial^2 C}{\\partial S^2} \\sigma^2 S^2 = rC\\] \u8fd9\u5c31\u662f Black-Scholes-Merton \u5fae\u5206\u65b9\u7a0b \u3002\u8fd9\u4e2a\u65b9\u7a0b\u7684\u7cbe\u5999\u4e4b\u5904\u5728\u4e8e\u6211\u4eec\u6d88\u6389\u4e86\u968f\u673a\u9879\u548c\u671f\u671b\u6536\u76ca\u7387 \\(\\mu\\) \u8fd9\u4e24\u4e2a\u975e\u5e38\u590d\u6742\u7684\u90e8\u5206\u3002 \u8fd9\u4e2a\u65b9\u7a0b\u6709\u5f88\u591a\u89e3\uff0c\u5bf9\u5e94\u4e8e\u5404\u79cd\u884d\u751f\u54c1\u3002\u5047\u8bbe\u4e00\u4e2a\u884d\u751f\u54c1\u4e0d\u6ee1\u8db3\u8fd9\u4e2a\u5fae\u5206\u65b9\u7a0b\uff0c\u4f8b\u5982 \\(e^S\\) \uff0c\u5219\u8be5\u884d\u751f\u54c1\u4e0d\u53ef\u80fd\u5b58\u5728\uff0c\u56e0\u4e3a\u4e00\u5b9a\u5b58\u5728\u5957\u5229\u673a\u4f1a\u3002 14.7 \u98ce\u9669\u4e2d\u6027\u5b9a\u4ef7 \u6211\u4eec\u6ce8\u610f\u5230\uff0c\u63a8\u5bfc\u51fa\u7684 Black-Scholes-Merton \u5fae\u5206\u65b9\u7a0b\u4e0d\u542b\u671f\u671b\u6536\u76ca \\(\\mu\\) \uff0c\u8fd9\u4e5f\u4ece\u8bc1\u660e\u4e86\u6211\u4eec\u5728\u7528\u4e8c\u53c9\u6811\u8fdb\u884c\u5b9a\u4ef7\u65f6\u7684\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u7684\u6b63\u786e\u6027\u3002\u56e0\u4e3a\u5b83\u4e0e\u6295\u8d44\u4eba\u7684\u98ce\u9669\u504f\u597d\u65e0\u5173\u3002\u6211\u4eec\u5c31\u53ef\u4ee5\u653e\u5fc3\u4f7f\u7528\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u7b80\u5316\u8ba1\u7b97\u3002 \u5047\u8bbe\u4ece\u6807\u7684\u7269\u83b7\u5f97\u7684\u671f\u671b\u6536\u76ca\u5c31\u662f\u65e0\u98ce\u9669\u5229\u7387 \\(r\\) \u8ba1\u7b97\u884d\u751f\u54c1\u7684\u671f\u671b\u7684 payoff \u5c06\u671f\u671b\u7684 payoff \u6298\u73b0\uff0c\u6298\u73b0\u7387\u4e5f\u7b49\u4e8e\u65e0\u98ce\u9669\u5229\u7387 \\(r\\) \u4f8b \u5047\u8bbe\u4e00\u4e2a\u8fdc\u671f\u5408\u7ea6\u591a\u5934\u5230\u671f\u65e5\u4e3a \\(T\\) \uff0c\u6267\u884c\u4ef7\u683c\u4e3a \\(K\\) \uff0c\u76ee\u524d\u73b0\u8d27\u4ef7\u683c\u662f \\(S_0\\) \uff0c\u65e0\u98ce\u9669\u5229\u7387\u4e3a \\(r\\) \uff0c\u5219\u8fdc\u671f\u5408\u7ea6\u4ef7\u683c\u4e3a\uff1f \u5047\u8bbe\u5230\u671f\u65e5\u6807\u7684\u7269\u4ef7\u683c\u4e3a \\(S_T\\) \uff0c\u5219\u5229\u7528\u4ee5\u4e0a\u4e09\u4e2a\u6b65\u9aa4\uff0c\u53ef\u4ee5\u5f97\u5230\uff1a \\[f = e^{-rT}~E(S_T- K) = e^{-rT}E(S_T) - Ke^{-rT}\\] \u7531\u4e8e\u6211\u4eec\u7684\u671f\u671b\u6536\u76ca\u7387\u4e3a\u65e0\u98ce\u9669\u5229\u7387 \\(r\\) \uff0c\u5219\u6709 \\(E(S_T) = S_0 e^{rT}\\) \uff0c\u5e26\u5165\u53ef\u4ee5\u5f97\u5230\uff1a \\[f = S_0 - Ke^{-rT}\\] \u8fd9\u7b26\u5408\u6211\u4eec\u5229\u7528\u65e0\u5957\u5229\u5047\u8bbe\u5f97\u51fa\u7684\u7ed3\u8bba\u3002 14.8 Black-Scholes-Merton \u5b9a\u4ef7\u516c\u5f0f \u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u5c06\u5229\u7528\u98ce\u9669\u4e2d\u6027\u5b9a\u4ef7\u539f\u7406\u6765\u63a8\u5bfc BSM \u5b9a\u4ef7\u516c\u5f0f\u3002\u8fd9\u6837\u53ef\u4ee5\u907f\u514d\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u590d\u6742\u5ea6\u3002 14.8.1 \u8ba1\u7b97 payoff \u671f\u671b \u4ee5\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u4e3a\u4f8b\uff0c\u5176\u5728\u5230\u671f\u65e5 \\(T\\) \u7684 payoff \u4e3a \\(f =\\max(S-K, 0)\\) \u3002\u5b83\u7684\u4ef7\u683c\u5e94\u8be5\u4e3a payoff \u7684\u671f\u671b\u6298\u73b0\u540e\u7684\u503c\u3002\u56e0\u6b64\u95ee\u9898\u8f6c\u5316\u4e3a\u6c42\uff1a \\[E(\\max(S-K, 0)) = \\int_{K}^{\\infty}(S-K)g(S)~dS\\] \u5176\u4e2d \\(g(S)\\) \u4ee3\u8868\u80a1\u7968\u4ef7\u683c\u4e3a \\(S\\) \u7684\u6982\u7387\u3002\u90a3\u4e48\u5982\u4f55\u5f97\u5230 \\(g(S)\\) \u5462\uff1f \u6211\u4eec\u5df2\u7ecf\u5047\u8bbe \\(S\\) \u670d\u4ece\u4f0a\u85e4\u8fc7\u7a0b\uff1a \\[\\frac{ dS }{ S } = \\mu ~dt + \\sigma ~dz\\] \u4ee4 \\(G = \\ln(S)\\) \uff0c\u7531\u4f0a\u85e4\u5f15\u7406\uff0c\u53ef\u4ee5\u5f97\u5230\uff1a \\[dG = (\\mu - \\frac{ 1 }{ 2 } \\sigma^2)~dt + \\sigma~dz\\] \u56e0\u6b64\u80a1\u7968\u4ef7\u683c \u53d6\u5bf9\u6570\u540e \u7684\u53d8\u5316\u91cf \\(\\ln(S_T) - \\ln(S_0)\\) \u670d\u4ece\u6b63\u6001\u5206\u5e03 \\(N((\\mu-\\frac{1}{2} \\sigma^2)T, \\sigma^2 T)\\) \u3002 \u4e3a\u4e86\u8868\u793a\u65b9\u4fbf\uff0c\u6211\u4eec\u8bb0\u4f5c \\(\\ln(S_T)\\) \u670d\u4ece \\(N(m, w^2)\\) \u3002 \u4ee4 \\(Q = \\frac{ \\ln(S) - m}{ w}\\) \uff0c\u5219 \\(Q\\) \u670d\u4ece\u6807\u51c6\u6b63\u6001\u5206\u5e03 \\(N(0,1)\\) \u3002\u5e76\u6709 \\(S = e^{Qw + m}\\) \u3002 \u6211\u4eec\u53ef\u4ee5\u5c06 payoff \u671f\u671b\u6539\u5199\u4e3a\uff1a \\[E( \\max(S-K, 0)) = \\int_{(\\ln(K)-m)/w}^{\\infty}(e^{Qw + m}-K)h(Q)~dQ\\] \u5206\u4e3a\u4e24\u90e8\u5206\uff1a \\[E(\\max(S-K, 0)) = \\int_{(\\ln(K)-m)/w}^{\\infty}e^{Qw + m}h(Q)~dQ - K\\int_{(\\ln(K)-m)/w}^{\\infty}h(Q)~dQ\\] \u5176\u4e2d \\(h(Q)\\) \u4e3a\u6807\u51c6\u6b63\u6001\u5206\u5e03\u5bc6\u5ea6\u51fd\u6570\uff1a \\[h(Q) = \\frac{ 1 }{ \\sqrt{ 2\\pi} } e^{ -\\frac{ Q^2 }{ 2 } }\\] \u6211\u4eec\u5c06\u8be5\u5f0f\u4ee3\u5165\u7b2c\u4e00\u90e8\u5206\uff0c\u5f97\u5230\uff1a \\[\\int_{(\\ln(K)-m)/w}^{\\infty}e^{Qw + m}h(Q)~dQ = e^{m+\\frac{ w^2 }{ 2 }} \\int_{(\\ln(K)-m)/w}^{\\infty} h(Q-w)~dQ\\] \u5047\u8bbe \\(\\Phi(x)\\) \u8868\u793a\u6807\u51c6\u6b63\u6001\u5206\u5e03\u53d8\u91cf\u5c0f\u4e8e \\(x\\) \u7684\u6982\u7387\uff0c\u5219\uff1a \\[\\int_{(\\ln(K)-m)/w}^{\\infty} h(Q-w)~dQ = 1-\\Phi(\\frac{ \\ln(K) - m}{w} - w) = \\Phi(w - \\frac{\\ln(K) - m}{w} )\\] \u540c\u7406\uff0c\u5bf9\u4e8e\u7b2c\u4e8c\u90e8\u5206\uff0c\u6709\uff1a \\[\\int_{ (\\ln(K)-m)/w}^{ \\infty}h(Q)~dQ = \\Phi(-\\frac{ \\ln(K) - m}{ w})\\] \u5176\u4e2d\uff1a \\[m = \\ln(S_0) + (\\mu - \\frac{1}{2} \\sigma^2)T\\] \\[w = \\sigma \\sqrt{T}\\] \u56e0\u6b64\u5f97\u51fa\u7ed3\u8bba\uff1a \\[E(\\max(S-K, 0)) = S_0 e^{\\mu T}\\Phi(d_1) - K\\Phi(d_2)\\] \u5176\u4e2d\uff1a \\[d_1 = \\frac{\\ln(\\frac{S_0}{K}) + (\\mu + \\frac{1}{2} \\sigma^2)T}{\\sigma \\sqrt{T}}\\] \\[d_2 = d_1 - \\sigma \\sqrt{T}\\] 14.8.2 \u5e94\u7528\u98ce\u9669\u4e2d\u6027\u5047\u8bbe \u6211\u4eec\u5728 14.7 \u4e2d\u5df2\u7ecf\u8bc1\u660e\u4e86\u53ef\u4ee5\u4f7f\u7528\u98ce\u9669\u4e2d\u6027\u5b9a\u4ef7\u3002\u90a3\u4e48\u671f\u671b\u6536\u76ca \\(\\mu\\) \u548c\u8d34\u73b0\u7387\u90fd\u7b49\u4e8e\u65e0\u98ce\u9669\u5229\u7387 \\(r\\) \u3002\u4ee3\u5165 14.8.1 \u5f97\u51fa\u7684 payoff\uff0c\u8d34\u73b0\u540e\u5f97\u51fa\u8be5\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u4ef7\u683c\uff1a \\[c = S_0 \\Phi(d_1) - Ke^{-rT}\\Phi(d_2)\\] \u5176\u4e2d\uff1a \\[ d_1 = \\frac{ \\ln(\\frac{S_0}{K} ) + (r + \\frac{1}{2}\\sigma^2)T}{\\sigma \\sqrt{T}} \\] \\[d_2 = d_1 - \\sigma \\sqrt{T} = \\frac{\\ln(\\frac{S_0}{K})+(r - \\frac{1}{2}\\sigma^2)T}{\\sigma \\sqrt{T}}\\] \u5229\u7528 put-call-parity\uff1a \\[c + Ke^{-rT} = p + S_0\\] \u53ef\u4ee5\u7b97\u51fa\u5bf9\u5e94\u7684\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\u7684\u4ef7\u683c\uff1a \\[p = Ke^{-rT}\\Phi(-d_2) - S_0 \\Phi(-d_1)\\] \u4f8b 1 \u67d0\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\u6267\u884c\u4ef7\u683c\u4e3a 50$\uff0c\u671f\u9650\u4e3a 3 \u4e2a\u6708\u3002\u6807\u7684\u80a1\u7968\u5f53\u524d\u4ef7\u683c\u4e3a 50$\uff0c\u6ce2\u52a8\u7387\u4e3a 30%\u6bcf\u5e74\u3002\u65e0\u98ce\u9669\u5229\u7387\u4e3a 10% \u6bcf\u5e74\u3002\u8ba1\u7b97\u8be5\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\u7684\u4ef7\u683c\u3002 \u5982\u679c\u5728 2 \u4e2a\u6708\u540e\u5c06\u6d3e\u53d1 1.5$ \u7684\u80a1\u606f\uff0c\u7ed3\u679c\u4f1a\u5982\u4f55\u53d8\u5316\uff1f \u5c06 \\(K = 50\\) \uff0c \\(S_0 = 50\\) \uff0c \\(r = 0.1\\) \uff0c \\(\\sigma = 0.3\\) \uff0c \\(T=0.25\\) \u4ee3\u5165 BSM \u516c\u5f0f\u3002\u53ef\u4ee5\u5f97\u5230\uff1a \\[ p = 50 \\times e^{- 0.1 \\times 0.25}\\Phi(-d_2) - 50\\Phi(-d_1)\\] \u5176\u4e2d\uff1a \\[d_1 = \\frac{ \\ln(\\frac{50}{50}) + (0.1 + \\frac{ 1 }{ 2 } \\times 0.3^2)\\times0.25 }{ 0.3 \\times \\sqrt{0.25} } = \\frac{ 29 }{120}\\] \\[d_2 = d_1 - \\sigma \\sqrt{T} = \\frac{11} {120}\\] \u6709 \\(\\Phi(-d_1) = 0.4052\\) \uff0c \\(\\Phi(-d_2) = 0.4641\\) \u3002 \u56e0\u6b64 \\(p = 2.372\\) \u3002 \u5982\u679c\u4e24\u4e2a\u6708\u540e\u4f1a\u6d3e\u53d1\u80a1\u606f\uff0c\u8bf4\u660e\u73b0\u5728\u7684\u80a1\u7968\u4ef7\u683c\u4e2d\u5305\u542b\u4e86\u80a1\u606f\u8d34\u73b0\u540e\u7684\u4ef7\u503c\u3002\u5728\u5e94\u7528 BSM \u516c\u5f0f\u4e4b\u524d\uff0c\u6211\u4eec\u9700\u8981\u5148\u5c06\u5176\u53bb\u6389\u3002\u56e0\u6b64\uff1a \\[S = 50 - 1.5e^{-2/12 \\times 0.1} = 48.5248\\] \u518d\u6309\u7167\u4ee5\u4e0a\u7684\u65b9\u6cd5\u8ba1\u7b97\uff0c\u5f97\u5230 \\(d_1 = 0.042\\) \\(d_2 = -0.108\\) \u3002 \\[p = 50 \\times e^{- 0.1 \\times 0.25}\\Phi(-d_2) - 48.5248\\Phi(-d_1) = 3.033\\] \u8fd9\u7b26\u5408\u6211\u4eec \u4e4b\u524d\u7684\u7ed3\u8bba \uff0c\u5bf9\u4e8e\u6d3e\u53d1\u80a1\u606f\u7684\u80a1\u7968\uff0c\u770b\u8dcc\u671f\u6743\u4ef7\u503c\u4f1a\u5347\u9ad8 \u4f8b 2 \u80a1\u7968\u4ef7\u683c\u4e3a $40\uff0c\u671f\u671b\u56de\u62a5\u7387\u4e3a 15%\uff0c\u6ce2\u52a8\u7387\u4e3a 25%\u3002\u5219 2 \u5e74\u6536\u76ca\u7387\u7684\u6982\u7387\u5206\u5e03\u662f\u4ec0\u4e48\uff1f \u80a1\u7968\u4ef7\u683c\u53d8\u5316\u6ee1\u8db3\u5bf9\u6570\u6b63\u6001\u5206\u5e03\uff0c\u5373\uff1a \\[\\ln( \\frac{S_T}{S_0} ) \\sim N(( \\mu - \\frac{\\sigma^2}{2} )T, ~\\sigma^2 T)\\] \u5047\u8bbe\u8981\u6c42\u7684\u6536\u76ca\u7387\u4e3a \\(r\\) \uff0c\u6ee1\u8db3\uff1a \\[S_T = S_0e^{rT}\\] \u5219\u663e\u7136 \\[r = \\frac{1}{T} \\ln(\\frac{S_T}{S_0}) \\sim N(\\mu - \\frac{\\sigma^2} {2}, \\frac{\\sigma^2}{T})\\] \u56e0\u6b64\u6536\u76ca\u7387\u7684\u5206\u5e03\u4e3a \\(N(0.11875, 0.03125)\\) \u3002 \u4f8b 3 \u67d0\u80a1\u7968\u4ef7\u683c\u670d\u4ece\u51e0\u4f55\u5e03\u6717\u8fd0\u52a8\uff0c\u671f\u671b\u56de\u62a5\u7387\u4e3a 16%\uff0c\u6ce2\u52a8\u7387\u4e3a 35%\uff0c\u5f53\u524d\u4ef7\u683c\u4e3a $38\u3002 (a). \u67d0\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u6267\u884c\u4ef7\u683c\u4e3a $40\uff0c\u5230\u671f\u65e5\u4e3a 6 \u4e2a\u6708\u540e\uff0c\u6c42\u5b83\u884c\u6743\u7684\u6982\u7387\u3002 (b). \u4e0e(a)\u4e2d\u5bf9\u5e94\u7684\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\u7684\u884c\u6743\u6982\u7387\u662f\u591a\u5c11 \u5df2\u77e5\u80a1\u7968\u4ef7\u683c\u7b26\u5408\u51e0\u4f55\u5e03\u6717\u8fd0\u52a8\uff0c\u5373\u6ee1\u8db3\uff1a \\[\\ln(\\frac{S_T}{S_0}) \\sim N((\\mu - \\frac{\\sigma^2}{2} )T, ~\\sigma^2 T)\\] \u90a3\u4e48\u6709\uff1a \\[\\frac{ \\ln(\\frac{S_T}{S_0}) - (\\mu - \\frac{ \\sigma^2}{2})T}{\\sigma \\sqrt{T}} \\sim N(0, 1)\\] \u6c42\u884c\u6743\u6982\u7387\u5b9e\u8d28\u4e0a\u662f\u6c42 \\(S_T > K\\) \u7684\u6982\u7387\u3002\u56e0\u6b64\uff1a \\[ P(S_T > K) = 1-\\Phi(\\frac{\\ln(\\frac{K}{S_0}) - (\\mu - \\frac{\\sigma^2}{2})T}{\\sigma \\sqrt{T}}) = \\Phi(-\\frac{\\ln(\\frac{K}{S_0}) - (\\mu - \\frac{\\sigma^2}{2})T}{\\sigma \\sqrt{T}})\\] \u4ee3\u5165 \\(K = 40\\) \\(S_0 = 38\\) \\(\\mu = 0.16\\) \\(\\sigma = 0.35\\) \\(T = 0.5\\) \uff0c\u5f97\u5230\u8be5\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u884c\u6743\u6982\u7387\u4e3a \\(\\Phi(- 0.007751) = 0.496\\) \u3002 \u770b\u8dcc\u671f\u6743\u884c\u6743\u6982\u7387\u5373 \\(S_T < K\\) \u7684\u6982\u7387\uff0c\u5373 \\(1 - 0.496 = 0.504\\) \u3002 \u4f8b 4 \u8003\u8651\u4e00\u4e2a\u884d\u751f\u54c1\uff0c\u5176\u5728 \\(T\\) \u65f6\u523b payoff \u4e3a \\(S_T ^n\\) \uff0c\u5176\u4e2d \\(S_T\\) \u662f\u6807\u7684\u80a1\u7968\u5728 \\(T\\) \u65f6\u523b\u4ef7\u683c\uff0c\u670d\u4ece\u51e0\u4f55\u5e03\u6717\u8fd0\u52a8\u3002\u5b83\u5728 \\(t\\) \u65f6\u523b\u7684\u4ef7\u683c\u53ef\u4ee5\u8868\u793a\u4e3a \\(h(t,T)S^n\\) \uff0c\u5176\u4e2d \\(S\\) \u8868\u793a \\(t\\) \u65f6\u523b\u80a1\u7968\u4ef7\u683c\uff0c \\(h\\) \u662f\u5173\u4e8e \\(t\\) \u548c \\(T\\) \u7684\u51fd\u6570\u3002 (a) \u5229\u7528 BSM \u504f\u5fae\u5206\u65b9\u7a0b\u63a8\u5bfc \\(h(t, T)\\) \u7684\u5fae\u5206\u65b9\u7a0b (b) \\(h(t, T)\\) \u7684\u8fb9\u754c\u6761\u4ef6\u662f\u4ec0\u4e48 (c) \u6c42\u51fa \\(h(t, T)\\) (a) \u5c06\u4ef7\u683c\u8868\u793a\u4e3a \\(f = h(t,T)S^n\\) \u3002\u5219\u8be5\u4ef7\u683c\u6ee1\u8db3\u5fae\u5206\u65b9\u7a0b\uff1a \\[\\frac{ \\partial f}{ \\partial t} + \\frac{ \\partial f}{ \\partial S}rS + \\frac{1}{2}\\frac{ \\partial^2 f}{\\partial S^2} \\sigma^2 S^2 = rf\\] \u6211\u4eec\u53ef\u4ee5\u7b97\u51fa \\[\\frac{\\partial f}{\\partial t} = \\frac{\\partial h}{\\partial t}S^n\\] \\[\\frac{\\partial f}{\\partial S} = nhS^{n-1}\\] \\[\\frac{\\partial^2 f}{\\partial S^2} = n(n-1)hS^{n-2}\\] \u4ee3\u5165\u6709\uff1a \\[\\frac{ \\partial h}{ \\partial t} + (n-1)rh + \\frac{1}{2}n(n-1)\\sigma^2h = 0\\] (b) \\(h(t, T)\\) \u6ee1\u8db3\u8fb9\u754c\u6761\u4ef6 \\(h(t, T) |_{t=T} = 1\\) (c) \u4e0a\u5f0f\u6ee1\u8db3 \\[\\frac{h'}{h} = - (n-1)r - \\frac{1}{2}n(n-1)\\sigma^2\\] \u4ee4 \\(x = \\ln(h)\\) \uff0c\u5219\u6709\uff1a \\[x' = - (n-1)r - \\frac{ 1}{2}n(n-1)\\sigma^2 \\] \u5f97\u51fa \\[x = [- (n-1)r - \\frac{1}{2} n(n-1) \\sigma^2]t + C\\] \u5176\u4e2d \\(C\\) \u4e3a\u5e38\u6570\u3002\u518d\u6839\u636e\u8fb9\u754c\u6761\u4ef6 \\(x|_{t=T} = \\ln(1) = 0\\) \uff0c\u5f97\u51fa\uff1a \\[x = [(n-1)r + \\frac{ 1}{2}n(n-1)\\sigma^2](T-t)\\] \u56e0\u6b64\uff1a \\[h(t, T) = e^{[(n-1)r + \\frac{1}{2}n(n-1)\\sigma^2](T-t)}\\] \u4f8b 5 (a) \u8bc1\u660e\uff1a\u5728\u98ce\u9669\u4e2d\u6027\u4e16\u754c\u4e2d\uff0c\u4e00\u4e2a\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u88ab\u884c\u6743\u7684\u6982\u7387\u7b49\u4e8e \\(\\Phi(d_2)\\) \u3002 (b) \u5047\u8bbe\u4e00\u4e2a\u884d\u751f\u54c1 payoff \u4e3a $100 \u5982\u679c\u80a1\u7968\u4ef7\u683c \\(S\\) \u5927\u4e8e \\(K\\) \uff0c\u6c42\u8be5\u884d\u751f\u54c1\u7684\u4ef7\u683c\u3002 (a) \u6b27\u5f0f\u770b\u6da8\u671f\u6743\u88ab\u884c\u6743\u7684\u6982\u7387\u662f \\(P(S_T > K)\\) \u3002\u800c \\(S_T\\) \u6ee1\u8db3\uff1a \\[\\ln(S_T) \\sim N(\\ln(S_0) + (\\mu-\\frac{1}{2}\\sigma^2)T, \\sigma^2 T)\\] \u7531\u4e8e\u5bf9\u6570\u51fd\u6570\u7684\u5355\u8c03\u6027\uff0c \\(P(S_T > K) = P(\\ln(S_T) > \\ln(K))\\) \uff0c\u4e14\u5728\u98ce\u9669\u4e2d\u6027\u4e16\u754c\u4e2d\uff0c\u6709 \\(\\mu = r\\) \uff0c\u5219\uff1a \\[P(S_T > K) = 1 - \\Phi(\\frac{\\ln(K) - \\ln(S_0) - (r-\\frac{1}{2}\\sigma^2)T}{\\sigma \\sqrt{T}}) = 1 - \\Phi(-d_2) = \\Phi(d_2)\\] (b) \u5229\u7528\u4e0a\u9762\u7684\u7ed3\u8bba\uff0c\u53ef\u4ee5\u5f97\u5230\u8be5\u884d\u751f\u54c1\u6536\u76ca\u671f\u671b\u4e3a \\(100 \\Phi(d_2)\\) \uff0c\u8d34\u73b0\u540e\u7684\u5373\u4e3a\u5f53\u524d\u4ef7\u683c\uff1a \\[100e^{-rT}\\Phi(d_2)\\] \u4f8b 6 \u67d0\u94f6\u884c\u7684\u67d0\u6b3e\u7406\u8d22\u4ea7\u54c1\u4fdd\u8bc1\u6295\u8d44\u8005\u5728 6 \u4e2a\u6708\u540e\u5f97\u5230\uff1a a. 0\uff0c\u5982\u679c\u80a1\u6307\u4e0b\u8dcc b. 40% \u80a1\u6307\u6536\u76ca \u7528\u80a1\u6307\u671f\u6743\u6765\u63cf\u8ff0\u8be5\u4ea7\u54c1\u7684\u6536\u76ca\u3002 \u5047\u8bbe\u65e0\u98ce\u9669\u5229\u7387\u662f 8%\uff0c\u80a1\u606f\u662f 3%\uff0c\u6ce2\u52a8\u7387\u662f 25%\uff0c\u8fd9\u4e2a\u7406\u8d22\u4ea7\u54c1\u503c\u5f97\u4e70\u5417\uff1f \u5047\u8bbe\u76ee\u524d\u80a1\u6307\u662f \\(S_0\\) \uff0c6 \u4e2a\u6708\u540e\u80a1\u6307\u4e3a \\(S_t\\) \u3002\u6211\u4eec\u53ef\u4ee5\u77e5\u9053\u5176\u6536\u76ca\u4e3a\uff1a \\[\\max(0, 0.4(S_t - S_0))\\] \u56e0\u6b64\u5176\u5b9e\u9645\u4e0a\u662f\u76f8\u5f53\u4e8e 0.4 \u500d\u7684\u6267\u884c\u4ef7\u683c\u4e3a \\(S_0\\) \u7684\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u7684\u6536\u76ca\u3002 \u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u6267\u884c\u4ef7\u683c\u4e3a \\(S_0\\) \uff0c\u5230\u671f\u65e5\u4e3a 6 \u4e2a\u6708\u7684\u6b27\u5f0f\u671f\u6743\u7684\u4ef7\u503c\uff1a \\[c = S_0e^{-qT}\\Phi(d_1) - Ke^{-rT}\\Phi(d_2)\\] \u5176\u4e2d \\[d_1 = \\frac{\\ln(\\frac{S_0}{K})+(r - q + \\frac{1}{2}\\sigma^2)T}{\\sigma \\sqrt{T}}\\] \\[d_2 = d_1 - \\sigma \\sqrt{T}\\] \u5c06 \\(K = S_0\\) \uff0c \\(T = 0.5\\) \uff0c \\(q = 0.03\\) \uff0c \\(r = 0.08\\) \uff0c \\(\\sigma = 0.25\\) \u4ee3\u5165\uff1a \\[c = 0.0814S_0\\] \u5047\u8bbe\u6295\u8d44\u91d1\u989d\u4e3a \\(M\\) \uff0c\u8be5\u7406\u8d22\u4ea7\u54c1\u7684\u73b0\u91d1\u6d41\u76f8\u5f53\u4e8e\u5728 0 \u65f6\u523b\uff0c\u514d\u8d39\u83b7\u5f97\u4e86 \\(0.4 \\frac{M}{S_0}\\) \u4efd\u770b\u6da8\u671f\u6743\uff0c\u5176\u4ee3\u4ef7\u662f\u5269\u4f59\u7684\u8d44\u91d1\u65e0\u6cd5\u8d5a\u53d6\u65e0\u98ce\u9669\u5229\u7387\u3002\u6211\u4eec\u9700\u8981\u6bd4\u8f83\u671f\u6743\u7684\u4ef7\u683c\u4ee5\u53ca\u65e0\u98ce\u9669\u5229\u7387\u7684\u6536\u76ca\u3002 \u73b0\u5728\u6211\u4eec\u5047\u8bbe\u6709\u4e24\u4e2a portfolio A \u548c B\u3002 - A\uff1a\u5168\u989d\u8d2d\u4e70\u8be5\u7406\u8d22\u4ea7\u54c1 - B\uff1a\u8d2d\u4e70\u4e86 \\(0.4 \\frac{M}{ S_0}\\) \u4efd\u770b\u6da8\u671f\u6743\uff0c\u5269\u4f59\u8d44\u91d1\u7528\u4e8e\u8d5a\u53d6\u65e0\u98ce\u9669\u5229\u7387 \u663e\u7136 B \u8d2d\u4e70\u7684\u671f\u6743\u5177\u6709\u548c A \u5b8c\u5168\u4e00\u81f4\u7684 payoff\u3002\u6211\u4eec\u53ea\u9700\u8981\u6bd4\u8f83\u5176\u4f59\u8d44\u91d1\u3002 \u5bf9\u4e8e A\uff0c\u516d\u4e2a\u6708\u540e\u4f1a\u83b7\u5f97 \\(M\\) \u5916\u52a0 payoff\u3002 \u5bf9\u4e8e B\uff0c\u9664\u4e86\u4e0e A \u4e00\u81f4\u7684 payoff\uff0c\u8fd8\u6709\uff1a \\[(M - 0.4 \\frac{ M }{ S_0 } c)e^{rT} = 1.007 M > M\\] \u56e0\u6b64\u663e\u7136\u8be5\u7406\u8d22\u4ea7\u54c1\u4e0d\u5212\u7b97\u3002 14.4 \u8ba1\u7b97\u5386\u53f2\u6ce2\u52a8\u7387 \\(\\sigma\\) \u5728 B-S-M \u6a21\u578b\u4e2d\uff0c\u552f\u4e00\u96be\u4ee5\u786e\u5b9a\u7684\u53c2\u6570\u5c31\u662f\u6ce2\u52a8\u7387 \\(\\sigma\\) \u3002\u5728\u5b9e\u9645\u4e2d\uff0c\u4e0d\u80fd\u76f4\u63a5\u4f7f\u7528\u5386\u53f2\u6ce2\u52a8\u7387\uff0c\u4f46\u662f\u53ef\u4ee5\u4f5c\u4e3a\u91cd\u8981\u53c2\u8003\u3002\u4ee5\u4e0b\u63d0\u5230\u7684\u6ce2\u52a8\u7387\u90fd\u6307\u5386\u53f2\u6ce2\u52a8\u7387\uff0c\u800c\u975e\u5b9e\u9645\uff08\u9690\u542b\uff09\u6ce2\u52a8\u7387\u3002 \\(\\sigma\\) \u7528\u4e8e\u8861\u91cf\u80a1\u7968\u56de\u62a5\u7387\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u6211\u4eec\u5c06\u6ce2\u52a8\u7387 \\(\\sigma\\) \u5b9a\u4e49\u4e3a \u8fde\u7eed\u590d\u5229\u4e0b\u80a1\u7968 1 \u5e74\u4e2d\u56de\u62a5\u7387\u7684\u6807\u51c6\u5dee \u3002\u5b83\u4e00\u822c\u5728 15% \u5230 60% \u4e4b\u95f4\u3002 \u8fde\u7eed\u590d\u5229\u4e0b\u7684\u80a1\u7968\u56de\u62a5\u7387\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\[x = \\frac{1}{T} \\ln( \\frac{S_T}{S_0} )\\] \u6211\u4eec\u5df2\u7ecf\u5047\u8bbe\uff1a \\[\\ln(S_T)-\\ln(S_0) \\sim N( (\\mu-\\frac{1}{2}\\sigma^2)T, \\sigma^2 T)\\] \u56e0\u6b64\u56de\u62a5\u7387\u6ee1\u8db3\uff1a \\[x \\sim N(\\mu-\\frac{1}{2}\\sigma^2, \\frac{\\sigma^2}{T})\\] \u5047\u8bbe\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u4ee5\u67d0\u4e2a\u8f83\u5c0f\u91c7\u6837\u95f4\u9694\uff08\u4f8b\u5982\u6bcf\u5468\uff09 \\(\\Delta t\\) \u7684\u80a1\u7968\u56de\u62a5\u7387\u5386\u53f2\u6570\u636e\uff0c\u6211\u4eec\u53ef\u4ee5\u4f30\u8ba1\u5176\u65b9\u5dee \\(D\\) \u3002 \u5047\u8bbe\u7b2c \\(i\\) \u4e2a \\(\\Delta t\\) \u5185\u7684\u56de\u62a5\u7387\u4e3a \\(u_i\\) \uff0c\u5176\u5e73\u5747\u503c\u4e3a \\(\\overline{u}\\) \u3002\u5bf9\u4e8e\u65b9\u5dee \\(D\\) \u7684\u65e0\u504f\u4f30\u8ba1\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\[\\hat{D} = \\frac{1}{n-1}\\sum_{i=1}^n (u_i - \\overline{u})^2\\] \u4e5f\u53ef\u4ee5\u5199\u4e3a\uff1a \\[ \\hat{D} = \\frac{ 1}{n-1} [ \\sum_{i = 1}^n u_i^2 - n \\overline{u}^2] \\] \u7136\u540e\u6839\u636e\u4e0b\u5f0f\u6c42\u6ce2\u52a8\u7387\u7684\u4f30\u8ba1\uff1a \\[\\hat{\\sigma} = \\sqrt{\\hat{D}~T}\\] \u8fd9\u4e2a \\(T\\) \u8868\u793a\u4e00\u5e74\u65f6\u95f4\uff0c\u5047\u8bbe \\(\\Delta t\\) \u662f\u5468\uff0c\u90a3\u4e48 \\(T = 365/7 = 52\\) \u3002 \u4f8b 1 \u5047\u8bbe\u6211\u4eec\u89c2\u5bdf\u5230\u67d0\u4e2a\u80a1\u7968\u5728\u8fde\u7eed 15 \u4e2a\u5468\u4e94\u7684\u4ef7\u683c\u4e3a\uff1a30.2; 32.0; 31.1; 30.1; 30.2; 30.3; 30.6; 33.0; 32.9; 33.0; 33.5; 33.5; 33.7; 33.5; 33.2\u3002 (a) \u4f30\u7b97\u8be5\u80a1\u7968\u7684\u6ce2\u52a8\u7387 (b) \u8fd9\u4e2a\u6ce2\u52a8\u7387\u7684\u4f30\u8ba1\u7684\u6807\u51c6\u5dee\u662f\u591a\u5c11\uff1f # \u80a1\u7968\u4ef7\u683c( \\(S\\) ) \u76f8\u5bf9\u4ef7\u683c( \\(S_{i+1}/S_i\\) ) \u5468\u56de\u62a5\u7387( \\(u = \\ln(S_{i+1}/S_i)\\) ) 1 30.2 2 32.0 1.05960 0.05789 3 31.1 0.97188 -0.02853 4 30.1 0.96785 -0.03268 5 30.2 1.00332 0.00332 6 30.3 1.00331 0.00331 7 30.6 1.00990 0.00985 8 33.0 1.07843 0.07551 9 32.9 0.99697 -0.00303 10 33.0 1.00304 0.00303 11 33.5 1.01515 0.01504 12 33.5 1.00000 0.00000 13 33.7 1.00597 0.00595 14 33.5 0.99407 -0.00595 15 33.2 0.99104 -0.00900 (a) \u9996\u5148\u8ba1\u7b97\u5f97\u5230\uff1a \\[\\sum_{i=1}^n u_i = 0.09471\\] \\[\\sum_{i=1}^n u_i^2 = 0.01145\\] \u8ba1\u7b97\u5f97 \\[\\hat{D} = \\frac{1}{13}(0.01145 - \\frac{0.09471^2}{14}) = 0.0008315\\] \\[\\sigma = \\sqrt{0.0008315 \\times 52} = 0.208\\] (b) \u8fd9\u4e2a\u4f30\u8ba1\u672c\u8eab\u7684\u6807\u51c6\u5dee\u4e3a \\[ \\frac{ \\sigma}{ \\sqrt{2n} } = \\frac{0.208}{\\sqrt{2 \\times 14} } = 0.0393\\]","title":"The Black-Scholes-Merton model"},{"location":"trading/option/BSM/#the-black-scholes-merton-model","text":"\u5728 1970 \u5e74\u4ee3\uff0cFischer Black, Myron Scholes, Robert Merton \u63d0\u51fa\u4e86\u4e00\u4e2a\u91cd\u8981\u7684\u6b27\u5f0f\u671f\u6743\u5b9a\u4ef7\u6a21\u578b\u3002\u8fd9\u4e2a\u6a21\u578b\u57fa\u4e8e\u4ee5\u4e0b 7 \u6761\u5047\u8bbe\uff1a \u80a1\u7968\u4ef7\u683c\u7b26\u5408\u4f0a\u85e4\u8fc7\u7a0b \\(\\frac{ dS }{ S } = \\mu ~dt + \\sigma ~dz\\) \u5141\u8bb8\u5356\u7a7a\u8bc1\u5238\u5e76\u5145\u5206\u5229\u7528\u6536\u76ca \u6ca1\u6709\u4ea4\u6613\u8d39\u7528\u548c\u7a0e\uff0c\u6240\u6709\u8bc1\u5238\u5b8c\u5168\u53ef\u5206\u5272 \u5728\u671f\u6743\u671f\u9650\u5185\uff0c\u80a1\u7968\u4e0d\u652f\u4ed8\u80a1\u606f \u4e0d\u5b58\u5728\u65e0\u98ce\u9669\u5957\u5229\u673a\u4f1a \u8bc1\u5238\u4ea4\u6613\u8fde\u7eed\u8fdb\u884c \u65e0\u98ce\u9669\u5229\u7387 \\(r\\) \u662f\u5e38\u6570\u5e76\u4e14\u5bf9\u6240\u6709\u671f\u9650\u76f8\u540c \u6ce8\u610f\uff0c\u8fd9\u5176\u4e2d\u5e76\u4e0d\u5305\u542b\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u3002\u4ece\u6839\u672c\u4e0a\u8bb2\uff0c\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u53ea\u662f\u4e00\u4e2a\u6570\u5b66\u4e0a\u7684\u6c42\u89e3\u6280\u5de7\uff0c\u5373\u4f7f\u4e0d\u4f7f\u7528\u8fd9\u4e2a\u6280\u5de7\uff0c\u4e00\u6837\u53ef\u4ee5\u901a\u8fc7\u66b4\u529b\u6c42\u89e3 PDE \u5f97\u5230\u540c\u6837\u7684\u7ed3\u679c\uff08Feynman-Kac Theorem\uff09\u3002\u8fd9\u4e00\u70b9\u975e\u5e38\u91cd\u8981\uff0c\u56e0\u4e3a\u771f\u5b9e\u4e16\u754c\u660e\u663e\u4e0d\u662f\u98ce\u9669\u4e2d\u6027\u7684\uff0cBSM \u516c\u5f0f\u4e5f\u4e0d\u53ef\u80fd\u57fa\u4e8e\u8fd9\u4e48\u4e00\u4e2a\u4e0d\u9760\u8c31\u7684\u5047\u8bbe\u3002","title":"The Black-Scholes-Merton model"},{"location":"trading/option/BSM/#146-black-scholes-merton","text":"\u6839\u636e\u5047\u8bbe\uff0c\u80a1\u7968\u7684\u4ef7\u683c\u670d\u4ece\u4ee5\u4e0b\u4f0a\u85e4\u8fc7\u7a0b\uff1a \\[\\frac{ dS }{ S } = \\mu ~dt + \\sigma ~dz\\] \u6211\u4eec\u7684\u76ee\u6807\uff0c\u4e5f\u5c31\u662f\u4ee5\u8be5\u80a1\u7968\u4e3a\u6807\u7684\u7269\u7684\u770b\u6da8\u671f\u6743\u7684\u4ef7\u683c \\(C\\) \u80af\u5b9a\u662f \\(S\\) \u548c \\(t\\) \u7684\u51fd\u6570\u3002\u6839\u636e\u4f0a\u85e4\u5f15\u7406\uff0c\u5f97\u5230\uff1a \\[dC = (\\frac{ \\partial C}{ \\partial S} \\mu S + \\frac{ \\partial C}{ \\partial t} + \\frac{1}{2} \\frac{ \\partial^2 C}{ \\partial S^2} \\sigma^2 S^2)~dt + \\frac{ \\partial C}{ \\partial S}\\sigma S~dz\\] \u8fd9\u662f\u4e00\u4e2a\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff0c\u6211\u4eec\u5f88\u96be\u76f4\u63a5\u6c42\u89e3\u3002\u4e8e\u662f\u6211\u4eec\u5e0c\u671b\u5229\u7528 \\(S\\) \u548c \\(C\\) \u7684\u7ebf\u6027\u7ec4\u5408\u6d88\u53bb\u5176\u968f\u673a\u9879\u3002 \u6784\u9020\u4e00\u4e2a portfolio \\(V = Q_S S + Q_C C\\) \uff0c\u5176\u4e2d \\(Q_S\\) \u548c \\(Q_C\\) \u5206\u522b\u662f\u80a1\u7968\u548c\u770b\u6da8\u671f\u6743\u7684\u6570\u91cf\u3002\u4e3a\u4e86\u6d88\u9664\u968f\u673a\u9879 \\(dz\\) \uff0c\u6211\u4eec\u9700\u8981\uff1a \\[Q_S \\sigma S + Q_C \\frac{\\partial C}{\\partial S}\\sigma S = 0\\] \u6211\u4eec\u53ef\u4ee5\u4ee4 \\(Q_S = \\frac{\\partial C}{\\partial S}\\) \uff0c \\(Q_C = -1\\) \u3002 \u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c \u6211\u4eec\u901a\u8fc7\u8fd9\u6837\u5b9e\u9645\u6784\u9020\u4e86\u4e00\u4e2a\u65e0\u98ce\u9669\u7684 portfolio\uff0c\u540c\u65f6\uff0c\u80a1\u7968\u7684\u6570\u91cf\u4e5f\u662f Greeks \u91cc\u9762\u7684 delta\u3002 \u7531\u4e8e\u8fd9\u662f\u4e00\u4e2a\u65e0\u98ce\u9669\u7684 portfolio\uff0c\u5176\u6ce2\u52a8\u7387\u4e3a 0\uff0c\u671f\u671b\u6536\u76ca\u7b49\u4e8e\u65e0\u98ce\u9669\u5229\u7387 \\(r\\) \u3002\u56e0\u6b64\uff1a \\[dV = rVdt\\] \u5e76\u4e14 \\[dV = Q_S~dS +Q_C~dC\\] \u5e26\u5165\u5f97\uff1a \\[\\frac{\\partial C}{\\partial S} rS + \\frac{\\partial C}{\\partial t} + \\frac{1}{2}\\frac{\\partial^2 C}{\\partial S^2} \\sigma^2 S^2 = rC\\] \u8fd9\u5c31\u662f Black-Scholes-Merton \u5fae\u5206\u65b9\u7a0b \u3002\u8fd9\u4e2a\u65b9\u7a0b\u7684\u7cbe\u5999\u4e4b\u5904\u5728\u4e8e\u6211\u4eec\u6d88\u6389\u4e86\u968f\u673a\u9879\u548c\u671f\u671b\u6536\u76ca\u7387 \\(\\mu\\) \u8fd9\u4e24\u4e2a\u975e\u5e38\u590d\u6742\u7684\u90e8\u5206\u3002 \u8fd9\u4e2a\u65b9\u7a0b\u6709\u5f88\u591a\u89e3\uff0c\u5bf9\u5e94\u4e8e\u5404\u79cd\u884d\u751f\u54c1\u3002\u5047\u8bbe\u4e00\u4e2a\u884d\u751f\u54c1\u4e0d\u6ee1\u8db3\u8fd9\u4e2a\u5fae\u5206\u65b9\u7a0b\uff0c\u4f8b\u5982 \\(e^S\\) \uff0c\u5219\u8be5\u884d\u751f\u54c1\u4e0d\u53ef\u80fd\u5b58\u5728\uff0c\u56e0\u4e3a\u4e00\u5b9a\u5b58\u5728\u5957\u5229\u673a\u4f1a\u3002","title":"14.6 Black-Scholes-Merton \u5fae\u5206\u65b9\u7a0b"},{"location":"trading/option/BSM/#147","text":"\u6211\u4eec\u6ce8\u610f\u5230\uff0c\u63a8\u5bfc\u51fa\u7684 Black-Scholes-Merton \u5fae\u5206\u65b9\u7a0b\u4e0d\u542b\u671f\u671b\u6536\u76ca \\(\\mu\\) \uff0c\u8fd9\u4e5f\u4ece\u8bc1\u660e\u4e86\u6211\u4eec\u5728\u7528\u4e8c\u53c9\u6811\u8fdb\u884c\u5b9a\u4ef7\u65f6\u7684\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u7684\u6b63\u786e\u6027\u3002\u56e0\u4e3a\u5b83\u4e0e\u6295\u8d44\u4eba\u7684\u98ce\u9669\u504f\u597d\u65e0\u5173\u3002\u6211\u4eec\u5c31\u53ef\u4ee5\u653e\u5fc3\u4f7f\u7528\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u7b80\u5316\u8ba1\u7b97\u3002 \u5047\u8bbe\u4ece\u6807\u7684\u7269\u83b7\u5f97\u7684\u671f\u671b\u6536\u76ca\u5c31\u662f\u65e0\u98ce\u9669\u5229\u7387 \\(r\\) \u8ba1\u7b97\u884d\u751f\u54c1\u7684\u671f\u671b\u7684 payoff \u5c06\u671f\u671b\u7684 payoff \u6298\u73b0\uff0c\u6298\u73b0\u7387\u4e5f\u7b49\u4e8e\u65e0\u98ce\u9669\u5229\u7387 \\(r\\)","title":"14.7 \u98ce\u9669\u4e2d\u6027\u5b9a\u4ef7"},{"location":"trading/option/BSM/#_1","text":"\u5047\u8bbe\u4e00\u4e2a\u8fdc\u671f\u5408\u7ea6\u591a\u5934\u5230\u671f\u65e5\u4e3a \\(T\\) \uff0c\u6267\u884c\u4ef7\u683c\u4e3a \\(K\\) \uff0c\u76ee\u524d\u73b0\u8d27\u4ef7\u683c\u662f \\(S_0\\) \uff0c\u65e0\u98ce\u9669\u5229\u7387\u4e3a \\(r\\) \uff0c\u5219\u8fdc\u671f\u5408\u7ea6\u4ef7\u683c\u4e3a\uff1f \u5047\u8bbe\u5230\u671f\u65e5\u6807\u7684\u7269\u4ef7\u683c\u4e3a \\(S_T\\) \uff0c\u5219\u5229\u7528\u4ee5\u4e0a\u4e09\u4e2a\u6b65\u9aa4\uff0c\u53ef\u4ee5\u5f97\u5230\uff1a \\[f = e^{-rT}~E(S_T- K) = e^{-rT}E(S_T) - Ke^{-rT}\\] \u7531\u4e8e\u6211\u4eec\u7684\u671f\u671b\u6536\u76ca\u7387\u4e3a\u65e0\u98ce\u9669\u5229\u7387 \\(r\\) \uff0c\u5219\u6709 \\(E(S_T) = S_0 e^{rT}\\) \uff0c\u5e26\u5165\u53ef\u4ee5\u5f97\u5230\uff1a \\[f = S_0 - Ke^{-rT}\\] \u8fd9\u7b26\u5408\u6211\u4eec\u5229\u7528\u65e0\u5957\u5229\u5047\u8bbe\u5f97\u51fa\u7684\u7ed3\u8bba\u3002","title":"\u4f8b"},{"location":"trading/option/BSM/#148-black-scholes-merton","text":"\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u5c06\u5229\u7528\u98ce\u9669\u4e2d\u6027\u5b9a\u4ef7\u539f\u7406\u6765\u63a8\u5bfc BSM \u5b9a\u4ef7\u516c\u5f0f\u3002\u8fd9\u6837\u53ef\u4ee5\u907f\u514d\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u590d\u6742\u5ea6\u3002","title":"14.8 Black-Scholes-Merton \u5b9a\u4ef7\u516c\u5f0f"},{"location":"trading/option/BSM/#1481-payoff","text":"\u4ee5\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u4e3a\u4f8b\uff0c\u5176\u5728\u5230\u671f\u65e5 \\(T\\) \u7684 payoff \u4e3a \\(f =\\max(S-K, 0)\\) \u3002\u5b83\u7684\u4ef7\u683c\u5e94\u8be5\u4e3a payoff \u7684\u671f\u671b\u6298\u73b0\u540e\u7684\u503c\u3002\u56e0\u6b64\u95ee\u9898\u8f6c\u5316\u4e3a\u6c42\uff1a \\[E(\\max(S-K, 0)) = \\int_{K}^{\\infty}(S-K)g(S)~dS\\] \u5176\u4e2d \\(g(S)\\) \u4ee3\u8868\u80a1\u7968\u4ef7\u683c\u4e3a \\(S\\) \u7684\u6982\u7387\u3002\u90a3\u4e48\u5982\u4f55\u5f97\u5230 \\(g(S)\\) \u5462\uff1f \u6211\u4eec\u5df2\u7ecf\u5047\u8bbe \\(S\\) \u670d\u4ece\u4f0a\u85e4\u8fc7\u7a0b\uff1a \\[\\frac{ dS }{ S } = \\mu ~dt + \\sigma ~dz\\] \u4ee4 \\(G = \\ln(S)\\) \uff0c\u7531\u4f0a\u85e4\u5f15\u7406\uff0c\u53ef\u4ee5\u5f97\u5230\uff1a \\[dG = (\\mu - \\frac{ 1 }{ 2 } \\sigma^2)~dt + \\sigma~dz\\] \u56e0\u6b64\u80a1\u7968\u4ef7\u683c \u53d6\u5bf9\u6570\u540e \u7684\u53d8\u5316\u91cf \\(\\ln(S_T) - \\ln(S_0)\\) \u670d\u4ece\u6b63\u6001\u5206\u5e03 \\(N((\\mu-\\frac{1}{2} \\sigma^2)T, \\sigma^2 T)\\) \u3002 \u4e3a\u4e86\u8868\u793a\u65b9\u4fbf\uff0c\u6211\u4eec\u8bb0\u4f5c \\(\\ln(S_T)\\) \u670d\u4ece \\(N(m, w^2)\\) \u3002 \u4ee4 \\(Q = \\frac{ \\ln(S) - m}{ w}\\) \uff0c\u5219 \\(Q\\) \u670d\u4ece\u6807\u51c6\u6b63\u6001\u5206\u5e03 \\(N(0,1)\\) \u3002\u5e76\u6709 \\(S = e^{Qw + m}\\) \u3002 \u6211\u4eec\u53ef\u4ee5\u5c06 payoff \u671f\u671b\u6539\u5199\u4e3a\uff1a \\[E( \\max(S-K, 0)) = \\int_{(\\ln(K)-m)/w}^{\\infty}(e^{Qw + m}-K)h(Q)~dQ\\] \u5206\u4e3a\u4e24\u90e8\u5206\uff1a \\[E(\\max(S-K, 0)) = \\int_{(\\ln(K)-m)/w}^{\\infty}e^{Qw + m}h(Q)~dQ - K\\int_{(\\ln(K)-m)/w}^{\\infty}h(Q)~dQ\\] \u5176\u4e2d \\(h(Q)\\) \u4e3a\u6807\u51c6\u6b63\u6001\u5206\u5e03\u5bc6\u5ea6\u51fd\u6570\uff1a \\[h(Q) = \\frac{ 1 }{ \\sqrt{ 2\\pi} } e^{ -\\frac{ Q^2 }{ 2 } }\\] \u6211\u4eec\u5c06\u8be5\u5f0f\u4ee3\u5165\u7b2c\u4e00\u90e8\u5206\uff0c\u5f97\u5230\uff1a \\[\\int_{(\\ln(K)-m)/w}^{\\infty}e^{Qw + m}h(Q)~dQ = e^{m+\\frac{ w^2 }{ 2 }} \\int_{(\\ln(K)-m)/w}^{\\infty} h(Q-w)~dQ\\] \u5047\u8bbe \\(\\Phi(x)\\) \u8868\u793a\u6807\u51c6\u6b63\u6001\u5206\u5e03\u53d8\u91cf\u5c0f\u4e8e \\(x\\) \u7684\u6982\u7387\uff0c\u5219\uff1a \\[\\int_{(\\ln(K)-m)/w}^{\\infty} h(Q-w)~dQ = 1-\\Phi(\\frac{ \\ln(K) - m}{w} - w) = \\Phi(w - \\frac{\\ln(K) - m}{w} )\\] \u540c\u7406\uff0c\u5bf9\u4e8e\u7b2c\u4e8c\u90e8\u5206\uff0c\u6709\uff1a \\[\\int_{ (\\ln(K)-m)/w}^{ \\infty}h(Q)~dQ = \\Phi(-\\frac{ \\ln(K) - m}{ w})\\] \u5176\u4e2d\uff1a \\[m = \\ln(S_0) + (\\mu - \\frac{1}{2} \\sigma^2)T\\] \\[w = \\sigma \\sqrt{T}\\] \u56e0\u6b64\u5f97\u51fa\u7ed3\u8bba\uff1a \\[E(\\max(S-K, 0)) = S_0 e^{\\mu T}\\Phi(d_1) - K\\Phi(d_2)\\] \u5176\u4e2d\uff1a \\[d_1 = \\frac{\\ln(\\frac{S_0}{K}) + (\\mu + \\frac{1}{2} \\sigma^2)T}{\\sigma \\sqrt{T}}\\] \\[d_2 = d_1 - \\sigma \\sqrt{T}\\]","title":"14.8.1 \u8ba1\u7b97 payoff \u671f\u671b"},{"location":"trading/option/BSM/#1482","text":"\u6211\u4eec\u5728 14.7 \u4e2d\u5df2\u7ecf\u8bc1\u660e\u4e86\u53ef\u4ee5\u4f7f\u7528\u98ce\u9669\u4e2d\u6027\u5b9a\u4ef7\u3002\u90a3\u4e48\u671f\u671b\u6536\u76ca \\(\\mu\\) \u548c\u8d34\u73b0\u7387\u90fd\u7b49\u4e8e\u65e0\u98ce\u9669\u5229\u7387 \\(r\\) \u3002\u4ee3\u5165 14.8.1 \u5f97\u51fa\u7684 payoff\uff0c\u8d34\u73b0\u540e\u5f97\u51fa\u8be5\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u4ef7\u683c\uff1a \\[c = S_0 \\Phi(d_1) - Ke^{-rT}\\Phi(d_2)\\] \u5176\u4e2d\uff1a \\[ d_1 = \\frac{ \\ln(\\frac{S_0}{K} ) + (r + \\frac{1}{2}\\sigma^2)T}{\\sigma \\sqrt{T}} \\] \\[d_2 = d_1 - \\sigma \\sqrt{T} = \\frac{\\ln(\\frac{S_0}{K})+(r - \\frac{1}{2}\\sigma^2)T}{\\sigma \\sqrt{T}}\\] \u5229\u7528 put-call-parity\uff1a \\[c + Ke^{-rT} = p + S_0\\] \u53ef\u4ee5\u7b97\u51fa\u5bf9\u5e94\u7684\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\u7684\u4ef7\u683c\uff1a \\[p = Ke^{-rT}\\Phi(-d_2) - S_0 \\Phi(-d_1)\\]","title":"14.8.2 \u5e94\u7528\u98ce\u9669\u4e2d\u6027\u5047\u8bbe"},{"location":"trading/option/BSM/#1","text":"\u67d0\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\u6267\u884c\u4ef7\u683c\u4e3a 50$\uff0c\u671f\u9650\u4e3a 3 \u4e2a\u6708\u3002\u6807\u7684\u80a1\u7968\u5f53\u524d\u4ef7\u683c\u4e3a 50$\uff0c\u6ce2\u52a8\u7387\u4e3a 30%\u6bcf\u5e74\u3002\u65e0\u98ce\u9669\u5229\u7387\u4e3a 10% \u6bcf\u5e74\u3002\u8ba1\u7b97\u8be5\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\u7684\u4ef7\u683c\u3002 \u5982\u679c\u5728 2 \u4e2a\u6708\u540e\u5c06\u6d3e\u53d1 1.5$ \u7684\u80a1\u606f\uff0c\u7ed3\u679c\u4f1a\u5982\u4f55\u53d8\u5316\uff1f \u5c06 \\(K = 50\\) \uff0c \\(S_0 = 50\\) \uff0c \\(r = 0.1\\) \uff0c \\(\\sigma = 0.3\\) \uff0c \\(T=0.25\\) \u4ee3\u5165 BSM \u516c\u5f0f\u3002\u53ef\u4ee5\u5f97\u5230\uff1a \\[ p = 50 \\times e^{- 0.1 \\times 0.25}\\Phi(-d_2) - 50\\Phi(-d_1)\\] \u5176\u4e2d\uff1a \\[d_1 = \\frac{ \\ln(\\frac{50}{50}) + (0.1 + \\frac{ 1 }{ 2 } \\times 0.3^2)\\times0.25 }{ 0.3 \\times \\sqrt{0.25} } = \\frac{ 29 }{120}\\] \\[d_2 = d_1 - \\sigma \\sqrt{T} = \\frac{11} {120}\\] \u6709 \\(\\Phi(-d_1) = 0.4052\\) \uff0c \\(\\Phi(-d_2) = 0.4641\\) \u3002 \u56e0\u6b64 \\(p = 2.372\\) \u3002 \u5982\u679c\u4e24\u4e2a\u6708\u540e\u4f1a\u6d3e\u53d1\u80a1\u606f\uff0c\u8bf4\u660e\u73b0\u5728\u7684\u80a1\u7968\u4ef7\u683c\u4e2d\u5305\u542b\u4e86\u80a1\u606f\u8d34\u73b0\u540e\u7684\u4ef7\u503c\u3002\u5728\u5e94\u7528 BSM \u516c\u5f0f\u4e4b\u524d\uff0c\u6211\u4eec\u9700\u8981\u5148\u5c06\u5176\u53bb\u6389\u3002\u56e0\u6b64\uff1a \\[S = 50 - 1.5e^{-2/12 \\times 0.1} = 48.5248\\] \u518d\u6309\u7167\u4ee5\u4e0a\u7684\u65b9\u6cd5\u8ba1\u7b97\uff0c\u5f97\u5230 \\(d_1 = 0.042\\) \\(d_2 = -0.108\\) \u3002 \\[p = 50 \\times e^{- 0.1 \\times 0.25}\\Phi(-d_2) - 48.5248\\Phi(-d_1) = 3.033\\] \u8fd9\u7b26\u5408\u6211\u4eec \u4e4b\u524d\u7684\u7ed3\u8bba \uff0c\u5bf9\u4e8e\u6d3e\u53d1\u80a1\u606f\u7684\u80a1\u7968\uff0c\u770b\u8dcc\u671f\u6743\u4ef7\u503c\u4f1a\u5347\u9ad8","title":"\u4f8b 1"},{"location":"trading/option/BSM/#2","text":"\u80a1\u7968\u4ef7\u683c\u4e3a $40\uff0c\u671f\u671b\u56de\u62a5\u7387\u4e3a 15%\uff0c\u6ce2\u52a8\u7387\u4e3a 25%\u3002\u5219 2 \u5e74\u6536\u76ca\u7387\u7684\u6982\u7387\u5206\u5e03\u662f\u4ec0\u4e48\uff1f \u80a1\u7968\u4ef7\u683c\u53d8\u5316\u6ee1\u8db3\u5bf9\u6570\u6b63\u6001\u5206\u5e03\uff0c\u5373\uff1a \\[\\ln( \\frac{S_T}{S_0} ) \\sim N(( \\mu - \\frac{\\sigma^2}{2} )T, ~\\sigma^2 T)\\] \u5047\u8bbe\u8981\u6c42\u7684\u6536\u76ca\u7387\u4e3a \\(r\\) \uff0c\u6ee1\u8db3\uff1a \\[S_T = S_0e^{rT}\\] \u5219\u663e\u7136 \\[r = \\frac{1}{T} \\ln(\\frac{S_T}{S_0}) \\sim N(\\mu - \\frac{\\sigma^2} {2}, \\frac{\\sigma^2}{T})\\] \u56e0\u6b64\u6536\u76ca\u7387\u7684\u5206\u5e03\u4e3a \\(N(0.11875, 0.03125)\\) \u3002","title":"\u4f8b 2"},{"location":"trading/option/BSM/#3","text":"\u67d0\u80a1\u7968\u4ef7\u683c\u670d\u4ece\u51e0\u4f55\u5e03\u6717\u8fd0\u52a8\uff0c\u671f\u671b\u56de\u62a5\u7387\u4e3a 16%\uff0c\u6ce2\u52a8\u7387\u4e3a 35%\uff0c\u5f53\u524d\u4ef7\u683c\u4e3a $38\u3002 (a). \u67d0\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u6267\u884c\u4ef7\u683c\u4e3a $40\uff0c\u5230\u671f\u65e5\u4e3a 6 \u4e2a\u6708\u540e\uff0c\u6c42\u5b83\u884c\u6743\u7684\u6982\u7387\u3002 (b). \u4e0e(a)\u4e2d\u5bf9\u5e94\u7684\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\u7684\u884c\u6743\u6982\u7387\u662f\u591a\u5c11 \u5df2\u77e5\u80a1\u7968\u4ef7\u683c\u7b26\u5408\u51e0\u4f55\u5e03\u6717\u8fd0\u52a8\uff0c\u5373\u6ee1\u8db3\uff1a \\[\\ln(\\frac{S_T}{S_0}) \\sim N((\\mu - \\frac{\\sigma^2}{2} )T, ~\\sigma^2 T)\\] \u90a3\u4e48\u6709\uff1a \\[\\frac{ \\ln(\\frac{S_T}{S_0}) - (\\mu - \\frac{ \\sigma^2}{2})T}{\\sigma \\sqrt{T}} \\sim N(0, 1)\\] \u6c42\u884c\u6743\u6982\u7387\u5b9e\u8d28\u4e0a\u662f\u6c42 \\(S_T > K\\) \u7684\u6982\u7387\u3002\u56e0\u6b64\uff1a \\[ P(S_T > K) = 1-\\Phi(\\frac{\\ln(\\frac{K}{S_0}) - (\\mu - \\frac{\\sigma^2}{2})T}{\\sigma \\sqrt{T}}) = \\Phi(-\\frac{\\ln(\\frac{K}{S_0}) - (\\mu - \\frac{\\sigma^2}{2})T}{\\sigma \\sqrt{T}})\\] \u4ee3\u5165 \\(K = 40\\) \\(S_0 = 38\\) \\(\\mu = 0.16\\) \\(\\sigma = 0.35\\) \\(T = 0.5\\) \uff0c\u5f97\u5230\u8be5\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u884c\u6743\u6982\u7387\u4e3a \\(\\Phi(- 0.007751) = 0.496\\) \u3002 \u770b\u8dcc\u671f\u6743\u884c\u6743\u6982\u7387\u5373 \\(S_T < K\\) \u7684\u6982\u7387\uff0c\u5373 \\(1 - 0.496 = 0.504\\) \u3002","title":"\u4f8b 3"},{"location":"trading/option/BSM/#4","text":"\u8003\u8651\u4e00\u4e2a\u884d\u751f\u54c1\uff0c\u5176\u5728 \\(T\\) \u65f6\u523b payoff \u4e3a \\(S_T ^n\\) \uff0c\u5176\u4e2d \\(S_T\\) \u662f\u6807\u7684\u80a1\u7968\u5728 \\(T\\) \u65f6\u523b\u4ef7\u683c\uff0c\u670d\u4ece\u51e0\u4f55\u5e03\u6717\u8fd0\u52a8\u3002\u5b83\u5728 \\(t\\) \u65f6\u523b\u7684\u4ef7\u683c\u53ef\u4ee5\u8868\u793a\u4e3a \\(h(t,T)S^n\\) \uff0c\u5176\u4e2d \\(S\\) \u8868\u793a \\(t\\) \u65f6\u523b\u80a1\u7968\u4ef7\u683c\uff0c \\(h\\) \u662f\u5173\u4e8e \\(t\\) \u548c \\(T\\) \u7684\u51fd\u6570\u3002 (a) \u5229\u7528 BSM \u504f\u5fae\u5206\u65b9\u7a0b\u63a8\u5bfc \\(h(t, T)\\) \u7684\u5fae\u5206\u65b9\u7a0b (b) \\(h(t, T)\\) \u7684\u8fb9\u754c\u6761\u4ef6\u662f\u4ec0\u4e48 (c) \u6c42\u51fa \\(h(t, T)\\) (a) \u5c06\u4ef7\u683c\u8868\u793a\u4e3a \\(f = h(t,T)S^n\\) \u3002\u5219\u8be5\u4ef7\u683c\u6ee1\u8db3\u5fae\u5206\u65b9\u7a0b\uff1a \\[\\frac{ \\partial f}{ \\partial t} + \\frac{ \\partial f}{ \\partial S}rS + \\frac{1}{2}\\frac{ \\partial^2 f}{\\partial S^2} \\sigma^2 S^2 = rf\\] \u6211\u4eec\u53ef\u4ee5\u7b97\u51fa \\[\\frac{\\partial f}{\\partial t} = \\frac{\\partial h}{\\partial t}S^n\\] \\[\\frac{\\partial f}{\\partial S} = nhS^{n-1}\\] \\[\\frac{\\partial^2 f}{\\partial S^2} = n(n-1)hS^{n-2}\\] \u4ee3\u5165\u6709\uff1a \\[\\frac{ \\partial h}{ \\partial t} + (n-1)rh + \\frac{1}{2}n(n-1)\\sigma^2h = 0\\] (b) \\(h(t, T)\\) \u6ee1\u8db3\u8fb9\u754c\u6761\u4ef6 \\(h(t, T) |_{t=T} = 1\\) (c) \u4e0a\u5f0f\u6ee1\u8db3 \\[\\frac{h'}{h} = - (n-1)r - \\frac{1}{2}n(n-1)\\sigma^2\\] \u4ee4 \\(x = \\ln(h)\\) \uff0c\u5219\u6709\uff1a \\[x' = - (n-1)r - \\frac{ 1}{2}n(n-1)\\sigma^2 \\] \u5f97\u51fa \\[x = [- (n-1)r - \\frac{1}{2} n(n-1) \\sigma^2]t + C\\] \u5176\u4e2d \\(C\\) \u4e3a\u5e38\u6570\u3002\u518d\u6839\u636e\u8fb9\u754c\u6761\u4ef6 \\(x|_{t=T} = \\ln(1) = 0\\) \uff0c\u5f97\u51fa\uff1a \\[x = [(n-1)r + \\frac{ 1}{2}n(n-1)\\sigma^2](T-t)\\] \u56e0\u6b64\uff1a \\[h(t, T) = e^{[(n-1)r + \\frac{1}{2}n(n-1)\\sigma^2](T-t)}\\]","title":"\u4f8b 4"},{"location":"trading/option/BSM/#5","text":"(a) \u8bc1\u660e\uff1a\u5728\u98ce\u9669\u4e2d\u6027\u4e16\u754c\u4e2d\uff0c\u4e00\u4e2a\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u88ab\u884c\u6743\u7684\u6982\u7387\u7b49\u4e8e \\(\\Phi(d_2)\\) \u3002 (b) \u5047\u8bbe\u4e00\u4e2a\u884d\u751f\u54c1 payoff \u4e3a $100 \u5982\u679c\u80a1\u7968\u4ef7\u683c \\(S\\) \u5927\u4e8e \\(K\\) \uff0c\u6c42\u8be5\u884d\u751f\u54c1\u7684\u4ef7\u683c\u3002 (a) \u6b27\u5f0f\u770b\u6da8\u671f\u6743\u88ab\u884c\u6743\u7684\u6982\u7387\u662f \\(P(S_T > K)\\) \u3002\u800c \\(S_T\\) \u6ee1\u8db3\uff1a \\[\\ln(S_T) \\sim N(\\ln(S_0) + (\\mu-\\frac{1}{2}\\sigma^2)T, \\sigma^2 T)\\] \u7531\u4e8e\u5bf9\u6570\u51fd\u6570\u7684\u5355\u8c03\u6027\uff0c \\(P(S_T > K) = P(\\ln(S_T) > \\ln(K))\\) \uff0c\u4e14\u5728\u98ce\u9669\u4e2d\u6027\u4e16\u754c\u4e2d\uff0c\u6709 \\(\\mu = r\\) \uff0c\u5219\uff1a \\[P(S_T > K) = 1 - \\Phi(\\frac{\\ln(K) - \\ln(S_0) - (r-\\frac{1}{2}\\sigma^2)T}{\\sigma \\sqrt{T}}) = 1 - \\Phi(-d_2) = \\Phi(d_2)\\] (b) \u5229\u7528\u4e0a\u9762\u7684\u7ed3\u8bba\uff0c\u53ef\u4ee5\u5f97\u5230\u8be5\u884d\u751f\u54c1\u6536\u76ca\u671f\u671b\u4e3a \\(100 \\Phi(d_2)\\) \uff0c\u8d34\u73b0\u540e\u7684\u5373\u4e3a\u5f53\u524d\u4ef7\u683c\uff1a \\[100e^{-rT}\\Phi(d_2)\\]","title":"\u4f8b 5"},{"location":"trading/option/BSM/#6","text":"\u67d0\u94f6\u884c\u7684\u67d0\u6b3e\u7406\u8d22\u4ea7\u54c1\u4fdd\u8bc1\u6295\u8d44\u8005\u5728 6 \u4e2a\u6708\u540e\u5f97\u5230\uff1a a. 0\uff0c\u5982\u679c\u80a1\u6307\u4e0b\u8dcc b. 40% \u80a1\u6307\u6536\u76ca \u7528\u80a1\u6307\u671f\u6743\u6765\u63cf\u8ff0\u8be5\u4ea7\u54c1\u7684\u6536\u76ca\u3002 \u5047\u8bbe\u65e0\u98ce\u9669\u5229\u7387\u662f 8%\uff0c\u80a1\u606f\u662f 3%\uff0c\u6ce2\u52a8\u7387\u662f 25%\uff0c\u8fd9\u4e2a\u7406\u8d22\u4ea7\u54c1\u503c\u5f97\u4e70\u5417\uff1f \u5047\u8bbe\u76ee\u524d\u80a1\u6307\u662f \\(S_0\\) \uff0c6 \u4e2a\u6708\u540e\u80a1\u6307\u4e3a \\(S_t\\) \u3002\u6211\u4eec\u53ef\u4ee5\u77e5\u9053\u5176\u6536\u76ca\u4e3a\uff1a \\[\\max(0, 0.4(S_t - S_0))\\] \u56e0\u6b64\u5176\u5b9e\u9645\u4e0a\u662f\u76f8\u5f53\u4e8e 0.4 \u500d\u7684\u6267\u884c\u4ef7\u683c\u4e3a \\(S_0\\) \u7684\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u7684\u6536\u76ca\u3002 \u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u6267\u884c\u4ef7\u683c\u4e3a \\(S_0\\) \uff0c\u5230\u671f\u65e5\u4e3a 6 \u4e2a\u6708\u7684\u6b27\u5f0f\u671f\u6743\u7684\u4ef7\u503c\uff1a \\[c = S_0e^{-qT}\\Phi(d_1) - Ke^{-rT}\\Phi(d_2)\\] \u5176\u4e2d \\[d_1 = \\frac{\\ln(\\frac{S_0}{K})+(r - q + \\frac{1}{2}\\sigma^2)T}{\\sigma \\sqrt{T}}\\] \\[d_2 = d_1 - \\sigma \\sqrt{T}\\] \u5c06 \\(K = S_0\\) \uff0c \\(T = 0.5\\) \uff0c \\(q = 0.03\\) \uff0c \\(r = 0.08\\) \uff0c \\(\\sigma = 0.25\\) \u4ee3\u5165\uff1a \\[c = 0.0814S_0\\] \u5047\u8bbe\u6295\u8d44\u91d1\u989d\u4e3a \\(M\\) \uff0c\u8be5\u7406\u8d22\u4ea7\u54c1\u7684\u73b0\u91d1\u6d41\u76f8\u5f53\u4e8e\u5728 0 \u65f6\u523b\uff0c\u514d\u8d39\u83b7\u5f97\u4e86 \\(0.4 \\frac{M}{S_0}\\) \u4efd\u770b\u6da8\u671f\u6743\uff0c\u5176\u4ee3\u4ef7\u662f\u5269\u4f59\u7684\u8d44\u91d1\u65e0\u6cd5\u8d5a\u53d6\u65e0\u98ce\u9669\u5229\u7387\u3002\u6211\u4eec\u9700\u8981\u6bd4\u8f83\u671f\u6743\u7684\u4ef7\u683c\u4ee5\u53ca\u65e0\u98ce\u9669\u5229\u7387\u7684\u6536\u76ca\u3002 \u73b0\u5728\u6211\u4eec\u5047\u8bbe\u6709\u4e24\u4e2a portfolio A \u548c B\u3002 - A\uff1a\u5168\u989d\u8d2d\u4e70\u8be5\u7406\u8d22\u4ea7\u54c1 - B\uff1a\u8d2d\u4e70\u4e86 \\(0.4 \\frac{M}{ S_0}\\) \u4efd\u770b\u6da8\u671f\u6743\uff0c\u5269\u4f59\u8d44\u91d1\u7528\u4e8e\u8d5a\u53d6\u65e0\u98ce\u9669\u5229\u7387 \u663e\u7136 B \u8d2d\u4e70\u7684\u671f\u6743\u5177\u6709\u548c A \u5b8c\u5168\u4e00\u81f4\u7684 payoff\u3002\u6211\u4eec\u53ea\u9700\u8981\u6bd4\u8f83\u5176\u4f59\u8d44\u91d1\u3002 \u5bf9\u4e8e A\uff0c\u516d\u4e2a\u6708\u540e\u4f1a\u83b7\u5f97 \\(M\\) \u5916\u52a0 payoff\u3002 \u5bf9\u4e8e B\uff0c\u9664\u4e86\u4e0e A \u4e00\u81f4\u7684 payoff\uff0c\u8fd8\u6709\uff1a \\[(M - 0.4 \\frac{ M }{ S_0 } c)e^{rT} = 1.007 M > M\\] \u56e0\u6b64\u663e\u7136\u8be5\u7406\u8d22\u4ea7\u54c1\u4e0d\u5212\u7b97\u3002","title":"\u4f8b 6"},{"location":"trading/option/BSM/#144-sigma","text":"\u5728 B-S-M \u6a21\u578b\u4e2d\uff0c\u552f\u4e00\u96be\u4ee5\u786e\u5b9a\u7684\u53c2\u6570\u5c31\u662f\u6ce2\u52a8\u7387 \\(\\sigma\\) \u3002\u5728\u5b9e\u9645\u4e2d\uff0c\u4e0d\u80fd\u76f4\u63a5\u4f7f\u7528\u5386\u53f2\u6ce2\u52a8\u7387\uff0c\u4f46\u662f\u53ef\u4ee5\u4f5c\u4e3a\u91cd\u8981\u53c2\u8003\u3002\u4ee5\u4e0b\u63d0\u5230\u7684\u6ce2\u52a8\u7387\u90fd\u6307\u5386\u53f2\u6ce2\u52a8\u7387\uff0c\u800c\u975e\u5b9e\u9645\uff08\u9690\u542b\uff09\u6ce2\u52a8\u7387\u3002 \\(\\sigma\\) \u7528\u4e8e\u8861\u91cf\u80a1\u7968\u56de\u62a5\u7387\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u6211\u4eec\u5c06\u6ce2\u52a8\u7387 \\(\\sigma\\) \u5b9a\u4e49\u4e3a \u8fde\u7eed\u590d\u5229\u4e0b\u80a1\u7968 1 \u5e74\u4e2d\u56de\u62a5\u7387\u7684\u6807\u51c6\u5dee \u3002\u5b83\u4e00\u822c\u5728 15% \u5230 60% \u4e4b\u95f4\u3002 \u8fde\u7eed\u590d\u5229\u4e0b\u7684\u80a1\u7968\u56de\u62a5\u7387\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\[x = \\frac{1}{T} \\ln( \\frac{S_T}{S_0} )\\] \u6211\u4eec\u5df2\u7ecf\u5047\u8bbe\uff1a \\[\\ln(S_T)-\\ln(S_0) \\sim N( (\\mu-\\frac{1}{2}\\sigma^2)T, \\sigma^2 T)\\] \u56e0\u6b64\u56de\u62a5\u7387\u6ee1\u8db3\uff1a \\[x \\sim N(\\mu-\\frac{1}{2}\\sigma^2, \\frac{\\sigma^2}{T})\\] \u5047\u8bbe\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u4ee5\u67d0\u4e2a\u8f83\u5c0f\u91c7\u6837\u95f4\u9694\uff08\u4f8b\u5982\u6bcf\u5468\uff09 \\(\\Delta t\\) \u7684\u80a1\u7968\u56de\u62a5\u7387\u5386\u53f2\u6570\u636e\uff0c\u6211\u4eec\u53ef\u4ee5\u4f30\u8ba1\u5176\u65b9\u5dee \\(D\\) \u3002 \u5047\u8bbe\u7b2c \\(i\\) \u4e2a \\(\\Delta t\\) \u5185\u7684\u56de\u62a5\u7387\u4e3a \\(u_i\\) \uff0c\u5176\u5e73\u5747\u503c\u4e3a \\(\\overline{u}\\) \u3002\u5bf9\u4e8e\u65b9\u5dee \\(D\\) \u7684\u65e0\u504f\u4f30\u8ba1\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\[\\hat{D} = \\frac{1}{n-1}\\sum_{i=1}^n (u_i - \\overline{u})^2\\] \u4e5f\u53ef\u4ee5\u5199\u4e3a\uff1a \\[ \\hat{D} = \\frac{ 1}{n-1} [ \\sum_{i = 1}^n u_i^2 - n \\overline{u}^2] \\] \u7136\u540e\u6839\u636e\u4e0b\u5f0f\u6c42\u6ce2\u52a8\u7387\u7684\u4f30\u8ba1\uff1a \\[\\hat{\\sigma} = \\sqrt{\\hat{D}~T}\\] \u8fd9\u4e2a \\(T\\) \u8868\u793a\u4e00\u5e74\u65f6\u95f4\uff0c\u5047\u8bbe \\(\\Delta t\\) \u662f\u5468\uff0c\u90a3\u4e48 \\(T = 365/7 = 52\\) \u3002","title":"14.4 \u8ba1\u7b97\u5386\u53f2\u6ce2\u52a8\u7387 \\(\\sigma\\)"},{"location":"trading/option/BSM/#1_1","text":"\u5047\u8bbe\u6211\u4eec\u89c2\u5bdf\u5230\u67d0\u4e2a\u80a1\u7968\u5728\u8fde\u7eed 15 \u4e2a\u5468\u4e94\u7684\u4ef7\u683c\u4e3a\uff1a30.2; 32.0; 31.1; 30.1; 30.2; 30.3; 30.6; 33.0; 32.9; 33.0; 33.5; 33.5; 33.7; 33.5; 33.2\u3002 (a) \u4f30\u7b97\u8be5\u80a1\u7968\u7684\u6ce2\u52a8\u7387 (b) \u8fd9\u4e2a\u6ce2\u52a8\u7387\u7684\u4f30\u8ba1\u7684\u6807\u51c6\u5dee\u662f\u591a\u5c11\uff1f # \u80a1\u7968\u4ef7\u683c( \\(S\\) ) \u76f8\u5bf9\u4ef7\u683c( \\(S_{i+1}/S_i\\) ) \u5468\u56de\u62a5\u7387( \\(u = \\ln(S_{i+1}/S_i)\\) ) 1 30.2 2 32.0 1.05960 0.05789 3 31.1 0.97188 -0.02853 4 30.1 0.96785 -0.03268 5 30.2 1.00332 0.00332 6 30.3 1.00331 0.00331 7 30.6 1.00990 0.00985 8 33.0 1.07843 0.07551 9 32.9 0.99697 -0.00303 10 33.0 1.00304 0.00303 11 33.5 1.01515 0.01504 12 33.5 1.00000 0.00000 13 33.7 1.00597 0.00595 14 33.5 0.99407 -0.00595 15 33.2 0.99104 -0.00900 (a) \u9996\u5148\u8ba1\u7b97\u5f97\u5230\uff1a \\[\\sum_{i=1}^n u_i = 0.09471\\] \\[\\sum_{i=1}^n u_i^2 = 0.01145\\] \u8ba1\u7b97\u5f97 \\[\\hat{D} = \\frac{1}{13}(0.01145 - \\frac{0.09471^2}{14}) = 0.0008315\\] \\[\\sigma = \\sqrt{0.0008315 \\times 52} = 0.208\\] (b) \u8fd9\u4e2a\u4f30\u8ba1\u672c\u8eab\u7684\u6807\u51c6\u5dee\u4e3a \\[ \\frac{ \\sigma}{ \\sqrt{2n} } = \\frac{0.208}{\\sqrt{2 \\times 14} } = 0.0393\\]","title":"\u4f8b 1"},{"location":"trading/option/BinomialTree/","text":"Binomial Trees binomial tree \u662f John Cox, Stephen Ross \u548c Mark Robinstein \u4e09\u4f4d\u6559\u6388\u63d0\u51fa\u7684\u4e00\u79cd\u4e0d\u9700\u8981\u9ad8\u7ea7\u6570\u5b66\u77e5\u8bc6\u7684\u671f\u6743\u5b9a\u4ef7\u65b9\u6cd5\u3002\u6700\u521d\u662f\u7528\u4e8e\u6559\u5b66\u7684\uff0c\u540e\u6765\u5e7f\u6cdb\u5e94\u7528\u4e8e\u7f8e\u5f0f\u671f\u6743\u7684\u5b9a\u4ef7\uff08\u56e0\u4e3a\u53ef\u4ee5\u968f\u65f6\u6267\u884c\uff0c\u65e0\u6cd5\u7528 BSM \u516c\u5f0f\u5b9a\u4ef7\uff09\u3002 \u8fd9\u4e2a\u65b9\u6cd5\u6784\u9020\u4e86\u4e00\u4e2a\u6811\u72b6\u56fe\u8868\u793a\u5728\u671f\u6743\u671f\u9650\u5185\u53ef\u80fd\u4f1a\u51fa\u73b0\u7684\u80a1\u7968\u4ef7\u683c\u53d8\u52a8\u7684\u8def\u5f84\u3002\u5728\u6811\u7684\u6bcf\u4e00\u6b65\uff08\u53ef\u80fd\u6309\u65f6\u95f4\u6765\u5212\u5206\uff09\uff0c\u80a1\u7968\u4ef7\u683c\u90fd\u6709\u4e00\u5b9a\u7684\u673a\u4f1a\u4e0a\u884c\u6216\u8005\u4e0b\u884c\u3002\u5f53\u6b65\u957f\u8db3\u591f\u5c0f\u65f6\uff0c\u80a1\u7968\u4ef7\u683c\u8d8b\u4e8e\u5bf9\u6570\u6b63\u6001\u5206\u5e03\uff0c\u4e5f\u5c31\u662f Black-Scholes-Merton \u6a21\u578b\u7684\u5047\u8bbe\u3002\u56e0\u6b64\uff0c\u7528\u4e8c\u53c9\u6811\u4f30\u8ba1\u7684\u671f\u6743\u4ef7\u683c\u6536\u655b\u4e8e Black-Scholes-Merton \u6a21\u578b\u7684\u5b9a\u4ef7\u3002 12.1 \u65e0\u5957\u5229\u5047\u8bbe\u4e0b\u7684\u4e00\u6b65\u4e8c\u53c9\u6811\u6a21\u578b \u73b0\u5728\u6211\u4eec\u6765\u63a8\u5bfc\u4e00\u4e0b\u671f\u6743\u7684\u4e8c\u53c9\u6811\u5b9a\u4ef7\u516c\u5f0f\u3002 \u6211\u4eec\u8003\u8651\u5982\u4e0b portfolio A\uff1a \u4e00\u5b9a\u6570\u91cf\u7684\u80a1\u7968 \u4e00\u4e2a short call\uff0c\u5728 T \u65f6\u523b\u5230\u671f\uff0c\u6267\u884c\u4ef7\u683c\u4e3a K \u6211\u4eec\u5c06\u8981\u7528\u5230\u7684\u7b26\u53f7\u7ea6\u5b9a\u5982\u4e0b\uff1a \\(S_0\\) : \u671f\u6743\u5728 0 \u65f6\u523b\u4ef7\u503c \\(u\\) : \u80a1\u7968\u5728 T \u65f6\u523b\u4e0a\u6da8\u5e45\u5ea6\uff0c\u6ee1\u8db3 \\(S_u = S_0u\\) \\(d\\) : \u80a1\u7968\u5728 T \u65f6\u523b\u4e0b\u8dcc\u5e45\u5ea6\uff0c\u6ee1\u8db3 \\(S_d = S_0d\\) \\(c\\) : \u5728 0 \u65f6\u523b\uff0c\u671f\u6743\u7684\u4ef7\u683c\uff0c\u5373\u6211\u4eec\u9700\u8981\u6c42\u5f97\u7684\u53d8\u91cf \\(f_u\\) : \u5728 T \u65f6\u523b\uff0c\u80a1\u7968\u4ef7\u683c\u4e0a\u6da8\u65f6\u7684 payoff\uff0c\u5bf9\u4e8e\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u662f \\(\\max(S-K, 0)\\) \\(f_d\\) : \u5728 T \u65f6\u523b\uff0c\u80a1\u7968\u4ef7\u683c\u4e0b\u8dcc\u65f6\u7684 payoff\uff0c\u5bf9\u4e8e\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u662f \\(\\max(S-K, 0)\\) \\(\\Delta\\) : \u4f7f\u5f97 portfolio A \u65e0\u98ce\u9669\u7684\u80a1\u7968\u4ed3\u4f4d \u6240\u8c13\u65e0\u98ce\u9669\uff0c\u5373\u65e0\u8bba\u80a1\u7968\u4ef7\u683c\u4e0a\u5347\u8fd8\u662f\u4e0b\u964d\uff0c\u90fd\u4e0d\u5f71\u54cd portfolio A \u7684\u4ef7\u503c\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\uff1a \\[\\Delta S_0 u - f_u = \\Delta S_0 d - f_d\\] \u6ce8\u610f\uff0c\u7531\u4e8e\u662f\u770b\u6da8\u671f\u6743\u7684\u7a7a\u5934\uff0c\u56e0\u6b64\u90fd\u662f\u51cf\u53bb payoff\u3002 \u6211\u4eec\u53ef\u4ee5\u89e3\u51fa \\(\\Delta\\) \uff1a \\[\\Delta = \\frac{f_u - f_d}{S_0 u - S_0 d}\\] \u7531\u4e8e\u4e0d\u5b58\u5728\u5957\u5229\u673a\u4f1a\uff0c\u800c\u8fd9\u4e2a portfolio \u662f\u65e0\u98ce\u9669\u7684\uff0c\u56e0\u6b64\u5b83\u7684\u6536\u76ca\u5fc5\u7136\u7b49\u4e8e\u65e0\u98ce\u9669\u5229\u7387 \\(r\\) \u3002\u5426\u5219\uff0c\u53ef\u4ee5\u501f\u94b1\u4e70\u5165\u8be5 portfolio\uff0c\u6216\u8005\u5356\u7a7a\u6765\u5957\u5229\u3002 \\[\\Delta S_0 u - f_u = (\\Delta S_0 - c)e^{rT}\\] \u5373 \\[c = (1 - ue^{-rT}) \\Delta S_0 + f_u e^{-rT}\\] \u6211\u4eec\u5c06 \\(\\Delta S_0 = \\frac{f_u - f_d}{u - d}\\) \u5e26\u5165\uff0c\u6709 \\[ c = \\frac{(1 - de^{-rT})f_u - (1 - ue^{-rT})f_d}{u - d}\\] \u6211\u4eec\u5f15\u5165 \\(p = \\frac{e^{rT} - d}{u - d}\\) \uff0c\u5219\u53ef\u4ee5\u5c06\u4e0a\u5f0f\u5199\u4e3a\uff1a \\[ c = e^{-rT}[p f_u + (1-p) f_d]\\] \u4f8b 1 \u6211\u4eec\u53ef\u4ee5\u7528\u4e00\u4e2a\u5b9e\u9645\u4f8b\u5b50\u6765\u8bf4\u660e\u5982\u4f55\u4f7f\u7528\u8fd9\u4e2a\u516c\u5f0f\u3002 \u5047\u8bbe\u76ee\u524d\u7684\u65e0\u98ce\u9669\u5229\u7387\u662f12%\u3002\u4e00\u4e2a\u80a1\u7968\u73b0\u5728\u4ef7\u503c\u4e3a $20\uff0c\u6211\u4eec\u5df2\u77e5 3 \u4e2a\u6708\u540e\u5b83\u53ef\u80fd\u4e0a\u6da8\u5230 $22\uff0c\u4e5f\u53ef\u80fd\u4e0b\u8dcc\u5230 $18\u3002\u5219\u671f\u9650\u662f 3 \u4e2a\u6708\uff0c\u6267\u884c\u4ef7\u683c\u662f $21 \u7684\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u4ef7\u683c\u662f\u591a\u5c11\uff1f \u6211\u4eec\u53ef\u4ee5\u5f97\u5230 \\(u = 1.1\\) \uff0c \\(d = 0.9\\) \uff0c \\(r = 0.12\\) \uff0c \\(T = 0.25\\) \uff0c \\(f_u = 1\\) \uff0c \\(f_d = 0\\) \u3002 \u4e8e\u662f\u8ba1\u7b97\u5f97\u51fa \\(p = 0.652\\) \uff0ccall \u7684\u4ef7\u683c\u4e3a \\(c = 0.633\\) \u3002 12.2 \u98ce\u9669\u4e2d\u6027\u5b9a\u4ef7 \u6211\u4eec\u5bf9\u98ce\u9669\u7684\u6001\u5ea6\u53ef\u4ee5\u5206\u4e3a\u4ee5\u4e0b\u4e09\u79cd\u7c7b\u578b\uff1a \u98ce\u9669\u538c\u6076 \u6295\u8d44\u8005\u671f\u671b\u4ece\u98ce\u9669\u66f4\u9ad8\u7684\u6295\u8d44\u4e2d\u83b7\u53d6\u66f4\u9ad8\u7684\u6536\u76ca\u3002\u8fd9\u4e5f\u662f\u73b0\u5b9e\u4e16\u754c\u4e2d\u5927\u90e8\u5206\u6295\u8d44\u8005\u7684\u6001\u5ea6\u3002 \u98ce\u9669\u4e2d\u6027 \u6295\u8d44\u8005\u5e76\u4e0d\u8981\u6c42\u4ece\u98ce\u9669\u66f4\u9ad8\u7684\u6295\u8d44\u4e2d\u83b7\u53d6\u66f4\u9ad8\u7684\u6536\u76ca\u3002 \u98ce\u9669\u504f\u597d \u6295\u8d44\u8005\u613f\u610f\u4ece\u9ad8\u98ce\u9669\u7684\u6295\u8d44\u4e2d\u83b7\u53d6\u66f4\u5c11\u7684\u6536\u76ca\u3002 \u7528\u629b\u786c\u5e01\u7684\u8d4c\u5c40\u6765\u4e3e\u4f8b\uff0c\u5047\u8bbe\u4e00\u679a\u5747\u5300\u786c\u5e01\uff0c\u6b63\u9762\u5219\u6295\u8d44\u8005\u83b7\u76ca 100\uff0c\u80cc\u9762\u5219\u635f\u5931\u672c\u91d1\u3002\u56e0\u6b64\u8be5\u8d4c\u5c40\u671f\u671b\u83b7\u76ca 50 \u5757\u3002\u90a3\u4e48\uff1a \u98ce\u9669\u538c\u6076\u7684\u6295\u8d44\u8005\u6700\u591a\u613f\u610f\u82b1\u4f4e\u4e8e 50 \u5757\u672c\u91d1\u53c2\u4e0e\u3002 \u98ce\u9669\u4e2d\u6027\u7684\u6295\u8d44\u8005\u6700\u591a\u613f\u610f\u82b1 50 \u5757\u672c\u91d1\u53c2\u4e0e\u3002 \u98ce\u9669\u504f\u597d\u7684\u6295\u8d44\u8005\u6700\u591a\u613f\u610f\u82b1\u9ad8\u4e8e 50 \u5757\u672c\u91d1\u53c2\u4e0e\u3002 \u6211\u4eec\u5e38\u5e38\u5047\u8bbe\u4e00\u4e2a\u98ce\u9669\u4e2d\u6027\u7684\u4e16\u754c\u6765\u7b80\u5316\u884d\u751f\u54c1\u5b9a\u4ef7\uff1a 1. \u6295\u8d44\u54c1\u7684\u671f\u671b\u56de\u62a5\u7387\u7b49\u4e8e\u65e0\u98ce\u9669\u5229\u7387 2. \u671f\u6743 payoff \u7684\u6298\u73b0\u7387\u7b49\u4e8e\u65e0\u98ce\u9669\u5229\u7387 \u6211\u4eec\u518d\u6765\u770b\u4e4b\u524d\u5f97\u5230\u7684\u671f\u6743\u5b9a\u4ef7\u516c\u5f0f\uff1a \\[ c = e^{-rT}[p f_u + (1-p) f_d]\\] \u6211\u4eec\u6765\u8ba1\u7b97\u4e00\u4e0b\u80a1\u7968\u4ef7\u683c\u5728 \\(T\\) \u65f6\u523b\u540e\u7684\u671f\u671b\uff1a \\[E(S_T) = p S_0 u + (1-p) S_0 d = p S_0 (u - d) + S_0 d\\] \u4ee3\u5165 \\(p = \\frac{e^{rT} - d}{u - d}\\) \u5f97\u5230\uff1a \\[E(S_T) = S_0 e^{rT}\\] \u6211\u4eec\u53d1\u73b0\uff0c\u5047\u8bbe \\(p\\) \u662f\u80a1\u7968\u4ef7\u683c\u4e0a\u6da8\u5230 \\(S_u\\) \u7684\u6982\u7387\uff0c \\(1-p\\) \u662f\u80a1\u7968\u4ef7\u683c\u4e0b\u8dcc\u5230 \\(S_d\\) \u7684\u6982\u7387\uff0c\u5219\u80a1\u7968\u6536\u76ca\u7387\u7684\u671f\u671b\u5c31\u662f\u65e0\u98ce\u9669\u5229\u7387\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u80a1\u7968\u8fd9\u79cd\u5b58\u5728\u98ce\u9669\u7684\u6295\u8d44\u4ea7\u54c1\u7684\u671f\u671b\u6536\u76ca\u7387\u4e0e\u65e0\u98ce\u9669\u5229\u7387\u76f8\u7b49\uff0c\u8fd9\u4e0e \u98ce\u9669\u4e2d\u6027 \u7684\u4e16\u754c\u76f8\u7b26\u3002 12.2.1 \u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u4e0b\u7684\u4e00\u6b65\u4e8c\u53c9\u6811\u6a21\u578b \u5728 12.1 \u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u65e0\u5957\u5229\u7684\u5047\u8bbe\u5f97\u5230 \\(p = \\frac{e^{rT} - d}{u - d}\\) \u3002\u57fa\u4e8e\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u53e6\u4e00\u79cd\u65b9\u6cd5\uff0c\u5373\u6839\u636e\u80a1\u7968\u7684\u671f\u671b\u4ef7\u503c\u6765\u8ba1\u7b97\u3002 \\[ p^{*} S_{u} + (1-p^{*}) S_{d} = 20 e^{rT}\\] \u5e26\u5165\u516c\u5f0f\u4e5f\u53ef\u4ee5\u5f97\u5230 \\(p^{*} = 0.652\\) \u3002 \u5bf9\u4e8e call \u7684\u4ef7\u503c\uff0c\u56e0\u4e3a\u5b83\u5728 \\(T\\) \u65f6\u523b\u6709 \\(p\\) \u7684\u51e0\u7387\u4ef7\u503c \\(S_u - K\\) \uff0c\u4e5f\u6709 \\(1-p\\) \u51e0\u7387\u4ef7\u503c0\uff0c\u56e0\u6b64\u5176\u5f53\u524d\u4ef7\u503c\u4e3a\u5176 payoff \u671f\u671b\u6298\u73b0\u540e\u7684\u7ed3\u679c\uff1a \\[c = p (S_u - K) e^{-rT} = 0.633 \\] \u4e0e 12.1 \u4e2d\u7684\u7ed3\u679c\u76f8\u540c\u3002\u5373\u5229\u7528\u65e0\u5957\u5229\u5047\u8bbe\u548c\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u83b7\u5f97\u7684\u7ed3\u679c\u76f8\u540c\u3002 12.2.2 Real World \u9700\u8981\u6307\u51fa\u7684\u662f\uff0c \\(p\\) \u662f \u98ce\u9669\u4e2d\u6027 \u5047\u8bbe\u4e0b\u80a1\u7968\u4ef7\u683c\u53d8\u4e3a \\(S_u\\) \u7684\u6982\u7387\u3002\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u8fd9\u548c\u73b0\u5b9e\u4e2d\u5e76\u4e0d\u76f8\u7b49\u3002\u56e0\u4e3a\u73b0\u5b9e\u4e16\u754c\u662f\u98ce\u9669\u538c\u6076\u578b\u7684\uff0c\u56e0\u6b64\u5bf9\u4e8e\u9ad8\u98ce\u9669\u7684\u80a1\u7968\u4f1a\u6709\u66f4\u9ad8\u7684\u6536\u76ca\u671f\u671b\u3002 \u73b0\u5b9e\u4e2d\u5f53\u65e0\u98ce\u9669\u6536\u76ca\u7387\u662f 12% \u65f6\uff0c\u5047\u8bbe\u5bf9\u80a1\u7968\u7684\u6536\u76ca\u671f\u671b\u662f 16%\uff0c\u5219 \\[ 22 p^* + 18(1 - p^*) = 20e^{0.16*3/12}\\] \u8ba1\u7b97\u5f97\u77e5 \\(p^* = 0.704\\) \u3002 \u5728 12.2.1 \u4e2d\u6211\u4eec\u8ba1\u7b97\u671f\u6743\u4ef7\u683c\u65f6\uff0c\u6211\u4eec\u91c7\u7528\u4e86\u4e0e\u80a1\u7968\u76f8\u540c\u7684\u5229\u7387\u5bf9 payoff \u8fdb\u884c\u8d34\u73b0\uff0c\u7136\u800c\u7531\u4e8e\u671f\u6743\u98ce\u9669\u6bd4\u80a1\u7968\u5927\uff0c\u6211\u4eec\u5bf9\u671f\u6743\u6536\u76ca\u7684\u8d34\u73b0\u7387\u5e94\u8be5\u5927\u4e8e 16%\u3002\u6211\u4eec\u65e0\u6cd5\u77e5\u9053\u5b9e\u9645\u7684\u8d34\u73b0\u7387\u56e0\u6b64\u65e0\u6cd5\u8ba1\u7b97\u3002 \u53ea\u6709\u5728\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u4e0b\uff0c\u6211\u4eec\u5bf9\u6240\u6709\u7684\u8d44\u4ea7\u56de\u62a5\u7387\u7684\u671f\u671b\u503c\u624d\u80fd\u90fd\u7b49\u4e8e\u65e0\u98ce\u9669\u5229\u7387\uff0c\u4ece\u800c\u53ef\u4ee5\u8ba1\u7b97\u671f\u6743\u7684\u4ef7\u683c\u3002 12.3 \u4e24\u6b65\u4e8c\u53c9\u6811 \u5047\u8bbe\u5728\u4e0a\u56fe\u4e2d\uff0c\u6bcf\u4e00\u6b65\u65f6\u95f4\u4e3a 3 \u4e2a\u6708\uff0c\u80a1\u7968\u53ef\u80fd\u4e0a\u6da8\u6216\u8005\u4e0b\u8dcc 10%\u3002 \u6211\u4eec\u5e0c\u671b\u8ba1\u7b97\u4e00\u4e2a\u6267\u884c\u4ef7\u683c 21\uff0c\u671f\u9650 6 \u4e2a\u6708\u7684 call \u7684\u4ef7\u503c\u3002 \u7531\u4e8e\u6bcf\u4e00\u6b65\u4e0a\u6da8/\u4e0b\u8dcc\u5e45\u5ea6\u662f\u4e00\u81f4\u7684\uff0c\u56e0\u6b64\u8ba1\u7b97\u6240\u5f97\u7684\u4e0a\u6da8/\u4e0b\u8dcc\u7684\u6982\u7387\u4e5f\u662f\u4e00\u81f4\u7684\u3002 \u6211\u4eec\u76f4\u63a5\u4ece\u6700\u7ec8\u72b6\u6001\u5165\u624b\uff0c \\[f = e^{-2r \\Delta t}[p^2 f_{uu} + 2p(1-p)f_{ud} +(1-p)^2f_{dd}]\\] \u5176\u4e2d \\(p = \\frac{e^{rT} - d}{u - d}\\) \u3002 12.3.1 Delta \u6211\u4eec\u4e4b\u524d\u5728\u4e00\u6b65\u4e8c\u53c9\u6811\u4e2d\u5df2\u7ecf\u7528\u5230\u4e86 \\(\\Delta\\) \uff0c\u5b83\u662f\u5f53\u6211\u4eec\u5356\u51fa\u4e00\u4efd\u671f\u6743\u65f6\uff0c\u4e3a\u4e86\u6784\u9020\u65e0\u98ce\u9669\u7ec4\u5408\u9700\u8981\u6301\u6709\u7684\u6807\u7684\u8d44\u4ea7\u6570\u91cf\u3002\u5b83\u4ee3\u8868\u4e86\u671f\u6743\u4ef7\u683c\u53d8\u5316\u4e0e\u80a1\u7968\u4ef7\u683c\u53d8\u5316\u7684\u6bd4\u7387\u3002 \u56e0\u6b64\uff0c\u5bf9\u4e8e 12.1 \u4f8b 1 \u4e2d\u7684 \\(\\Delta\\) \uff0c\u6211\u4eec\u7528\u5982\u4e0b\u5f0f\u5b50\u8ba1\u7b97\uff1a \\[ \\Delta = = \\frac{f_u - f_d}{S_0 u - S_0 d} = \\frac{1-0}{22-18} = 0.25\\] \u5728\u4e24\u6b65\u4e8c\u53c9\u6811\u4e2d\uff0c\u6211\u4eec\u53d1\u73b0 \\(\\Delta\\) \u662f\u968f\u65f6\u95f4\u53d8\u5316\u7684\u3002\u56e0\u6b64\u65e0\u6cd5\u6784\u9020\u4e00\u4e2a portfolio \u4f7f\u5b83\u5728\u5230\u671f\u65e5\u524d\u90fd\u4fdd\u6301\u98ce\u9669\u4e2d\u6027\u3002\u5728\u5b9e\u9645\u4e2d\uff0c\u6211\u4eec\u9700\u8981\u4e0d\u65ad\u8c03\u8282\u6301\u6709\u80a1\u7968\u7684\u6570\u91cf\u6765\u8fdb\u884c\u5bf9\u51b2\u3002 12.5 \u7f8e\u5f0f\u671f\u6743 \u6211\u4eec\u4e4b\u524d\u8ba8\u8bba\u7684\u90fd\u662f\u6b27\u5f0f\u671f\u6743\uff0c\u56e0\u6b64\u53ef\u4ee5\u53ea\u4f9d\u8d56\u6700\u7ec8\u72b6\u6001\u6765\u786e\u5b9a\u4ef7\u683c\u3002\u4f46\u662f\u5bf9\u4e8e\u7f8e\u5f0f\u671f\u6743\uff0c\u7531\u4e8e\u53ef\u4ee5\u63d0\u524d\u884c\u6743\uff0c\u5728\u6bcf\u4e00\u6b65\uff0c\u671f\u6743\u7684 payoff \u90fd\u5e94\u8be5\u53d6\u4ee5\u4e0b\u4e24\u4e2a\u503c\u7684\u6700\u5927\u503c\uff1a \u901a\u8fc7 \\(f = e^{-r \\Delta t}[pf_u + (1-p)f_d]\\) \u8ba1\u7b97\u51fa\u7684 payoff \u7acb\u5373\u884c\u6743\u7684 payoff \u5047\u8bbe\u80a1\u7968\u4ef7\u683c\u53d8\u5316\u5982\u4e0b\u56fe\u3002\u6bcf\u6b65\u65f6\u95f4\u4e3a 1 \u5e74\uff0c\u53ef\u80fd\u6709 20% \u7684\u4e0a\u6da8\u6216\u8005\u4e0b\u8dcc\u3002\u65e0\u98ce\u9669\u5229\u7387\u4e3a 5%\u3002 \u6ce8\u610f\u4e0a\u56fe\u7684 C \u70b9\u3002 \u6211\u4eec\u9996\u5148\u8ba1\u7b97 \\(p = \\frac{e^{rT} - d}{u - d} = 0.6282\\) \uff0c\u5219\u5728 C \u70b9\u65f6\uff0c \\(f = 9.4636\\) \u3002\u7136\u800c\uff0c\u5047\u8bbe\u9009\u62e9\u5728 C \u70b9\u65f6\u7acb\u5373\u884c\u6743\uff0c\u6211\u4eec\u53ef\u4ee5\u83b7\u5f97 $12\u3002\u56e0\u6b64\u5728 C \u70b9\u671f\u6743\u7684\u4ef7\u503c\u4e3a 12 \u800c\u975e 9.4636\u3002 \u5728 B \u70b9\uff0c\u671f\u6743\u4ef7\u503c\u4e3a 1.4147\uff0c\u5728 A \u70b9\uff0c\u671f\u6743\u4ef7\u503c\u4e3a 5.0894\u3002 12.7 \u4f7f \\(u\\) \u548c \\(d\\) \u4e0e\u6ce2\u52a8\u7387\u543b\u5408 \u5728\u5b9e\u9645\u4e2d\uff0c\u5f53\u6211\u4eec\u6784\u9020\u4e8c\u53c9\u6811\u6765\u8868\u793a\u80a1\u7968\u4ef7\u683c\u53d8\u5316\u65f6\uff0c\u6211\u4eec\u9700\u8981\u9009\u53d6\u6070\u5f53\u7684 \\(u\\) \u548c \\(d\\) \u4f7f\u80a1\u7968\u7684\u53d8\u5316\u548c\u6ce2\u52a8\u7387 \\(\\sigma\\) \u4e00\u81f4\u3002\u90a3\u6211\u4eec\u7a76\u7adf\u9700\u8981\u5339\u914d\u73b0\u5b9e\u4e2d\u7684\u6ce2\u52a8\u7387\uff0c\u8fd8\u662f\u98ce\u9669\u4e2d\u6027\u7684\u6ce2\u52a8\u7387\u5462\uff1f \u6211\u4eec\u9a6c\u4e0a\u5c06\u8981\u8bc1\u660e\uff0c \u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u6ce2\u52a8\u7387\u548c\u98ce\u9669\u4e2d\u6027\u4e16\u754c\u4e2d\u7684\u6ce2\u52a8\u7387\u662f\u76f8\u7b49\u7684 \u3002 \u80a1\u7968\u4ef7\u683c\u53d8\u5316\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u5047\u8bbe\u80a1\u7968\u7684\u6ce2\u52a8\u7387 \\(\\sigma\\) \uff0c\u5219\u80a1\u7968\u56de\u62a5\u7387\u7684\u65b9\u5dee\u4e3a \\(\\sigma^2 \\Delta t\\) \u3002 \u5bf9\u4e8e\u73b0\u5b9e\u4e16\u754c\uff0c\u80a1\u7968\u6709 \\(p^*\\) \u7684\u6982\u7387\u56de\u62a5\u7387\u4e3a \\(u -1\\) \uff0c\u540c\u65f6\u6709 \\(1-p^*\\) \u7684\u6982\u7387\u56de\u62a5\u7387\u4e3a \\(d - 1\\) \u3002\u7531\u4e8e +1 \u5e76\u4e0d\u5f71\u54cd\u65b9\u5dee\uff0c\u6211\u4eec\u53ef\u4ee5\u8f6c\u4e3a\u8ba1\u7b97\u80a1\u7968 \u7ec8\u503c/\u521d\u503c \u7684\u65b9\u5dee\u3002 \\[D(x) = E(x^2) - [E(x)]^2\\] \u56e0\u6b64\u6709 \\[ [p^* u^2 + (1-p^*)d^2] - [p^*u + (1-p^*)d]^2 = \\sigma^2 \\Delta t\\] \u5316\u7b80\u5f97\u5230 \\[ p^* (1-p^*)(u-d)^2 = \\sigma^2 \\Delta t\\] \u53e6\u4e00\u65b9\u9762\uff0c\u5047\u8bbe\u73b0\u5b9e\u4e2d\u6211\u4eec\u5bf9\u80a1\u7968\u6536\u76ca\u7684\u671f\u671b\u56de\u62a5\u7387\u662f \\(\\mu\\) \uff0c\u5219\u6709\uff1a \\[ p^{*} S_0 u+ (1-p^{*}) S_0 d = S_0 e^{\\mu \\Delta t} \\] \\[p^* = \\frac{e^{\\mu \\Delta t} - d}{u - d} \\] \u4ece\u800c\u5f97\u5230 \\[(e^{\\mu \\Delta t} - d)(e^{\\mu \\Delta t} - u) + \\sigma^2 \\Delta t = 0\\] \u5c06\u4e0a\u5f0f Taylor \u5c55\u5f00\u5e76\u5ffd\u7565 \\(\\Delta t\\) \u7684\u9ad8\u6b21\u9879\uff0c\u53ef\u4ee5\u5f97\u5230 \\(u, d\\) \u7684\u4e00\u7ec4\u89e3\uff1a \\[u = e^{\\sigma \\sqrt{\\Delta t}}\\] \\[d = e^{- \\sigma \\sqrt{\\Delta t}}\\] \uff08\u6211\u597d\u50cf\u6ca1\u6709\u529e\u6cd5\u901a\u8fc7\u6cf0\u52d2\u7ea7\u6570\u5f97\u5230\u540c\u6837\u7684\u7ed3\u679c\uff0c\u6682\u4e14\u5148\u7559\u7740\uff09","title":"Binomial Trees"},{"location":"trading/option/BinomialTree/#binomial-trees","text":"binomial tree \u662f John Cox, Stephen Ross \u548c Mark Robinstein \u4e09\u4f4d\u6559\u6388\u63d0\u51fa\u7684\u4e00\u79cd\u4e0d\u9700\u8981\u9ad8\u7ea7\u6570\u5b66\u77e5\u8bc6\u7684\u671f\u6743\u5b9a\u4ef7\u65b9\u6cd5\u3002\u6700\u521d\u662f\u7528\u4e8e\u6559\u5b66\u7684\uff0c\u540e\u6765\u5e7f\u6cdb\u5e94\u7528\u4e8e\u7f8e\u5f0f\u671f\u6743\u7684\u5b9a\u4ef7\uff08\u56e0\u4e3a\u53ef\u4ee5\u968f\u65f6\u6267\u884c\uff0c\u65e0\u6cd5\u7528 BSM \u516c\u5f0f\u5b9a\u4ef7\uff09\u3002 \u8fd9\u4e2a\u65b9\u6cd5\u6784\u9020\u4e86\u4e00\u4e2a\u6811\u72b6\u56fe\u8868\u793a\u5728\u671f\u6743\u671f\u9650\u5185\u53ef\u80fd\u4f1a\u51fa\u73b0\u7684\u80a1\u7968\u4ef7\u683c\u53d8\u52a8\u7684\u8def\u5f84\u3002\u5728\u6811\u7684\u6bcf\u4e00\u6b65\uff08\u53ef\u80fd\u6309\u65f6\u95f4\u6765\u5212\u5206\uff09\uff0c\u80a1\u7968\u4ef7\u683c\u90fd\u6709\u4e00\u5b9a\u7684\u673a\u4f1a\u4e0a\u884c\u6216\u8005\u4e0b\u884c\u3002\u5f53\u6b65\u957f\u8db3\u591f\u5c0f\u65f6\uff0c\u80a1\u7968\u4ef7\u683c\u8d8b\u4e8e\u5bf9\u6570\u6b63\u6001\u5206\u5e03\uff0c\u4e5f\u5c31\u662f Black-Scholes-Merton \u6a21\u578b\u7684\u5047\u8bbe\u3002\u56e0\u6b64\uff0c\u7528\u4e8c\u53c9\u6811\u4f30\u8ba1\u7684\u671f\u6743\u4ef7\u683c\u6536\u655b\u4e8e Black-Scholes-Merton \u6a21\u578b\u7684\u5b9a\u4ef7\u3002","title":"Binomial Trees"},{"location":"trading/option/BinomialTree/#121","text":"\u73b0\u5728\u6211\u4eec\u6765\u63a8\u5bfc\u4e00\u4e0b\u671f\u6743\u7684\u4e8c\u53c9\u6811\u5b9a\u4ef7\u516c\u5f0f\u3002 \u6211\u4eec\u8003\u8651\u5982\u4e0b portfolio A\uff1a \u4e00\u5b9a\u6570\u91cf\u7684\u80a1\u7968 \u4e00\u4e2a short call\uff0c\u5728 T \u65f6\u523b\u5230\u671f\uff0c\u6267\u884c\u4ef7\u683c\u4e3a K \u6211\u4eec\u5c06\u8981\u7528\u5230\u7684\u7b26\u53f7\u7ea6\u5b9a\u5982\u4e0b\uff1a \\(S_0\\) : \u671f\u6743\u5728 0 \u65f6\u523b\u4ef7\u503c \\(u\\) : \u80a1\u7968\u5728 T \u65f6\u523b\u4e0a\u6da8\u5e45\u5ea6\uff0c\u6ee1\u8db3 \\(S_u = S_0u\\) \\(d\\) : \u80a1\u7968\u5728 T \u65f6\u523b\u4e0b\u8dcc\u5e45\u5ea6\uff0c\u6ee1\u8db3 \\(S_d = S_0d\\) \\(c\\) : \u5728 0 \u65f6\u523b\uff0c\u671f\u6743\u7684\u4ef7\u683c\uff0c\u5373\u6211\u4eec\u9700\u8981\u6c42\u5f97\u7684\u53d8\u91cf \\(f_u\\) : \u5728 T \u65f6\u523b\uff0c\u80a1\u7968\u4ef7\u683c\u4e0a\u6da8\u65f6\u7684 payoff\uff0c\u5bf9\u4e8e\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u662f \\(\\max(S-K, 0)\\) \\(f_d\\) : \u5728 T \u65f6\u523b\uff0c\u80a1\u7968\u4ef7\u683c\u4e0b\u8dcc\u65f6\u7684 payoff\uff0c\u5bf9\u4e8e\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u662f \\(\\max(S-K, 0)\\) \\(\\Delta\\) : \u4f7f\u5f97 portfolio A \u65e0\u98ce\u9669\u7684\u80a1\u7968\u4ed3\u4f4d \u6240\u8c13\u65e0\u98ce\u9669\uff0c\u5373\u65e0\u8bba\u80a1\u7968\u4ef7\u683c\u4e0a\u5347\u8fd8\u662f\u4e0b\u964d\uff0c\u90fd\u4e0d\u5f71\u54cd portfolio A \u7684\u4ef7\u503c\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\uff1a \\[\\Delta S_0 u - f_u = \\Delta S_0 d - f_d\\] \u6ce8\u610f\uff0c\u7531\u4e8e\u662f\u770b\u6da8\u671f\u6743\u7684\u7a7a\u5934\uff0c\u56e0\u6b64\u90fd\u662f\u51cf\u53bb payoff\u3002 \u6211\u4eec\u53ef\u4ee5\u89e3\u51fa \\(\\Delta\\) \uff1a \\[\\Delta = \\frac{f_u - f_d}{S_0 u - S_0 d}\\] \u7531\u4e8e\u4e0d\u5b58\u5728\u5957\u5229\u673a\u4f1a\uff0c\u800c\u8fd9\u4e2a portfolio \u662f\u65e0\u98ce\u9669\u7684\uff0c\u56e0\u6b64\u5b83\u7684\u6536\u76ca\u5fc5\u7136\u7b49\u4e8e\u65e0\u98ce\u9669\u5229\u7387 \\(r\\) \u3002\u5426\u5219\uff0c\u53ef\u4ee5\u501f\u94b1\u4e70\u5165\u8be5 portfolio\uff0c\u6216\u8005\u5356\u7a7a\u6765\u5957\u5229\u3002 \\[\\Delta S_0 u - f_u = (\\Delta S_0 - c)e^{rT}\\] \u5373 \\[c = (1 - ue^{-rT}) \\Delta S_0 + f_u e^{-rT}\\] \u6211\u4eec\u5c06 \\(\\Delta S_0 = \\frac{f_u - f_d}{u - d}\\) \u5e26\u5165\uff0c\u6709 \\[ c = \\frac{(1 - de^{-rT})f_u - (1 - ue^{-rT})f_d}{u - d}\\] \u6211\u4eec\u5f15\u5165 \\(p = \\frac{e^{rT} - d}{u - d}\\) \uff0c\u5219\u53ef\u4ee5\u5c06\u4e0a\u5f0f\u5199\u4e3a\uff1a \\[ c = e^{-rT}[p f_u + (1-p) f_d]\\]","title":"12.1 \u65e0\u5957\u5229\u5047\u8bbe\u4e0b\u7684\u4e00\u6b65\u4e8c\u53c9\u6811\u6a21\u578b"},{"location":"trading/option/BinomialTree/#1","text":"\u6211\u4eec\u53ef\u4ee5\u7528\u4e00\u4e2a\u5b9e\u9645\u4f8b\u5b50\u6765\u8bf4\u660e\u5982\u4f55\u4f7f\u7528\u8fd9\u4e2a\u516c\u5f0f\u3002 \u5047\u8bbe\u76ee\u524d\u7684\u65e0\u98ce\u9669\u5229\u7387\u662f12%\u3002\u4e00\u4e2a\u80a1\u7968\u73b0\u5728\u4ef7\u503c\u4e3a $20\uff0c\u6211\u4eec\u5df2\u77e5 3 \u4e2a\u6708\u540e\u5b83\u53ef\u80fd\u4e0a\u6da8\u5230 $22\uff0c\u4e5f\u53ef\u80fd\u4e0b\u8dcc\u5230 $18\u3002\u5219\u671f\u9650\u662f 3 \u4e2a\u6708\uff0c\u6267\u884c\u4ef7\u683c\u662f $21 \u7684\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u4ef7\u683c\u662f\u591a\u5c11\uff1f \u6211\u4eec\u53ef\u4ee5\u5f97\u5230 \\(u = 1.1\\) \uff0c \\(d = 0.9\\) \uff0c \\(r = 0.12\\) \uff0c \\(T = 0.25\\) \uff0c \\(f_u = 1\\) \uff0c \\(f_d = 0\\) \u3002 \u4e8e\u662f\u8ba1\u7b97\u5f97\u51fa \\(p = 0.652\\) \uff0ccall \u7684\u4ef7\u683c\u4e3a \\(c = 0.633\\) \u3002","title":"\u4f8b 1"},{"location":"trading/option/BinomialTree/#122","text":"\u6211\u4eec\u5bf9\u98ce\u9669\u7684\u6001\u5ea6\u53ef\u4ee5\u5206\u4e3a\u4ee5\u4e0b\u4e09\u79cd\u7c7b\u578b\uff1a \u98ce\u9669\u538c\u6076 \u6295\u8d44\u8005\u671f\u671b\u4ece\u98ce\u9669\u66f4\u9ad8\u7684\u6295\u8d44\u4e2d\u83b7\u53d6\u66f4\u9ad8\u7684\u6536\u76ca\u3002\u8fd9\u4e5f\u662f\u73b0\u5b9e\u4e16\u754c\u4e2d\u5927\u90e8\u5206\u6295\u8d44\u8005\u7684\u6001\u5ea6\u3002 \u98ce\u9669\u4e2d\u6027 \u6295\u8d44\u8005\u5e76\u4e0d\u8981\u6c42\u4ece\u98ce\u9669\u66f4\u9ad8\u7684\u6295\u8d44\u4e2d\u83b7\u53d6\u66f4\u9ad8\u7684\u6536\u76ca\u3002 \u98ce\u9669\u504f\u597d \u6295\u8d44\u8005\u613f\u610f\u4ece\u9ad8\u98ce\u9669\u7684\u6295\u8d44\u4e2d\u83b7\u53d6\u66f4\u5c11\u7684\u6536\u76ca\u3002 \u7528\u629b\u786c\u5e01\u7684\u8d4c\u5c40\u6765\u4e3e\u4f8b\uff0c\u5047\u8bbe\u4e00\u679a\u5747\u5300\u786c\u5e01\uff0c\u6b63\u9762\u5219\u6295\u8d44\u8005\u83b7\u76ca 100\uff0c\u80cc\u9762\u5219\u635f\u5931\u672c\u91d1\u3002\u56e0\u6b64\u8be5\u8d4c\u5c40\u671f\u671b\u83b7\u76ca 50 \u5757\u3002\u90a3\u4e48\uff1a \u98ce\u9669\u538c\u6076\u7684\u6295\u8d44\u8005\u6700\u591a\u613f\u610f\u82b1\u4f4e\u4e8e 50 \u5757\u672c\u91d1\u53c2\u4e0e\u3002 \u98ce\u9669\u4e2d\u6027\u7684\u6295\u8d44\u8005\u6700\u591a\u613f\u610f\u82b1 50 \u5757\u672c\u91d1\u53c2\u4e0e\u3002 \u98ce\u9669\u504f\u597d\u7684\u6295\u8d44\u8005\u6700\u591a\u613f\u610f\u82b1\u9ad8\u4e8e 50 \u5757\u672c\u91d1\u53c2\u4e0e\u3002 \u6211\u4eec\u5e38\u5e38\u5047\u8bbe\u4e00\u4e2a\u98ce\u9669\u4e2d\u6027\u7684\u4e16\u754c\u6765\u7b80\u5316\u884d\u751f\u54c1\u5b9a\u4ef7\uff1a 1. \u6295\u8d44\u54c1\u7684\u671f\u671b\u56de\u62a5\u7387\u7b49\u4e8e\u65e0\u98ce\u9669\u5229\u7387 2. \u671f\u6743 payoff \u7684\u6298\u73b0\u7387\u7b49\u4e8e\u65e0\u98ce\u9669\u5229\u7387 \u6211\u4eec\u518d\u6765\u770b\u4e4b\u524d\u5f97\u5230\u7684\u671f\u6743\u5b9a\u4ef7\u516c\u5f0f\uff1a \\[ c = e^{-rT}[p f_u + (1-p) f_d]\\] \u6211\u4eec\u6765\u8ba1\u7b97\u4e00\u4e0b\u80a1\u7968\u4ef7\u683c\u5728 \\(T\\) \u65f6\u523b\u540e\u7684\u671f\u671b\uff1a \\[E(S_T) = p S_0 u + (1-p) S_0 d = p S_0 (u - d) + S_0 d\\] \u4ee3\u5165 \\(p = \\frac{e^{rT} - d}{u - d}\\) \u5f97\u5230\uff1a \\[E(S_T) = S_0 e^{rT}\\] \u6211\u4eec\u53d1\u73b0\uff0c\u5047\u8bbe \\(p\\) \u662f\u80a1\u7968\u4ef7\u683c\u4e0a\u6da8\u5230 \\(S_u\\) \u7684\u6982\u7387\uff0c \\(1-p\\) \u662f\u80a1\u7968\u4ef7\u683c\u4e0b\u8dcc\u5230 \\(S_d\\) \u7684\u6982\u7387\uff0c\u5219\u80a1\u7968\u6536\u76ca\u7387\u7684\u671f\u671b\u5c31\u662f\u65e0\u98ce\u9669\u5229\u7387\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u80a1\u7968\u8fd9\u79cd\u5b58\u5728\u98ce\u9669\u7684\u6295\u8d44\u4ea7\u54c1\u7684\u671f\u671b\u6536\u76ca\u7387\u4e0e\u65e0\u98ce\u9669\u5229\u7387\u76f8\u7b49\uff0c\u8fd9\u4e0e \u98ce\u9669\u4e2d\u6027 \u7684\u4e16\u754c\u76f8\u7b26\u3002","title":"12.2 \u98ce\u9669\u4e2d\u6027\u5b9a\u4ef7"},{"location":"trading/option/BinomialTree/#1221","text":"\u5728 12.1 \u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u65e0\u5957\u5229\u7684\u5047\u8bbe\u5f97\u5230 \\(p = \\frac{e^{rT} - d}{u - d}\\) \u3002\u57fa\u4e8e\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u53e6\u4e00\u79cd\u65b9\u6cd5\uff0c\u5373\u6839\u636e\u80a1\u7968\u7684\u671f\u671b\u4ef7\u503c\u6765\u8ba1\u7b97\u3002 \\[ p^{*} S_{u} + (1-p^{*}) S_{d} = 20 e^{rT}\\] \u5e26\u5165\u516c\u5f0f\u4e5f\u53ef\u4ee5\u5f97\u5230 \\(p^{*} = 0.652\\) \u3002 \u5bf9\u4e8e call \u7684\u4ef7\u503c\uff0c\u56e0\u4e3a\u5b83\u5728 \\(T\\) \u65f6\u523b\u6709 \\(p\\) \u7684\u51e0\u7387\u4ef7\u503c \\(S_u - K\\) \uff0c\u4e5f\u6709 \\(1-p\\) \u51e0\u7387\u4ef7\u503c0\uff0c\u56e0\u6b64\u5176\u5f53\u524d\u4ef7\u503c\u4e3a\u5176 payoff \u671f\u671b\u6298\u73b0\u540e\u7684\u7ed3\u679c\uff1a \\[c = p (S_u - K) e^{-rT} = 0.633 \\] \u4e0e 12.1 \u4e2d\u7684\u7ed3\u679c\u76f8\u540c\u3002\u5373\u5229\u7528\u65e0\u5957\u5229\u5047\u8bbe\u548c\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u83b7\u5f97\u7684\u7ed3\u679c\u76f8\u540c\u3002","title":"12.2.1 \u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u4e0b\u7684\u4e00\u6b65\u4e8c\u53c9\u6811\u6a21\u578b"},{"location":"trading/option/BinomialTree/#1222-real-world","text":"\u9700\u8981\u6307\u51fa\u7684\u662f\uff0c \\(p\\) \u662f \u98ce\u9669\u4e2d\u6027 \u5047\u8bbe\u4e0b\u80a1\u7968\u4ef7\u683c\u53d8\u4e3a \\(S_u\\) \u7684\u6982\u7387\u3002\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u8fd9\u548c\u73b0\u5b9e\u4e2d\u5e76\u4e0d\u76f8\u7b49\u3002\u56e0\u4e3a\u73b0\u5b9e\u4e16\u754c\u662f\u98ce\u9669\u538c\u6076\u578b\u7684\uff0c\u56e0\u6b64\u5bf9\u4e8e\u9ad8\u98ce\u9669\u7684\u80a1\u7968\u4f1a\u6709\u66f4\u9ad8\u7684\u6536\u76ca\u671f\u671b\u3002 \u73b0\u5b9e\u4e2d\u5f53\u65e0\u98ce\u9669\u6536\u76ca\u7387\u662f 12% \u65f6\uff0c\u5047\u8bbe\u5bf9\u80a1\u7968\u7684\u6536\u76ca\u671f\u671b\u662f 16%\uff0c\u5219 \\[ 22 p^* + 18(1 - p^*) = 20e^{0.16*3/12}\\] \u8ba1\u7b97\u5f97\u77e5 \\(p^* = 0.704\\) \u3002 \u5728 12.2.1 \u4e2d\u6211\u4eec\u8ba1\u7b97\u671f\u6743\u4ef7\u683c\u65f6\uff0c\u6211\u4eec\u91c7\u7528\u4e86\u4e0e\u80a1\u7968\u76f8\u540c\u7684\u5229\u7387\u5bf9 payoff \u8fdb\u884c\u8d34\u73b0\uff0c\u7136\u800c\u7531\u4e8e\u671f\u6743\u98ce\u9669\u6bd4\u80a1\u7968\u5927\uff0c\u6211\u4eec\u5bf9\u671f\u6743\u6536\u76ca\u7684\u8d34\u73b0\u7387\u5e94\u8be5\u5927\u4e8e 16%\u3002\u6211\u4eec\u65e0\u6cd5\u77e5\u9053\u5b9e\u9645\u7684\u8d34\u73b0\u7387\u56e0\u6b64\u65e0\u6cd5\u8ba1\u7b97\u3002 \u53ea\u6709\u5728\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u4e0b\uff0c\u6211\u4eec\u5bf9\u6240\u6709\u7684\u8d44\u4ea7\u56de\u62a5\u7387\u7684\u671f\u671b\u503c\u624d\u80fd\u90fd\u7b49\u4e8e\u65e0\u98ce\u9669\u5229\u7387\uff0c\u4ece\u800c\u53ef\u4ee5\u8ba1\u7b97\u671f\u6743\u7684\u4ef7\u683c\u3002","title":"12.2.2 Real World"},{"location":"trading/option/BinomialTree/#123","text":"\u5047\u8bbe\u5728\u4e0a\u56fe\u4e2d\uff0c\u6bcf\u4e00\u6b65\u65f6\u95f4\u4e3a 3 \u4e2a\u6708\uff0c\u80a1\u7968\u53ef\u80fd\u4e0a\u6da8\u6216\u8005\u4e0b\u8dcc 10%\u3002 \u6211\u4eec\u5e0c\u671b\u8ba1\u7b97\u4e00\u4e2a\u6267\u884c\u4ef7\u683c 21\uff0c\u671f\u9650 6 \u4e2a\u6708\u7684 call \u7684\u4ef7\u503c\u3002 \u7531\u4e8e\u6bcf\u4e00\u6b65\u4e0a\u6da8/\u4e0b\u8dcc\u5e45\u5ea6\u662f\u4e00\u81f4\u7684\uff0c\u56e0\u6b64\u8ba1\u7b97\u6240\u5f97\u7684\u4e0a\u6da8/\u4e0b\u8dcc\u7684\u6982\u7387\u4e5f\u662f\u4e00\u81f4\u7684\u3002 \u6211\u4eec\u76f4\u63a5\u4ece\u6700\u7ec8\u72b6\u6001\u5165\u624b\uff0c \\[f = e^{-2r \\Delta t}[p^2 f_{uu} + 2p(1-p)f_{ud} +(1-p)^2f_{dd}]\\] \u5176\u4e2d \\(p = \\frac{e^{rT} - d}{u - d}\\) \u3002","title":"12.3 \u4e24\u6b65\u4e8c\u53c9\u6811"},{"location":"trading/option/BinomialTree/#1231-delta","text":"\u6211\u4eec\u4e4b\u524d\u5728\u4e00\u6b65\u4e8c\u53c9\u6811\u4e2d\u5df2\u7ecf\u7528\u5230\u4e86 \\(\\Delta\\) \uff0c\u5b83\u662f\u5f53\u6211\u4eec\u5356\u51fa\u4e00\u4efd\u671f\u6743\u65f6\uff0c\u4e3a\u4e86\u6784\u9020\u65e0\u98ce\u9669\u7ec4\u5408\u9700\u8981\u6301\u6709\u7684\u6807\u7684\u8d44\u4ea7\u6570\u91cf\u3002\u5b83\u4ee3\u8868\u4e86\u671f\u6743\u4ef7\u683c\u53d8\u5316\u4e0e\u80a1\u7968\u4ef7\u683c\u53d8\u5316\u7684\u6bd4\u7387\u3002 \u56e0\u6b64\uff0c\u5bf9\u4e8e 12.1 \u4f8b 1 \u4e2d\u7684 \\(\\Delta\\) \uff0c\u6211\u4eec\u7528\u5982\u4e0b\u5f0f\u5b50\u8ba1\u7b97\uff1a \\[ \\Delta = = \\frac{f_u - f_d}{S_0 u - S_0 d} = \\frac{1-0}{22-18} = 0.25\\] \u5728\u4e24\u6b65\u4e8c\u53c9\u6811\u4e2d\uff0c\u6211\u4eec\u53d1\u73b0 \\(\\Delta\\) \u662f\u968f\u65f6\u95f4\u53d8\u5316\u7684\u3002\u56e0\u6b64\u65e0\u6cd5\u6784\u9020\u4e00\u4e2a portfolio \u4f7f\u5b83\u5728\u5230\u671f\u65e5\u524d\u90fd\u4fdd\u6301\u98ce\u9669\u4e2d\u6027\u3002\u5728\u5b9e\u9645\u4e2d\uff0c\u6211\u4eec\u9700\u8981\u4e0d\u65ad\u8c03\u8282\u6301\u6709\u80a1\u7968\u7684\u6570\u91cf\u6765\u8fdb\u884c\u5bf9\u51b2\u3002","title":"12.3.1 Delta"},{"location":"trading/option/BinomialTree/#125","text":"\u6211\u4eec\u4e4b\u524d\u8ba8\u8bba\u7684\u90fd\u662f\u6b27\u5f0f\u671f\u6743\uff0c\u56e0\u6b64\u53ef\u4ee5\u53ea\u4f9d\u8d56\u6700\u7ec8\u72b6\u6001\u6765\u786e\u5b9a\u4ef7\u683c\u3002\u4f46\u662f\u5bf9\u4e8e\u7f8e\u5f0f\u671f\u6743\uff0c\u7531\u4e8e\u53ef\u4ee5\u63d0\u524d\u884c\u6743\uff0c\u5728\u6bcf\u4e00\u6b65\uff0c\u671f\u6743\u7684 payoff \u90fd\u5e94\u8be5\u53d6\u4ee5\u4e0b\u4e24\u4e2a\u503c\u7684\u6700\u5927\u503c\uff1a \u901a\u8fc7 \\(f = e^{-r \\Delta t}[pf_u + (1-p)f_d]\\) \u8ba1\u7b97\u51fa\u7684 payoff \u7acb\u5373\u884c\u6743\u7684 payoff \u5047\u8bbe\u80a1\u7968\u4ef7\u683c\u53d8\u5316\u5982\u4e0b\u56fe\u3002\u6bcf\u6b65\u65f6\u95f4\u4e3a 1 \u5e74\uff0c\u53ef\u80fd\u6709 20% \u7684\u4e0a\u6da8\u6216\u8005\u4e0b\u8dcc\u3002\u65e0\u98ce\u9669\u5229\u7387\u4e3a 5%\u3002 \u6ce8\u610f\u4e0a\u56fe\u7684 C \u70b9\u3002 \u6211\u4eec\u9996\u5148\u8ba1\u7b97 \\(p = \\frac{e^{rT} - d}{u - d} = 0.6282\\) \uff0c\u5219\u5728 C \u70b9\u65f6\uff0c \\(f = 9.4636\\) \u3002\u7136\u800c\uff0c\u5047\u8bbe\u9009\u62e9\u5728 C \u70b9\u65f6\u7acb\u5373\u884c\u6743\uff0c\u6211\u4eec\u53ef\u4ee5\u83b7\u5f97 $12\u3002\u56e0\u6b64\u5728 C \u70b9\u671f\u6743\u7684\u4ef7\u503c\u4e3a 12 \u800c\u975e 9.4636\u3002 \u5728 B \u70b9\uff0c\u671f\u6743\u4ef7\u503c\u4e3a 1.4147\uff0c\u5728 A \u70b9\uff0c\u671f\u6743\u4ef7\u503c\u4e3a 5.0894\u3002","title":"12.5 \u7f8e\u5f0f\u671f\u6743"},{"location":"trading/option/BinomialTree/#127-u-d","text":"\u5728\u5b9e\u9645\u4e2d\uff0c\u5f53\u6211\u4eec\u6784\u9020\u4e8c\u53c9\u6811\u6765\u8868\u793a\u80a1\u7968\u4ef7\u683c\u53d8\u5316\u65f6\uff0c\u6211\u4eec\u9700\u8981\u9009\u53d6\u6070\u5f53\u7684 \\(u\\) \u548c \\(d\\) \u4f7f\u80a1\u7968\u7684\u53d8\u5316\u548c\u6ce2\u52a8\u7387 \\(\\sigma\\) \u4e00\u81f4\u3002\u90a3\u6211\u4eec\u7a76\u7adf\u9700\u8981\u5339\u914d\u73b0\u5b9e\u4e2d\u7684\u6ce2\u52a8\u7387\uff0c\u8fd8\u662f\u98ce\u9669\u4e2d\u6027\u7684\u6ce2\u52a8\u7387\u5462\uff1f \u6211\u4eec\u9a6c\u4e0a\u5c06\u8981\u8bc1\u660e\uff0c \u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u6ce2\u52a8\u7387\u548c\u98ce\u9669\u4e2d\u6027\u4e16\u754c\u4e2d\u7684\u6ce2\u52a8\u7387\u662f\u76f8\u7b49\u7684 \u3002 \u80a1\u7968\u4ef7\u683c\u53d8\u5316\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u5047\u8bbe\u80a1\u7968\u7684\u6ce2\u52a8\u7387 \\(\\sigma\\) \uff0c\u5219\u80a1\u7968\u56de\u62a5\u7387\u7684\u65b9\u5dee\u4e3a \\(\\sigma^2 \\Delta t\\) \u3002 \u5bf9\u4e8e\u73b0\u5b9e\u4e16\u754c\uff0c\u80a1\u7968\u6709 \\(p^*\\) \u7684\u6982\u7387\u56de\u62a5\u7387\u4e3a \\(u -1\\) \uff0c\u540c\u65f6\u6709 \\(1-p^*\\) \u7684\u6982\u7387\u56de\u62a5\u7387\u4e3a \\(d - 1\\) \u3002\u7531\u4e8e +1 \u5e76\u4e0d\u5f71\u54cd\u65b9\u5dee\uff0c\u6211\u4eec\u53ef\u4ee5\u8f6c\u4e3a\u8ba1\u7b97\u80a1\u7968 \u7ec8\u503c/\u521d\u503c \u7684\u65b9\u5dee\u3002 \\[D(x) = E(x^2) - [E(x)]^2\\] \u56e0\u6b64\u6709 \\[ [p^* u^2 + (1-p^*)d^2] - [p^*u + (1-p^*)d]^2 = \\sigma^2 \\Delta t\\] \u5316\u7b80\u5f97\u5230 \\[ p^* (1-p^*)(u-d)^2 = \\sigma^2 \\Delta t\\] \u53e6\u4e00\u65b9\u9762\uff0c\u5047\u8bbe\u73b0\u5b9e\u4e2d\u6211\u4eec\u5bf9\u80a1\u7968\u6536\u76ca\u7684\u671f\u671b\u56de\u62a5\u7387\u662f \\(\\mu\\) \uff0c\u5219\u6709\uff1a \\[ p^{*} S_0 u+ (1-p^{*}) S_0 d = S_0 e^{\\mu \\Delta t} \\] \\[p^* = \\frac{e^{\\mu \\Delta t} - d}{u - d} \\] \u4ece\u800c\u5f97\u5230 \\[(e^{\\mu \\Delta t} - d)(e^{\\mu \\Delta t} - u) + \\sigma^2 \\Delta t = 0\\] \u5c06\u4e0a\u5f0f Taylor \u5c55\u5f00\u5e76\u5ffd\u7565 \\(\\Delta t\\) \u7684\u9ad8\u6b21\u9879\uff0c\u53ef\u4ee5\u5f97\u5230 \\(u, d\\) \u7684\u4e00\u7ec4\u89e3\uff1a \\[u = e^{\\sigma \\sqrt{\\Delta t}}\\] \\[d = e^{- \\sigma \\sqrt{\\Delta t}}\\] \uff08\u6211\u597d\u50cf\u6ca1\u6709\u529e\u6cd5\u901a\u8fc7\u6cf0\u52d2\u7ea7\u6570\u5f97\u5230\u540c\u6837\u7684\u7ed3\u679c\uff0c\u6682\u4e14\u5148\u7559\u7740\uff09","title":"12.7 \u4f7f \\(u\\) \u548c \\(d\\) \u4e0e\u6ce2\u52a8\u7387\u543b\u5408"},{"location":"trading/option/Greeks/","text":"The Greek letters Greeks \u662f\u4e3a\u63cf\u8ff0\u671f\u6743\u6301\u4ed3\u98ce\u9669\u5f15\u5165\u7684\uff0c\u4ed6\u4eec\u5404\u81ea\u4ee3\u8868\u4e00\u4e2a\u7ef4\u5ea6\u7684\u98ce\u9669\u3002 18.4 Delta delta ( \\(\\Delta\\) ) \u8868\u793a\u671f\u6743\u4ef7\u683c\u53d8\u52a8\u4e0e\u6807\u7684\u7269\u4ef7\u683c\u53d8\u52a8\u4e4b\u95f4\u7684\u6bd4\u7387\u3002\u82e5\u5047\u8bbe \\(c\\) \u4e3a\u770b\u6da8\u671f\u6743\u4ef7\u683c\uff0c \\(S\\) \u4e3a\u5bf9\u5e94\u7684\u80a1\u7968\u4ef7\u683c\uff0c\u5219\u6709\uff1a \\[\\Delta = \\frac{\\partial c}{\\partial S}\\] \u4f8b\u5982\uff0c\u67d0\u80a1\u7968\u4ef7\u683c\u4e3a $100\uff0c\u5b83\u7684\u67d0\u4e2a\u770b\u6da8\u671f\u6743\u4ef7\u683c\u4e3a $10\u3002\u4e00\u4e2a\u6295\u8d44\u8005\u5356\u4e86 20 \u4efd\u770b\u6da8\u671f\u6743\uff08\u6bcf\u4efd 100 share\uff0c\u5171 2000 share\uff09\u3002\u8fd9\u4e2a\u6295\u8d44\u8005\u7684\u4ed3\u4f4d\u53ef\u4ee5\u901a\u8fc7\u8d2d\u4e70 \\(0.6 \\times 2000 = 1200\\) share \u80a1\u7968\u5bf9\u51b2\uff0c\u4f7f\u6574\u4e2a\u7ec4\u5408\u7684 delta \u4e3a 0\uff0c\u5373 delta \u4e2d\u6027\u3002 \u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u7531\u4e8e\u671f\u6743\u7684 delta \u662f\u4e00\u76f4\u53d8\u5316\u7684\uff0c\u4e0a\u9762\u4f8b\u5b50\u4e2d\u7684 delta \u4e2d\u6027\u53ea\u80fd\u4fdd\u6301\u975e\u5e38\u77ed\u7684\u4e00\u6bb5\u65f6\u95f4\u3002 \u5047\u8bbe\u8fc7\u4e00\u6bb5\u65f6\u95f4\uff0c\u8be5\u80a1\u7968\u4ef7\u683c\u6da8\u5230\u4e86 $110\uff0c\u770b\u6da8\u671f\u6743\u7684 delta \u968f\u4e4b\u4e0a\u6da8\u5230 0.65\u3002\u5219\u6211\u4eec\u9700\u8981\u989d\u5916\u518d\u4e70\u5165 \\(0.05 \\times 2000 = 100\\) share \u6765\u4fdd\u6301 delta \u4e2d\u6027\u3002\u8fd9\u6837\u6301\u7eed\u4f9d\u636e\u6700\u65b0\u7684 delta \u8fdb\u884c\u5bf9\u51b2\u7684\u8fc7\u7a0b\u88ab\u79f0\u4e3a\u52a8\u6001\u5bf9\u51b2( dynamic hedging )\u3002\u5426\u5219\u88ab\u79f0\u4e3a\u9759\u6001\u5bf9\u51b2\u3002 18.4.1 \u6b27\u5f0f\u671f\u6743\u7684 Delta \u5bf9\u4e8e\u4e00\u4e2a\u6b27\u5f0f\u770b\u6da8\u671f\u6743\uff0c\u5229\u7528 B-S-M \u516c\u5f0f\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\uff1a \\[\\Delta_{call} = \\Phi(d_1)\\] \u5bf9\u4e8e\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\uff0c\u5219\u6709\uff1a \\[\\Delta_{put} = \\Delta_{call} - 1\\] \u8bc1\u660e \u7531 B-S-M \u516c\u5f0f\u7a0d\u4f5c\u53d8\u5f62\uff08\u8ba1\u7b97 \\(t\\) \u65f6\u523b\u800c\u975e 0 \u65f6\u523b\u7684\u4ef7\u683c\uff09\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\uff1a \\[c = S \\Phi(d_1) - Ke^{-r(T-t)}\\Phi(d_2)\\] \u6211\u4eec\u4e0d\u80fd\u7b80\u5355\u5f97\u5230\u7ed3\u679c\uff0c\u56e0\u4e3a \\(d_1\\) \u548c \\(d_2\\) \u90fd\u662f\u5173\u4e8e \\(S\\) \u7684\u51fd\u6570\uff1a \\[d_1 = \\frac{\\ln(\\frac{ S }{ K }) + (r + \\frac{ 1}{ 2} \\sigma^2)(T-t)} {\\sigma \\sqrt{T-t}}\\] \\[d_2 = d_1 - \\sigma \\sqrt{T-t}\\] \u6211\u4eec\u5229\u7528\u6c42\u5bfc\u516c\u5f0f\u6709\uff1a \\[\\frac{ \\partial c}{ \\partial S} = \\Phi(d_1) + S\\Phi'(d_1)\\frac{ \\partial d_1}{ \\partial S} - Ke^{-r(T-t)}\\Phi'(d_2)\\frac{ \\partial d_2}{ \\partial S}\\] \u5176\u4e2d \\(\\Phi'(x)\\) \u662f\u6b63\u6001\u5206\u5e03\u7684\u5bc6\u5ea6\u51fd\u6570\uff1a \\[\\Phi'(x) = \\frac{1}{ \\sqrt{2\\pi}}e^{-\\frac{ x^2}{2}}\\] \u6211\u4eec\u5f88\u5bb9\u6613\u5f97\u5230\uff1a \\[\\frac{\\partial d_1}{\\partial S} = \\frac{\\partial d_2}{\\partial S} = \\frac{1}{S\\sigma \\sqrt{T-t}}\\] \u800c\u5229\u7528 \\(d_1 = d_2 + \\sigma \\sqrt{T-t}\\) \u53ef\u4ee5\u5f97\u5230\uff1a \\[S\\Phi'(d_1) = \\frac{S}{\\sqrt{2\\pi}}e^{-\\frac{(d_2 + \\sigma \\sqrt{T-t})^2}{2}} = Se^{-d_2\\sigma\\sqrt{T-t} ~-\\frac{1}{2}\\sigma^2(T-t)}\\Phi'(d_2)\\] \u4ee3\u5165 \\(d_2\\) \uff1a \\[d_2 = \\frac{\\ln(\\frac{S}{K}) + (r - \\frac{1}{2}\\sigma^2)(T-t)}{\\sigma \\sqrt{T-t}}\\] \u53ef\u4ee5\u5f97\u5230\uff1a \\[S\\Phi'(d_1) = Se^{-\\ln(\\frac{S}{K}) - r (T-t)} \\Phi'(d_2) = Ke^{-r(T-t)}\\Phi'(d_2)\\] \u56e0\u6b64\u6709\uff1a \\[\\frac{\\partial c}{\\partial S} = \\Delta = \\Phi(d_1)\\] \u5bf9\u4e8e\u770b\u8dcc\u671f\u6743\uff0c\u53ef\u4ee5\u7531 put-call-parity \u5f97\u5230\u3002 \u5178\u578b\u7684 \\(\\Delta\\) \u4e0e\u6807\u7684\u7269\u4ef7\u683c\u7684\u5173\u7cfb\u56fe\u5982\u4e0b\uff1a \u53ef\u4ee5\u770b\u5230 call \u548c put \u4e24\u8005\u8d8b\u52bf\u4e00\u81f4\uff0c\u5dee\u8ddd 1.0\u3002 call \u7684 \\(\\Delta\\) \u4e0e\u5230\u671f\u65f6\u95f4\u7684\u5173\u7cfb\u56fe\u5982\u4e0b\uff1a \u5373\uff0c\u79bb\u5230\u671f\u65e5\u8d8a\u8fd1\uff0cOTM \u4f1a\u8d8a\u6765\u8d8a\u4e0d\u503c\u94b1\uff0cDelta \u8d8b\u8fd1\u4e8e 0\u3002 ITM \u7684 Delta \u5219\u4f1a\u8d8b\u8fd1\u4e8e 1\u3002\u8fd9\u7b26\u5408\u76f4\u89c2\u3002 \u6709\u79cd\u8bf4\u6cd5\u662f\uff0c\u5c06 Delta \u7406\u89e3\u4e3a\u671f\u6743\u5230\u671f\u65f6 In The Money \u7684\u6982\u7387\u3002\u8fd9\u5e76\u4e0d\u662f\u5f88\u51c6\u786e\uff0c\u6211\u4eec\u5728 \u7b2c\u5341\u56db\u7ae0 \u4f8b 5 \u4e2d\u5df2\u7ecf\u8bc1\u660e\u4e86\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u6b27\u5f0f\u770b\u6da8\u671f\u6743\uff0c\u5230\u671f\u65f6 In The Money \u7684\u6982\u7387\u662f \\(\\Phi(d_2)\\) \u800c\u4e0d\u662f \\(\\Delta = \\Phi(d_1)\\) \u3002\u51c6\u786e\u7684\u8bf4\u5b83\u53ea\u662f\u8fd9\u4e2a\u6982\u7387\u7684\u4e00\u4e2a proxy\uff0c\u5982 Delta of Calls vs. Puts and Probability of Expiring In the Money \u6240\u63cf\u8ff0\u7684\u3002 18.4.3 \u8fdc\u671f\u5408\u7ea6 Delta \u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u4e00\u4e2a\u8fdc\u671f\u5408\u7ea6\u7684\u4ef7\u503c\u4e3a\uff1a \\[f = S_0 - Ke^{-rT}\\] \u5176\u4e2d \\(K\\) \u662f\u4ea4\u5272\u4ef7\u683c\uff0c \\(T\\) \u662f\u8ddd\u79bb\u5230\u671f\u65e5\u65f6\u95f4\u3002\u56e0\u6b64\u82e5\u80a1\u7968\u4ef7\u683c\u53d8\u5316 \\(\\Delta S\\) \uff0c\u5219\u8fdc\u671f\u5408\u7ea6\u4ef7\u683c\u4e5f\u53d8\u5316 \\(\\Delta S\\) \u3002\u8fd9\u8bf4\u660e\u5b83\u7684 Delta \u6052\u7b49\u4e8e 1.0\uff0c\u4e0e\u73b0\u8d27\u4e00\u81f4\u3002 18.4.4 \u671f\u8d27\u7684 Delta \u671f\u8d27\u7684\u5408\u7ea6\u4ef7\u683c\u4e3a\uff1a \\[F = S_0e^{rT}\\] \u5176\u4e2d \\(S_0\\) \u4e3a\u5f53\u524d\u73b0\u8d27\u4ef7\u683c\uff0c \\(T\\) \u4e3a\u8ddd\u79bb\u4ea4\u5272\u65e5\u65f6\u95f4\u3002 \u56e0\u6b64\u4e00\u4e2a\u671f\u8d27\u7684 Delta \u5c31\u662f \\(e^{rT}\\) \uff0c\u5728 \\(r > 0\\) \u65f6\u6709 \\(\\Delta > 1\\) \u3002\u8fd9\u770b\u8d77\u6765\u53ef\u80fd\u5f88\u5947\u602a\uff0c\u56e0\u4e3a\u671f\u8d27\u662f\u6bcf\u5929 settle\uff0c\u56e0\u6b64\u51e0\u4e4e\u80fd\u7acb\u5373\u62ff\u5230\u8fd9\u4e2a\u94b1\u3002 \u6709\u65f6\u6211\u4eec\u7528\u671f\u8d27\u5408\u7ea6\u6765\u8fbe\u6210 Delta \u4e2d\u6027\u3002\u5047\u8bbe \\(T\\) \u662f\u8ddd\u79bb\u671f\u8d27\u5230\u671f\u65e5\u65f6\u95f4\uff0c \\(H_A\\) \u662f\u7528\u6807\u7684\u7269\u8d44\u4ea7\u5bf9\u51b2\u9700\u8981\u7684\u7684\u4ed3\u4f4d\uff0c \\(H_F\\) \u662f\u7528\u671f\u8d27\u5bf9\u51b2\u65f6\u9700\u8981\u7684\u4ed3\u4f4d\u3002\u6709\uff1a \\[H_F = e^{-rT}H_A\\] \u6b27\u5f0f\u671f\u8d27\u671f\u6743\u7684 Delta \u901a\u5e38\u88ab\u5b9a\u4e49\u4e3a\u4e0e \u671f\u8d27\u4ef7\u683c\uff08\u800c\u975e\u5373\u671f\u4ef7\u683c\uff09 \u76f8\u5173\u7684\u671f\u6743\u4ef7\u683c\u53d8\u5316\u7387\uff0c\u5373 \u8fdc\u671f\uff08\u800c\u975e\u5373\u671f\uff09 \u7684 Delta\u3002 \u8bc1\u660e \u5df2\u77e5\u671f\u8d27\u4ef7\u683c \\(F\\) \u6ee1\u8db3\uff1a \\[F = S_0 e^{rT}\\] \u5982\u679c\u671f\u8d27\u7684\u5230\u671f\u65e5\u4e3a \\(T_1\\) \uff0c\u671f\u6743\u7684\u5230\u671f\u65e5\u4e3a \\(T_2\\) \uff0c\u90a3\u4e48\u53ef\u4ee5\u5c06 \\(d_1\\) \u8868\u793a\u4e3a\uff1a \\[d_1 = \\frac{\\ln(\\frac{Fe^{-rT_2}}{K}) + (r + \\frac{1}{2}\\sigma^2)T_1}{\\sigma \\sqrt{T_1}} = \\frac{\\ln(\\frac{F}{K}) + r(T_1 - T_2) + \\frac{1}{2}\\sigma^2T_1}{\\sigma \\sqrt{T_1}} \\] \u5047\u8bbe \\(T_1 = T_2 = T\\) \u90a3\u4e48\u8fd9\u4e2a\u671f\u6743\u5173\u4e8e \u73b0\u8d27 \u7684 Delta \u5c31\u53ef\u4ee5\u5199\u4e3a\uff1a \\[\\Delta = \\Phi(d_1) = \\Phi(\\frac{\\ln(\\frac{F}{K}) + \\frac{1}{2}\\sigma^2T} {\\sigma \\sqrt{T}})\\] \u7531\u4e8e\u73b0\u8d27\u7684 Delta \u662f 1\uff0c\u800c\u671f\u8d27\u7684 Delta \u662f \\(e^{rT}\\) \uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u51fa\u8be5\u671f\u6743\u5173\u4e8e \u671f\u8d27 \u7684 Delta\uff1a \\[\\Delta_F = e^{-rT} \\Delta \\] \u4f8b 1 \u5047\u8bbe\u67d0\u767d\u94f6\u671f\u8d27\u4ea4\u5272\u65e5\u5728 9 \u4e2a\u6708\u4ee5\u540e\uff0c\u4ea4\u5272\u4ef7\u683c\u4e3a $8 \u6bcf\u76ce\u53f8\u3002\u540c\u65f6\u67d0\u4e2a\u767d\u94f6\u7684\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u5230\u671f\u65e5\u5728 8 \u4e2a\u6708\u4ee5\u540e\uff0c\u6267\u884c\u4ef7\u683c\u4e3a $8 \u6bcf\u76ce\u53f8\u3002\u65e0\u98ce\u9669\u5229\u7387\u4e3a 12% \u6bcf\u5e74\uff0c\u767d\u94f6\u7684\u6ce2\u52a8\u7387\u4e3a 18% \u6bcf\u5e74\u3002 \u5219 1000 \u4efd\u8be5\u767d\u94f6\u671f\u8d27\u7684\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u7a7a\u5934\u7684 Delta \u662f\u591a\u5c11\uff1f \u7531\u4e8e\u671f\u8d27\u671f\u6743\u7684 Delta \u5b9a\u4e49\u4e3a\u4e0e \u671f\u8d27\u4ea4\u5272\u4ef7\u683c \u76f8\u5173\u7684\u53d8\u5316\u7387\uff0c\u56e0\u6b64\u8fd9\u91cc\u6211\u4eec\u9700\u8981\u8ba1\u7b97\uff1a \\[d_1 = \\frac{\\ln(\\frac{F}{K}) + r(T_1 - T_2) + \\frac{1}{2}\\sigma^2 T_1}{\\sigma \\sqrt{T_1}} = 0.00544331 \\] \u7136\u540e\u53ef\u4ee5\u7ee7\u7eed\u5f97\u5230 \\[\\Delta = e^{-rT}\\Phi(d_1) = e^{-0.12*9/12} \\times 0.5022 = 0.4590\\] \u56e0\u6b641000\u4efd\u8be5\u671f\u6743\u7a7a\u5934\u7684 Delta \u4e3a -459.0\uff0c\u6ce8\u610f\u8fd9\u4e2a Delta \u662f\u5173\u4e8e\u671f\u8d27\u7684 Delta\u3002 \u4f8b 2 \u5728\u4f8b 1 \u4e2d\uff0c\u4e3a\u4e86\u5bf9\u51b2\u5fc5\u9700\u7684\u767d\u94f6\u671f\u8d27\u521d\u59cb\u4ed3\u4f4d\u662f\u591a\u5c11\uff1f\u5982\u679c\u76f4\u63a5\u7528\u767d\u94f6\u73b0\u8d27\u5bf9\u51b2\uff0c\u521d\u59cb\u4ed3\u4f4d\u53c8\u8be5\u662f\u591a\u5c11\uff1f\u5982\u679c\u7528\u8fd8\u6709 12 \u4e2a\u6708\u5230\u671f\u7684\u767d\u94f6\u671f\u8d27\u5462\uff1f\u5ffd\u7565\u767d\u94f6\u7684\u5b58\u653e\u8d39\u7528\u3002 \u82e5\u7528 9 \u4e2a\u6708\u540e\u5230\u671f\u7684\u671f\u8d27\u8fdb\u884c\u5bf9\u51b2\uff0c\u5219\u5e94\u8be5\u7528 459.0 \u76ce\u53f8\u3002 \u82e5\u7528\u767d\u94f6\u73b0\u8d27\uff0c\u5219\u9700\u8981\u628a\u8fdc\u671f Delta \u8f6c\u4e3a\u5373\u671f\u7684\uff0c\u5373 502.2 \u76ce\u53f8\u3002 \u82e5\u7528 12 \u4e2a\u6708\u5230\u671f\u7684\uff0c\u5219\u4ee5\u5373\u671f\u7684\u4e58\u4ee5 \\(e^{-0.12}\\) \uff0c\u5f97 445.4 \u76ce\u53f8\u3002 18.5 Theta Theta( \\(\\Theta\\) ) \u7528\u4e8e\u63cf\u8ff0 portfolio \u4ef7\u503c\u968f\u65f6\u95f4\u7684\u53d8\u5316\u7387\uff0c\u5373 time decay\u3002\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\[\\Theta = \\frac{\\partial c}{\\partial t}\\] \u5bf9\u4e8e call \u6709\uff1a \\[\\Theta_{call} = -\\frac{ S_0 \\Phi'(d_1)\\sigma} { 2 \\sqrt{T-t}} - rKe^{-r(T-t)}\\Phi(d_2)\\] \u5bf9\u4e8e put \u6709\uff1a \\[\\Theta_{put} = \\Theta_{call} + rKe^{-r(T-t)} \\] \u5176\u4e2d \\[\\Phi'(x) = \\frac{ 1}{ \\sqrt{2\\pi} }e^{-\\frac{ x^2 }{ 2}}\\] \u6211\u4eec\u901a\u8fc7\u516c\u5f0f\u53d1\u73b0\uff0c\u5bf9\u4e8e call\uff0c \\(\\Theta\\) \u603b\u662f\u5c0f\u4e8e 0 \u7684 \u3002\u5373\u968f\u7740\u5230\u671f\u65e5\u4e34\u8fd1\uff0c\u671f\u6743\u8d8a\u6765\u8d8a\u4e0d\u503c\u94b1\u3002 \u4f46\u662f\u6709\u4e00\u4e2a\u4f8b\u5916\u5c31\u662f\u5bf9\u4e8e deep in the money \u7684 put\uff0c \\(\\Theta\\) \u53ef\u80fd\u4e3a\u6b63\u3002\u76f4\u89c2\u4e0a\uff0c\u5047\u8bbe\u67d0\u4e2a\u80a1\u7968\u4ef7\u683c\u5df2\u7ecf\u8dcc\u5230\u63a5\u8fd10\uff0c\u968f\u7740\u5230\u671f\u65e5\u4e34\u8fd1\uff0c\u8be5\u80a1\u7968\u4e0a\u6da8\u7684\u6982\u7387\u8d8a\u4f4e\uff0c\u6240\u4ee5\u5b83\u7684 put \u5177\u6709\u66f4\u5927\u7684\u786e\u5b9a\u6027\u8d5a\u94b1\u3002 \u5173\u4e8e\u8fd9\u70b9\uff0c\u53ef\u4ee5\u53c2\u8003 \u80a1\u7968\u671f\u6743\u7684\u6027\u8d28 \u4e2d\u7684\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\u7684\u4e0a\u4e0b\u9650\u5206\u6790\u90e8\u5206\u3002\u5728\u5176\u4e2d\u6211\u4eec\u6307\u51fa\u4e86\u5bf9\u4e8e deep in the money \u7684 put\uff0c\u5b83\u7684\u65f6\u95f4\u4ef7\u503c\u4e3a\u8d1f\u3002\u800c\u671f\u6743\u968f\u7740\u5230\u671f\u65e5\u4e34\u8fd1\uff0c\u65f6\u95f4\u4ef7\u503c\u603b\u662f\u8d8b\u8fd1\u4e8e0\u3002\u56e0\u6b64\u5fc5\u7136\u6709\u4e00\u4e2a\u6e10\u6e10\u589e\u5927\u7684\u8fc7\u7a0b\u3002 \u8bc1\u660e \u6211\u4eec\u9700\u8981\u5229\u7528 B-S-M \u516c\u5f0f\u5f97\u51fa\u671f\u6743\u4ef7\u683c\u76f8\u5bf9\u4e8e\u65f6\u95f4\u7684\u5bfc\u6570\u3002\u6ce8\u610f\uff0c\u8fd9\u91cc\u4e0d\u80fd\u76f4\u63a5\u5bf9 \\(T\\) \u6c42\u5bfc\uff0c\u56e0\u4e3a\u5b83\u662f\u5230\u671f\u65f6\u95f4\uff0c\u6211\u4eec\u5b9e\u9645\u9700\u8981\u5bf9 \\(t\\) \u6c42\u5bfc\u3002 \u5148\u5c06 B-S-M \u5199\u6210\u5728 \\(t\\) \u65f6\u523b\u800c\u975e \\(0\\) \u65f6\u523b\u7684\u8868\u8fbe\u5f62\u5f0f\uff1a \\[c = S_t\\Phi(d_1) - Ke^{-r(T-t)}\\Phi(d_2)\\] \u5176\u4e2d\uff1a \\[d_1 = \\frac{ \\ln(\\frac{S_t}{ K}) + (r + \\frac{ 1}{ 2}\\sigma^2)(T-t)}{\\sigma \\sqrt{T-t}}\\] \\[d_2 = d_1 - \\sigma \\sqrt{T-t}\\] \u5bf9 \\(t\\) \u6c42\u5bfc\uff0c\u6709\uff1a \\[\\frac{\\partial c}{\\partial t} = S_t\\Phi'(d_1)\\frac{\\partial d_1}{\\partial t} - Ke^{-r(T-t)}\\Phi'(d_2)\\frac{\\partial d_2}{\\partial t} - rKe^{-r(T-t)}\\Phi(d_2)\\] \u6211\u4eec\u5df2\u7ecf\u5728\u8bc1\u660e \\(\\Delta = \\Phi(d_1)\\) \u8fc7\u7a0b\u4e2d\u5f97\u5230\uff1a \\[S_t\\Phi'(d_1) = Ke^{-r(T-t)}\\Phi'(d_2)\\] \u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\uff1a \\[\\frac{\\partial c}{\\partial t} = S_t\\Phi'(d_1)\\frac{\\partial(d_1 - d_2)}{\\partial t} - rKe^{-r(T-t)}\\Phi(d_2) = -\\frac{\\sigma S_t}{2\\sqrt{T-t}}\\Phi'(d_1) - rKe^{-r(T-t)}\\Phi(d_2)\\] \u5bf9\u4e8e\u4e00\u4e2a put\uff0cB-S-M \u516c\u5f0f\u4e3a\uff1a \\[p = c + Ke^{-r(T-t)} - S_t\\] \u663e\u7136\u6709\uff1a \\[\\frac{\\partial p}{\\partial t} = \\frac{\\partial c}{\\partial t} + rKe^{-r(T-t)}\\] \u5178\u578b\u7684 call \u7684 \\(\\Theta\\) \u4e0e\u80a1\u7968\u4ef7\u683c\u5173\u7cfb\u7684\u66f2\u7ebf\u5982\u4e0b\uff1a \u5f53\u80a1\u7968\u4ef7\u683c\u8db3\u591f\u9ad8\u65f6\uff0c \\(d_1\\) \u548c \\(d_2\\) \u8d8b\u8fd1\u4e8e\u65e0\u9650\u5927\u3002\u6b64\u65f6 \\(\\Phi'(d_1) \\to 0\\) \uff0c \\(\\Phi(d_2) \\to 1\\) \u3002\u56e0\u6b64\u6709\u770b\u6da8\u671f\u6743\u7684 \\(\\Theta \\to -rKe^{-r(T-t)}\\) \u3002 \\(\\Theta\\) \u4e0e\u8ddd\u79bb\u5230\u671f\u65e5\u65f6\u95f4\u7684\u5173\u7cfb\u5982\u4e0b\uff1a \u53ef\u4ee5\u770b\u5230\uff0c\u5bf9\u4e8e\u6240\u6709\u7c7b\u578b\u7684\u671f\u6743\uff0c \\(\\Theta\\) \u662f\u5c0f\u4e8e 0 \u7684\u3002\u5373\u968f\u7740\u5230\u671f\u65e5\u4e34\u8fd1\uff0c\u671f\u6743\u4ef7\u683c\u8d8b\u8fd1\u4e8e\u964d\u4f4e\u3002\u5bf9\u4e8e ATM \u7684\u770b\u6da8\u671f\u6743\uff0c\u5f53\u4e34\u8fd1\u5230\u671f\u65e5( \\(t \\to T\\) )\u65f6\uff0c\u5b83\u7684 \\(\\Theta\\) \u8d8b\u8fd1\u4e8e\u8d1f\u65e0\u7a77\u3002 \u7efc\u5408\u6765\u770b\uff0c \u77ed\u671f\u7684 ATM \u671f\u6743\u5177\u6709\u7edd\u5bf9\u503c\u6700\u5927\u7684\u8d1f Theta \u3002 \u4f8b \u4e00\u4e2a\u671f\u6743\u7684 Theta \u4e3a -0.1 \uff08\u4ee5\u5e74\u8ba1\u7b97\uff09\u542b\u4e49\u662f\u4ec0\u4e48\uff1f\u5982\u679c\u4ea4\u6613\u5458\u8ba4\u4e3a\u80a1\u7968\u4ef7\u683c\u548c\u6ce2\u52a8\u7387\u90fd\u4e0d\u4f1a\u53d8\u5316\uff0c\u90a3\u4e48\u8fd9\u4e2a\u671f\u6743\u7684\u4ed3\u4f4d\u5e94\u8be5\u662f\u591a\u5c11\uff1f \u8fd9\u8868\u793a\u6bcf\u7ecf\u8fc7\u4e00\u4e2a\u5f88\u77ed\u7684\u65f6\u95f4 \\(\\Delta t\\) \uff0c\u671f\u6743\u7684\u4ef7\u683c\u4f1a\u53d8\u5316 \\(-0.1\\Delta t\\) \u3002 \u5982\u679c\u80a1\u7968\u4ef7\u683c\u548c\u6ce2\u52a8\u7387\u90fd\u4e0d\u4f1a\u53d8\u5316\uff0c\u5219\u8be5\u671f\u6743\u4ef7\u683c\u4f1a\u968f\u7740\u5230\u671f\u65e5\u4e34\u8fd1\u8d8a\u6765\u8d8a\u4f4e\u3002\u4ea4\u6613\u5458\u5e94\u8be5\u9009\u62e9\u5356\u51fa Theta \u4e3a\u8d1f\uff0c\u4e14\u7edd\u5bf9\u503c\u8f83\u5927\u7684\u671f\u6743\u3002\u800c\u7531\u4e8e \u77ed\u671f\u7684 ATM \u671f\u6743\u5177\u6709\u7edd\u5bf9\u503c\u6700\u5927\u7684\u8d1f Theta \uff0c\u5e94\u8be5\u5356\u51fa\u77ed\u671f\u7684 ATM \u671f\u6743\u3002 18.6 Gamma Gamma ( \\(\\Gamma\\) ) \u8868\u793a portfolio \u7684 Delta \u968f\u6807\u7684\u7269\u4ef7\u683c\u53d8\u52a8\u7684\u53d8\u5316\u7387\u3002 \u5047\u8bbe\u67d0 portfolio \u4ef7\u503c\u4e3a \\(\\Pi\\) \uff0c\u6807\u7684\u7269\u4ef7\u683c\u4e3a \\(S\\) \uff0c\u5219\u6709\uff1a \\[\\Delta = \\frac{\\partial \\Pi}{\\partial S}\\] \\[ \\Gamma = \\frac{ \\partial \\Delta} {\\partial S} = \\frac{ \\partial^2 \\Pi}{\\partial S^2} \\] \u5982\u679c Gamma \u7edd\u5bf9\u503c\u8f83\u5c0f\uff0c\u90a3 portfolio \u7684 Delta \u53d8\u5316\u4e5f\u8f83\u6162\uff0c\u56e0\u6b64\u7ef4\u6301\u8fd9\u4e2a portfolio Delta \u4e2d\u6027\u8f83\u5bb9\u6613\u3002\u5426\u5219\uff0c\u5373\u4f7f\u5728\u5f88\u77ed\u7684\u65f6\u95f4\u5185\u4e0d\u8fdb\u884c Rebalance\uff0c\u90fd \u6709\u8f83\u9ad8\u7684\u98ce\u9669\u3002 \u5bf9\u4e8e\u4e00\u4e2a Delta \u4e2d\u6027\u7684 portfolio\uff0c\u6211\u4eec\u6709\u4ee5\u4e0b\u5173\u7cfb\uff08\u8fd9\u91cc\u7684 \\(\\Delta\\) \u8868\u793a\u5168\u5fae\u5206\uff09\uff1a \\[\\Delta \\Pi = \\Theta ~ \\Delta t + \\frac{1}{2}\\Gamma \\Delta S^2\\] \u8fd9\u4e2a\u7ed3\u8bba\u53ef\u4ee5\u5229\u7528 Taylor \u5c55\u5f00\uff0c\u4ee3\u5165 \\(\\frac{ \\partial \\Pi}{ \\partial S} = 0\\) \uff0c \u5e76\u5ffd\u7565 \\(\\Delta t\\) \u7684\u9ad8\u9636\u9879\u5f97\u5230\u3002 \u4e0b\u9762\u7684\u56fe\u63cf\u8ff0\u4e86\u80a1\u7968\u4ef7\u683c\u53d8\u5316\u5bf9\u4e8e\u4e0d\u540c Gamma \u7684 portfolio \u7684\u4ef7\u503c\u5f71\u54cd\u3002 \u4f8b\u5982\uff0c\u67d0\u4e2a Delta \u4e2d\u6027\u7684 portfolio \u7684 Gamma \u662f -10000\uff0c\u8be5\u516c\u5f0f\u8868\u660e\uff0c\u5982\u679c\u6807\u7684\u7269\u8d44\u4ea7\u4ef7\u683c\u5728\u5f88\u77ed\u7684\u65f6\u95f4\u5185\u53d8\u52a8 +2 \u6216\u8005 -2\uff0c\u5373\u4f7f\u5b83\u5728\u4ef7\u683c\u53d8\u52a8\u4e4b\u524d\u662f Delta \u4e2d\u6027\u7684\uff0c\u8fd9\u4e2a portfolio \u4f1a\u635f\u5931 20000\u3002 18.6.1 Gamma \u4e2d\u6027 \u521a\u624d\u7684\u4f8b\u5b50\u8868\u660e\uff0c\u6211\u4eec\u5e0c\u671b\u4e00\u4e2a portfolio \u6709\u8f83\u5c0f\u7684 Gamma \u4ee5\u964d\u4f4e\u98ce\u9669\u3002 \u7531\u4e8e\u6807\u7684\u7269\u8d44\u4ea7\u7684 Delta \u4e3a\u5e38\u6570 1\uff0c\u56e0\u6b64\u5b83\u7684 Gamma \u4e3a 0\uff0c\u4e0d\u80fd\u7528\u4e8e\u8c03\u8282 portfolio \u7684 Gamma\u3002\u56e0\u6b64\uff0c\u4e0d\u540c\u4e8e Delta Hedging\uff0c\u6211\u4eec\u9700\u8981\u4f7f\u7528\u548c\u6807\u7684\u7269\u8d44\u4ea7 \u975e\u7ebf\u5f62\u76f8\u5173\u7684 \u884d\u751f\u54c1\uff0c\u4f8b\u5982\u671f\u6743\uff0c\u6765\u8fdb\u884c Gamma \u7684\u8c03\u8282\u3002 \u5047\u8bbe\u4e00\u4e2a portfolio Delta \u4e2d\u6027\uff0c\u4f46\u6709 -3000 \u7684 Gamma\u3002\u540c\u65f6\uff0c\u67d0\u4e2a call option \u7684 Delta \u548c Gamma \u5206\u522b\u4e3a 0.62 \u548c 1.50\u3002\u5219\u53ef\u4ee5\u901a\u8fc7\u4e70\u5165 \\(3000/1.5 = 2000\\) \u5355\u4f4d\u7684 call \u6765\u4f7f\u8fd9\u4e2a portfolio Gamma \u4e2d\u6027\u3002 \u4f46\u662f\uff0c\u8fd9\u6837\u53c8\u5f15\u5165\u4e86\u989d\u5916\u7684 \\(0.62 \\times 2000 = 1240\\) \u7684 Delta\uff0c\u56e0\u6b64\u6211\u4eec\u8fd8\u9700\u8981\u5356\u51fa 1240 \u4e2a\u6807\u7684\u8d44\u4ea7\uff0c\u4f7f\u5f97\u8be5 portfolio \u7684 Delta \u548c Gamma \u5747\u4e3a\u4e2d\u6027\u3002 18.6.2 Gamma \u8ba1\u7b97 \u53ef\u4ee5\u7b80\u5355\u901a\u8fc7\u6c42\u5bfc\u5f97\u5230\uff1a \\[\\Gamma = \\frac{ \\partial \\Delta }{ \\partial S } = \\Phi'(d_1) \\frac{\\partial d_1}{\\partial S} = \\frac{\\Phi'(d_1)}{\\sigma S_0 \\sqrt{T}}\\] \u5176\u4e2d \\[\\Phi'(x) = \\frac{ 1 }{ \\sqrt{2 \\ pi} } e^{-\\frac{ x^2 }{ 2 }}\\] \u53ef\u4ee5\u770b\u51fa\uff0c \\(\\Gamma > 0\\) \u603b\u662f\u6210\u7acb\u7684 \u3002\u53ef\u4ee5\u56de\u60f3 Delta \u5173\u4e8e\u80a1\u7968\u4ef7\u683c\u7684\u66f2\u7ebf\uff0c\u65e0\u8bba\u5bf9\u4e8e put \u8fd8\u662f call\uff0c\u968f\u7740\u80a1\u7968\u4ef7\u683c\u4e0a\u5347\uff0cDelta \u603b\u662f\u589e\u52a0\u7684\u3002\u5373 \\(\\Gamma = \\frac{ \\partial \\Delta} { \\partial S}> 0\\) \u3002 \\(\\Gamma\\) \u4e0e\u80a1\u7968\u4ef7\u683c \\(S\\) \u5173\u7cfb\u5982\u4e0b\u6240\u793a\uff1a \\(\\Gamma\\) \u4e0e\u8ddd\u79bb\u5230\u671f\u65e5\u65f6\u95f4\u7684\u5173\u7cfb\u5982\u4e0b\u6240\u793a\uff1a \u53ef\u4ee5\u770b\u51fa\uff1a - Gamma \u4e00\u5b9a\u4e3a\u975e\u8d1f\u6570 - \u5bf9\u4e8e ATM \u7684\u671f\u6743\uff0cGamma \u6700\u5927 - \u968f\u7740\u5230\u671f\u65e5\u4e34\u8fd1\uff0cATM \u7684\u671f\u6743 Gamma \u5355\u8c03\u589e\u52a0\uff0c\u800c ITM \u548c OTM \u90fd\u662f\u5148\u589e\u52a0\u540e\u51cf\u5c11\u81f3 0 \u4f8b 1 \u67d0\u516c\u53f8\u5bf9\u7531\u6807\u7684\u7269\u662f\u8d27\u5e01\u7684\u770b\u6da8/\u770b\u8dcc\u671f\u6743\u7ec4\u6210\u7684 portfolio \u8fdb\u884c\u4e86 Delta \u5bf9\u51b2\u3002\u54ea\u79cd\u60c5\u51b5\u4e0b portfolio \u76c8\u5229\u60c5\u51b5\u8f83\u597d\uff1f a. \u8be5\u8d27\u5e01\u6c47\u7387\u57fa\u672c\u7a33\u5b9a b. \u8be5\u8d27\u5e01\u6c47\u7387\u5267\u70c8\u6ce2\u52a8 \u4ece portfolio \u4ef7\u503c\u4e0a\u8bb2\uff0c\u6839\u636e\u516c\u5f0f\uff08\u8fd9\u91cc \\(\\Delta\\) \u8868\u793a\u5168\u5fae\u5206\uff09\uff1a \\[\\Delta \\Pi = \\Theta ~\\Delta t + \\frac{1}{2}\\Gamma \\Delta S^2\\] \u6211\u4eec\u53ef\u4ee5\u53d1\u73b0\u5bf9\u4e8e\u6b63\u7684 Gamma\uff0c\u5f53\u6807\u7684\u7269\u4ef7\u683c\u53d8\u52a8\u8f83\u5927\u65f6\uff0cportfolio \u4ef7\u503c\u4f1a\u53d8\u9ad8\uff08\u53ef\u4ee5\u56de\u5fc6\u56fe 18.8\uff09\u3002 \u540c\u65f6\uff0c\u671f\u6743\u591a\u5934\u5177\u6709\u6b63\u7684 Gamma\uff0cGamma \u7edd\u5bf9\u503c\u5c0f\u5219\u5bf9\u51b2\u6548\u679c\u597d\u3002\u6839\u636e\u516c\u5f0f\u53ef\u77e5\uff0c \\(\\sigma\\) \u8d8a\u5c0f Gamma \u8d8a\u5927\uff0c\u56e0\u6b64\u5982\u679c\u6c47\u7387\u5267\u70c8\u6ce2\u52a8\u5219 Gamma \u4f1a\u8f83\u5c0f\uff0c\u5bf9\u51b2\u4e5f\u8f83\u5bb9\u6613\u3002 \u4f8b 2 \u4f8b 1 \u4e2d\uff0c\u82e5 portfolio \u662f\u7a7a\u5934\uff0c\u54ea\u79cd\u60c5\u51b5\u597d\uff1f \u671f\u6743\u7a7a\u5934\u5177\u6709\u8d1f\u7684 Gamma\uff0c\u6807\u7684\u7269\u4ef7\u683c\u53d8\u52a8\u5c0f\u5219 portfolio \u4ef7\u503c\u53d8\u9ad8\u3002 18.7 Delta, Theta, Gamma \u4e4b\u95f4\u7684\u5173\u7cfb \u6211\u4eec\u4e4b\u524d\u5df2\u7ecf\u63a8\u5bfc\u8fc7 B-S-M \u5fae\u5206\u65b9\u7a0b\uff1a \\[\\frac{\\partial \\Pi}{\\partial t} + \\frac{\\partial \\Pi}{\\partial S}rS + \\frac{1}{2} \\frac{\\partial^2 \\Pi}{\\partial S^2}\\sigma^2 S^2 = r\\Pi\\] \u6839\u636e\u6211\u4eec\u5bf9 Delta, Theta, Gamma \u7684\u5b9a\u4e49\uff0c\u4e0a\u5f0f\u53ef\u4ee5\u6539\u5199\u4e3a\uff1a \\[\\Theta + rS \\Delta + \\frac{1}{2} \\sigma^2 S^2 \\Gamma = r \\Pi \\] \u90a3\u4e48\u5bf9\u4e8e Delta \u4e2d\u6027\u7684 portfolio\uff0c\u6211\u4eec\u6709\uff1a \\[\\Theta + \\frac{ 1 }{ 2 } \\sigma^2 S^2 \\Gamma = r \\ \\Pi \\] \u6211\u4eec\u53d1\u73b0\uff0c\u5982\u679c\u4e00\u4e2a Delta \u4e2d\u6027\u7684 portfolio \u7684 \\(\\Theta\\) \u662f\u4e00\u4e2a\u5f88\u5927\u7684\u8d1f\u6570\uff0c\u5219 \\(\\Gamma\\) \u4f1a\u662f\u4e00\u4e2a\u5f88\u5927\u7684\u6b63\u6570\uff0c\u53cd\u4e4b\u540c\u7406\u3002 \u8fd9\u4e5f\u5c31\u662f\u4e0a\u4e00\u7ae0\u4e2d\u63d0\u5230\u7684\uff0c \\(\\Theta\\) \u53ef\u4ee5\u4f5c \\(\\Gamma\\) \u7684\u4e00\u4e2a \u201cproxy\u201d\u3002 \u4f8b 1 \u8ba1\u7b97 Delta, Theta, Gamma \u7684\u5173\u7cfb\u5f0f\uff0c\u9488\u5bf9\uff1a a. \u8d27\u5e01\u7684\u884d\u751f\u54c1 b. \u671f\u8d27\u7684\u884d\u751f\u54c1 18.8 Vega \u6211\u4eec\u4e4b\u524d\u4e3a\u4e86\u7b80\u5316\uff0c\u4e00\u76f4\u628a volatility \u4f5c\u4e3a\u4e00\u4e2a\u5e38\u6570\u3002\u5b9e\u9645\u4e0a\uff0cvolatility \u4e5f\u662f\u4e0d\u65ad\u53d8\u5316\u7684\u3002\u884d\u751f\u54c1\u7684\u4ef7\u683c\u540c\u6837\u4f1a\u7531\u4e8e volatility \u7684\u53d8\u5316\u800c\u53d8\u5316\u3002\u6211\u4eec\u5c06\u8fd9\u4e2a\u53d8\u5316\u7387\u79f0\u4e3a Vega ( \\(\\nu\\) )\uff1a \\[\\nu = \\frac{ \\partial \\Pi}{ \\partial \\sigma}\\] \u5bf9\u4e8e\u6b27\u5f0f\u770b\u6da8\u548c\u770b\u8dcc\u671f\u6743\uff0c\u6709\uff1a \\[\\nu = \\frac{ \\partial c}{ \\partial \\sigma} = \\frac{ \\partial p}{ \\partial \\sigma} = S_0 \\sqrt{T} \\Phi'(d_1)\\] \u8bc1\u660e\u8f83\u7b80\u5355\uff0c\u76f4\u63a5\u6c42\u5bfc\u5e76\u5229\u7528 \\(S_0\\Phi'(d_1) = Ke^{-rT}\\Phi'(d_2)\\) \u5c31\u53ef\u4ee5\u5f97\u5230\u3002\u53ef\u4ee5\u770b\u51fa\u5fc5\u7136\u6709 \\(\\nu > 0\\) \uff0c\u8fd9\u4e0e\u6211\u4eec\u4e4b\u524d\u7684\u7ed3\u8bba\u543b\u5408\uff0cvolatility \u4e0a\u5347\u4f1a\u5f15\u8d77\u770b\u6da8\u548c\u770b\u8dcc\u671f\u6743\u4ef7\u683c\u4e0a\u5347\u3002 \u6807\u7684\u7269\u7684 Vega \u4e3a 0 \u3002\u56e0\u6b64\u6211\u4eec\u5982\u679c\u9700\u8981 Vega \u4e2d\u6027\uff0c\u9700\u8981\u901a\u8fc7\u4e70\u5356\u671f\u6743\u5b9e\u73b0\u3002\u4e00\u822c\u800c\u8a00\uff0c\u6211\u4eec\u9700\u8981 2 \u79cd\u4ee5\u4e0a\u7684\u671f\u6743\u7684\u7ec4\u5408\u6765\u5b9e\u73b0 Gamma \u548c Vega \u540c\u65f6\u5448\u4e2d\u6027\u3002 \u4f8b 1 \u8003\u8651\u4e00\u4e2a Delta \u4e2d\u6027\u7684 portfolio\uff0c\u5b83\u73b0\u5728\u5177\u6709 -5000 \u7684 Gamma \u548c -8000 \u7684 Vega\u3002\u6709\u4e24\u79cd\u53ef\u4ee5\u4ea4\u6613\u7684\u671f\u6743\uff0c\u5982\u4e0b\u8868\u6240\u793a\uff1a Delta Gamma Vega Portfolio 0 -5000 -8000 Option 1 0.6 0.5 2.0 Option 2 0.5 0.8 1.2 \u6211\u4eec\u9700\u8981 Vega \u548c Gamma \u540c\u65f6\u4e2d\u6027\uff0c\u5047\u8bbe\u4e24\u8005\u6570\u91cf\u914d\u6bd4\u5206\u522b\u4e3a \\(w_1\\) \u548c \\(w_2\\) \uff0c\u5219\uff1a \\[0.5w_1 + 0.8w_2 = 5000\\] \\[2.0w_1 + 1.2w_2 = 8000\\] \u53ef\u4ee5\u89e3\u51fa \\(w_1 = 400\\) \uff0c \\(w_2 = 6000\\) \u3002\u4e70\u5165 400 \u4efd Option 1 \u548c 6000 \u4efd Option 2 \u540e\uff0cDelta \u4ece 0 \u53d8\u4e3a 3240\uff0c\u6240\u4ee5\u8fd8\u9700\u8981\u5356\u51fa 3240 \u4efd\u6807\u7684\u8d44\u4ea7\u3002 Gamma \u4e2d\u6027\u53ef\u4ee5\u5728 Delta Hedging \u7684\u95f4\u9694\u65f6\u95f4\u91cc\u4fdd\u62a4 portfolio \u7684\u4ef7\u503c\u4e0d\u56e0\u4e3a\u6807\u7684\u8d44\u4ea7\u7684\u4ef7\u683c\u53d8\u5316\u4ea7\u751f\u53d8\u52a8\uff0c\u800c Vega \u4e2d\u6027\u53ef\u4ee5\u5728 volatility \u53d8\u5316\u7684\u65f6\u5019\u4fdd\u62a4 portfolio \u7684\u4ef7\u503c\u3002\u9700\u8981\u6839\u636e\u5bf9\u51b2\u518d\u5e73\u8861\u95f4\u9694\u65f6\u95f4\u4ee5\u53ca\u6ce2\u52a8\u7387\u7684\u6ce2\u52a8\u7387\u6765\u51b3\u5b9a\u9009\u62e9\u54ea\u4e9b\u671f\u6743\u3002 \u4f8b 2 \u4ec0\u4e48\u60c5\u51b5\u4e0b 2 \u4e2a\u6307\u6570\u7684\u6b27\u5f0f\u671f\u6743\u7ec4\u6210\u7684 portfolio \u53ef\u4ee5\u540c\u65f6 Gamma \u548c Vega \u4e2d\u6027\uff1f \u5373\u4ee5\u4e0b\u5173\u4e8e \\(w_1\\) \uff0c \\(w_2\\) \u7684\u65b9\u7a0b\u7ec4\u6709\u975e\u96f6\u89e3\uff1a \\[\\Gamma_1 w_1 + \\Gamma_2 w_2 = 0\\] \\[\\nu_1 w_1 + \\nu_2 w_2 = 0\\] \u53ef\u4ee5\u5f97\u5230 \\[\\Gamma_1 \\nu_2 = \\Gamma_2 \\nu_1\\] \u4e24\u4e2a\u671f\u6743\u57fa\u4e8e\u540c\u4e00\u4e2a\u6807\u7684\u7269\uff0c\u56e0\u6b64\u5fc5\u7136\u6709\u540c\u6837\u7684 \\(S_0\\) , \\(q\\) , \\(r\\) , \\(\\sigma\\) \u3002\u552f\u4e00\u4e0d\u540c\u7684\u5c31\u662f\u5230\u671f\u65e5 \\(T\\) \u548c\u6267\u884c\u4ef7\u683c \\(K\\) \uff0c\u8fd9\u4e5f\u5bfc\u81f4\u5177\u6709\u4e0d\u540c\u7684 \\(d_1\\) \u548c \\(d_2\\) \u3002 \\[\\Gamma_1 \\nu_2 = \\frac{1}{\\sigma} e^{-q(T_1 + T_2)} \\sqrt{\\frac{T_2}{T_1}} \\Phi'(d_{1(1)}) \\Phi'(d_{1(2)}) \\] \\[\\Gamma_2 \\nu_1 = \\frac{1}{\\sigma} e^{-q(T_1 + T_2)} \\sqrt{\\frac{T_1}{T_2}} \\Phi'(d_{1(1)}) \\Phi'(d_{1(2)}) \\] \u8981\u4e24\u8005\u76f8\u7b49\uff0c\u5fc5\u7136\u6709 \\(T_1 = T_2\\) \uff0c\u5373\u671f\u9650\u76f8\u540c\u3002 \u4f8b 3 \u67d0\u94f6\u884c\u6301\u6709\u7684\u7f8e\u5143/\u6b27\u5143\u6c47\u7387\u671f\u6743\u5934\u5bf8\u6709 30000 \u7684 Delta \u548c -80000 \u7684 Gamma\u3002 a. \u89e3\u91ca\u8fd9\u4e9b\u6570\u636e\u7684\u542b\u4e49 b. \u5047\u8bbe\u76ee\u524d\u6c47\u7387\u662f 0.90 \u7f8e\u5143\u5151\u6362 1.0 \u6b27\u5143\uff0c\u5219\u5982\u4f55\u4f7f\u5934\u5bf8 Delta \u4e2d\u6027\uff1f c. \u5728\u5f88\u77ed\u7684\u65f6\u95f4\u540e\uff0c\u6b27\u5143\u5347\u503c\uff0c\u6c47\u7387\u53d8\u4e3a 0.93 \u7f8e\u5143\u5151\u6362 1.0 \u6b27\u5143\uff0c\u5219\u65b0\u7684 Delta \u4e3a\u591a\u5c11\uff1f\u5982\u679c\u8981\u4fdd\u6301\u5176 Delta \u4e2d\u6027\uff0c\u9700\u8981\u4ec0\u4e48\u989d\u5916\u7684\u4ea4\u6613\u64cd\u4f5c\uff1f d. \u5047\u8bbe\u8be5\u5934\u5bf8\u6700\u521d\u662f Delta \u4e2d\u6027\u7684\uff0c\u90a3\u4e48\u5b83\u4ece\u6c47\u7387\u7684\u53d8\u5316\u4e2d\u8d5a\u4e86\u8fd8\u662f\u8d54\u4e86\uff1f \u8bf4\u660e\u82e5\u6b27\u5143\u5347\u503c 0.01 \u7f8e\u5143\uff0c\u5219\u8be5\u5934\u5bf8\u7684\u4ef7\u503c\u4e0a\u5347 300\uff0cDelta \u964d\u4f4e 800\u3002\u8be5\u94f6\u884c\u5e94\u8be5\u662f\u6301\u6709\u6b27\u5143\u770b\u8dcc\u671f\u6743\u7684\u7a7a\u5934\uff0c\u56e0\u6b64\u5177\u6709\u6b63\u7684 Delta \u548c\u8d1f\u7684 Gamma\u3002 \u9700\u8981\u5356\u7a7a 30000 \u6b27\u5143\u3002 \u65b0\u7684 Delta \u4e3a 30000 - 80000*0.03 = 27600\uff0c\u5982\u679c\u5df2\u7ecf\u5356\u7a7a 30000 \u6b27\u5143\u4f7f\u5176 Delta \u4e2d\u6027\uff0c\u90a3\u4e48\u8fd8\u9700\u8981\u4e70\u5165 2400 \u6b27\u5143\u4ee5\u4fdd\u6301 Delta \u4e2d\u6027\u3002 \u7531\u4e8e\u6700\u521d Delta \u4e2d\u6027\uff0cGamma \u4e3a\u8d1f\uff0c\u56e0\u6b64\u6b27\u5143\u6c47\u7387\u5728\u6700\u521d\u80af\u5b9a\u5927\u4e8e 0.9 \u7f8e\u5143\uff0c\u5728\u4e0b\u964d\u8fc7\u7a0b\u4e2d\uff0cDelta \u53d8\u4e3a\u6b63\u3002\u800c\u5b83\u6301\u6709\u6b27\u5143\u770b\u8dcc\u671f\u6743\u7684\u7a7a\u5934\uff0c\u56e0\u6b64\u6b27\u5143\u6c47\u7387\u4e0b\u8dcc\uff0c\u8fd9\u4e2a\u5934\u5bf8\u6709\u4e8f\u635f\u3002 18.9 Rho Rho \u63cf\u8ff0\u4e86 portfolio \u4ef7\u503c\u968f\u5229\u7387 \\(r\\) \u7684\u53d8\u5316\u7387\uff1a \\[\\rho = \\frac{\\partial \\Pi}{\\partial r}\\] \u901a\u8fc7\u7b80\u5355\u7684\u6c42\u5bfc\u53ef\u4ee5\u5f97\u5230\uff1a \\[\\rho_{call} = KTe^{-rT}\\Phi(d_2)\\] \u518d\u5229\u7528 put-call-parity \u53ef\u4ee5\u5f97\u5230\uff1a \\[\\rho_{put} = -KTe^{-rT}\\Phi(-d_2)\\] \u6211\u4eec\u53d1\u73b0\uff0c\u5229\u7387\u4e0a\u5347\u4f1a\u4fc3\u4f7f call \u7684\u4ef7\u503c\u4e0a\u5347\uff0cput \u7684\u4ef7\u503c\u4e0b\u964d\u3002\u8fd9\u662f\u7b26\u5408\u6211\u4eec\u76f4\u89c2\u7684\u3002\u5f53\u5229\u7387\u4e0a\u5347\uff08\u5047\u8bbe\u8d44\u4ea7\u4ef7\u683c\u4e0d\u53d8\uff09\uff0c\u6267\u884c\u4ef7\u683c\u6298\u73b0\u540e\u53d8\u5c11\u3002\u56e0\u6b64 call \u76f8\u5f53\u4e8e\u4ee5\u66f4\u4fbf\u5b9c\u7684\u4ef7\u683c\u4e70\u5230\u4e86\u8d44\u4ea7\uff0c\u4ef7\u683c\u4f1a\u5347\u9ad8\u3002put \u5219\u53cd\u4e4b\u3002 \u7531\u4e8e\u5229\u7387\u4e0d\u7ecf\u5e38\u53d8\u5316\uff0c\u8fd9\u4e2a Greek \u5e76\u6ca1\u6709\u5176\u4ed6\u51e0\u4e2a\u53d7\u5173\u6ce8\u3002 18.10 \u5b9e\u9645\u5e94\u7528 \u5bf9\u4e8e\u4e00\u4e2a portfolio \u7684\u6bcf\u4e2a Greek\uff0c\u4ea4\u6613\u516c\u53f8\u90fd\u4f1a\u8bbe\u7f6e\u4e00\u4e2a\u4e0a\u9650\u3002 Delta \u7684\u4e0a\u9650\u901a\u5e38\u8868\u793a\u4e3a\u6807\u7684\u7269\u6700\u5927\u4ed3\u4f4d\u3002\u4f8b\u5982\u5bf9\u4e8e\u4e00\u4e2a\u80a1\u7968\u7684 cash Delta \u4e0a\u9650\u662f 100 \u4e07\uff0c\u80a1\u7968\u4ef7\u683c\u4e3a 50\uff0c\u5219\u6700\u5927\u4ed3\u4f4d\u4e3a 2 \u4e07\u3002 Vega \u7684\u4e0a\u9650\u901a\u5e38\u8868\u793a\u4e3a 1% \u7684 volatility \u53d8\u5316\u5f15\u8d77\u7684 portfolio \u4ef7\u503c\u53d8\u5316\u7684\u4e0a\u9650\u3002 \u671f\u6743\u4ea4\u6613\u5458\u4f1a\u5c3d\u91cf\u4f7f\u5f97\u81ea\u5df1\u5728\u6bcf\u5929\u4ea4\u6613\u7ed3\u675f\u65f6 Delta \u4e2d\u6027\u3002Gamma \u548c Vega \u4e5f\u4f1a\u76d1\u63a7\uff0c\u4f46\u662f\u4e0d\u4f1a\u8981\u6c42\u6bcf\u5929\u90fd\u662f\u4e2d\u6027\u3002 \u6211\u4eec\u4ece Gamma \u548c Vega \u7684\u66f2\u7ebf\u53ef\u4ee5\u770b\u51fa\uff0cATM \u7684\u671f\u6743\u5177\u6709\u6700\u9ad8\u7684 Gamma \u548cVega\u3002\u968f\u7740\u80a1\u4ef7\u53d8\u5316\uff0c\u8fd9\u4e9b\u671f\u6743\u6162\u6162\u53d8\u4e3a OTM \u6216\u8005 ITM\uff0cGamma \u548c Vega \u5c31\u4f1a\u81ea\u7136\u51cf\u5c0f\u3002 18.12 \u516c\u5f0f\u7684\u63a8\u5e7f \u6211\u4eec\u76ee\u524d\u5bfc\u51fa\u7684\u516c\u5f0f\u90fd\u662f\u9488\u5bf9\u65e0\u80a1\u606f\u80a1\u7968\u7684\u6b27\u5f0f\u671f\u6743\u3002 \u5047\u8bbe\u80a1\u7968\u7684\u80a1\u606f\u6536\u76ca\u4ee5\u590d\u5229\u8ba1\u7b97\u4e3a \\(q\\) \uff0c\u5219\u6211\u4eec\u53ef\u4ee5\u5c06 \\(S_0\\) \u66ff\u6362\u4e3a \\(S_0 e^{-qT}\\) \uff0c\u5f97\u5230\u9002\u7528\u4e8e\u6709\u6536\u76ca\u7684\u6807\u7684\u7269\u7684 B-S-M \u516c\u5f0f\uff1a \\[c = S_0 e^{-qT} \\Phi(d_1) - K e^{-rT} \\Phi(d_2)\\] \\[p = K e^{-rT} \\Phi(-d_2) - S_0 e^{-qT} \\Phi(-d_1)\\] \\[d_1 = \\frac{\\ln(S_0 / K) + (r - q + \\frac{1}{2}\\sigma^2)T}{\\sigma \\sqrt{T}}\\] \\[d_2 = d_1 - \\sigma \\sqrt{T}\\] \u6839\u636e\u8fd9\u4e2a\u63a8\u5bfc\u51fa\u5176\u5404\u4e2a Greeks \u7684\u8ba1\u7b97\u516c\u5f0f\uff1a Greeks European call European put Delta \\(e^{-qT}\\Phi(d_1)\\) \\(\\Delta_{call} - e^{-qT}\\) Theta \\(q e^{-qT} S_0 \\Phi(d_1) - rKe^{-rT}\\Phi(d_2) - \\frac{e^{-qT}S_0 \\Phi'(d_1)\\sigma}{2\\sqrt{T}}\\) \\(\\Theta_{call} + rKe^{-rT}\\) Gamma \\(\\frac{ e^{-qT}\\Phi'(d_1) }{ \\sigma S_0\\sqrt{T} }\\) \\(\\Gamma_{call}\\) Vega \\(e^{-qT}S_0\\sqrt{T}\\Phi'(d_1)\\) \\(\\nu_{call}\\) Rho \\(KTe^{-rT}\\Phi(d_2)\\) \\(\\rho_{call} - KTe^{-rT}\\) \u65e0\u80a1\u606f\u7684\u60c5\u51b5\u5176\u5b9e\u662f\u4e0a\u9762\u7684\u4e00\u4e2a\u7279\u4f8b\uff0c\u4ee4 \\(q = 0\\) \u5373\u53ef\u5f97\u5230\u3002 \u4ee4 \\(q = r\\) \uff0c\u5219\u53ef\u4ee5\u5f97\u5230\u671f\u8d27\u671f\u6743\u7684\u516c\u5f0f\uff0c \u6b64\u65f6 Rho \u4e0d\u80fd\u4f7f\u7528\u901a\u7528\u516c\u5f0f \u3002 \\(\\rho_{call} = -cT\\) \uff0c \\(\\rho_{put} = -pT\\) \u3002\u8fd9\u662f\u7531\u4e8e \\(q = r\\) \uff0c\u5bf9 \\(r\\) \u6c42\u5bfc\u65f6\u4e0d\u80fd\u628a \\(q\\) \u4f5c\u4e3a\u5e38\u6570\u3002 \u5f53\u6211\u4eec\u5206\u6790\u8d27\u5e01\u671f\u6743\u65f6\uff0c\u6709\u4e24\u4e2a\u5229\u7387\uff0c\u672c\u5e01\u65e0\u98ce\u9669\u5229\u7387 \\(r\\) \u548c\u5916\u5e01\u65e0\u98ce\u9669\u5229\u7387 \\(r_f\\) \uff0c\u4ee4 \\(q = r_f\\) \u5373\u5f97\u5230\u5bf9\u8d27\u5e01\u671f\u6743\u7684\u516c\u5f0f\u3002 \u4f8b 1 \u67d0\u4e2a\u91d1\u878d\u673a\u6784\u521a\u521a\u51fa\u552e\u4e86 1000 \u4efd 7 \u4e2a\u6708\u540e\u5230\u671f\u7684\u6807\u7684\u7269\u662f\u65e5\u5143\u7684\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u3002\u5047\u8bbe\u5373\u671f\u6c47\u7387\u662f 0.8 \u7f8e\u5206\u5151\u6362 1 \u65e5\u5143\uff0c\u6267\u884c\u4ef7\u683c\u662f 0.81 \u7f8e\u5206\u3002\u7f8e\u56fd\u7684\u65e0\u98ce\u9669\u5229\u7387\u662f 8%\uff0c\u65e5\u672c\u7684\u65e0\u98ce\u9669\u5229\u7387\u662f 5%\u3002\u65e5\u5143\u6ce2\u52a8\u7387\u662f 15%\u3002\u8ba1\u7b97\u8be5\u4ed3\u4f4d\u7684 Delta, Gamma, Vega, Theta, Rho\u3002 \u6211\u4eec\u53ef\u4ee5\u5c06 \\(q = r_f = 0.05\\) \u4ee3\u5165\u4e0a\u9762\u8868\u683c\u4e2d\u7684\u516c\u5f0f\u8fdb\u884c\u8ba1\u7b97\uff0c\u5c06\u6267\u884c\u4ef7\u683c\u7edf\u4e00\u6362\u7b97\u4e3a\u7f8e\u5143\u3002 \u7136\u540e\u8ba1\u7b97 \\(d_1\\) \uff1a \\[d_1 = \\frac{\\ln(S_0 / K) + (r - q + \\frac{1}{2}\\sigma^2)T}{\\sigma \\sqrt{T}} = 0.1016\\] \\[d_2 = d_1 - \\sigma \\sqrt{T} = -0.0130\\] \\[\\Phi(d_1) = 0.5405 \\] \\[\\Phi(d_2) = 0.4948 \\] \\[\\Phi'(d_1) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{d_1^2}{2}} = 0.3969\\] Greeks European call Value Delta \\(e^{-qT}\\Phi(d_1)\\) 0.5250 Theta \\(q e^{-qT} S_0 \\Phi(d_1) - rKe^{-rT}\\Phi(d_2) - \\frac{e^{-qT}S_0 \\Phi'(d_1)\\sigma}{2\\sqrt{T}}\\) 0.0004 Gamma \\(\\frac{e^{-qT}\\Phi'(d_1)}{\\sigma S_0\\sqrt{T}}\\) 420.6051 Vega \\(e^{-qT}S_0\\sqrt{T}\\Phi'(d_1)\\) 0.0024 Rho \\(KTe^{-rT}\\Phi(d_2)\\) 0.0022 \u4f8b 2 \u4e00\u4e2a\u80a1\u6307\u7684\u8fdc\u671f\u5408\u7ea6\u548c\u671f\u8d27\u5177\u6709\u540c\u6837\u7684 Delta \u5417\uff1f\u89e3\u91ca\u4f60\u7684\u7ed3\u8bba\u3002 \u80a1\u6307\u671f\u8d27\u4f1a\u5b9a\u671f\u6d3e\u53d1\u80a1\u606f\uff0c\u5047\u8bbe\u5176\u80a1\u606f\u6536\u76ca\u6309\u590d\u5229\u8ba1\u7b97\u4e3a \\(q\\) \uff0c\u5219\u8fdc\u671f\u5408\u7ea6\u591a\u5934\u4ef7\u503c\u4e3a\uff1a \\[S_0e^{-qT} - Ke^{-rT}\\] \u5176 Delta \u4e3a \\(e^{-qT}\\) \u3002 \u5bf9\u4e8e\u671f\u8d27\uff0c\u5176\u7ea6\u5b9a\u7684\u6267\u884c\u4ef7\u683c\u6ee1\u8db3\uff1a \\[K = S_0e^{(r-q)T}\\] \u867d\u7136\u5b83\u4ec5\u4ec5\u662f\u672a\u6765\u7684\u6267\u884c\u4ef7\u683c\uff0c\u4f46\u662f\u7531\u4e8e\u671f\u8d27\u6bcf\u65e5\u7ed3\u7b97\u5236\u5ea6\uff0c\u6295\u8d44\u8005\u80fd\u7acb\u5373\u62ff\u5230\u6536\u76ca\u3002\u6240\u4ee5\u5176\u5373\u671f\u4ef7\u503c\u5c31\u662f\u6267\u884c\u4ef7\u683c\uff0cDelta \u4e3a \\(e^{(r-q)T}\\) \u3002 \u56e0\u6b64\u4e24\u8005\u7684 Delta \u4e0d\u540c\uff0c\u671f\u8d27 Delta \u662f\u8fdc\u671f Delta \u7684 \\(e^{rT}\\) \u500d\u3002 \u4f8b 3 \u671f\u8d27\u7684\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u4e0e\u671f\u8d27\u4ef7\u683c \\(F_0\\) \u5173\u7cfb\u5f0f\u4e3a\uff1a \\(c = e^{-rT}[F_0 \\Phi(d_1) - K \\Phi(d_2)]\\) \u5176\u4e2d \\(d_1 = \\frac{\\ln(F_0 / K) + \\frac{1}{2}\\sigma^2 T}{\\sigma \\sqrt{T}}\\) \\(d_2 = d_1 - \\sigma \\sqrt{T}\\) a. \u8bc1\u660e \\(F_0 \\Phi'(d_1) = K \\Phi'(d_2)\\) b. \u8bc1\u660e\u5176 Delta \u7b49\u4e8e \\(e^{-rT}\\Phi(d_1)\\) c. \u8bc1\u660e\u5176 Vega \u7b49\u4e8e \\(F_0 \\sqrt{T} \\Phi'(d_1) e^{-rT}\\) d. \u8bc1\u660e\u5176 Rho \u7b49\u4e8e \\(-cT\\) (a) \u7531\u4e8e \\[\\Phi'(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}\\] \u4ee3\u5165\u53ef\u77e5\uff1a \\[F_0\\Phi'(d_1) = \\frac{F_0}{\\sqrt{2\\pi}} e^{-\\frac{d_2^2 + 2\\sigma \\sqrt{T}d_2 + \\sigma^2 T}{2}}\\] \u800c \\[2\\sigma \\sqrt{T}d_2 + \\sigma^2 T = 2\\ln(\\frac{F_0} {K})\\] \u4ee3\u5165\u53ef\u4ee5\u5f97\u5230\uff1a \\[F_0\\Phi'(d_1) = \\frac{F_0}{\\sqrt{2\\pi}} \\frac{K}{F_0} e^{-\\frac{d_2^2} {2} } = K \\Phi'(d_2)\\] (b) \\[\\Delta = \\frac{\\partial c}{\\partial F_0} = e^{-rT}[\\Phi(d_1) + F_0 \\Phi'(d_1) \\frac{\\partial d_1}{\\partial F_0} - K \\Phi'(d_2) \\frac{\\partial d_2}{\\partial F_0} ]\\] \u5229\u7528 (a) \u4e2d\u7684\u7ed3\u8bba\uff0c\u6709\uff1a \\[\\Delta = e^{-rT}\\Phi(d_1)\\] (c) \\[\\nu = \\frac{\\partial c}{\\partial \\sigma} = e^{-rT}[F_0 \\Phi'(d_1)\\frac{\\partial d_1}{\\partial \\sigma} - K \\Phi'(d_2) \\frac{\\partial d_2}{\\partial \\sigma}]\\] \u5229\u7528 (a) \u4e2d\u7684\u7ed3\u8bba\uff0c\u6709\uff1a \\[\\nu = e^{-rT} F_0 \\sqrt{T} \\Phi'(d_1)\\] (d) \\[\\rho = \\frac{\\partial c}{\\partial r} = -Te^{-rT}[F_0 \\Phi(d_1) - K \\Phi(d_2)] = -cT\\] Appendix: Greeks from Trader's perspective \u4ee5\u4e0a\u90fd\u662f\u4ee5\u5de5\u79d1\u601d\u7ef4\u6765\u8003\u8651 Greeks\u3002\u90a3\u4e48\u5728\u5b9e\u9645\u4ea4\u6613\u4e2d\uff0c\u6211\u4eec\u600e\u4e48\u5229\u7528 Greeks \u5462\uff1f \u5728\u5b9e\u9645\u4ea4\u6613\u4e2d\uff0c\u6211\u4eec\u5f80\u5f80\u4ea4\u6613\u7684\u90fd\u662f\u8fd1\u6708\u7684\u671f\u6743\u548c\u671f\u8d27\u3002\u51e0\u4e4e\u53ef\u4ee5\u5ffd\u7565\u8d34\u73b0\u95ee\u9898\u3002\u5373\uff0c\u671f\u8d27\u4ef7\u683c\u548c\u73b0\u8d27\u4ef7\u683c\u6211\u4eec\u8ba4\u4e3a\u662f\u51e0\u4e4e\u76f8\u7b49\u7684\u3002\u5728\u4ee5\u4e0b\u7684\u5185\u5bb9\u4e2d\uff0c\u6211\u4eec\u90fd\u4e0d\u518d\u6d89\u53ca\u8d34\u73b0\u95ee\u9898\uff0c\u4e5f\u4e0d\u523b\u610f\u533a\u5206\u73b0\u8d27\u548c\u671f\u8d27\u4ef7\u683c\u3002 A.1 cash Greeks \u5728\u5b9e\u9645\u4ea4\u6613\u4e2d\uff0c\u6211\u4eec\u5e38\u5e38\u9700\u8981\u6bd4\u8f83\u4e0d\u540c underlying\uff0c\u4e0d\u540c portfolio \u7684\u98ce\u9669\u3002\u56e0\u6b64\u6211\u4eec\u5f15\u5165\u4e86 cash Delta, cash Gamma \u7b49\u6982\u5ff5\u3002\u5b9e\u9645\u4e0a\u5c31\u662f\u5c06 Greeks \u8f6c\u4e3a\u5b9e\u9645\u7684\u73b0\u91d1\u3002 \u5047\u8bbe\u67d0\u6807\u7684\u8d44\u4ea7\u7684\u4ef7\u683c\u4e3a \\(S\\) \u3002\u5b83\u7684 1 \u4efd\u671f\u8d27\u5408\u7ea6\u5305\u62ec\u6807\u7684\u8d44\u4ea7\u4e3a \\(M\\) \u4efd(multiplier)\u3002\u5219\u5bf9\u4e8e\u8be5\u671f\u8d27\u4ee5\u53ca\u5176\u671f\u6743\u884d\u751f\u54c1\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u51fa\u4ee5\u4e0b\u5173\u7cfb\uff1a cash Greek \u5b9a\u4e49 \u8ba1\u7b97 cash Delta \u7531 Delta \u51b3\u5b9a\u7684 portfolio \u7684\u4ef7\u503c \\(S \\times M \\times \\Delta\\) cash Gamma \u5f53 underlying \u4ef7\u683c\u53d8\u5316 1% \u65f6 cache Delta \u7684\u53d8\u5316\u91cf \\(\\frac{S^2}{100} \\times M \\times \\Gamma\\) \u4e3b\u8981\u8bf4\u4e0b cash Gamma \u7684\u8ba1\u7b97\u3002\u7531\u4e8e \\(\\Gamma\\) \u5b9a\u4e49\u4e3a\u6807\u7684\u8d44\u4ea7\u4ef7\u683c\u53d8\u5316 1 \u65f6 \\(\\Delta\\) \u7684\u53d8\u5316\u91cf\uff0c\u56e0\u6b64 \\(\\frac{S}{100} \\Gamma\\) \u5c31\u662f\u6807\u7684\u8d44\u4ea7\u4ef7\u683c\u53d8\u5316 1% \u65f6 \\(\\Delta\\) \u7684\u53d8\u5316\u91cf\u3002\u518d\u4e58\u4ee5\u7cfb\u6570 \\(S \\times M\\) \u5c31\u662f\u5bf9 cash Delta \u7684\u5f71\u54cd\u3002 \u7389\u7c73\u4ef7\u683c\u4e3a $3.5 \u6bcf bushel\uff0c\u4e00\u4e2a\u671f\u8d27\u5408\u7ea6\u4ea4\u6613 5000 bushels\u3002\u5047\u8bbe\u6211\u4eec\u6301\u6709 3 \u4e2a Delta \u4e3a 0.3 \u7684\u770b\u6da8\u671f\u6743\uff0c\u90a3 cashe Delta \u662f\u591a\u5c11\uff1f \\[3 \\times 0.3 \\times 3.5 \\times 5000 = 15750\\] \u5373\u6211\u4eec long 15.75k cash Delta\u3002\u82e5\u7389\u7c73\u4ef7\u683c\u4e0a\u5347 1% \u5c06\u76c8\u5229 $157.5\uff0c\u53cd\u4e4b\u4e8f\u635f $157.5\u3002 \u539f\u6cb9\u4ef7\u683c\u4e3a $50 \u4e00\u6876\uff0c\u4e00\u4e2a\u671f\u8d27\u5408\u7ea6\u4ea4\u6613 1000 \u6876\u539f\u6cb9\u3002\u67d0\u539f\u6cb9\u4e3a\u6807\u7684\u7269\u7684 portfolio \u5982\u679c\u4ef7\u683c\u4e0a\u5347 1% \u4f1a\u5bfc\u81f4 +3 Delta\uff0ccash Gamma \u662f\u591a\u5c11\uff1f \u5c06 3 Delta \u8f6c\u5316\u4e3a cash Delta\uff1a \\[3 * 50 * 1000 = 150000\\] \u4e5f\u5c31\u662f\u8bf4 1% \u7684\u539f\u6cb9\u4ef7\u683c\u53d8\u5316\u4f1a\u5bfc\u81f4\u6211\u4eec\u589e\u52a0 150k \u7684 cash Delta\u3002\u56e0\u6b64\u6211\u4eec long 150k cash Gamma\u3002 \u539f\u6cb9\u73b0\u8d27\u4ef7\u683c\u4e3a $104.8\uff0c\u671f\u8d27\u7684 multiplier \u4e3a 1000\u3002\u5df2\u77e5\u6267\u884c\u4ef7\u683c\u4e3a $105 \u7684\u770b\u6da8\u671f\u6743 Gamma \u4e3a 0.1527\u3002\u73b0\u5728\u6301\u6709 50 \u4e2a $105 \u7684 straddle\u3002 (a) Gamma \u4e3a\u591a\u5c11\uff1fcash Gamma \u4e3a\u591a\u5c11\uff1f (b) \u5047\u8bbe\u539f\u6cb9\u4ef7\u683c\u4e0a\u6da8 0.5%\uff0c\u6301\u4ed3\u7684 Delta \u5982\u4f55\u53d8\u5316 (a) straddle \u662f\u4e70\u5165\u540c\u6837\u6267\u884c\u4ef7\u683c\u7684 call \u548c put\uff0c\u4ed6\u4eec\u5177\u6709\u540c\u6837\u7684 Gamma\u3002 \\[\\Gamma = 0.1527 \\times 2 \\times 50 = 15.27\\] \\[cash~\\Gamma = \\frac{104.8^2}{100} \\times 1000 \\times \\Gamma = 1.677 \\times 10^6\\] (b) \u6b63\u7684 Gamma \u5bfc\u81f4\u7684 Delta \u53d8\u5316\u4e3a\uff1a \\[0.5\\% \\times 104.8 \\times \\Gamma = 8 \\] \u5373\u989d\u5916 long 8 Delta\u3002 A.2 Gamma \u548c Theta \u5f53\u6211\u4eec\u6301\u6709\u671f\u6743\u65f6\uff0cGamma \u4e3a\u6b63\u3002\u6b64\u65f6\uff0c\u82e5\u6807\u7684\u7269\u4ef7\u683c\u4e0a\u6da8\uff0cDelta \u4e5f\u968f\u4e4b\u4e0a\u6da8\u3002\u6211\u4eec\u9700\u8981\u5356\u51fa\u989d\u5916\u7684\u6807\u7684\u8d44\u4ea7\u3002\u76f8\u53cd\uff0c\u5f53\u6807\u7684\u7269\u4ef7\u683c\u4e0b\u8dcc\uff0cDelta \u4e5f\u968f\u4e4b\u4e0b\u8dcc\uff0c\u6211\u4eec\u9700\u8981\u4e70\u5165\u989d\u5916\u7684\u6807\u7684\u8d44\u4ea7\u3002 \u5982\u679c\u4e0d\u8003\u8651 Theta\uff0c\u4ee5\u4e0a\u7684\u4ea4\u6613\u770b\u8d77\u6765\u4f3c\u4e4e\u6709\u5229\u53ef\u56fe\u3002\u671f\u6743\u5e26\u6765\u7684Gamma \u9f13\u52b1\u6211\u4eec\u4f4e\u4e70\u9ad8\u5356\u5f97\u5230\u6536\u76ca\uff0c\u90a3\u4e3a\u4ec0\u4e48\u9700\u8981\u5356\u51fa\u671f\u6743\u5462\uff1f\u4e8b\u5b9e\u4e0a\uff0c\u6301\u6709\u671f\u6743\u65f6 Theta \u4e00\u822c\u4f1a\u5e26\u6765\u635f\u5931\u3002 \u5728 18.6 \u4e2d\u6211\u4eec\u5df2\u7ecf\u8bc1\u660e\uff0c\u4e8e\u4e00\u4e2a Delta \u4e2d\u6027\u7684 portfolio\uff0c\u6211\u4eec\u6709\u4ee5\u4e0b\u5173\u7cfb\uff08\u8fd9\u91cc\u7684 \\(\\Delta\\) \u8868\u793a\u5168\u5fae\u5206\uff09\uff1a \\[\\Delta \\Pi = \\Theta ~ \\Delta t + \\frac{1}{2}\\Gamma \\Delta S^2\\] \u4e0a\u5f0f\u8bf4\u660e\uff0c\u5728\u4fdd\u6301 Delta \u4e2d\u6027\u65f6\uff0cportfolio \u4ef7\u503c\u53d8\u5316\u53ef\u7531 Theta \u548c Gamma \u5171\u540c\u51b3\u5b9a\u3002\u6211\u4eec\u9700\u8981\u6bd4\u8f83\u5230\u5e95\u662f\u5728 Theta \u4e0a\u4e8f\u7684\u94b1\u591a\u8fd8\u662f\u5728 Gamma \u4e0a\u8d5a\u7684\u94b1\u591a\u3002 \u6211\u4eec\u53ef\u4ee5\u4ee4 \\(\\Delta t\\) \u4e3a\u4e00\u5929\uff0c\u6b64\u65f6 \\(\\Delta S\\) \u7684\u6700\u597d\u4f30\u8ba1\u5c31\u662f\u5c06 \\(\\sigma\\) \u4e5f\u8f6c\u4e3a\u4e00\u5929\u7684\u53d8\u5316\u540e\u518d\u4e58\u4ee5 \\(S\\) \u3002\u5f53\u4ee5\u4e0b\u5173\u7cfb\u6210\u7acb\u65f6\uff0c\u6211\u4eec\u8ba4\u4e3a\u4ed3\u4f4d\u662f \"effecient\" \u7684\uff1a \\[ \\Theta t_{day} + \\frac{1}{2} \\Gamma \\sigma_{day}^2 S^2 > 0\\] \u800c \\[\\Gamma_{cash} = \\frac{S^2} {100} \\times M \\times \\Gamma \\] \u6211\u4eec\u53ef\u4ee5\u5f97\u51fa\uff0c\u6bcf\u5929\u6301\u4ed3\u7684\u73b0\u91d1 Decay \u5e94\u8be5\u5c0f\u4e8e\uff1a \\[ \\frac{1}{2} \\times 100 \\times \\sigma_{day}^2 \\Gamma_{cash} \\] \u5047\u8bbe\u6211\u4eec\u4ed3\u4f4d\u7684 cash Gamma \u4e3a 1,000,000\uff0c\u6ce2\u52a8\u7387\u4e3a 16%\u3002\u95ee\u6211\u4eec\u80fd\u63a5\u53d7\u7684\u6700\u5927\u7684 Decay \u662f\u591a\u5c11\uff1f \u4e00\u5e74\u6709\u7ea6 250 \u4e2a\u4ea4\u6613\u65e5\uff0c\u7531\u6ce2\u52a8\u7387\u4e3a 16%\uff0c\u53ef\u4ee5\u5f97\u51fa\u6bcf\u5929\u7684\u6ce2\u52a8\u7387\u5927\u7ea6\u5728 1%\u3002\u53ef\u4ee5\u8ba1\u7b97\u80fd\u63a5\u53d7\u7684\u6700\u5927 Decay\uff1a \\[ 0.5 \\times 100 \\times 0.01^2 *10^6 = 5000\\] A.3 Slippage slippage \u5b9a\u4e49\u4e3a\u901a\u8fc7\u4ea4\u6613\u6807\u7684\u7269\u6765\u5bf9\u51b2 Delta \u7684\u6210\u672c\u3002\u5bf9\u4e8e\u671f\u6743\u4ea4\u6613\u8005\u6765\u8bf4\uff0c\u7531\u4e8e\u5fc5\u987b\u7ef4\u6301\u4e2d\u6027\u7684 Delta\uff0c\u8fd9\u662f\u5fc5\u7136\u7684\u6210\u672c\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\u6211\u4eec\u80fd\u5728\u7406\u8bba\u4ef7\u683c\u4e0a\u53bb\u4ea4\u6613\uff0c\u5b9e\u9645\u4e0a\uff0c\u6211\u4eec\u6709\u65f6\u5019\u4e0d\u80fd\u5b8c\u5168\u5728 top of book \u6210\u4ea4\uff0c\u6709\u65f6\u751a\u81f3\u9700\u8981\u4ea4\u6613\u51e0\u4e2a level \u6765\u5bf9\u51b2\u3002\u8fd9\u5c06\u5f71\u54cd\u6211\u4eec\u5728\u671f\u6743\u4ea4\u6613\u4e2d\u7684\u6536\u76ca\u3002 \u4e3e\u4f8b\u6765\u8bb2\uff0c\u8fd9\u662f\u67d0\u4e2a\u65f6\u523b\u539f\u6cb9\u671f\u8d27\u7684 book\uff08\u4ec5\u5217\u51fa 3 \u4e2a level\uff09\u3002 Bid Quantity Price Ask Quantity 66.87 31 66.86 59 66.85 38 30 66.84 59 66.83 50 66.82 \u6b64\u65f6\u7684\u7406\u8bba\u4ef7\u683c\u662f 66.843 \uff08\u8be5\u4ef7\u683c\u901a\u8fc7 book \u5f97\u51fa\uff0c\u5177\u4f53\u4e0d\u5c55\u5f00\uff09 \u540c\u65f6\uff0c\u4e0e\u8be5\u539f\u6cb9\u671f\u8d27\u76f8\u540c\u5230\u671f\u65e5\u7684\u4e24\u4e2a\u6b63\u5728\u4ea4\u6613\u7684\u671f\u6743\uff1a # Delta Bid Price Theo Ask Price 1 0.30 1.23 1.237 1.24 2 0.15 0.63 0.640 0.65 \u4ee5\u4e0b\u5b9e\u9645\u4f8b\u5b50\u53ef\u4ee5\u5e2e\u52a9\u7406\u89e3\u5bf9\u51b2\u6210\u672c\uff08slippage\uff09\uff0c\u6211\u4eec\u540c\u65f6\u8fd8\u53ef\u4ee5\u5f15\u5165\u4e00\u4e2a Retained Edge \u6982\u5ff5\u3002\u8fd9\u662f\u7528\u4e8e\u8868\u793a\u5728 hedge \u4e4b\u540e\u6211\u4eec\u8fd8\u80fd\u4fdd\u7559\u7684\u6765\u81ea\u671f\u6743\u4ea4\u6613\u7684 edge\u3002 Operation Option Edge Hedge Loss Retained Edge buy option #1 1.237 - 1.230 = 0.007 0.003*0.3 = 0.0009 0.0061 (87%) buy option #2 0.640 - 0.63 = 0.01 0.003*0.15 = 0.00045 0.00955 (96%) sell option #1 1.24 - 1.237 = 0.003 0.007*0.3 = 0.0021 0.0009 (30%) sell option #2 0.65 - 0.64 = 0.01 0.007*0.15 = 0.00105 0.00895 (90%) \u6216\u8005\uff0c\u4e5f\u53ef\u4ee5\u4ece\u53e6\u4e00\u79cd\u65b9\u5f0f\u7406\u89e3\u3002\u671f\u6743\u7684\u7406\u8bba\u4ef7\u683c\u7531\u671f\u8d27\u7684 book \u51b3\u5b9a\u3002\u6211\u4eec\u5728\u4ea4\u6613\u671f\u6743\u540e\uff0c\u9700\u8981\u5728\u671f\u8d27\u4e0a hedge\u3002\u8fd9\u4e2a\u884c\u4e3a\u4f1a\u5bfc\u81f4\u671f\u8d27\u7684 book \u53d8\u52a8\uff0c\u4ece\u800c\u5bfc\u81f4\u671f\u6743\u7684\u7406\u8bba\u4ef7\u683c\u5411 \u4e0d\u5229 \u6211\u4eec\u7684\u65b9\u5411\u66f4\u65b0\u3002Retained Edge \u662f\u6307\u5229\u7528\u66f4\u65b0\u540e\u7684\u7406\u8bba\u4ef7\u683c\u5f97\u5230\u7684 edge\uff0c\u800c\u975e\u4ea4\u6613\u671f\u6743\u65f6\u523b\u7684\u7406\u8bba\u4ef7\u683c\u3002 \u5bf9\u4e8e\u4e0a\u9762\u8868\u683c\u4e2d\u7684\u7b2c\u4e00\u4e2a\u4f8b\u5b50\uff0c\u4ea4\u6613\u671f\u6743\u65f6\u7406\u8bba\u4ef7\u683c\u662f1.237\uff0c\u6b64\u540e\u53bb hedge \u65f6\uff0c\u7531\u4e8e\u6211\u4eec\u9700\u8981\u8de8\u8d8a bid ask spread \u53bb\u5356\u51fa\u671f\u8d27\uff0c\u4ea4\u6613\u53d1\u751f\u65f6\u523b\u671f\u8d27\u7684\u7406\u8bba\u4ef7\u683c\u4e0d\u518d\u662f 66.843\uff0c\u800c\u662f\u671f\u8d27\u7684 top of book bid\uff0c\u537366.84\u3002 \u671f\u8d27\u7406\u8bba\u4ef7\u683c\u53d8\u52a8\u4e86 -0.003\uff0c\u4e58\u4ee5\u671f\u6743 #1 \u7684 Delta 0.3\uff0c\u53ef\u4ee5\u5f97\u51fa\u671f\u6743\u7684\u7406\u8bba\u4ef7\u683c\u53d8\u52a8\u4e3a -0.0009\uff0c\u65b0\u7684\u671f\u6743\u4ef7\u683c\u4e3a 1.2361\u3002\u6b64\u65f6\u518d\u6765\u770b\u8fd9\u7b14\u4ea4\u6613\u7684 Edge\uff0c\u5c31\u662f Retained Edge\uff0c1.2361 - 1.23 = 0.0061\u3002\u4e0e\u8868\u683c\u4e2d\u7ed3\u8bba\u4e00\u81f4\u3002 \u53c2\u8003 \u5728\u7ebf\u6b63\u6001\u5206\u5e03\u8ba1\u7b97\u5668 Trading 101","title":"The Greek letters"},{"location":"trading/option/Greeks/#the-greek-letters","text":"Greeks \u662f\u4e3a\u63cf\u8ff0\u671f\u6743\u6301\u4ed3\u98ce\u9669\u5f15\u5165\u7684\uff0c\u4ed6\u4eec\u5404\u81ea\u4ee3\u8868\u4e00\u4e2a\u7ef4\u5ea6\u7684\u98ce\u9669\u3002","title":"The Greek letters"},{"location":"trading/option/Greeks/#184-delta","text":"delta ( \\(\\Delta\\) ) \u8868\u793a\u671f\u6743\u4ef7\u683c\u53d8\u52a8\u4e0e\u6807\u7684\u7269\u4ef7\u683c\u53d8\u52a8\u4e4b\u95f4\u7684\u6bd4\u7387\u3002\u82e5\u5047\u8bbe \\(c\\) \u4e3a\u770b\u6da8\u671f\u6743\u4ef7\u683c\uff0c \\(S\\) \u4e3a\u5bf9\u5e94\u7684\u80a1\u7968\u4ef7\u683c\uff0c\u5219\u6709\uff1a \\[\\Delta = \\frac{\\partial c}{\\partial S}\\] \u4f8b\u5982\uff0c\u67d0\u80a1\u7968\u4ef7\u683c\u4e3a $100\uff0c\u5b83\u7684\u67d0\u4e2a\u770b\u6da8\u671f\u6743\u4ef7\u683c\u4e3a $10\u3002\u4e00\u4e2a\u6295\u8d44\u8005\u5356\u4e86 20 \u4efd\u770b\u6da8\u671f\u6743\uff08\u6bcf\u4efd 100 share\uff0c\u5171 2000 share\uff09\u3002\u8fd9\u4e2a\u6295\u8d44\u8005\u7684\u4ed3\u4f4d\u53ef\u4ee5\u901a\u8fc7\u8d2d\u4e70 \\(0.6 \\times 2000 = 1200\\) share \u80a1\u7968\u5bf9\u51b2\uff0c\u4f7f\u6574\u4e2a\u7ec4\u5408\u7684 delta \u4e3a 0\uff0c\u5373 delta \u4e2d\u6027\u3002 \u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u7531\u4e8e\u671f\u6743\u7684 delta \u662f\u4e00\u76f4\u53d8\u5316\u7684\uff0c\u4e0a\u9762\u4f8b\u5b50\u4e2d\u7684 delta \u4e2d\u6027\u53ea\u80fd\u4fdd\u6301\u975e\u5e38\u77ed\u7684\u4e00\u6bb5\u65f6\u95f4\u3002 \u5047\u8bbe\u8fc7\u4e00\u6bb5\u65f6\u95f4\uff0c\u8be5\u80a1\u7968\u4ef7\u683c\u6da8\u5230\u4e86 $110\uff0c\u770b\u6da8\u671f\u6743\u7684 delta \u968f\u4e4b\u4e0a\u6da8\u5230 0.65\u3002\u5219\u6211\u4eec\u9700\u8981\u989d\u5916\u518d\u4e70\u5165 \\(0.05 \\times 2000 = 100\\) share \u6765\u4fdd\u6301 delta \u4e2d\u6027\u3002\u8fd9\u6837\u6301\u7eed\u4f9d\u636e\u6700\u65b0\u7684 delta \u8fdb\u884c\u5bf9\u51b2\u7684\u8fc7\u7a0b\u88ab\u79f0\u4e3a\u52a8\u6001\u5bf9\u51b2( dynamic hedging )\u3002\u5426\u5219\u88ab\u79f0\u4e3a\u9759\u6001\u5bf9\u51b2\u3002","title":"18.4 Delta"},{"location":"trading/option/Greeks/#1841-delta","text":"\u5bf9\u4e8e\u4e00\u4e2a\u6b27\u5f0f\u770b\u6da8\u671f\u6743\uff0c\u5229\u7528 B-S-M \u516c\u5f0f\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\uff1a \\[\\Delta_{call} = \\Phi(d_1)\\] \u5bf9\u4e8e\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\uff0c\u5219\u6709\uff1a \\[\\Delta_{put} = \\Delta_{call} - 1\\]","title":"18.4.1 \u6b27\u5f0f\u671f\u6743\u7684 Delta"},{"location":"trading/option/Greeks/#_1","text":"\u7531 B-S-M \u516c\u5f0f\u7a0d\u4f5c\u53d8\u5f62\uff08\u8ba1\u7b97 \\(t\\) \u65f6\u523b\u800c\u975e 0 \u65f6\u523b\u7684\u4ef7\u683c\uff09\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\uff1a \\[c = S \\Phi(d_1) - Ke^{-r(T-t)}\\Phi(d_2)\\] \u6211\u4eec\u4e0d\u80fd\u7b80\u5355\u5f97\u5230\u7ed3\u679c\uff0c\u56e0\u4e3a \\(d_1\\) \u548c \\(d_2\\) \u90fd\u662f\u5173\u4e8e \\(S\\) \u7684\u51fd\u6570\uff1a \\[d_1 = \\frac{\\ln(\\frac{ S }{ K }) + (r + \\frac{ 1}{ 2} \\sigma^2)(T-t)} {\\sigma \\sqrt{T-t}}\\] \\[d_2 = d_1 - \\sigma \\sqrt{T-t}\\] \u6211\u4eec\u5229\u7528\u6c42\u5bfc\u516c\u5f0f\u6709\uff1a \\[\\frac{ \\partial c}{ \\partial S} = \\Phi(d_1) + S\\Phi'(d_1)\\frac{ \\partial d_1}{ \\partial S} - Ke^{-r(T-t)}\\Phi'(d_2)\\frac{ \\partial d_2}{ \\partial S}\\] \u5176\u4e2d \\(\\Phi'(x)\\) \u662f\u6b63\u6001\u5206\u5e03\u7684\u5bc6\u5ea6\u51fd\u6570\uff1a \\[\\Phi'(x) = \\frac{1}{ \\sqrt{2\\pi}}e^{-\\frac{ x^2}{2}}\\] \u6211\u4eec\u5f88\u5bb9\u6613\u5f97\u5230\uff1a \\[\\frac{\\partial d_1}{\\partial S} = \\frac{\\partial d_2}{\\partial S} = \\frac{1}{S\\sigma \\sqrt{T-t}}\\] \u800c\u5229\u7528 \\(d_1 = d_2 + \\sigma \\sqrt{T-t}\\) \u53ef\u4ee5\u5f97\u5230\uff1a \\[S\\Phi'(d_1) = \\frac{S}{\\sqrt{2\\pi}}e^{-\\frac{(d_2 + \\sigma \\sqrt{T-t})^2}{2}} = Se^{-d_2\\sigma\\sqrt{T-t} ~-\\frac{1}{2}\\sigma^2(T-t)}\\Phi'(d_2)\\] \u4ee3\u5165 \\(d_2\\) \uff1a \\[d_2 = \\frac{\\ln(\\frac{S}{K}) + (r - \\frac{1}{2}\\sigma^2)(T-t)}{\\sigma \\sqrt{T-t}}\\] \u53ef\u4ee5\u5f97\u5230\uff1a \\[S\\Phi'(d_1) = Se^{-\\ln(\\frac{S}{K}) - r (T-t)} \\Phi'(d_2) = Ke^{-r(T-t)}\\Phi'(d_2)\\] \u56e0\u6b64\u6709\uff1a \\[\\frac{\\partial c}{\\partial S} = \\Delta = \\Phi(d_1)\\] \u5bf9\u4e8e\u770b\u8dcc\u671f\u6743\uff0c\u53ef\u4ee5\u7531 put-call-parity \u5f97\u5230\u3002 \u5178\u578b\u7684 \\(\\Delta\\) \u4e0e\u6807\u7684\u7269\u4ef7\u683c\u7684\u5173\u7cfb\u56fe\u5982\u4e0b\uff1a \u53ef\u4ee5\u770b\u5230 call \u548c put \u4e24\u8005\u8d8b\u52bf\u4e00\u81f4\uff0c\u5dee\u8ddd 1.0\u3002 call \u7684 \\(\\Delta\\) \u4e0e\u5230\u671f\u65f6\u95f4\u7684\u5173\u7cfb\u56fe\u5982\u4e0b\uff1a \u5373\uff0c\u79bb\u5230\u671f\u65e5\u8d8a\u8fd1\uff0cOTM \u4f1a\u8d8a\u6765\u8d8a\u4e0d\u503c\u94b1\uff0cDelta \u8d8b\u8fd1\u4e8e 0\u3002 ITM \u7684 Delta \u5219\u4f1a\u8d8b\u8fd1\u4e8e 1\u3002\u8fd9\u7b26\u5408\u76f4\u89c2\u3002 \u6709\u79cd\u8bf4\u6cd5\u662f\uff0c\u5c06 Delta \u7406\u89e3\u4e3a\u671f\u6743\u5230\u671f\u65f6 In The Money \u7684\u6982\u7387\u3002\u8fd9\u5e76\u4e0d\u662f\u5f88\u51c6\u786e\uff0c\u6211\u4eec\u5728 \u7b2c\u5341\u56db\u7ae0 \u4f8b 5 \u4e2d\u5df2\u7ecf\u8bc1\u660e\u4e86\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u6b27\u5f0f\u770b\u6da8\u671f\u6743\uff0c\u5230\u671f\u65f6 In The Money \u7684\u6982\u7387\u662f \\(\\Phi(d_2)\\) \u800c\u4e0d\u662f \\(\\Delta = \\Phi(d_1)\\) \u3002\u51c6\u786e\u7684\u8bf4\u5b83\u53ea\u662f\u8fd9\u4e2a\u6982\u7387\u7684\u4e00\u4e2a proxy\uff0c\u5982 Delta of Calls vs. Puts and Probability of Expiring In the Money \u6240\u63cf\u8ff0\u7684\u3002","title":"\u8bc1\u660e"},{"location":"trading/option/Greeks/#1843-delta","text":"\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u4e00\u4e2a\u8fdc\u671f\u5408\u7ea6\u7684\u4ef7\u503c\u4e3a\uff1a \\[f = S_0 - Ke^{-rT}\\] \u5176\u4e2d \\(K\\) \u662f\u4ea4\u5272\u4ef7\u683c\uff0c \\(T\\) \u662f\u8ddd\u79bb\u5230\u671f\u65e5\u65f6\u95f4\u3002\u56e0\u6b64\u82e5\u80a1\u7968\u4ef7\u683c\u53d8\u5316 \\(\\Delta S\\) \uff0c\u5219\u8fdc\u671f\u5408\u7ea6\u4ef7\u683c\u4e5f\u53d8\u5316 \\(\\Delta S\\) \u3002\u8fd9\u8bf4\u660e\u5b83\u7684 Delta \u6052\u7b49\u4e8e 1.0\uff0c\u4e0e\u73b0\u8d27\u4e00\u81f4\u3002","title":"18.4.3 \u8fdc\u671f\u5408\u7ea6 Delta"},{"location":"trading/option/Greeks/#1844-delta","text":"\u671f\u8d27\u7684\u5408\u7ea6\u4ef7\u683c\u4e3a\uff1a \\[F = S_0e^{rT}\\] \u5176\u4e2d \\(S_0\\) \u4e3a\u5f53\u524d\u73b0\u8d27\u4ef7\u683c\uff0c \\(T\\) \u4e3a\u8ddd\u79bb\u4ea4\u5272\u65e5\u65f6\u95f4\u3002 \u56e0\u6b64\u4e00\u4e2a\u671f\u8d27\u7684 Delta \u5c31\u662f \\(e^{rT}\\) \uff0c\u5728 \\(r > 0\\) \u65f6\u6709 \\(\\Delta > 1\\) \u3002\u8fd9\u770b\u8d77\u6765\u53ef\u80fd\u5f88\u5947\u602a\uff0c\u56e0\u4e3a\u671f\u8d27\u662f\u6bcf\u5929 settle\uff0c\u56e0\u6b64\u51e0\u4e4e\u80fd\u7acb\u5373\u62ff\u5230\u8fd9\u4e2a\u94b1\u3002 \u6709\u65f6\u6211\u4eec\u7528\u671f\u8d27\u5408\u7ea6\u6765\u8fbe\u6210 Delta \u4e2d\u6027\u3002\u5047\u8bbe \\(T\\) \u662f\u8ddd\u79bb\u671f\u8d27\u5230\u671f\u65e5\u65f6\u95f4\uff0c \\(H_A\\) \u662f\u7528\u6807\u7684\u7269\u8d44\u4ea7\u5bf9\u51b2\u9700\u8981\u7684\u7684\u4ed3\u4f4d\uff0c \\(H_F\\) \u662f\u7528\u671f\u8d27\u5bf9\u51b2\u65f6\u9700\u8981\u7684\u4ed3\u4f4d\u3002\u6709\uff1a \\[H_F = e^{-rT}H_A\\] \u6b27\u5f0f\u671f\u8d27\u671f\u6743\u7684 Delta \u901a\u5e38\u88ab\u5b9a\u4e49\u4e3a\u4e0e \u671f\u8d27\u4ef7\u683c\uff08\u800c\u975e\u5373\u671f\u4ef7\u683c\uff09 \u76f8\u5173\u7684\u671f\u6743\u4ef7\u683c\u53d8\u5316\u7387\uff0c\u5373 \u8fdc\u671f\uff08\u800c\u975e\u5373\u671f\uff09 \u7684 Delta\u3002","title":"18.4.4 \u671f\u8d27\u7684 Delta"},{"location":"trading/option/Greeks/#_2","text":"\u5df2\u77e5\u671f\u8d27\u4ef7\u683c \\(F\\) \u6ee1\u8db3\uff1a \\[F = S_0 e^{rT}\\] \u5982\u679c\u671f\u8d27\u7684\u5230\u671f\u65e5\u4e3a \\(T_1\\) \uff0c\u671f\u6743\u7684\u5230\u671f\u65e5\u4e3a \\(T_2\\) \uff0c\u90a3\u4e48\u53ef\u4ee5\u5c06 \\(d_1\\) \u8868\u793a\u4e3a\uff1a \\[d_1 = \\frac{\\ln(\\frac{Fe^{-rT_2}}{K}) + (r + \\frac{1}{2}\\sigma^2)T_1}{\\sigma \\sqrt{T_1}} = \\frac{\\ln(\\frac{F}{K}) + r(T_1 - T_2) + \\frac{1}{2}\\sigma^2T_1}{\\sigma \\sqrt{T_1}} \\] \u5047\u8bbe \\(T_1 = T_2 = T\\) \u90a3\u4e48\u8fd9\u4e2a\u671f\u6743\u5173\u4e8e \u73b0\u8d27 \u7684 Delta \u5c31\u53ef\u4ee5\u5199\u4e3a\uff1a \\[\\Delta = \\Phi(d_1) = \\Phi(\\frac{\\ln(\\frac{F}{K}) + \\frac{1}{2}\\sigma^2T} {\\sigma \\sqrt{T}})\\] \u7531\u4e8e\u73b0\u8d27\u7684 Delta \u662f 1\uff0c\u800c\u671f\u8d27\u7684 Delta \u662f \\(e^{rT}\\) \uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u51fa\u8be5\u671f\u6743\u5173\u4e8e \u671f\u8d27 \u7684 Delta\uff1a \\[\\Delta_F = e^{-rT} \\Delta \\]","title":"\u8bc1\u660e"},{"location":"trading/option/Greeks/#1","text":"\u5047\u8bbe\u67d0\u767d\u94f6\u671f\u8d27\u4ea4\u5272\u65e5\u5728 9 \u4e2a\u6708\u4ee5\u540e\uff0c\u4ea4\u5272\u4ef7\u683c\u4e3a $8 \u6bcf\u76ce\u53f8\u3002\u540c\u65f6\u67d0\u4e2a\u767d\u94f6\u7684\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u5230\u671f\u65e5\u5728 8 \u4e2a\u6708\u4ee5\u540e\uff0c\u6267\u884c\u4ef7\u683c\u4e3a $8 \u6bcf\u76ce\u53f8\u3002\u65e0\u98ce\u9669\u5229\u7387\u4e3a 12% \u6bcf\u5e74\uff0c\u767d\u94f6\u7684\u6ce2\u52a8\u7387\u4e3a 18% \u6bcf\u5e74\u3002 \u5219 1000 \u4efd\u8be5\u767d\u94f6\u671f\u8d27\u7684\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u7a7a\u5934\u7684 Delta \u662f\u591a\u5c11\uff1f \u7531\u4e8e\u671f\u8d27\u671f\u6743\u7684 Delta \u5b9a\u4e49\u4e3a\u4e0e \u671f\u8d27\u4ea4\u5272\u4ef7\u683c \u76f8\u5173\u7684\u53d8\u5316\u7387\uff0c\u56e0\u6b64\u8fd9\u91cc\u6211\u4eec\u9700\u8981\u8ba1\u7b97\uff1a \\[d_1 = \\frac{\\ln(\\frac{F}{K}) + r(T_1 - T_2) + \\frac{1}{2}\\sigma^2 T_1}{\\sigma \\sqrt{T_1}} = 0.00544331 \\] \u7136\u540e\u53ef\u4ee5\u7ee7\u7eed\u5f97\u5230 \\[\\Delta = e^{-rT}\\Phi(d_1) = e^{-0.12*9/12} \\times 0.5022 = 0.4590\\] \u56e0\u6b641000\u4efd\u8be5\u671f\u6743\u7a7a\u5934\u7684 Delta \u4e3a -459.0\uff0c\u6ce8\u610f\u8fd9\u4e2a Delta \u662f\u5173\u4e8e\u671f\u8d27\u7684 Delta\u3002","title":"\u4f8b 1"},{"location":"trading/option/Greeks/#2","text":"\u5728\u4f8b 1 \u4e2d\uff0c\u4e3a\u4e86\u5bf9\u51b2\u5fc5\u9700\u7684\u767d\u94f6\u671f\u8d27\u521d\u59cb\u4ed3\u4f4d\u662f\u591a\u5c11\uff1f\u5982\u679c\u76f4\u63a5\u7528\u767d\u94f6\u73b0\u8d27\u5bf9\u51b2\uff0c\u521d\u59cb\u4ed3\u4f4d\u53c8\u8be5\u662f\u591a\u5c11\uff1f\u5982\u679c\u7528\u8fd8\u6709 12 \u4e2a\u6708\u5230\u671f\u7684\u767d\u94f6\u671f\u8d27\u5462\uff1f\u5ffd\u7565\u767d\u94f6\u7684\u5b58\u653e\u8d39\u7528\u3002 \u82e5\u7528 9 \u4e2a\u6708\u540e\u5230\u671f\u7684\u671f\u8d27\u8fdb\u884c\u5bf9\u51b2\uff0c\u5219\u5e94\u8be5\u7528 459.0 \u76ce\u53f8\u3002 \u82e5\u7528\u767d\u94f6\u73b0\u8d27\uff0c\u5219\u9700\u8981\u628a\u8fdc\u671f Delta \u8f6c\u4e3a\u5373\u671f\u7684\uff0c\u5373 502.2 \u76ce\u53f8\u3002 \u82e5\u7528 12 \u4e2a\u6708\u5230\u671f\u7684\uff0c\u5219\u4ee5\u5373\u671f\u7684\u4e58\u4ee5 \\(e^{-0.12}\\) \uff0c\u5f97 445.4 \u76ce\u53f8\u3002","title":"\u4f8b 2"},{"location":"trading/option/Greeks/#185-theta","text":"Theta( \\(\\Theta\\) ) \u7528\u4e8e\u63cf\u8ff0 portfolio \u4ef7\u503c\u968f\u65f6\u95f4\u7684\u53d8\u5316\u7387\uff0c\u5373 time decay\u3002\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\[\\Theta = \\frac{\\partial c}{\\partial t}\\] \u5bf9\u4e8e call \u6709\uff1a \\[\\Theta_{call} = -\\frac{ S_0 \\Phi'(d_1)\\sigma} { 2 \\sqrt{T-t}} - rKe^{-r(T-t)}\\Phi(d_2)\\] \u5bf9\u4e8e put \u6709\uff1a \\[\\Theta_{put} = \\Theta_{call} + rKe^{-r(T-t)} \\] \u5176\u4e2d \\[\\Phi'(x) = \\frac{ 1}{ \\sqrt{2\\pi} }e^{-\\frac{ x^2 }{ 2}}\\] \u6211\u4eec\u901a\u8fc7\u516c\u5f0f\u53d1\u73b0\uff0c\u5bf9\u4e8e call\uff0c \\(\\Theta\\) \u603b\u662f\u5c0f\u4e8e 0 \u7684 \u3002\u5373\u968f\u7740\u5230\u671f\u65e5\u4e34\u8fd1\uff0c\u671f\u6743\u8d8a\u6765\u8d8a\u4e0d\u503c\u94b1\u3002 \u4f46\u662f\u6709\u4e00\u4e2a\u4f8b\u5916\u5c31\u662f\u5bf9\u4e8e deep in the money \u7684 put\uff0c \\(\\Theta\\) \u53ef\u80fd\u4e3a\u6b63\u3002\u76f4\u89c2\u4e0a\uff0c\u5047\u8bbe\u67d0\u4e2a\u80a1\u7968\u4ef7\u683c\u5df2\u7ecf\u8dcc\u5230\u63a5\u8fd10\uff0c\u968f\u7740\u5230\u671f\u65e5\u4e34\u8fd1\uff0c\u8be5\u80a1\u7968\u4e0a\u6da8\u7684\u6982\u7387\u8d8a\u4f4e\uff0c\u6240\u4ee5\u5b83\u7684 put \u5177\u6709\u66f4\u5927\u7684\u786e\u5b9a\u6027\u8d5a\u94b1\u3002 \u5173\u4e8e\u8fd9\u70b9\uff0c\u53ef\u4ee5\u53c2\u8003 \u80a1\u7968\u671f\u6743\u7684\u6027\u8d28 \u4e2d\u7684\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\u7684\u4e0a\u4e0b\u9650\u5206\u6790\u90e8\u5206\u3002\u5728\u5176\u4e2d\u6211\u4eec\u6307\u51fa\u4e86\u5bf9\u4e8e deep in the money \u7684 put\uff0c\u5b83\u7684\u65f6\u95f4\u4ef7\u503c\u4e3a\u8d1f\u3002\u800c\u671f\u6743\u968f\u7740\u5230\u671f\u65e5\u4e34\u8fd1\uff0c\u65f6\u95f4\u4ef7\u503c\u603b\u662f\u8d8b\u8fd1\u4e8e0\u3002\u56e0\u6b64\u5fc5\u7136\u6709\u4e00\u4e2a\u6e10\u6e10\u589e\u5927\u7684\u8fc7\u7a0b\u3002","title":"18.5 Theta"},{"location":"trading/option/Greeks/#_3","text":"\u6211\u4eec\u9700\u8981\u5229\u7528 B-S-M \u516c\u5f0f\u5f97\u51fa\u671f\u6743\u4ef7\u683c\u76f8\u5bf9\u4e8e\u65f6\u95f4\u7684\u5bfc\u6570\u3002\u6ce8\u610f\uff0c\u8fd9\u91cc\u4e0d\u80fd\u76f4\u63a5\u5bf9 \\(T\\) \u6c42\u5bfc\uff0c\u56e0\u4e3a\u5b83\u662f\u5230\u671f\u65f6\u95f4\uff0c\u6211\u4eec\u5b9e\u9645\u9700\u8981\u5bf9 \\(t\\) \u6c42\u5bfc\u3002 \u5148\u5c06 B-S-M \u5199\u6210\u5728 \\(t\\) \u65f6\u523b\u800c\u975e \\(0\\) \u65f6\u523b\u7684\u8868\u8fbe\u5f62\u5f0f\uff1a \\[c = S_t\\Phi(d_1) - Ke^{-r(T-t)}\\Phi(d_2)\\] \u5176\u4e2d\uff1a \\[d_1 = \\frac{ \\ln(\\frac{S_t}{ K}) + (r + \\frac{ 1}{ 2}\\sigma^2)(T-t)}{\\sigma \\sqrt{T-t}}\\] \\[d_2 = d_1 - \\sigma \\sqrt{T-t}\\] \u5bf9 \\(t\\) \u6c42\u5bfc\uff0c\u6709\uff1a \\[\\frac{\\partial c}{\\partial t} = S_t\\Phi'(d_1)\\frac{\\partial d_1}{\\partial t} - Ke^{-r(T-t)}\\Phi'(d_2)\\frac{\\partial d_2}{\\partial t} - rKe^{-r(T-t)}\\Phi(d_2)\\] \u6211\u4eec\u5df2\u7ecf\u5728\u8bc1\u660e \\(\\Delta = \\Phi(d_1)\\) \u8fc7\u7a0b\u4e2d\u5f97\u5230\uff1a \\[S_t\\Phi'(d_1) = Ke^{-r(T-t)}\\Phi'(d_2)\\] \u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\uff1a \\[\\frac{\\partial c}{\\partial t} = S_t\\Phi'(d_1)\\frac{\\partial(d_1 - d_2)}{\\partial t} - rKe^{-r(T-t)}\\Phi(d_2) = -\\frac{\\sigma S_t}{2\\sqrt{T-t}}\\Phi'(d_1) - rKe^{-r(T-t)}\\Phi(d_2)\\] \u5bf9\u4e8e\u4e00\u4e2a put\uff0cB-S-M \u516c\u5f0f\u4e3a\uff1a \\[p = c + Ke^{-r(T-t)} - S_t\\] \u663e\u7136\u6709\uff1a \\[\\frac{\\partial p}{\\partial t} = \\frac{\\partial c}{\\partial t} + rKe^{-r(T-t)}\\] \u5178\u578b\u7684 call \u7684 \\(\\Theta\\) \u4e0e\u80a1\u7968\u4ef7\u683c\u5173\u7cfb\u7684\u66f2\u7ebf\u5982\u4e0b\uff1a \u5f53\u80a1\u7968\u4ef7\u683c\u8db3\u591f\u9ad8\u65f6\uff0c \\(d_1\\) \u548c \\(d_2\\) \u8d8b\u8fd1\u4e8e\u65e0\u9650\u5927\u3002\u6b64\u65f6 \\(\\Phi'(d_1) \\to 0\\) \uff0c \\(\\Phi(d_2) \\to 1\\) \u3002\u56e0\u6b64\u6709\u770b\u6da8\u671f\u6743\u7684 \\(\\Theta \\to -rKe^{-r(T-t)}\\) \u3002 \\(\\Theta\\) \u4e0e\u8ddd\u79bb\u5230\u671f\u65e5\u65f6\u95f4\u7684\u5173\u7cfb\u5982\u4e0b\uff1a \u53ef\u4ee5\u770b\u5230\uff0c\u5bf9\u4e8e\u6240\u6709\u7c7b\u578b\u7684\u671f\u6743\uff0c \\(\\Theta\\) \u662f\u5c0f\u4e8e 0 \u7684\u3002\u5373\u968f\u7740\u5230\u671f\u65e5\u4e34\u8fd1\uff0c\u671f\u6743\u4ef7\u683c\u8d8b\u8fd1\u4e8e\u964d\u4f4e\u3002\u5bf9\u4e8e ATM \u7684\u770b\u6da8\u671f\u6743\uff0c\u5f53\u4e34\u8fd1\u5230\u671f\u65e5( \\(t \\to T\\) )\u65f6\uff0c\u5b83\u7684 \\(\\Theta\\) \u8d8b\u8fd1\u4e8e\u8d1f\u65e0\u7a77\u3002 \u7efc\u5408\u6765\u770b\uff0c \u77ed\u671f\u7684 ATM \u671f\u6743\u5177\u6709\u7edd\u5bf9\u503c\u6700\u5927\u7684\u8d1f Theta \u3002","title":"\u8bc1\u660e"},{"location":"trading/option/Greeks/#_4","text":"\u4e00\u4e2a\u671f\u6743\u7684 Theta \u4e3a -0.1 \uff08\u4ee5\u5e74\u8ba1\u7b97\uff09\u542b\u4e49\u662f\u4ec0\u4e48\uff1f\u5982\u679c\u4ea4\u6613\u5458\u8ba4\u4e3a\u80a1\u7968\u4ef7\u683c\u548c\u6ce2\u52a8\u7387\u90fd\u4e0d\u4f1a\u53d8\u5316\uff0c\u90a3\u4e48\u8fd9\u4e2a\u671f\u6743\u7684\u4ed3\u4f4d\u5e94\u8be5\u662f\u591a\u5c11\uff1f \u8fd9\u8868\u793a\u6bcf\u7ecf\u8fc7\u4e00\u4e2a\u5f88\u77ed\u7684\u65f6\u95f4 \\(\\Delta t\\) \uff0c\u671f\u6743\u7684\u4ef7\u683c\u4f1a\u53d8\u5316 \\(-0.1\\Delta t\\) \u3002 \u5982\u679c\u80a1\u7968\u4ef7\u683c\u548c\u6ce2\u52a8\u7387\u90fd\u4e0d\u4f1a\u53d8\u5316\uff0c\u5219\u8be5\u671f\u6743\u4ef7\u683c\u4f1a\u968f\u7740\u5230\u671f\u65e5\u4e34\u8fd1\u8d8a\u6765\u8d8a\u4f4e\u3002\u4ea4\u6613\u5458\u5e94\u8be5\u9009\u62e9\u5356\u51fa Theta \u4e3a\u8d1f\uff0c\u4e14\u7edd\u5bf9\u503c\u8f83\u5927\u7684\u671f\u6743\u3002\u800c\u7531\u4e8e \u77ed\u671f\u7684 ATM \u671f\u6743\u5177\u6709\u7edd\u5bf9\u503c\u6700\u5927\u7684\u8d1f Theta \uff0c\u5e94\u8be5\u5356\u51fa\u77ed\u671f\u7684 ATM \u671f\u6743\u3002","title":"\u4f8b"},{"location":"trading/option/Greeks/#186-gamma","text":"Gamma ( \\(\\Gamma\\) ) \u8868\u793a portfolio \u7684 Delta \u968f\u6807\u7684\u7269\u4ef7\u683c\u53d8\u52a8\u7684\u53d8\u5316\u7387\u3002 \u5047\u8bbe\u67d0 portfolio \u4ef7\u503c\u4e3a \\(\\Pi\\) \uff0c\u6807\u7684\u7269\u4ef7\u683c\u4e3a \\(S\\) \uff0c\u5219\u6709\uff1a \\[\\Delta = \\frac{\\partial \\Pi}{\\partial S}\\] \\[ \\Gamma = \\frac{ \\partial \\Delta} {\\partial S} = \\frac{ \\partial^2 \\Pi}{\\partial S^2} \\] \u5982\u679c Gamma \u7edd\u5bf9\u503c\u8f83\u5c0f\uff0c\u90a3 portfolio \u7684 Delta \u53d8\u5316\u4e5f\u8f83\u6162\uff0c\u56e0\u6b64\u7ef4\u6301\u8fd9\u4e2a portfolio Delta \u4e2d\u6027\u8f83\u5bb9\u6613\u3002\u5426\u5219\uff0c\u5373\u4f7f\u5728\u5f88\u77ed\u7684\u65f6\u95f4\u5185\u4e0d\u8fdb\u884c Rebalance\uff0c\u90fd \u6709\u8f83\u9ad8\u7684\u98ce\u9669\u3002 \u5bf9\u4e8e\u4e00\u4e2a Delta \u4e2d\u6027\u7684 portfolio\uff0c\u6211\u4eec\u6709\u4ee5\u4e0b\u5173\u7cfb\uff08\u8fd9\u91cc\u7684 \\(\\Delta\\) \u8868\u793a\u5168\u5fae\u5206\uff09\uff1a \\[\\Delta \\Pi = \\Theta ~ \\Delta t + \\frac{1}{2}\\Gamma \\Delta S^2\\] \u8fd9\u4e2a\u7ed3\u8bba\u53ef\u4ee5\u5229\u7528 Taylor \u5c55\u5f00\uff0c\u4ee3\u5165 \\(\\frac{ \\partial \\Pi}{ \\partial S} = 0\\) \uff0c \u5e76\u5ffd\u7565 \\(\\Delta t\\) \u7684\u9ad8\u9636\u9879\u5f97\u5230\u3002 \u4e0b\u9762\u7684\u56fe\u63cf\u8ff0\u4e86\u80a1\u7968\u4ef7\u683c\u53d8\u5316\u5bf9\u4e8e\u4e0d\u540c Gamma \u7684 portfolio \u7684\u4ef7\u503c\u5f71\u54cd\u3002 \u4f8b\u5982\uff0c\u67d0\u4e2a Delta \u4e2d\u6027\u7684 portfolio \u7684 Gamma \u662f -10000\uff0c\u8be5\u516c\u5f0f\u8868\u660e\uff0c\u5982\u679c\u6807\u7684\u7269\u8d44\u4ea7\u4ef7\u683c\u5728\u5f88\u77ed\u7684\u65f6\u95f4\u5185\u53d8\u52a8 +2 \u6216\u8005 -2\uff0c\u5373\u4f7f\u5b83\u5728\u4ef7\u683c\u53d8\u52a8\u4e4b\u524d\u662f Delta \u4e2d\u6027\u7684\uff0c\u8fd9\u4e2a portfolio \u4f1a\u635f\u5931 20000\u3002","title":"18.6 Gamma"},{"location":"trading/option/Greeks/#1861-gamma","text":"\u521a\u624d\u7684\u4f8b\u5b50\u8868\u660e\uff0c\u6211\u4eec\u5e0c\u671b\u4e00\u4e2a portfolio \u6709\u8f83\u5c0f\u7684 Gamma \u4ee5\u964d\u4f4e\u98ce\u9669\u3002 \u7531\u4e8e\u6807\u7684\u7269\u8d44\u4ea7\u7684 Delta \u4e3a\u5e38\u6570 1\uff0c\u56e0\u6b64\u5b83\u7684 Gamma \u4e3a 0\uff0c\u4e0d\u80fd\u7528\u4e8e\u8c03\u8282 portfolio \u7684 Gamma\u3002\u56e0\u6b64\uff0c\u4e0d\u540c\u4e8e Delta Hedging\uff0c\u6211\u4eec\u9700\u8981\u4f7f\u7528\u548c\u6807\u7684\u7269\u8d44\u4ea7 \u975e\u7ebf\u5f62\u76f8\u5173\u7684 \u884d\u751f\u54c1\uff0c\u4f8b\u5982\u671f\u6743\uff0c\u6765\u8fdb\u884c Gamma \u7684\u8c03\u8282\u3002 \u5047\u8bbe\u4e00\u4e2a portfolio Delta \u4e2d\u6027\uff0c\u4f46\u6709 -3000 \u7684 Gamma\u3002\u540c\u65f6\uff0c\u67d0\u4e2a call option \u7684 Delta \u548c Gamma \u5206\u522b\u4e3a 0.62 \u548c 1.50\u3002\u5219\u53ef\u4ee5\u901a\u8fc7\u4e70\u5165 \\(3000/1.5 = 2000\\) \u5355\u4f4d\u7684 call \u6765\u4f7f\u8fd9\u4e2a portfolio Gamma \u4e2d\u6027\u3002 \u4f46\u662f\uff0c\u8fd9\u6837\u53c8\u5f15\u5165\u4e86\u989d\u5916\u7684 \\(0.62 \\times 2000 = 1240\\) \u7684 Delta\uff0c\u56e0\u6b64\u6211\u4eec\u8fd8\u9700\u8981\u5356\u51fa 1240 \u4e2a\u6807\u7684\u8d44\u4ea7\uff0c\u4f7f\u5f97\u8be5 portfolio \u7684 Delta \u548c Gamma \u5747\u4e3a\u4e2d\u6027\u3002","title":"18.6.1 Gamma \u4e2d\u6027"},{"location":"trading/option/Greeks/#1862-gamma","text":"\u53ef\u4ee5\u7b80\u5355\u901a\u8fc7\u6c42\u5bfc\u5f97\u5230\uff1a \\[\\Gamma = \\frac{ \\partial \\Delta }{ \\partial S } = \\Phi'(d_1) \\frac{\\partial d_1}{\\partial S} = \\frac{\\Phi'(d_1)}{\\sigma S_0 \\sqrt{T}}\\] \u5176\u4e2d \\[\\Phi'(x) = \\frac{ 1 }{ \\sqrt{2 \\ pi} } e^{-\\frac{ x^2 }{ 2 }}\\] \u53ef\u4ee5\u770b\u51fa\uff0c \\(\\Gamma > 0\\) \u603b\u662f\u6210\u7acb\u7684 \u3002\u53ef\u4ee5\u56de\u60f3 Delta \u5173\u4e8e\u80a1\u7968\u4ef7\u683c\u7684\u66f2\u7ebf\uff0c\u65e0\u8bba\u5bf9\u4e8e put \u8fd8\u662f call\uff0c\u968f\u7740\u80a1\u7968\u4ef7\u683c\u4e0a\u5347\uff0cDelta \u603b\u662f\u589e\u52a0\u7684\u3002\u5373 \\(\\Gamma = \\frac{ \\partial \\Delta} { \\partial S}> 0\\) \u3002 \\(\\Gamma\\) \u4e0e\u80a1\u7968\u4ef7\u683c \\(S\\) \u5173\u7cfb\u5982\u4e0b\u6240\u793a\uff1a \\(\\Gamma\\) \u4e0e\u8ddd\u79bb\u5230\u671f\u65e5\u65f6\u95f4\u7684\u5173\u7cfb\u5982\u4e0b\u6240\u793a\uff1a \u53ef\u4ee5\u770b\u51fa\uff1a - Gamma \u4e00\u5b9a\u4e3a\u975e\u8d1f\u6570 - \u5bf9\u4e8e ATM \u7684\u671f\u6743\uff0cGamma \u6700\u5927 - \u968f\u7740\u5230\u671f\u65e5\u4e34\u8fd1\uff0cATM \u7684\u671f\u6743 Gamma \u5355\u8c03\u589e\u52a0\uff0c\u800c ITM \u548c OTM \u90fd\u662f\u5148\u589e\u52a0\u540e\u51cf\u5c11\u81f3 0","title":"18.6.2 Gamma \u8ba1\u7b97"},{"location":"trading/option/Greeks/#1_1","text":"\u67d0\u516c\u53f8\u5bf9\u7531\u6807\u7684\u7269\u662f\u8d27\u5e01\u7684\u770b\u6da8/\u770b\u8dcc\u671f\u6743\u7ec4\u6210\u7684 portfolio \u8fdb\u884c\u4e86 Delta \u5bf9\u51b2\u3002\u54ea\u79cd\u60c5\u51b5\u4e0b portfolio \u76c8\u5229\u60c5\u51b5\u8f83\u597d\uff1f a. \u8be5\u8d27\u5e01\u6c47\u7387\u57fa\u672c\u7a33\u5b9a b. \u8be5\u8d27\u5e01\u6c47\u7387\u5267\u70c8\u6ce2\u52a8 \u4ece portfolio \u4ef7\u503c\u4e0a\u8bb2\uff0c\u6839\u636e\u516c\u5f0f\uff08\u8fd9\u91cc \\(\\Delta\\) \u8868\u793a\u5168\u5fae\u5206\uff09\uff1a \\[\\Delta \\Pi = \\Theta ~\\Delta t + \\frac{1}{2}\\Gamma \\Delta S^2\\] \u6211\u4eec\u53ef\u4ee5\u53d1\u73b0\u5bf9\u4e8e\u6b63\u7684 Gamma\uff0c\u5f53\u6807\u7684\u7269\u4ef7\u683c\u53d8\u52a8\u8f83\u5927\u65f6\uff0cportfolio \u4ef7\u503c\u4f1a\u53d8\u9ad8\uff08\u53ef\u4ee5\u56de\u5fc6\u56fe 18.8\uff09\u3002 \u540c\u65f6\uff0c\u671f\u6743\u591a\u5934\u5177\u6709\u6b63\u7684 Gamma\uff0cGamma \u7edd\u5bf9\u503c\u5c0f\u5219\u5bf9\u51b2\u6548\u679c\u597d\u3002\u6839\u636e\u516c\u5f0f\u53ef\u77e5\uff0c \\(\\sigma\\) \u8d8a\u5c0f Gamma \u8d8a\u5927\uff0c\u56e0\u6b64\u5982\u679c\u6c47\u7387\u5267\u70c8\u6ce2\u52a8\u5219 Gamma \u4f1a\u8f83\u5c0f\uff0c\u5bf9\u51b2\u4e5f\u8f83\u5bb9\u6613\u3002","title":"\u4f8b 1"},{"location":"trading/option/Greeks/#2_1","text":"\u4f8b 1 \u4e2d\uff0c\u82e5 portfolio \u662f\u7a7a\u5934\uff0c\u54ea\u79cd\u60c5\u51b5\u597d\uff1f \u671f\u6743\u7a7a\u5934\u5177\u6709\u8d1f\u7684 Gamma\uff0c\u6807\u7684\u7269\u4ef7\u683c\u53d8\u52a8\u5c0f\u5219 portfolio \u4ef7\u503c\u53d8\u9ad8\u3002","title":"\u4f8b 2"},{"location":"trading/option/Greeks/#187-delta-theta-gamma","text":"\u6211\u4eec\u4e4b\u524d\u5df2\u7ecf\u63a8\u5bfc\u8fc7 B-S-M \u5fae\u5206\u65b9\u7a0b\uff1a \\[\\frac{\\partial \\Pi}{\\partial t} + \\frac{\\partial \\Pi}{\\partial S}rS + \\frac{1}{2} \\frac{\\partial^2 \\Pi}{\\partial S^2}\\sigma^2 S^2 = r\\Pi\\] \u6839\u636e\u6211\u4eec\u5bf9 Delta, Theta, Gamma \u7684\u5b9a\u4e49\uff0c\u4e0a\u5f0f\u53ef\u4ee5\u6539\u5199\u4e3a\uff1a \\[\\Theta + rS \\Delta + \\frac{1}{2} \\sigma^2 S^2 \\Gamma = r \\Pi \\] \u90a3\u4e48\u5bf9\u4e8e Delta \u4e2d\u6027\u7684 portfolio\uff0c\u6211\u4eec\u6709\uff1a \\[\\Theta + \\frac{ 1 }{ 2 } \\sigma^2 S^2 \\Gamma = r \\ \\Pi \\] \u6211\u4eec\u53d1\u73b0\uff0c\u5982\u679c\u4e00\u4e2a Delta \u4e2d\u6027\u7684 portfolio \u7684 \\(\\Theta\\) \u662f\u4e00\u4e2a\u5f88\u5927\u7684\u8d1f\u6570\uff0c\u5219 \\(\\Gamma\\) \u4f1a\u662f\u4e00\u4e2a\u5f88\u5927\u7684\u6b63\u6570\uff0c\u53cd\u4e4b\u540c\u7406\u3002 \u8fd9\u4e5f\u5c31\u662f\u4e0a\u4e00\u7ae0\u4e2d\u63d0\u5230\u7684\uff0c \\(\\Theta\\) \u53ef\u4ee5\u4f5c \\(\\Gamma\\) \u7684\u4e00\u4e2a \u201cproxy\u201d\u3002","title":"18.7 Delta, Theta, Gamma \u4e4b\u95f4\u7684\u5173\u7cfb"},{"location":"trading/option/Greeks/#1_2","text":"\u8ba1\u7b97 Delta, Theta, Gamma \u7684\u5173\u7cfb\u5f0f\uff0c\u9488\u5bf9\uff1a a. \u8d27\u5e01\u7684\u884d\u751f\u54c1 b. \u671f\u8d27\u7684\u884d\u751f\u54c1","title":"\u4f8b 1"},{"location":"trading/option/Greeks/#188-vega","text":"\u6211\u4eec\u4e4b\u524d\u4e3a\u4e86\u7b80\u5316\uff0c\u4e00\u76f4\u628a volatility \u4f5c\u4e3a\u4e00\u4e2a\u5e38\u6570\u3002\u5b9e\u9645\u4e0a\uff0cvolatility \u4e5f\u662f\u4e0d\u65ad\u53d8\u5316\u7684\u3002\u884d\u751f\u54c1\u7684\u4ef7\u683c\u540c\u6837\u4f1a\u7531\u4e8e volatility \u7684\u53d8\u5316\u800c\u53d8\u5316\u3002\u6211\u4eec\u5c06\u8fd9\u4e2a\u53d8\u5316\u7387\u79f0\u4e3a Vega ( \\(\\nu\\) )\uff1a \\[\\nu = \\frac{ \\partial \\Pi}{ \\partial \\sigma}\\] \u5bf9\u4e8e\u6b27\u5f0f\u770b\u6da8\u548c\u770b\u8dcc\u671f\u6743\uff0c\u6709\uff1a \\[\\nu = \\frac{ \\partial c}{ \\partial \\sigma} = \\frac{ \\partial p}{ \\partial \\sigma} = S_0 \\sqrt{T} \\Phi'(d_1)\\] \u8bc1\u660e\u8f83\u7b80\u5355\uff0c\u76f4\u63a5\u6c42\u5bfc\u5e76\u5229\u7528 \\(S_0\\Phi'(d_1) = Ke^{-rT}\\Phi'(d_2)\\) \u5c31\u53ef\u4ee5\u5f97\u5230\u3002\u53ef\u4ee5\u770b\u51fa\u5fc5\u7136\u6709 \\(\\nu > 0\\) \uff0c\u8fd9\u4e0e\u6211\u4eec\u4e4b\u524d\u7684\u7ed3\u8bba\u543b\u5408\uff0cvolatility \u4e0a\u5347\u4f1a\u5f15\u8d77\u770b\u6da8\u548c\u770b\u8dcc\u671f\u6743\u4ef7\u683c\u4e0a\u5347\u3002 \u6807\u7684\u7269\u7684 Vega \u4e3a 0 \u3002\u56e0\u6b64\u6211\u4eec\u5982\u679c\u9700\u8981 Vega \u4e2d\u6027\uff0c\u9700\u8981\u901a\u8fc7\u4e70\u5356\u671f\u6743\u5b9e\u73b0\u3002\u4e00\u822c\u800c\u8a00\uff0c\u6211\u4eec\u9700\u8981 2 \u79cd\u4ee5\u4e0a\u7684\u671f\u6743\u7684\u7ec4\u5408\u6765\u5b9e\u73b0 Gamma \u548c Vega \u540c\u65f6\u5448\u4e2d\u6027\u3002","title":"18.8 Vega"},{"location":"trading/option/Greeks/#1_3","text":"\u8003\u8651\u4e00\u4e2a Delta \u4e2d\u6027\u7684 portfolio\uff0c\u5b83\u73b0\u5728\u5177\u6709 -5000 \u7684 Gamma \u548c -8000 \u7684 Vega\u3002\u6709\u4e24\u79cd\u53ef\u4ee5\u4ea4\u6613\u7684\u671f\u6743\uff0c\u5982\u4e0b\u8868\u6240\u793a\uff1a Delta Gamma Vega Portfolio 0 -5000 -8000 Option 1 0.6 0.5 2.0 Option 2 0.5 0.8 1.2 \u6211\u4eec\u9700\u8981 Vega \u548c Gamma \u540c\u65f6\u4e2d\u6027\uff0c\u5047\u8bbe\u4e24\u8005\u6570\u91cf\u914d\u6bd4\u5206\u522b\u4e3a \\(w_1\\) \u548c \\(w_2\\) \uff0c\u5219\uff1a \\[0.5w_1 + 0.8w_2 = 5000\\] \\[2.0w_1 + 1.2w_2 = 8000\\] \u53ef\u4ee5\u89e3\u51fa \\(w_1 = 400\\) \uff0c \\(w_2 = 6000\\) \u3002\u4e70\u5165 400 \u4efd Option 1 \u548c 6000 \u4efd Option 2 \u540e\uff0cDelta \u4ece 0 \u53d8\u4e3a 3240\uff0c\u6240\u4ee5\u8fd8\u9700\u8981\u5356\u51fa 3240 \u4efd\u6807\u7684\u8d44\u4ea7\u3002 Gamma \u4e2d\u6027\u53ef\u4ee5\u5728 Delta Hedging \u7684\u95f4\u9694\u65f6\u95f4\u91cc\u4fdd\u62a4 portfolio \u7684\u4ef7\u503c\u4e0d\u56e0\u4e3a\u6807\u7684\u8d44\u4ea7\u7684\u4ef7\u683c\u53d8\u5316\u4ea7\u751f\u53d8\u52a8\uff0c\u800c Vega \u4e2d\u6027\u53ef\u4ee5\u5728 volatility \u53d8\u5316\u7684\u65f6\u5019\u4fdd\u62a4 portfolio \u7684\u4ef7\u503c\u3002\u9700\u8981\u6839\u636e\u5bf9\u51b2\u518d\u5e73\u8861\u95f4\u9694\u65f6\u95f4\u4ee5\u53ca\u6ce2\u52a8\u7387\u7684\u6ce2\u52a8\u7387\u6765\u51b3\u5b9a\u9009\u62e9\u54ea\u4e9b\u671f\u6743\u3002","title":"\u4f8b 1"},{"location":"trading/option/Greeks/#2_2","text":"\u4ec0\u4e48\u60c5\u51b5\u4e0b 2 \u4e2a\u6307\u6570\u7684\u6b27\u5f0f\u671f\u6743\u7ec4\u6210\u7684 portfolio \u53ef\u4ee5\u540c\u65f6 Gamma \u548c Vega \u4e2d\u6027\uff1f \u5373\u4ee5\u4e0b\u5173\u4e8e \\(w_1\\) \uff0c \\(w_2\\) \u7684\u65b9\u7a0b\u7ec4\u6709\u975e\u96f6\u89e3\uff1a \\[\\Gamma_1 w_1 + \\Gamma_2 w_2 = 0\\] \\[\\nu_1 w_1 + \\nu_2 w_2 = 0\\] \u53ef\u4ee5\u5f97\u5230 \\[\\Gamma_1 \\nu_2 = \\Gamma_2 \\nu_1\\] \u4e24\u4e2a\u671f\u6743\u57fa\u4e8e\u540c\u4e00\u4e2a\u6807\u7684\u7269\uff0c\u56e0\u6b64\u5fc5\u7136\u6709\u540c\u6837\u7684 \\(S_0\\) , \\(q\\) , \\(r\\) , \\(\\sigma\\) \u3002\u552f\u4e00\u4e0d\u540c\u7684\u5c31\u662f\u5230\u671f\u65e5 \\(T\\) \u548c\u6267\u884c\u4ef7\u683c \\(K\\) \uff0c\u8fd9\u4e5f\u5bfc\u81f4\u5177\u6709\u4e0d\u540c\u7684 \\(d_1\\) \u548c \\(d_2\\) \u3002 \\[\\Gamma_1 \\nu_2 = \\frac{1}{\\sigma} e^{-q(T_1 + T_2)} \\sqrt{\\frac{T_2}{T_1}} \\Phi'(d_{1(1)}) \\Phi'(d_{1(2)}) \\] \\[\\Gamma_2 \\nu_1 = \\frac{1}{\\sigma} e^{-q(T_1 + T_2)} \\sqrt{\\frac{T_1}{T_2}} \\Phi'(d_{1(1)}) \\Phi'(d_{1(2)}) \\] \u8981\u4e24\u8005\u76f8\u7b49\uff0c\u5fc5\u7136\u6709 \\(T_1 = T_2\\) \uff0c\u5373\u671f\u9650\u76f8\u540c\u3002","title":"\u4f8b 2"},{"location":"trading/option/Greeks/#3","text":"\u67d0\u94f6\u884c\u6301\u6709\u7684\u7f8e\u5143/\u6b27\u5143\u6c47\u7387\u671f\u6743\u5934\u5bf8\u6709 30000 \u7684 Delta \u548c -80000 \u7684 Gamma\u3002 a. \u89e3\u91ca\u8fd9\u4e9b\u6570\u636e\u7684\u542b\u4e49 b. \u5047\u8bbe\u76ee\u524d\u6c47\u7387\u662f 0.90 \u7f8e\u5143\u5151\u6362 1.0 \u6b27\u5143\uff0c\u5219\u5982\u4f55\u4f7f\u5934\u5bf8 Delta \u4e2d\u6027\uff1f c. \u5728\u5f88\u77ed\u7684\u65f6\u95f4\u540e\uff0c\u6b27\u5143\u5347\u503c\uff0c\u6c47\u7387\u53d8\u4e3a 0.93 \u7f8e\u5143\u5151\u6362 1.0 \u6b27\u5143\uff0c\u5219\u65b0\u7684 Delta \u4e3a\u591a\u5c11\uff1f\u5982\u679c\u8981\u4fdd\u6301\u5176 Delta \u4e2d\u6027\uff0c\u9700\u8981\u4ec0\u4e48\u989d\u5916\u7684\u4ea4\u6613\u64cd\u4f5c\uff1f d. \u5047\u8bbe\u8be5\u5934\u5bf8\u6700\u521d\u662f Delta \u4e2d\u6027\u7684\uff0c\u90a3\u4e48\u5b83\u4ece\u6c47\u7387\u7684\u53d8\u5316\u4e2d\u8d5a\u4e86\u8fd8\u662f\u8d54\u4e86\uff1f \u8bf4\u660e\u82e5\u6b27\u5143\u5347\u503c 0.01 \u7f8e\u5143\uff0c\u5219\u8be5\u5934\u5bf8\u7684\u4ef7\u503c\u4e0a\u5347 300\uff0cDelta \u964d\u4f4e 800\u3002\u8be5\u94f6\u884c\u5e94\u8be5\u662f\u6301\u6709\u6b27\u5143\u770b\u8dcc\u671f\u6743\u7684\u7a7a\u5934\uff0c\u56e0\u6b64\u5177\u6709\u6b63\u7684 Delta \u548c\u8d1f\u7684 Gamma\u3002 \u9700\u8981\u5356\u7a7a 30000 \u6b27\u5143\u3002 \u65b0\u7684 Delta \u4e3a 30000 - 80000*0.03 = 27600\uff0c\u5982\u679c\u5df2\u7ecf\u5356\u7a7a 30000 \u6b27\u5143\u4f7f\u5176 Delta \u4e2d\u6027\uff0c\u90a3\u4e48\u8fd8\u9700\u8981\u4e70\u5165 2400 \u6b27\u5143\u4ee5\u4fdd\u6301 Delta \u4e2d\u6027\u3002 \u7531\u4e8e\u6700\u521d Delta \u4e2d\u6027\uff0cGamma \u4e3a\u8d1f\uff0c\u56e0\u6b64\u6b27\u5143\u6c47\u7387\u5728\u6700\u521d\u80af\u5b9a\u5927\u4e8e 0.9 \u7f8e\u5143\uff0c\u5728\u4e0b\u964d\u8fc7\u7a0b\u4e2d\uff0cDelta \u53d8\u4e3a\u6b63\u3002\u800c\u5b83\u6301\u6709\u6b27\u5143\u770b\u8dcc\u671f\u6743\u7684\u7a7a\u5934\uff0c\u56e0\u6b64\u6b27\u5143\u6c47\u7387\u4e0b\u8dcc\uff0c\u8fd9\u4e2a\u5934\u5bf8\u6709\u4e8f\u635f\u3002","title":"\u4f8b 3"},{"location":"trading/option/Greeks/#189-rho","text":"Rho \u63cf\u8ff0\u4e86 portfolio \u4ef7\u503c\u968f\u5229\u7387 \\(r\\) \u7684\u53d8\u5316\u7387\uff1a \\[\\rho = \\frac{\\partial \\Pi}{\\partial r}\\] \u901a\u8fc7\u7b80\u5355\u7684\u6c42\u5bfc\u53ef\u4ee5\u5f97\u5230\uff1a \\[\\rho_{call} = KTe^{-rT}\\Phi(d_2)\\] \u518d\u5229\u7528 put-call-parity \u53ef\u4ee5\u5f97\u5230\uff1a \\[\\rho_{put} = -KTe^{-rT}\\Phi(-d_2)\\] \u6211\u4eec\u53d1\u73b0\uff0c\u5229\u7387\u4e0a\u5347\u4f1a\u4fc3\u4f7f call \u7684\u4ef7\u503c\u4e0a\u5347\uff0cput \u7684\u4ef7\u503c\u4e0b\u964d\u3002\u8fd9\u662f\u7b26\u5408\u6211\u4eec\u76f4\u89c2\u7684\u3002\u5f53\u5229\u7387\u4e0a\u5347\uff08\u5047\u8bbe\u8d44\u4ea7\u4ef7\u683c\u4e0d\u53d8\uff09\uff0c\u6267\u884c\u4ef7\u683c\u6298\u73b0\u540e\u53d8\u5c11\u3002\u56e0\u6b64 call \u76f8\u5f53\u4e8e\u4ee5\u66f4\u4fbf\u5b9c\u7684\u4ef7\u683c\u4e70\u5230\u4e86\u8d44\u4ea7\uff0c\u4ef7\u683c\u4f1a\u5347\u9ad8\u3002put \u5219\u53cd\u4e4b\u3002 \u7531\u4e8e\u5229\u7387\u4e0d\u7ecf\u5e38\u53d8\u5316\uff0c\u8fd9\u4e2a Greek \u5e76\u6ca1\u6709\u5176\u4ed6\u51e0\u4e2a\u53d7\u5173\u6ce8\u3002","title":"18.9 Rho"},{"location":"trading/option/Greeks/#1810","text":"\u5bf9\u4e8e\u4e00\u4e2a portfolio \u7684\u6bcf\u4e2a Greek\uff0c\u4ea4\u6613\u516c\u53f8\u90fd\u4f1a\u8bbe\u7f6e\u4e00\u4e2a\u4e0a\u9650\u3002 Delta \u7684\u4e0a\u9650\u901a\u5e38\u8868\u793a\u4e3a\u6807\u7684\u7269\u6700\u5927\u4ed3\u4f4d\u3002\u4f8b\u5982\u5bf9\u4e8e\u4e00\u4e2a\u80a1\u7968\u7684 cash Delta \u4e0a\u9650\u662f 100 \u4e07\uff0c\u80a1\u7968\u4ef7\u683c\u4e3a 50\uff0c\u5219\u6700\u5927\u4ed3\u4f4d\u4e3a 2 \u4e07\u3002 Vega \u7684\u4e0a\u9650\u901a\u5e38\u8868\u793a\u4e3a 1% \u7684 volatility \u53d8\u5316\u5f15\u8d77\u7684 portfolio \u4ef7\u503c\u53d8\u5316\u7684\u4e0a\u9650\u3002 \u671f\u6743\u4ea4\u6613\u5458\u4f1a\u5c3d\u91cf\u4f7f\u5f97\u81ea\u5df1\u5728\u6bcf\u5929\u4ea4\u6613\u7ed3\u675f\u65f6 Delta \u4e2d\u6027\u3002Gamma \u548c Vega \u4e5f\u4f1a\u76d1\u63a7\uff0c\u4f46\u662f\u4e0d\u4f1a\u8981\u6c42\u6bcf\u5929\u90fd\u662f\u4e2d\u6027\u3002 \u6211\u4eec\u4ece Gamma \u548c Vega \u7684\u66f2\u7ebf\u53ef\u4ee5\u770b\u51fa\uff0cATM \u7684\u671f\u6743\u5177\u6709\u6700\u9ad8\u7684 Gamma \u548cVega\u3002\u968f\u7740\u80a1\u4ef7\u53d8\u5316\uff0c\u8fd9\u4e9b\u671f\u6743\u6162\u6162\u53d8\u4e3a OTM \u6216\u8005 ITM\uff0cGamma \u548c Vega \u5c31\u4f1a\u81ea\u7136\u51cf\u5c0f\u3002","title":"18.10 \u5b9e\u9645\u5e94\u7528"},{"location":"trading/option/Greeks/#1812","text":"\u6211\u4eec\u76ee\u524d\u5bfc\u51fa\u7684\u516c\u5f0f\u90fd\u662f\u9488\u5bf9\u65e0\u80a1\u606f\u80a1\u7968\u7684\u6b27\u5f0f\u671f\u6743\u3002 \u5047\u8bbe\u80a1\u7968\u7684\u80a1\u606f\u6536\u76ca\u4ee5\u590d\u5229\u8ba1\u7b97\u4e3a \\(q\\) \uff0c\u5219\u6211\u4eec\u53ef\u4ee5\u5c06 \\(S_0\\) \u66ff\u6362\u4e3a \\(S_0 e^{-qT}\\) \uff0c\u5f97\u5230\u9002\u7528\u4e8e\u6709\u6536\u76ca\u7684\u6807\u7684\u7269\u7684 B-S-M \u516c\u5f0f\uff1a \\[c = S_0 e^{-qT} \\Phi(d_1) - K e^{-rT} \\Phi(d_2)\\] \\[p = K e^{-rT} \\Phi(-d_2) - S_0 e^{-qT} \\Phi(-d_1)\\] \\[d_1 = \\frac{\\ln(S_0 / K) + (r - q + \\frac{1}{2}\\sigma^2)T}{\\sigma \\sqrt{T}}\\] \\[d_2 = d_1 - \\sigma \\sqrt{T}\\] \u6839\u636e\u8fd9\u4e2a\u63a8\u5bfc\u51fa\u5176\u5404\u4e2a Greeks \u7684\u8ba1\u7b97\u516c\u5f0f\uff1a Greeks European call European put Delta \\(e^{-qT}\\Phi(d_1)\\) \\(\\Delta_{call} - e^{-qT}\\) Theta \\(q e^{-qT} S_0 \\Phi(d_1) - rKe^{-rT}\\Phi(d_2) - \\frac{e^{-qT}S_0 \\Phi'(d_1)\\sigma}{2\\sqrt{T}}\\) \\(\\Theta_{call} + rKe^{-rT}\\) Gamma \\(\\frac{ e^{-qT}\\Phi'(d_1) }{ \\sigma S_0\\sqrt{T} }\\) \\(\\Gamma_{call}\\) Vega \\(e^{-qT}S_0\\sqrt{T}\\Phi'(d_1)\\) \\(\\nu_{call}\\) Rho \\(KTe^{-rT}\\Phi(d_2)\\) \\(\\rho_{call} - KTe^{-rT}\\) \u65e0\u80a1\u606f\u7684\u60c5\u51b5\u5176\u5b9e\u662f\u4e0a\u9762\u7684\u4e00\u4e2a\u7279\u4f8b\uff0c\u4ee4 \\(q = 0\\) \u5373\u53ef\u5f97\u5230\u3002 \u4ee4 \\(q = r\\) \uff0c\u5219\u53ef\u4ee5\u5f97\u5230\u671f\u8d27\u671f\u6743\u7684\u516c\u5f0f\uff0c \u6b64\u65f6 Rho \u4e0d\u80fd\u4f7f\u7528\u901a\u7528\u516c\u5f0f \u3002 \\(\\rho_{call} = -cT\\) \uff0c \\(\\rho_{put} = -pT\\) \u3002\u8fd9\u662f\u7531\u4e8e \\(q = r\\) \uff0c\u5bf9 \\(r\\) \u6c42\u5bfc\u65f6\u4e0d\u80fd\u628a \\(q\\) \u4f5c\u4e3a\u5e38\u6570\u3002 \u5f53\u6211\u4eec\u5206\u6790\u8d27\u5e01\u671f\u6743\u65f6\uff0c\u6709\u4e24\u4e2a\u5229\u7387\uff0c\u672c\u5e01\u65e0\u98ce\u9669\u5229\u7387 \\(r\\) \u548c\u5916\u5e01\u65e0\u98ce\u9669\u5229\u7387 \\(r_f\\) \uff0c\u4ee4 \\(q = r_f\\) \u5373\u5f97\u5230\u5bf9\u8d27\u5e01\u671f\u6743\u7684\u516c\u5f0f\u3002","title":"18.12 \u516c\u5f0f\u7684\u63a8\u5e7f"},{"location":"trading/option/Greeks/#1_4","text":"\u67d0\u4e2a\u91d1\u878d\u673a\u6784\u521a\u521a\u51fa\u552e\u4e86 1000 \u4efd 7 \u4e2a\u6708\u540e\u5230\u671f\u7684\u6807\u7684\u7269\u662f\u65e5\u5143\u7684\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u3002\u5047\u8bbe\u5373\u671f\u6c47\u7387\u662f 0.8 \u7f8e\u5206\u5151\u6362 1 \u65e5\u5143\uff0c\u6267\u884c\u4ef7\u683c\u662f 0.81 \u7f8e\u5206\u3002\u7f8e\u56fd\u7684\u65e0\u98ce\u9669\u5229\u7387\u662f 8%\uff0c\u65e5\u672c\u7684\u65e0\u98ce\u9669\u5229\u7387\u662f 5%\u3002\u65e5\u5143\u6ce2\u52a8\u7387\u662f 15%\u3002\u8ba1\u7b97\u8be5\u4ed3\u4f4d\u7684 Delta, Gamma, Vega, Theta, Rho\u3002 \u6211\u4eec\u53ef\u4ee5\u5c06 \\(q = r_f = 0.05\\) \u4ee3\u5165\u4e0a\u9762\u8868\u683c\u4e2d\u7684\u516c\u5f0f\u8fdb\u884c\u8ba1\u7b97\uff0c\u5c06\u6267\u884c\u4ef7\u683c\u7edf\u4e00\u6362\u7b97\u4e3a\u7f8e\u5143\u3002 \u7136\u540e\u8ba1\u7b97 \\(d_1\\) \uff1a \\[d_1 = \\frac{\\ln(S_0 / K) + (r - q + \\frac{1}{2}\\sigma^2)T}{\\sigma \\sqrt{T}} = 0.1016\\] \\[d_2 = d_1 - \\sigma \\sqrt{T} = -0.0130\\] \\[\\Phi(d_1) = 0.5405 \\] \\[\\Phi(d_2) = 0.4948 \\] \\[\\Phi'(d_1) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{d_1^2}{2}} = 0.3969\\] Greeks European call Value Delta \\(e^{-qT}\\Phi(d_1)\\) 0.5250 Theta \\(q e^{-qT} S_0 \\Phi(d_1) - rKe^{-rT}\\Phi(d_2) - \\frac{e^{-qT}S_0 \\Phi'(d_1)\\sigma}{2\\sqrt{T}}\\) 0.0004 Gamma \\(\\frac{e^{-qT}\\Phi'(d_1)}{\\sigma S_0\\sqrt{T}}\\) 420.6051 Vega \\(e^{-qT}S_0\\sqrt{T}\\Phi'(d_1)\\) 0.0024 Rho \\(KTe^{-rT}\\Phi(d_2)\\) 0.0022","title":"\u4f8b 1"},{"location":"trading/option/Greeks/#2_3","text":"\u4e00\u4e2a\u80a1\u6307\u7684\u8fdc\u671f\u5408\u7ea6\u548c\u671f\u8d27\u5177\u6709\u540c\u6837\u7684 Delta \u5417\uff1f\u89e3\u91ca\u4f60\u7684\u7ed3\u8bba\u3002 \u80a1\u6307\u671f\u8d27\u4f1a\u5b9a\u671f\u6d3e\u53d1\u80a1\u606f\uff0c\u5047\u8bbe\u5176\u80a1\u606f\u6536\u76ca\u6309\u590d\u5229\u8ba1\u7b97\u4e3a \\(q\\) \uff0c\u5219\u8fdc\u671f\u5408\u7ea6\u591a\u5934\u4ef7\u503c\u4e3a\uff1a \\[S_0e^{-qT} - Ke^{-rT}\\] \u5176 Delta \u4e3a \\(e^{-qT}\\) \u3002 \u5bf9\u4e8e\u671f\u8d27\uff0c\u5176\u7ea6\u5b9a\u7684\u6267\u884c\u4ef7\u683c\u6ee1\u8db3\uff1a \\[K = S_0e^{(r-q)T}\\] \u867d\u7136\u5b83\u4ec5\u4ec5\u662f\u672a\u6765\u7684\u6267\u884c\u4ef7\u683c\uff0c\u4f46\u662f\u7531\u4e8e\u671f\u8d27\u6bcf\u65e5\u7ed3\u7b97\u5236\u5ea6\uff0c\u6295\u8d44\u8005\u80fd\u7acb\u5373\u62ff\u5230\u6536\u76ca\u3002\u6240\u4ee5\u5176\u5373\u671f\u4ef7\u503c\u5c31\u662f\u6267\u884c\u4ef7\u683c\uff0cDelta \u4e3a \\(e^{(r-q)T}\\) \u3002 \u56e0\u6b64\u4e24\u8005\u7684 Delta \u4e0d\u540c\uff0c\u671f\u8d27 Delta \u662f\u8fdc\u671f Delta \u7684 \\(e^{rT}\\) \u500d\u3002","title":"\u4f8b 2"},{"location":"trading/option/Greeks/#3_1","text":"\u671f\u8d27\u7684\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u4e0e\u671f\u8d27\u4ef7\u683c \\(F_0\\) \u5173\u7cfb\u5f0f\u4e3a\uff1a \\(c = e^{-rT}[F_0 \\Phi(d_1) - K \\Phi(d_2)]\\) \u5176\u4e2d \\(d_1 = \\frac{\\ln(F_0 / K) + \\frac{1}{2}\\sigma^2 T}{\\sigma \\sqrt{T}}\\) \\(d_2 = d_1 - \\sigma \\sqrt{T}\\) a. \u8bc1\u660e \\(F_0 \\Phi'(d_1) = K \\Phi'(d_2)\\) b. \u8bc1\u660e\u5176 Delta \u7b49\u4e8e \\(e^{-rT}\\Phi(d_1)\\) c. \u8bc1\u660e\u5176 Vega \u7b49\u4e8e \\(F_0 \\sqrt{T} \\Phi'(d_1) e^{-rT}\\) d. \u8bc1\u660e\u5176 Rho \u7b49\u4e8e \\(-cT\\) (a) \u7531\u4e8e \\[\\Phi'(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}\\] \u4ee3\u5165\u53ef\u77e5\uff1a \\[F_0\\Phi'(d_1) = \\frac{F_0}{\\sqrt{2\\pi}} e^{-\\frac{d_2^2 + 2\\sigma \\sqrt{T}d_2 + \\sigma^2 T}{2}}\\] \u800c \\[2\\sigma \\sqrt{T}d_2 + \\sigma^2 T = 2\\ln(\\frac{F_0} {K})\\] \u4ee3\u5165\u53ef\u4ee5\u5f97\u5230\uff1a \\[F_0\\Phi'(d_1) = \\frac{F_0}{\\sqrt{2\\pi}} \\frac{K}{F_0} e^{-\\frac{d_2^2} {2} } = K \\Phi'(d_2)\\] (b) \\[\\Delta = \\frac{\\partial c}{\\partial F_0} = e^{-rT}[\\Phi(d_1) + F_0 \\Phi'(d_1) \\frac{\\partial d_1}{\\partial F_0} - K \\Phi'(d_2) \\frac{\\partial d_2}{\\partial F_0} ]\\] \u5229\u7528 (a) \u4e2d\u7684\u7ed3\u8bba\uff0c\u6709\uff1a \\[\\Delta = e^{-rT}\\Phi(d_1)\\] (c) \\[\\nu = \\frac{\\partial c}{\\partial \\sigma} = e^{-rT}[F_0 \\Phi'(d_1)\\frac{\\partial d_1}{\\partial \\sigma} - K \\Phi'(d_2) \\frac{\\partial d_2}{\\partial \\sigma}]\\] \u5229\u7528 (a) \u4e2d\u7684\u7ed3\u8bba\uff0c\u6709\uff1a \\[\\nu = e^{-rT} F_0 \\sqrt{T} \\Phi'(d_1)\\] (d) \\[\\rho = \\frac{\\partial c}{\\partial r} = -Te^{-rT}[F_0 \\Phi(d_1) - K \\Phi(d_2)] = -cT\\]","title":"\u4f8b 3"},{"location":"trading/option/Greeks/#appendix-greeks-from-traders-perspective","text":"\u4ee5\u4e0a\u90fd\u662f\u4ee5\u5de5\u79d1\u601d\u7ef4\u6765\u8003\u8651 Greeks\u3002\u90a3\u4e48\u5728\u5b9e\u9645\u4ea4\u6613\u4e2d\uff0c\u6211\u4eec\u600e\u4e48\u5229\u7528 Greeks \u5462\uff1f \u5728\u5b9e\u9645\u4ea4\u6613\u4e2d\uff0c\u6211\u4eec\u5f80\u5f80\u4ea4\u6613\u7684\u90fd\u662f\u8fd1\u6708\u7684\u671f\u6743\u548c\u671f\u8d27\u3002\u51e0\u4e4e\u53ef\u4ee5\u5ffd\u7565\u8d34\u73b0\u95ee\u9898\u3002\u5373\uff0c\u671f\u8d27\u4ef7\u683c\u548c\u73b0\u8d27\u4ef7\u683c\u6211\u4eec\u8ba4\u4e3a\u662f\u51e0\u4e4e\u76f8\u7b49\u7684\u3002\u5728\u4ee5\u4e0b\u7684\u5185\u5bb9\u4e2d\uff0c\u6211\u4eec\u90fd\u4e0d\u518d\u6d89\u53ca\u8d34\u73b0\u95ee\u9898\uff0c\u4e5f\u4e0d\u523b\u610f\u533a\u5206\u73b0\u8d27\u548c\u671f\u8d27\u4ef7\u683c\u3002","title":"Appendix: Greeks from Trader's perspective"},{"location":"trading/option/Greeks/#a1-cash-greeks","text":"\u5728\u5b9e\u9645\u4ea4\u6613\u4e2d\uff0c\u6211\u4eec\u5e38\u5e38\u9700\u8981\u6bd4\u8f83\u4e0d\u540c underlying\uff0c\u4e0d\u540c portfolio \u7684\u98ce\u9669\u3002\u56e0\u6b64\u6211\u4eec\u5f15\u5165\u4e86 cash Delta, cash Gamma \u7b49\u6982\u5ff5\u3002\u5b9e\u9645\u4e0a\u5c31\u662f\u5c06 Greeks \u8f6c\u4e3a\u5b9e\u9645\u7684\u73b0\u91d1\u3002 \u5047\u8bbe\u67d0\u6807\u7684\u8d44\u4ea7\u7684\u4ef7\u683c\u4e3a \\(S\\) \u3002\u5b83\u7684 1 \u4efd\u671f\u8d27\u5408\u7ea6\u5305\u62ec\u6807\u7684\u8d44\u4ea7\u4e3a \\(M\\) \u4efd(multiplier)\u3002\u5219\u5bf9\u4e8e\u8be5\u671f\u8d27\u4ee5\u53ca\u5176\u671f\u6743\u884d\u751f\u54c1\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u51fa\u4ee5\u4e0b\u5173\u7cfb\uff1a cash Greek \u5b9a\u4e49 \u8ba1\u7b97 cash Delta \u7531 Delta \u51b3\u5b9a\u7684 portfolio \u7684\u4ef7\u503c \\(S \\times M \\times \\Delta\\) cash Gamma \u5f53 underlying \u4ef7\u683c\u53d8\u5316 1% \u65f6 cache Delta \u7684\u53d8\u5316\u91cf \\(\\frac{S^2}{100} \\times M \\times \\Gamma\\) \u4e3b\u8981\u8bf4\u4e0b cash Gamma \u7684\u8ba1\u7b97\u3002\u7531\u4e8e \\(\\Gamma\\) \u5b9a\u4e49\u4e3a\u6807\u7684\u8d44\u4ea7\u4ef7\u683c\u53d8\u5316 1 \u65f6 \\(\\Delta\\) \u7684\u53d8\u5316\u91cf\uff0c\u56e0\u6b64 \\(\\frac{S}{100} \\Gamma\\) \u5c31\u662f\u6807\u7684\u8d44\u4ea7\u4ef7\u683c\u53d8\u5316 1% \u65f6 \\(\\Delta\\) \u7684\u53d8\u5316\u91cf\u3002\u518d\u4e58\u4ee5\u7cfb\u6570 \\(S \\times M\\) \u5c31\u662f\u5bf9 cash Delta \u7684\u5f71\u54cd\u3002 \u7389\u7c73\u4ef7\u683c\u4e3a $3.5 \u6bcf bushel\uff0c\u4e00\u4e2a\u671f\u8d27\u5408\u7ea6\u4ea4\u6613 5000 bushels\u3002\u5047\u8bbe\u6211\u4eec\u6301\u6709 3 \u4e2a Delta \u4e3a 0.3 \u7684\u770b\u6da8\u671f\u6743\uff0c\u90a3 cashe Delta \u662f\u591a\u5c11\uff1f \\[3 \\times 0.3 \\times 3.5 \\times 5000 = 15750\\] \u5373\u6211\u4eec long 15.75k cash Delta\u3002\u82e5\u7389\u7c73\u4ef7\u683c\u4e0a\u5347 1% \u5c06\u76c8\u5229 $157.5\uff0c\u53cd\u4e4b\u4e8f\u635f $157.5\u3002 \u539f\u6cb9\u4ef7\u683c\u4e3a $50 \u4e00\u6876\uff0c\u4e00\u4e2a\u671f\u8d27\u5408\u7ea6\u4ea4\u6613 1000 \u6876\u539f\u6cb9\u3002\u67d0\u539f\u6cb9\u4e3a\u6807\u7684\u7269\u7684 portfolio \u5982\u679c\u4ef7\u683c\u4e0a\u5347 1% \u4f1a\u5bfc\u81f4 +3 Delta\uff0ccash Gamma \u662f\u591a\u5c11\uff1f \u5c06 3 Delta \u8f6c\u5316\u4e3a cash Delta\uff1a \\[3 * 50 * 1000 = 150000\\] \u4e5f\u5c31\u662f\u8bf4 1% \u7684\u539f\u6cb9\u4ef7\u683c\u53d8\u5316\u4f1a\u5bfc\u81f4\u6211\u4eec\u589e\u52a0 150k \u7684 cash Delta\u3002\u56e0\u6b64\u6211\u4eec long 150k cash Gamma\u3002 \u539f\u6cb9\u73b0\u8d27\u4ef7\u683c\u4e3a $104.8\uff0c\u671f\u8d27\u7684 multiplier \u4e3a 1000\u3002\u5df2\u77e5\u6267\u884c\u4ef7\u683c\u4e3a $105 \u7684\u770b\u6da8\u671f\u6743 Gamma \u4e3a 0.1527\u3002\u73b0\u5728\u6301\u6709 50 \u4e2a $105 \u7684 straddle\u3002 (a) Gamma \u4e3a\u591a\u5c11\uff1fcash Gamma \u4e3a\u591a\u5c11\uff1f (b) \u5047\u8bbe\u539f\u6cb9\u4ef7\u683c\u4e0a\u6da8 0.5%\uff0c\u6301\u4ed3\u7684 Delta \u5982\u4f55\u53d8\u5316 (a) straddle \u662f\u4e70\u5165\u540c\u6837\u6267\u884c\u4ef7\u683c\u7684 call \u548c put\uff0c\u4ed6\u4eec\u5177\u6709\u540c\u6837\u7684 Gamma\u3002 \\[\\Gamma = 0.1527 \\times 2 \\times 50 = 15.27\\] \\[cash~\\Gamma = \\frac{104.8^2}{100} \\times 1000 \\times \\Gamma = 1.677 \\times 10^6\\] (b) \u6b63\u7684 Gamma \u5bfc\u81f4\u7684 Delta \u53d8\u5316\u4e3a\uff1a \\[0.5\\% \\times 104.8 \\times \\Gamma = 8 \\] \u5373\u989d\u5916 long 8 Delta\u3002","title":"A.1 cash Greeks"},{"location":"trading/option/Greeks/#a2-gamma-theta","text":"\u5f53\u6211\u4eec\u6301\u6709\u671f\u6743\u65f6\uff0cGamma \u4e3a\u6b63\u3002\u6b64\u65f6\uff0c\u82e5\u6807\u7684\u7269\u4ef7\u683c\u4e0a\u6da8\uff0cDelta \u4e5f\u968f\u4e4b\u4e0a\u6da8\u3002\u6211\u4eec\u9700\u8981\u5356\u51fa\u989d\u5916\u7684\u6807\u7684\u8d44\u4ea7\u3002\u76f8\u53cd\uff0c\u5f53\u6807\u7684\u7269\u4ef7\u683c\u4e0b\u8dcc\uff0cDelta \u4e5f\u968f\u4e4b\u4e0b\u8dcc\uff0c\u6211\u4eec\u9700\u8981\u4e70\u5165\u989d\u5916\u7684\u6807\u7684\u8d44\u4ea7\u3002 \u5982\u679c\u4e0d\u8003\u8651 Theta\uff0c\u4ee5\u4e0a\u7684\u4ea4\u6613\u770b\u8d77\u6765\u4f3c\u4e4e\u6709\u5229\u53ef\u56fe\u3002\u671f\u6743\u5e26\u6765\u7684Gamma \u9f13\u52b1\u6211\u4eec\u4f4e\u4e70\u9ad8\u5356\u5f97\u5230\u6536\u76ca\uff0c\u90a3\u4e3a\u4ec0\u4e48\u9700\u8981\u5356\u51fa\u671f\u6743\u5462\uff1f\u4e8b\u5b9e\u4e0a\uff0c\u6301\u6709\u671f\u6743\u65f6 Theta \u4e00\u822c\u4f1a\u5e26\u6765\u635f\u5931\u3002 \u5728 18.6 \u4e2d\u6211\u4eec\u5df2\u7ecf\u8bc1\u660e\uff0c\u4e8e\u4e00\u4e2a Delta \u4e2d\u6027\u7684 portfolio\uff0c\u6211\u4eec\u6709\u4ee5\u4e0b\u5173\u7cfb\uff08\u8fd9\u91cc\u7684 \\(\\Delta\\) \u8868\u793a\u5168\u5fae\u5206\uff09\uff1a \\[\\Delta \\Pi = \\Theta ~ \\Delta t + \\frac{1}{2}\\Gamma \\Delta S^2\\] \u4e0a\u5f0f\u8bf4\u660e\uff0c\u5728\u4fdd\u6301 Delta \u4e2d\u6027\u65f6\uff0cportfolio \u4ef7\u503c\u53d8\u5316\u53ef\u7531 Theta \u548c Gamma \u5171\u540c\u51b3\u5b9a\u3002\u6211\u4eec\u9700\u8981\u6bd4\u8f83\u5230\u5e95\u662f\u5728 Theta \u4e0a\u4e8f\u7684\u94b1\u591a\u8fd8\u662f\u5728 Gamma \u4e0a\u8d5a\u7684\u94b1\u591a\u3002 \u6211\u4eec\u53ef\u4ee5\u4ee4 \\(\\Delta t\\) \u4e3a\u4e00\u5929\uff0c\u6b64\u65f6 \\(\\Delta S\\) \u7684\u6700\u597d\u4f30\u8ba1\u5c31\u662f\u5c06 \\(\\sigma\\) \u4e5f\u8f6c\u4e3a\u4e00\u5929\u7684\u53d8\u5316\u540e\u518d\u4e58\u4ee5 \\(S\\) \u3002\u5f53\u4ee5\u4e0b\u5173\u7cfb\u6210\u7acb\u65f6\uff0c\u6211\u4eec\u8ba4\u4e3a\u4ed3\u4f4d\u662f \"effecient\" \u7684\uff1a \\[ \\Theta t_{day} + \\frac{1}{2} \\Gamma \\sigma_{day}^2 S^2 > 0\\] \u800c \\[\\Gamma_{cash} = \\frac{S^2} {100} \\times M \\times \\Gamma \\] \u6211\u4eec\u53ef\u4ee5\u5f97\u51fa\uff0c\u6bcf\u5929\u6301\u4ed3\u7684\u73b0\u91d1 Decay \u5e94\u8be5\u5c0f\u4e8e\uff1a \\[ \\frac{1}{2} \\times 100 \\times \\sigma_{day}^2 \\Gamma_{cash} \\] \u5047\u8bbe\u6211\u4eec\u4ed3\u4f4d\u7684 cash Gamma \u4e3a 1,000,000\uff0c\u6ce2\u52a8\u7387\u4e3a 16%\u3002\u95ee\u6211\u4eec\u80fd\u63a5\u53d7\u7684\u6700\u5927\u7684 Decay \u662f\u591a\u5c11\uff1f \u4e00\u5e74\u6709\u7ea6 250 \u4e2a\u4ea4\u6613\u65e5\uff0c\u7531\u6ce2\u52a8\u7387\u4e3a 16%\uff0c\u53ef\u4ee5\u5f97\u51fa\u6bcf\u5929\u7684\u6ce2\u52a8\u7387\u5927\u7ea6\u5728 1%\u3002\u53ef\u4ee5\u8ba1\u7b97\u80fd\u63a5\u53d7\u7684\u6700\u5927 Decay\uff1a \\[ 0.5 \\times 100 \\times 0.01^2 *10^6 = 5000\\]","title":"A.2 Gamma \u548c Theta"},{"location":"trading/option/Greeks/#a3-slippage","text":"slippage \u5b9a\u4e49\u4e3a\u901a\u8fc7\u4ea4\u6613\u6807\u7684\u7269\u6765\u5bf9\u51b2 Delta \u7684\u6210\u672c\u3002\u5bf9\u4e8e\u671f\u6743\u4ea4\u6613\u8005\u6765\u8bf4\uff0c\u7531\u4e8e\u5fc5\u987b\u7ef4\u6301\u4e2d\u6027\u7684 Delta\uff0c\u8fd9\u662f\u5fc5\u7136\u7684\u6210\u672c\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\u6211\u4eec\u80fd\u5728\u7406\u8bba\u4ef7\u683c\u4e0a\u53bb\u4ea4\u6613\uff0c\u5b9e\u9645\u4e0a\uff0c\u6211\u4eec\u6709\u65f6\u5019\u4e0d\u80fd\u5b8c\u5168\u5728 top of book \u6210\u4ea4\uff0c\u6709\u65f6\u751a\u81f3\u9700\u8981\u4ea4\u6613\u51e0\u4e2a level \u6765\u5bf9\u51b2\u3002\u8fd9\u5c06\u5f71\u54cd\u6211\u4eec\u5728\u671f\u6743\u4ea4\u6613\u4e2d\u7684\u6536\u76ca\u3002 \u4e3e\u4f8b\u6765\u8bb2\uff0c\u8fd9\u662f\u67d0\u4e2a\u65f6\u523b\u539f\u6cb9\u671f\u8d27\u7684 book\uff08\u4ec5\u5217\u51fa 3 \u4e2a level\uff09\u3002 Bid Quantity Price Ask Quantity 66.87 31 66.86 59 66.85 38 30 66.84 59 66.83 50 66.82 \u6b64\u65f6\u7684\u7406\u8bba\u4ef7\u683c\u662f 66.843 \uff08\u8be5\u4ef7\u683c\u901a\u8fc7 book \u5f97\u51fa\uff0c\u5177\u4f53\u4e0d\u5c55\u5f00\uff09 \u540c\u65f6\uff0c\u4e0e\u8be5\u539f\u6cb9\u671f\u8d27\u76f8\u540c\u5230\u671f\u65e5\u7684\u4e24\u4e2a\u6b63\u5728\u4ea4\u6613\u7684\u671f\u6743\uff1a # Delta Bid Price Theo Ask Price 1 0.30 1.23 1.237 1.24 2 0.15 0.63 0.640 0.65 \u4ee5\u4e0b\u5b9e\u9645\u4f8b\u5b50\u53ef\u4ee5\u5e2e\u52a9\u7406\u89e3\u5bf9\u51b2\u6210\u672c\uff08slippage\uff09\uff0c\u6211\u4eec\u540c\u65f6\u8fd8\u53ef\u4ee5\u5f15\u5165\u4e00\u4e2a Retained Edge \u6982\u5ff5\u3002\u8fd9\u662f\u7528\u4e8e\u8868\u793a\u5728 hedge \u4e4b\u540e\u6211\u4eec\u8fd8\u80fd\u4fdd\u7559\u7684\u6765\u81ea\u671f\u6743\u4ea4\u6613\u7684 edge\u3002 Operation Option Edge Hedge Loss Retained Edge buy option #1 1.237 - 1.230 = 0.007 0.003*0.3 = 0.0009 0.0061 (87%) buy option #2 0.640 - 0.63 = 0.01 0.003*0.15 = 0.00045 0.00955 (96%) sell option #1 1.24 - 1.237 = 0.003 0.007*0.3 = 0.0021 0.0009 (30%) sell option #2 0.65 - 0.64 = 0.01 0.007*0.15 = 0.00105 0.00895 (90%) \u6216\u8005\uff0c\u4e5f\u53ef\u4ee5\u4ece\u53e6\u4e00\u79cd\u65b9\u5f0f\u7406\u89e3\u3002\u671f\u6743\u7684\u7406\u8bba\u4ef7\u683c\u7531\u671f\u8d27\u7684 book \u51b3\u5b9a\u3002\u6211\u4eec\u5728\u4ea4\u6613\u671f\u6743\u540e\uff0c\u9700\u8981\u5728\u671f\u8d27\u4e0a hedge\u3002\u8fd9\u4e2a\u884c\u4e3a\u4f1a\u5bfc\u81f4\u671f\u8d27\u7684 book \u53d8\u52a8\uff0c\u4ece\u800c\u5bfc\u81f4\u671f\u6743\u7684\u7406\u8bba\u4ef7\u683c\u5411 \u4e0d\u5229 \u6211\u4eec\u7684\u65b9\u5411\u66f4\u65b0\u3002Retained Edge \u662f\u6307\u5229\u7528\u66f4\u65b0\u540e\u7684\u7406\u8bba\u4ef7\u683c\u5f97\u5230\u7684 edge\uff0c\u800c\u975e\u4ea4\u6613\u671f\u6743\u65f6\u523b\u7684\u7406\u8bba\u4ef7\u683c\u3002 \u5bf9\u4e8e\u4e0a\u9762\u8868\u683c\u4e2d\u7684\u7b2c\u4e00\u4e2a\u4f8b\u5b50\uff0c\u4ea4\u6613\u671f\u6743\u65f6\u7406\u8bba\u4ef7\u683c\u662f1.237\uff0c\u6b64\u540e\u53bb hedge \u65f6\uff0c\u7531\u4e8e\u6211\u4eec\u9700\u8981\u8de8\u8d8a bid ask spread \u53bb\u5356\u51fa\u671f\u8d27\uff0c\u4ea4\u6613\u53d1\u751f\u65f6\u523b\u671f\u8d27\u7684\u7406\u8bba\u4ef7\u683c\u4e0d\u518d\u662f 66.843\uff0c\u800c\u662f\u671f\u8d27\u7684 top of book bid\uff0c\u537366.84\u3002 \u671f\u8d27\u7406\u8bba\u4ef7\u683c\u53d8\u52a8\u4e86 -0.003\uff0c\u4e58\u4ee5\u671f\u6743 #1 \u7684 Delta 0.3\uff0c\u53ef\u4ee5\u5f97\u51fa\u671f\u6743\u7684\u7406\u8bba\u4ef7\u683c\u53d8\u52a8\u4e3a -0.0009\uff0c\u65b0\u7684\u671f\u6743\u4ef7\u683c\u4e3a 1.2361\u3002\u6b64\u65f6\u518d\u6765\u770b\u8fd9\u7b14\u4ea4\u6613\u7684 Edge\uff0c\u5c31\u662f Retained Edge\uff0c1.2361 - 1.23 = 0.0061\u3002\u4e0e\u8868\u683c\u4e2d\u7ed3\u8bba\u4e00\u81f4\u3002","title":"A.3 Slippage"},{"location":"trading/option/Greeks/#_5","text":"\u5728\u7ebf\u6b63\u6001\u5206\u5e03\u8ba1\u7b97\u5668 Trading 101","title":"\u53c2\u8003"},{"location":"trading/option/Ito/","text":"Wiener processes and Ito\u2019s lemma \u82e5\u67d0\u4e00\u53d8\u91cf\u7684\u4ee5\u4e00\u79cd\u4e0d\u786e\u5b9a\u7684\u65b9\u5f0f\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u6211\u4eec\u79f0\u5b83\u670d\u4ece\u67d0\u79cd\u968f\u673a\u8fc7\u7a0b\uff08stochastic process\uff09\u3002\u968f\u673a\u8fc7\u7a0b\u53ef\u4ee5\u5206\u4e3a\u79bb\u6563\u65f6\u95f4\u548c\u8fde\u7eed\u65f6\u95f4\u4e24\u7c7b\u3002\u800c\u53d8\u91cf\u672c\u8eab\u4e5f\u53ef\u4ee5\u5206\u4e3a\u8fde\u7eed\u53d8\u91cf\u548c\u79bb\u6563\u53d8\u91cf\u4e24\u7c7b\u3002 \u672c\u7ae0\u6211\u4eec\u5c06\u5bfc\u51fa\u80a1\u7968\u4ef7\u683c\u7684\u8fde\u7eed\u53d8\u91cf\uff0c\u8fde\u7eed\u65f6\u95f4\u7684\u968f\u673a\u8fc7\u7a0b\u3002 13.1 \u9a6c\u5c14\u79d1\u592b\u6027\u8d28 Markov Process \u662f\u4e00\u79cd\u7279\u6b8a\u7684\u968f\u673a\u8fc7\u7a0b\u3002\u5728\u8be5\u8fc7\u7a0b\u4e2d\uff0c\u53ea\u6709\u5f53\u524d\u7684\u503c\u4e0e\u672a\u6765\u7684\u9884\u6d4b\u76f8\u5173\u3002 \u6211\u4eec\u901a\u5e38\u5047\u8bbe\u80a1\u7968\u7b26\u5408\u4e00\u4e2a Markov Process\u3002\u5373\u6211\u4eec\u5bf9\u80a1\u7968\u672a\u6765\u4ef7\u683c\u7684\u9884\u6d4b\u53ea\u548c\u80a1\u7968\u5f53\u524d\u4ef7\u683c\u6709\u5173\uff0c\u4e0e\u4e00\u5468\u524d\uff0c\u4e00\u5e74\u524d\u7684\u4ef7\u683c\u65e0\u5173\u3002 \u8fd9\u4e5f\u7b26\u5408\u5f31\u578b\u5e02\u573a\u6709\u6548\u6027\uff08the weak form of market efficiency\uff09\u3002\u5b83\u6307\u51fa\uff0c\u4e00\u79cd\u80a1\u7968\u7684\u5f53\u524d\u4ef7\u683c\u5305\u542b\u8fc7\u53bb\u4ef7\u683c\u7684\u6240\u6709\u4fe1\u606f\u3002\u5982\u679c\u5f31\u578b\u5e02\u573a\u6709\u6548\u6027\u4e0d\u6210\u7acb\uff0c\u5219\u5206\u6790\u5e08\u53ef\u4ee5\u901a\u8fc7\u5386\u53f2\u6570\u636e\u83b7\u5f97\u9ad8\u4e8e\u5e73\u5747\u6536\u76ca\u7387\u7684\u6536\u76ca\u3002\u4e8b\u5b9e\u4e0a\uff0c\u73b0\u5b9e\u4e2d\u6211\u4eec\u6ca1\u6709\u4efb\u4f55\u8bc1\u636e\u8bc1\u660e\u53ef\u4ee5\u505a\u5230\u8fd9\u4e00\u70b9\u3002 13.2 \u8fde\u7eed\u65f6\u95f4\u968f\u673a\u8fc7\u7a0b \u5047\u8bbe\u4e00\u4e2a\u53d8\u91cf\u670d\u4ece Markov Process\u3002\u5b83\u73b0\u5728\u7684\u503c\u662f 10\uff0c\u5728\u4e00\u5e74\u4e2d\u7684\u53d8\u5316\u6ee1\u8db3\u6b63\u6001\u5206\u5e03 \\(N(\\mu, \\sigma^2)\\) \u3002\u90a3\u4e48\u5b83\u5728 2 \u5e74\u4e2d\u7684\u53d8\u5316\u7684\u6982\u7387\u5206\u5e03\u662f\u4ec0\u4e48\uff1f \u5047\u8bbe\u5728\u7b2c 1 \u5e74\u4e2d\u7684\u53d8\u5316\u662f \\(x_1\\) \uff0c\u7b2c\u4e8c\u5e74\u4e2d\u7684\u53d8\u5316\u662f \\(x_2\\) \u3002\u5047\u8bbe\u4e24\u8005\u76f8\u4e92\u72ec\u7acb\u3002 \u663e\u7136\uff0c \\(x_1\\) \u548c \\(x_2\\) \u90fd\u670d\u4ece \\(N(\\mu, \\sigma^2)\\) \u3002\u5219\u4e24\u8005\u7684\u548c\u670d\u4ece\u5206\u5e03 \\(N(2\\mu, 2\\sigma^2)\\) \u3002 \u540c\u7406\uff0c0.5 \u5e74\u4e2d\u7684\u53d8\u5316\u7684\u6982\u7387\u5206\u5e03\u4e3a \\(N(0.5\\mu, 0.5\\sigma^2)\\) \u3002 \u7ed3\u8bba\u662f\uff0c\u53d8\u91cf\u5728\u4efb\u610f\u65f6\u95f4\u6bb5 \\(T\\) \uff08\u4ee5\u5e74\u4e3a\u5355\u4f4d\uff09\u53d8\u5316\u7684\u5206\u5e03\u670d\u4ece \\(N(\\mu T, \\sigma^2 T)\\) \u3002 \u8bc1\u660e \u5747\u503c\u90e8\u5206\u5f88\u7b80\u5355\uff0c\u53ef\u4ee5\u7a0d\u5fae\u8bc1\u660e\u4e00\u4e0b\u65b9\u5dee\u90e8\u5206\u3002 \u5df2\u77e5 \\(D(x_1)\\) \u548c \\(D(x_2)\\) \uff0c\u4e14 \\(x_1\\) \uff0c \\(x_2\\) \u76f8\u4e92\u72ec\u7acb\uff0c\u6c42 \\(D(x_1 + x_2)\\) \u3002 \u5c06 \\(D(x_1 + x_2)\\) \u505a\u5982\u4e0b\u53d8\u5f62\uff1a \\[\\begin{align} D(x_1 + x_2) &= E[(x_1+x_2)^2] - [E(x_1+x_2)]^2 \\\\ &= D(x_1) + D(x_2) + 2E(x_1 x_2) - 2E(x_1)E(x_2) \\end{align}\\] \u7531\u4e8e \\(x_1\\) \uff0c \\(x_2\\) \u76f8\u4e92\u72ec\u7acb\uff0c\u6709\uff1a \\[COV(x_1,x_2) = E(x_1 x_2) - E(x_1)E(x_2) = 0\\] \u56e0\u6b64\u6709\uff1a \\[D(x_1 + x_2) = D(x_1) + D(x_2)\\] 12.2.1 \u7ef4\u7eb3\u8fc7\u7a0b \u5982\u679c\u6211\u4eec\u4ee4\u4ee5\u4e0a\u53d8\u5316\u7684\u671f\u671b \\(\\mu = 0\\) \uff0c \\(\\sigma = 1\\) \uff0c\u6211\u4eec\u5c31\u5f97\u5230 \u7ef4\u7eb3\u8fc7\u7a0b (Wiener Process)\u3002\u5b83\u5728\u7269\u7406\u5b66\u4e2d\u88ab\u7528\u6765\u63cf\u8ff0\u67d0\u4e2a\u7c92\u5b50\u53d7\u5230\u5927\u91cf\u5206\u5b50\u78b0\u649e\u7684\u8fd0\u52a8\uff0c\u4e5f\u88ab\u79f0\u4f5c \u5e03\u6717\u8fd0\u52a8 (Brownian Motion)\u3002 \u4e25\u683c\u6765\u8bb2\uff0c\u4e00\u4e2a\u670d\u4ece\u7ef4\u7eb3\u8fc7\u7a0b\u7684\u53d8\u91cf \\(z\\) \u5177\u6709\u5982\u4e0b\u4e24\u6761\u6027\u8d28\uff1a \u53d8\u5316\u91cf \\(\\Delta z\\) \u5728\u4e00\u4e2a\u5c0f\u7684\u65f6\u95f4 \\(\\Delta t\\) \u4e2d\u7b26\u5408\uff1a \\[\\Delta z = \\epsilon\\sqrt{\\Delta t}\\] \u5176\u4e2d \\(\\epsilon\\) \u670d\u4ece\u6807\u51c6\u6b63\u6001\u5206\u5e03 \\(N(0,1)\\) \u53d8\u5316\u91cf \\(\\Delta z\\) \u5728\u4efb\u610f\u4e24\u4e2a\u4e0d\u540c\u7684\u65f6\u95f4\u6bb5\u72ec\u7acb \u5e7f\u4e49\u7ef4\u7eb3\u8fc7\u7a0b \u76ee\u524d\u6211\u4eec\u8ba8\u8bba\u7684\u7ef4\u7eb3\u8fc7\u7a0b\u4e2d\uff0c\u5bf9 \\(z\\) \u672a\u6765\u65f6\u523b\u7684\u671f\u671b\u603b\u662f\u7b49\u4e8e\u5b83\u7684\u521d\u503c\u3002\u6211\u4eec\u5c06\u5176\u505a\u4e00\u5b9a\u63a8\u5e7f\uff0c\u5373\u5bf9\u5176\u53e0\u52a0\u4e00\u4e2a\u968f\u65f6\u95f4\u53d8\u52a8\u7684\u56e0\u5b50 \\(a~dt\\) \uff1a \\[dx = a~dt + b~dz\\] \u5176\u4e2d\uff0c \\(a~dt\\) \u8868\u793a \\(x\\) \u5355\u4f4d\u65f6\u95f4\u5185\u6f02\u79fb\u901f\u5ea6\u4e3a \\(a\\) \u3002 \\(b~dz\\) \u8868\u793a\u566a\u58f0\uff0c\u8be5\u566a\u58f0\u7684\u53d8\u52a8\u662f \\(b\\) \u500d\u7684\u7ef4\u7eb3\u8fc7\u7a0b\uff0c\u5373\u670d\u4ece \\(N(0, b^2)\\) \u3002 \u5728\u4e00\u4e2a\u5f88\u77ed\u7684\u65f6\u95f4 \\(\\Delta t\\) \u4e2d\uff0c \\(x\\) \u7684\u53d8\u52a8 \\(\\Delta x\\) \u53ef\u4ee5\u5199\u4e3a\uff1a \\[\\Delta x = a \\Delta t + b \\epsilon \\sqrt{\\Delta t}\\] \u56e0\u6b64\uff0c\u5728 \\(T\\) \u65f6\u523b\u5b83\u670d\u4ece\u6b63\u6001\u5206\u5e03 \\(N(aT, b^2T)\\) \u3002 \u4e00\u4e2a\u5178\u578b\u7684\u5e7f\u4e49\u7ef4\u7eb3\u8fc7\u7a0b\u5982\u4e0b\u6240\u793a\uff1a \u4f8b \u4e00\u4e2a\u516c\u53f8\u7684\u73b0\u91d1\u670d\u4ece\u5e7f\u4e49\u7ef4\u7eb3\u8fc7\u7a0b\uff0cdrift \u4e3a 0.5 \u6bcf\u5b63\u5ea6\uff0c\u65b9\u5dee\u662f 4.0 \u6bcf\u5b63\u5ea6\u3002\u8be5\u516c\u53f8\u9700\u8981\u591a\u5c11\u521d\u59cb\u73b0\u91d1\u624d\u80fd\u4fdd\u8bc1 1 \u5e74\u540e\u73b0\u91d1\u4e3a\u8d1f\u7684\u6982\u7387\u5c0f\u4e8e 5%\uff1f \u6839\u636e\u4e0a\u9762\u5e7f\u4e49\u7ef4\u7eb3\u8fc7\u7a0b\u7684\u63a8\u8bba\uff0c\u5047\u8bbe\u5176\u521d\u59cb\u73b0\u91d1\u662f \\(m_0\\) \uff0c1 \u5e74\u540e\u73b0\u91d1 \\(m\\) \u670d\u4ece \\(N(m_0 + 4 \\times 0.5, 4 \\times 4)\\) \u3002 \u5047\u8bbe \\(\\epsilon\\) \u670d\u4ece\u6807\u51c6\u6b63\u6001\u5206\u5e03 \\(N(0,1)\\) \uff0c\u663e\u7136 \\(m = m_0 + 2 + 4\\epsilon\\) \u3002 \u56e0\u6b64\u95ee\u9898\u8f6c\u5316\u4e3a \\(P(m < 0) = P(\\epsilon < -\\frac{m_0+2}{4})\\leq 0.05\\) \u3002 \u67e5 \u6807\u51c6\u6b63\u6001\u5206\u5e03\u8868 \u5f97\u5230 \\(P(\\epsilon < 1.65) = 0.9505\\) \uff0c\u56e0\u6b64 \\(P(\\epsilon < -1.65) = 0.0495\\) \u3002\u56e0\u6b64\u6709 \\(m_0 = 4.6\\) \u3002\u5373\u9700\u8981\u521d\u59cb\u8d44\u91d1 4.6 \u767e\u4e07\u7f8e\u5143\u3002 12.2.2 \u4f0a\u85e4\u8fc7\u7a0b \u5f53\u5e7f\u4e49\u7ef4\u7eb3\u8fc7\u7a0b\u4e2d\u7684 \\(a\\) \uff0c \\(b\\) \u4e0d\u662f\u5e38\u6570\uff0c\u800c\u662f\u5173\u4e8e \\((x,t)\\) \u7684\u51fd\u6570\u65f6\uff0c\u5c31\u53d8\u4e3a\u4e86\u4e00\u4e2a\u4f0a\u85e4\u8fc7\u7a0b\uff1a \\[dx = a(x,t)~dt + b(x,t)~dz\\] \u5728\u4e00\u4e2a\u5f88\u77ed\u7684\u65f6\u95f4 \\(\\Delta t\\) \u5185\uff0c\u5047\u8bbe \\(a\\) \u548c \\(b\\) \u5728 \\(t\\) \u5230 \\(t+\\Delta t\\) \u4e2d\u4fdd\u6301\u4e0d\u53d8\uff0c\u6211\u4eec\u6709\uff1a \\[\\Delta x = a(x, t)~\\Delta t + b(x,t) \\epsilon \\sqrt{\\Delta t}\\] 12.3 \u63cf\u8ff0\u80a1\u4ef7\u53d8\u5316\u7684\u8fc7\u7a0b \u5047\u8bbe\u6211\u4eec\u5bf9\u80a1\u7968\u7684\u671f\u671b\u6536\u76ca\u7387\u4e3a \\(\\mu\\) \uff0c\u5219\u7ecf\u8fc7\u4e00\u4e2a\u5f88\u77ed\u7684\u65f6\u95f4 \\(\\Delta t\\) \uff0c\u6211\u4eec\u671f\u671b\u7684\u80a1\u7968\u4ef7\u503c\u662f \\(\\mu S \\Delta t\\) \u3002\u5229\u7528\u4f0a\u85e4\u8fc7\u7a0b\u6765\u7406\u89e3\uff0c\u5219\u80a1\u7968\u4ef7\u683c\u7684\u6f02\u79fb\u901f\u5ea6 (drift rate) \u662f \\(\\mu S\\) \u3002 \u5982\u679c\u6211\u4eec\u4e0d\u8003\u8651\u4efb\u4f55\u6270\u52a8\uff0c\u5373\u80a1\u7968\u4ef7\u683c\u603b\u6309\u7167\u671f\u671b\u4e0a\u6da8\u3002\u5219\u53ef\u4ee5\u8ba1\u7b97\uff1a \\[\\frac{dS}{dt} = \\mu S\\] \u5c06 S \u4ece 0 \u81f3 T \u79ef\u5206\uff0c\u53ef\u4ee5\u5f97\u51fa\uff1a \\[S_T = S_0 e^{\\mu T}\\] \u73b0\u5b9e\u4e2d\u80af\u5b9a\u662f\u5b58\u5728\u6270\u52a8\u7684\uff0c\u6211\u4eec\u4e00\u822c\u5047\u8bbe\u6270\u52a8\u4e0e\u80a1\u7968\u4ef7\u683c\u6210\u6b63\u6bd4\uff0c\u5047\u8bbe\u6bd4\u4f8b\u662f \\(\\sigma\\) \uff0c\u5219\u6211\u4eec\u5f97\u5230\u4ee5\u4e0b\u4f0a\u85e4\u8fc7\u7a0b\uff1a \\[dS = \\mu S dt + \\sigma S dz \\] \u5373\uff1a \\[\\frac{ dS}{ S} = \\mu dt + \\sigma dz\\] \u5176\u79bb\u6563\u65f6\u95f4\u6a21\u578b\u4e3a\uff1a \\[\\frac{\\Delta S}{S} = \\mu \\Delta t + \\sigma \\epsilon \\sqrt{\\Delta t}\\] \u53ef\u4ee5\u53d1\u73b0 \\(\\frac{ \\Delta S }{ S }\\) \u670d\u4ece\u6b63\u6001\u5206\u5e03 \\(N(\\mu \\Delta t, \\sigma^2 \\Delta t)\\) \u3002 \u5176\u4e2d\uff1a - \\(\\mu\\) \uff1a\u80a1\u7968\u7684\u671f\u671b\u56de\u62a5\u7387\uff0c\u5728\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u4e0b\uff0c \\(\\mu\\) \u7b49\u4e8e\u65e0\u98ce\u9669\u5229\u7387 \\(r\\) - \\(\\sigma\\) : \u80a1\u7968\u4ef7\u683c\u7684\u6ce2\u52a8\u7387 \u4f8b \u5206\u6790\u4ee5\u4e0a\u80a1\u7968\u4ef7\u683c\u53d8\u5316\u8fc7\u7a0b\u4e0e\u4e0b\u9762\u4e09\u4e2a\u8fc7\u7a0b\u7684\u533a\u522b\uff0c\u5e76\u89e3\u91ca\u4e3a\u4ec0\u4e48\u4e0a\u8ff0\u6a21\u578b\u66f4\u597d\u3002 \\(\\Delta S = \\mu \\Delta t + \\sigma \\epsilon \\sqrt{\\Delta t}\\) \\(\\Delta S = \\mu S \\Delta t + \\sigma \\epsilon \\sqrt{\\Delta t}\\) \\(\\Delta S = \\mu \\Delta t + \\sigma S \\epsilon \\sqrt{\\Delta t}\\) \u80a1\u7968\u4ef7\u683c\u7684\u9884\u671f\u589e\u957f\u91cf\u548c\u53d8\u5316\u91cf\u90fd\u5e94\u8be5\u4e0e\u80a1\u7968\u5f53\u65f6\u4ef7\u683c\u6210\u6b63\u6bd4\u3002\u56e0\u6b64\u4ee5\u4e0a\u8fc7\u7a0b\u90fd\u4e0d\u5982\u4e0b\u5f0f\u7684\u63cf\u8ff0\u51c6\u786e \\[\\frac{\\Delta S}{S} = \\mu \\Delta t + \\sigma \\epsilon \\sqrt{\\Delta t}\\] 12.6 \u4f0a\u85e4\u5f15\u7406 \u82e5\u53d8\u91cf x \u7b26\u5408\u4ee5\u4e0b\u4f0a\u85e4\u8fc7\u7a0b\uff1a \\[dx = a(x,t)~dt + b(x,t)~dz\\] \u90a3\u4e48\u5173\u4e8e \\(x\\) \u548c \\(t\\) \u7684\u53ef\u5fae\u51fd\u6570 \\(G(x,t)\\) \u9075\u5faa\u4ee5\u4e0b\u4f0a\u85e4\u8fc7\u7a0b\uff1a \\[dG = (\\frac{\\partial G}{\\partial x}a + \\frac{\\partial G}{\\partial t} + \\frac{1}{2} \\frac{\\partial^2 G}{\\partial x^2}b^2)~dt + \\frac{\\partial G}{\\partial x}b~dz\\] \u8bc1\u660e \u6839\u636e\u591a\u5143\u6cf0\u52d2\u5c55\u5f00\u516c\u5f0f\uff0c\u5bf9 \\(G(x,t)\\) \u4f5c\u4e8c\u9636\u5c55\u5f00\uff0c\u5f97\uff1a \\[\\Delta G = \\frac{\\partial G}{\\partial x}\\Delta x + \\frac{\\partial G}{\\partial t}\\Delta t + \\frac{1}{2!}(\\frac{\\partial^2 G}{\\partial x^2}\\Delta x^2 + 2\\frac{\\partial^2 G}{\\partial x \\partial t}\\Delta x \\Delta t + \\frac{\\partial^2 G}{\\partial x^2}\\Delta t^2)\\] \u7531\u4e8e \\(\\Delta x\\) \u4e5f\u662f \\(\\Delta t\\) \u7684\u51fd\u6570\uff1a \\[\\Delta x = a(x,t)~\\Delta t + b(x,t) \\epsilon \\sqrt{\\Delta t}\\] \u5ffd\u7565 \\(\\Delta t\\) \u7684\u9ad8\u9636\u65e0\u7a77\u5c0f \\(o(\\Delta t)\\) \uff0c\u53ef\u5f97\uff1a \\[\\Delta x^2 = b^2(x,t) \\epsilon^2 \\Delta t \\] \u7531\u4e8e \\(\\epsilon\\) \u670d\u4ece \\(N(0,1)\\) \uff0c\u53ef\u77e5 \\(\\epsilon^2\\) \u670d\u4ece \\(\\chi^2_1\\) \uff0c\u5176\u4e2d \\(\\chi^2_n\\) \u662f\u5361\u65b9\u5206\u5e03\uff0c\u6ee1\u8db3 \\(E(\\chi^2_n) = n\\) \uff0c \\(D(\\chi^2_n) = 2n\\) \u3002 \u56e0\u6b64\uff0c\u5bf9\u4e8e \\(\\epsilon^2 \\Delta t\\) \uff0c\u5b83\u7684\u671f\u671b\u503c\u662f \\(\\Delta t\\) \uff0c\u65b9\u5dee\u662f \\(2\\Delta t^2\\) \u3002 \u5c31\u6574\u4e2a \\(\\Delta G\\) \u6765\u770b\uff1a \\[\\Delta G = \\frac{\\partial G}{\\partial x}\\Delta x + \\frac{\\partial G}{\\partial t}\\Delta t + \\frac{1}{2}\\frac{\\partial^2 G}{\\partial x^2}\\Delta x^2\\] \u7531\u4e8e \\(\\Delta x\\) \u90e8\u5206\u8fd8\u6709\u65b9\u5dee\u4e3a \\(\\Delta t\\) \u6270\u52a8\uff0c\u56e0\u6b64\u65b9\u5dee\u4e3a \\(\\Delta t^2\\) \u7684\u6270\u52a8\u4ece\u6570\u91cf\u7ea7\u4e0a\u5c31\u53ef\u4ee5\u5ffd\u7565\u3002\u6211\u4eec\u56e0\u6b64\u53ef\u4ee5\u76f4\u63a5\u628a \\(\\epsilon^2\\) \u8fd1\u4f3c\u4e3a\u5e38\u6570\uff0c\u4e5f\u5c31\u662f\u5b83\u7684\u671f\u671b\u503c 1\u3002\u5f97\u5230\uff1a \\[\\Delta G = \\frac{ \\partial G}{ \\partial x}(a\\Delta t + b \\epsilon \\sqrt{\\Delta t}) + \\frac{\\partial G}{\\partial t}\\Delta t + \\frac{1}{2}\\frac{\\partial^2 G}{\\partial x^2}b^2\\Delta t\\] \\[\\Delta G = (\\frac{\\partial G}{\\partial x}a + \\frac{\\partial G}{\\partial t} + \\frac{1}{2}\\frac{\\partial^2 G}{\\partial x^2}b^2)\\Delta t + \\frac{\\partial G}{\\partial x} b \\epsilon \\sqrt{\\Delta t}\\] \u4e5f\u5199\u4f5c\uff1a \\[ dG = (\\frac{\\partial G}{\\partial x}a + \\frac{\\partial G}{\\partial t} + \\frac{1}{2}\\frac{\\partial^2 G}{\\partial x^2}b^2)~dt + \\frac{\\partial G}{\\partial x} b~dz \\] \u5e94\u7528\uff1a\u8fdc\u671f\u5408\u7ea6 \u5bf9\u4e8e\u8fdc\u671f\u5408\u7ea6\uff0c\u5047\u8bbe\u5230\u671f\u65f6\u95f4\u4e3a \\(T\\) \uff0c\u65e0\u98ce\u9669\u5229\u7387\u4e3a \\(r\\) \uff0c\u5f53\u524d\u65f6\u95f4\u4e3a \\(t\\) \uff0c\u5f53\u524d\u73b0\u8d27\u4ef7\u683c\u4e3a \\(S\\) \uff0c\u5219\u8fdc\u671f\u5408\u7ea6\u7684\u6267\u884c\u4ef7\u683c\u5e94\u8be5\u4e3a \\(S\\) \u548c \\(t\\) \u7684\u51fd\u6570\uff08\u5426\u5219\u5b58\u5728\u5957\u5229\u673a\u4f1a\uff09\uff1a \\[F = Se^{r(T-t)}\\] \u5982\u6211\u4eec\u5728 12.3 \u4ecb\u7ecd\u7684\uff0c\u5047\u8bbe \\(S\\) \u6ee1\u8db3\u4f0a\u85e4\u8fc7\u7a0b\uff1a \\[dS = \\mu S dt + \\sigma S dz \\] \u5176\u4e2d\u671f\u671b\u6536\u76ca\u4e3a \\(\\mu\\) \uff0c\u6ce2\u52a8\u7387\u4e3a \\(\\sigma\\) \u3002\u5219 \\(F\\) \u7684\u4ef7\u683c\u53d8\u5316\u8fc7\u7a0b\u53ef\u4ee5\u5229\u7528\u4f0a\u85e4\u5f15\u7406\u786e\u5b9a\u3002 \\(\\frac{ \\partial F}{\\partial S} = e^{r(T-t)}\\) \uff0c \\(\\frac{\\partial^2 F}{\\partial S^2} = 0\\) \uff0c \\(\\frac{\\partial F}{\\partial t} = -r S e^{r(T-t)}\\) \uff0c\u5e26\u5165\u4f0a\u85e4\u5f15\u7406\u6709\uff1a \\[dF = (a - r S) e^{r(T-t)}~dt + e^{r(T-t)}b~dz \\] \u800c\uff0c \\(a\\) \u4e3a\u671f\u671b\u6536\u76ca \\(\\mu S\\) \uff0c \\(b\\) \u4e3a\u6ce2\u52a8\u7387 \\(\\sigma S\\) \uff0c\u5e26\u5165\u6709\uff1a \\[dF = (\\mu - r ) F~dt + \\sigma F~dz\\] \u4f8b1 \u5047\u8bbe \\(G(S, t)\\) \u662f\u5173\u4e8e\u80a1\u7968\u4ef7\u683c \\(S\\) \u548c\u65f6\u95f4 \\(t\\) \u7684\u51fd\u6570\uff0c \\(\\sigma_S\\) \u53ca \\(\\sigma_G\\) \u5206\u522b\u4e3a \\(S\\) \u548c \\(G\\) \u7684\u6ce2\u52a8\u7387\uff0c\u8bc1\u660e\u5f53 \\(S\\) \u7684\u671f\u671b\u56de\u62a5\u4e0a\u5347 \\(\\lambda \\sigma_S\\) \u65f6\uff0c \\(G\\) \u7684\u671f\u671b\u56de\u62a5\u4e0a\u5347 \\(\\lambda \\sigma_G\\) \uff0c\u5176\u4e2d \\(\\lambda\\) \u662f\u5e38\u6570\u3002 \u5047\u8bbe \\(S\\) \u7b26\u5408\u4f0a\u85e4\u8fc7\u7a0b\uff1a \\[ dS = a~dt + b~dz\\] \u7531\u4f0a\u85e4\u5f15\u7406\u53ef\u77e5\uff1a \\[ dG = (\\frac{\\partial G}{\\partial x}a + \\frac{\\partial G}{\\partial t} + \\frac{1}{2}\\frac{\\partial^2 G}{\\partial x^2}b^2)~dt + \\frac{\\partial G}{\\partial x} b~dz \\] \u56e0\u6b64\uff0c\u6ce2\u52a8\u7387\u6709\u5982\u4e0b\u5173\u7cfb\uff1a \\[ \\sigma_G = \\frac{ \\partial G }{ \\partial x } \\sigma_S \\] \u82e5 \\(S\\) \u7684\u671f\u671b\u6536\u76ca \\(a\\) \u4e0a\u5347\u4e86 \\(\\lambda \\sigma_S\\) \uff0c\u5219\u663e\u7136\u6709 \\(G\\) \u7684\u671f\u671b\u6536\u76ca\u4e0a\u5347\u4e86 \\(\\frac{ \\partial G }{\\partial x } \\lambda \\sigma_S = \\lambda \\sigma_G\\) \u3002 \u4f8b2 \u5047\u8bbe\u80a1\u7968\u4ef7\u683c \\(S\\) \u670d\u4ece\u51e0\u4f55\u5e03\u6717\u8fd0\u52a8\uff1a \\(dS = \\mu S~dt + \\sigma S~dz\\) \u5176\u4e2d\u671f\u671b\u56de\u62a5\u7387\u662f \\(\\mu\\) \uff0c\u6ce2\u52a8\u7387\u662f \\(\\sigma\\) \u3002\u8bc1\u660e \\(S^n\\) \u4e5f\u670d\u4ece\u51e0\u4f55\u5e03\u6717\u8fd0\u52a8\u3002 \u540c\u6837\u662f\u4f0a\u85e4\u5f15\u7406\u7684\u5e94\u7528\u3002\u4ee4 \\(G(S,t) = S^n\\) \u3002\u5219\u6709\uff1a \\[dG = (\\frac{\\partial G}{\\partial S} a + \\frac{\\partial G}{\\partial t} + \\frac{1}{2}\\frac{\\partial^2 G}{\\partial S^2}b^2)~dt + \\frac{\\partial G}{\\partial S} b~dz\\] \u5e26\u5165 \\(a = \\mu S\\) \uff0c \\(b = \\sigma S\\) \u53ef\u5f97\uff1a \\[dG = (n\\mu + \\frac{ 1}{ 2} n(n-1)\\sigma^2) G~dt + n \\sigma G~dz\\] \u56e0\u6b64 \\(S^n\\) \u4e0e \\(S\\) \u5177\u6709\u540c\u6837\u7684\u5f62\u5f0f\uff0c\u4e5f\u6ee1\u8db3\u51e0\u4f55\u5e03\u6717\u8fd0\u52a8\u3002\u5176\u671f\u671b\u7684\u6536\u76ca\u7387\u4e3a \\(n\\mu + \\frac{1}{2} n(n-1)\\sigma^2\\) \uff0c\u6ce2\u52a8\u7387\u4e3a \\(n \\sigma\\) \u3002","title":"Wiener processes and Ito\u2019s lemma"},{"location":"trading/option/Ito/#wiener-processes-and-itos-lemma","text":"\u82e5\u67d0\u4e00\u53d8\u91cf\u7684\u4ee5\u4e00\u79cd\u4e0d\u786e\u5b9a\u7684\u65b9\u5f0f\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u6211\u4eec\u79f0\u5b83\u670d\u4ece\u67d0\u79cd\u968f\u673a\u8fc7\u7a0b\uff08stochastic process\uff09\u3002\u968f\u673a\u8fc7\u7a0b\u53ef\u4ee5\u5206\u4e3a\u79bb\u6563\u65f6\u95f4\u548c\u8fde\u7eed\u65f6\u95f4\u4e24\u7c7b\u3002\u800c\u53d8\u91cf\u672c\u8eab\u4e5f\u53ef\u4ee5\u5206\u4e3a\u8fde\u7eed\u53d8\u91cf\u548c\u79bb\u6563\u53d8\u91cf\u4e24\u7c7b\u3002 \u672c\u7ae0\u6211\u4eec\u5c06\u5bfc\u51fa\u80a1\u7968\u4ef7\u683c\u7684\u8fde\u7eed\u53d8\u91cf\uff0c\u8fde\u7eed\u65f6\u95f4\u7684\u968f\u673a\u8fc7\u7a0b\u3002","title":"Wiener processes and Ito\u2019s lemma"},{"location":"trading/option/Ito/#131","text":"Markov Process \u662f\u4e00\u79cd\u7279\u6b8a\u7684\u968f\u673a\u8fc7\u7a0b\u3002\u5728\u8be5\u8fc7\u7a0b\u4e2d\uff0c\u53ea\u6709\u5f53\u524d\u7684\u503c\u4e0e\u672a\u6765\u7684\u9884\u6d4b\u76f8\u5173\u3002 \u6211\u4eec\u901a\u5e38\u5047\u8bbe\u80a1\u7968\u7b26\u5408\u4e00\u4e2a Markov Process\u3002\u5373\u6211\u4eec\u5bf9\u80a1\u7968\u672a\u6765\u4ef7\u683c\u7684\u9884\u6d4b\u53ea\u548c\u80a1\u7968\u5f53\u524d\u4ef7\u683c\u6709\u5173\uff0c\u4e0e\u4e00\u5468\u524d\uff0c\u4e00\u5e74\u524d\u7684\u4ef7\u683c\u65e0\u5173\u3002 \u8fd9\u4e5f\u7b26\u5408\u5f31\u578b\u5e02\u573a\u6709\u6548\u6027\uff08the weak form of market efficiency\uff09\u3002\u5b83\u6307\u51fa\uff0c\u4e00\u79cd\u80a1\u7968\u7684\u5f53\u524d\u4ef7\u683c\u5305\u542b\u8fc7\u53bb\u4ef7\u683c\u7684\u6240\u6709\u4fe1\u606f\u3002\u5982\u679c\u5f31\u578b\u5e02\u573a\u6709\u6548\u6027\u4e0d\u6210\u7acb\uff0c\u5219\u5206\u6790\u5e08\u53ef\u4ee5\u901a\u8fc7\u5386\u53f2\u6570\u636e\u83b7\u5f97\u9ad8\u4e8e\u5e73\u5747\u6536\u76ca\u7387\u7684\u6536\u76ca\u3002\u4e8b\u5b9e\u4e0a\uff0c\u73b0\u5b9e\u4e2d\u6211\u4eec\u6ca1\u6709\u4efb\u4f55\u8bc1\u636e\u8bc1\u660e\u53ef\u4ee5\u505a\u5230\u8fd9\u4e00\u70b9\u3002","title":"13.1 \u9a6c\u5c14\u79d1\u592b\u6027\u8d28"},{"location":"trading/option/Ito/#132","text":"\u5047\u8bbe\u4e00\u4e2a\u53d8\u91cf\u670d\u4ece Markov Process\u3002\u5b83\u73b0\u5728\u7684\u503c\u662f 10\uff0c\u5728\u4e00\u5e74\u4e2d\u7684\u53d8\u5316\u6ee1\u8db3\u6b63\u6001\u5206\u5e03 \\(N(\\mu, \\sigma^2)\\) \u3002\u90a3\u4e48\u5b83\u5728 2 \u5e74\u4e2d\u7684\u53d8\u5316\u7684\u6982\u7387\u5206\u5e03\u662f\u4ec0\u4e48\uff1f \u5047\u8bbe\u5728\u7b2c 1 \u5e74\u4e2d\u7684\u53d8\u5316\u662f \\(x_1\\) \uff0c\u7b2c\u4e8c\u5e74\u4e2d\u7684\u53d8\u5316\u662f \\(x_2\\) \u3002\u5047\u8bbe\u4e24\u8005\u76f8\u4e92\u72ec\u7acb\u3002 \u663e\u7136\uff0c \\(x_1\\) \u548c \\(x_2\\) \u90fd\u670d\u4ece \\(N(\\mu, \\sigma^2)\\) \u3002\u5219\u4e24\u8005\u7684\u548c\u670d\u4ece\u5206\u5e03 \\(N(2\\mu, 2\\sigma^2)\\) \u3002 \u540c\u7406\uff0c0.5 \u5e74\u4e2d\u7684\u53d8\u5316\u7684\u6982\u7387\u5206\u5e03\u4e3a \\(N(0.5\\mu, 0.5\\sigma^2)\\) \u3002 \u7ed3\u8bba\u662f\uff0c\u53d8\u91cf\u5728\u4efb\u610f\u65f6\u95f4\u6bb5 \\(T\\) \uff08\u4ee5\u5e74\u4e3a\u5355\u4f4d\uff09\u53d8\u5316\u7684\u5206\u5e03\u670d\u4ece \\(N(\\mu T, \\sigma^2 T)\\) \u3002","title":"13.2 \u8fde\u7eed\u65f6\u95f4\u968f\u673a\u8fc7\u7a0b"},{"location":"trading/option/Ito/#_1","text":"\u5747\u503c\u90e8\u5206\u5f88\u7b80\u5355\uff0c\u53ef\u4ee5\u7a0d\u5fae\u8bc1\u660e\u4e00\u4e0b\u65b9\u5dee\u90e8\u5206\u3002 \u5df2\u77e5 \\(D(x_1)\\) \u548c \\(D(x_2)\\) \uff0c\u4e14 \\(x_1\\) \uff0c \\(x_2\\) \u76f8\u4e92\u72ec\u7acb\uff0c\u6c42 \\(D(x_1 + x_2)\\) \u3002 \u5c06 \\(D(x_1 + x_2)\\) \u505a\u5982\u4e0b\u53d8\u5f62\uff1a \\[\\begin{align} D(x_1 + x_2) &= E[(x_1+x_2)^2] - [E(x_1+x_2)]^2 \\\\ &= D(x_1) + D(x_2) + 2E(x_1 x_2) - 2E(x_1)E(x_2) \\end{align}\\] \u7531\u4e8e \\(x_1\\) \uff0c \\(x_2\\) \u76f8\u4e92\u72ec\u7acb\uff0c\u6709\uff1a \\[COV(x_1,x_2) = E(x_1 x_2) - E(x_1)E(x_2) = 0\\] \u56e0\u6b64\u6709\uff1a \\[D(x_1 + x_2) = D(x_1) + D(x_2)\\]","title":"\u8bc1\u660e"},{"location":"trading/option/Ito/#1221","text":"\u5982\u679c\u6211\u4eec\u4ee4\u4ee5\u4e0a\u53d8\u5316\u7684\u671f\u671b \\(\\mu = 0\\) \uff0c \\(\\sigma = 1\\) \uff0c\u6211\u4eec\u5c31\u5f97\u5230 \u7ef4\u7eb3\u8fc7\u7a0b (Wiener Process)\u3002\u5b83\u5728\u7269\u7406\u5b66\u4e2d\u88ab\u7528\u6765\u63cf\u8ff0\u67d0\u4e2a\u7c92\u5b50\u53d7\u5230\u5927\u91cf\u5206\u5b50\u78b0\u649e\u7684\u8fd0\u52a8\uff0c\u4e5f\u88ab\u79f0\u4f5c \u5e03\u6717\u8fd0\u52a8 (Brownian Motion)\u3002 \u4e25\u683c\u6765\u8bb2\uff0c\u4e00\u4e2a\u670d\u4ece\u7ef4\u7eb3\u8fc7\u7a0b\u7684\u53d8\u91cf \\(z\\) \u5177\u6709\u5982\u4e0b\u4e24\u6761\u6027\u8d28\uff1a \u53d8\u5316\u91cf \\(\\Delta z\\) \u5728\u4e00\u4e2a\u5c0f\u7684\u65f6\u95f4 \\(\\Delta t\\) \u4e2d\u7b26\u5408\uff1a \\[\\Delta z = \\epsilon\\sqrt{\\Delta t}\\] \u5176\u4e2d \\(\\epsilon\\) \u670d\u4ece\u6807\u51c6\u6b63\u6001\u5206\u5e03 \\(N(0,1)\\) \u53d8\u5316\u91cf \\(\\Delta z\\) \u5728\u4efb\u610f\u4e24\u4e2a\u4e0d\u540c\u7684\u65f6\u95f4\u6bb5\u72ec\u7acb","title":"12.2.1 \u7ef4\u7eb3\u8fc7\u7a0b"},{"location":"trading/option/Ito/#_2","text":"\u76ee\u524d\u6211\u4eec\u8ba8\u8bba\u7684\u7ef4\u7eb3\u8fc7\u7a0b\u4e2d\uff0c\u5bf9 \\(z\\) \u672a\u6765\u65f6\u523b\u7684\u671f\u671b\u603b\u662f\u7b49\u4e8e\u5b83\u7684\u521d\u503c\u3002\u6211\u4eec\u5c06\u5176\u505a\u4e00\u5b9a\u63a8\u5e7f\uff0c\u5373\u5bf9\u5176\u53e0\u52a0\u4e00\u4e2a\u968f\u65f6\u95f4\u53d8\u52a8\u7684\u56e0\u5b50 \\(a~dt\\) \uff1a \\[dx = a~dt + b~dz\\] \u5176\u4e2d\uff0c \\(a~dt\\) \u8868\u793a \\(x\\) \u5355\u4f4d\u65f6\u95f4\u5185\u6f02\u79fb\u901f\u5ea6\u4e3a \\(a\\) \u3002 \\(b~dz\\) \u8868\u793a\u566a\u58f0\uff0c\u8be5\u566a\u58f0\u7684\u53d8\u52a8\u662f \\(b\\) \u500d\u7684\u7ef4\u7eb3\u8fc7\u7a0b\uff0c\u5373\u670d\u4ece \\(N(0, b^2)\\) \u3002 \u5728\u4e00\u4e2a\u5f88\u77ed\u7684\u65f6\u95f4 \\(\\Delta t\\) \u4e2d\uff0c \\(x\\) \u7684\u53d8\u52a8 \\(\\Delta x\\) \u53ef\u4ee5\u5199\u4e3a\uff1a \\[\\Delta x = a \\Delta t + b \\epsilon \\sqrt{\\Delta t}\\] \u56e0\u6b64\uff0c\u5728 \\(T\\) \u65f6\u523b\u5b83\u670d\u4ece\u6b63\u6001\u5206\u5e03 \\(N(aT, b^2T)\\) \u3002 \u4e00\u4e2a\u5178\u578b\u7684\u5e7f\u4e49\u7ef4\u7eb3\u8fc7\u7a0b\u5982\u4e0b\u6240\u793a\uff1a","title":"\u5e7f\u4e49\u7ef4\u7eb3\u8fc7\u7a0b"},{"location":"trading/option/Ito/#_3","text":"\u4e00\u4e2a\u516c\u53f8\u7684\u73b0\u91d1\u670d\u4ece\u5e7f\u4e49\u7ef4\u7eb3\u8fc7\u7a0b\uff0cdrift \u4e3a 0.5 \u6bcf\u5b63\u5ea6\uff0c\u65b9\u5dee\u662f 4.0 \u6bcf\u5b63\u5ea6\u3002\u8be5\u516c\u53f8\u9700\u8981\u591a\u5c11\u521d\u59cb\u73b0\u91d1\u624d\u80fd\u4fdd\u8bc1 1 \u5e74\u540e\u73b0\u91d1\u4e3a\u8d1f\u7684\u6982\u7387\u5c0f\u4e8e 5%\uff1f \u6839\u636e\u4e0a\u9762\u5e7f\u4e49\u7ef4\u7eb3\u8fc7\u7a0b\u7684\u63a8\u8bba\uff0c\u5047\u8bbe\u5176\u521d\u59cb\u73b0\u91d1\u662f \\(m_0\\) \uff0c1 \u5e74\u540e\u73b0\u91d1 \\(m\\) \u670d\u4ece \\(N(m_0 + 4 \\times 0.5, 4 \\times 4)\\) \u3002 \u5047\u8bbe \\(\\epsilon\\) \u670d\u4ece\u6807\u51c6\u6b63\u6001\u5206\u5e03 \\(N(0,1)\\) \uff0c\u663e\u7136 \\(m = m_0 + 2 + 4\\epsilon\\) \u3002 \u56e0\u6b64\u95ee\u9898\u8f6c\u5316\u4e3a \\(P(m < 0) = P(\\epsilon < -\\frac{m_0+2}{4})\\leq 0.05\\) \u3002 \u67e5 \u6807\u51c6\u6b63\u6001\u5206\u5e03\u8868 \u5f97\u5230 \\(P(\\epsilon < 1.65) = 0.9505\\) \uff0c\u56e0\u6b64 \\(P(\\epsilon < -1.65) = 0.0495\\) \u3002\u56e0\u6b64\u6709 \\(m_0 = 4.6\\) \u3002\u5373\u9700\u8981\u521d\u59cb\u8d44\u91d1 4.6 \u767e\u4e07\u7f8e\u5143\u3002","title":"\u4f8b"},{"location":"trading/option/Ito/#1222","text":"\u5f53\u5e7f\u4e49\u7ef4\u7eb3\u8fc7\u7a0b\u4e2d\u7684 \\(a\\) \uff0c \\(b\\) \u4e0d\u662f\u5e38\u6570\uff0c\u800c\u662f\u5173\u4e8e \\((x,t)\\) \u7684\u51fd\u6570\u65f6\uff0c\u5c31\u53d8\u4e3a\u4e86\u4e00\u4e2a\u4f0a\u85e4\u8fc7\u7a0b\uff1a \\[dx = a(x,t)~dt + b(x,t)~dz\\] \u5728\u4e00\u4e2a\u5f88\u77ed\u7684\u65f6\u95f4 \\(\\Delta t\\) \u5185\uff0c\u5047\u8bbe \\(a\\) \u548c \\(b\\) \u5728 \\(t\\) \u5230 \\(t+\\Delta t\\) \u4e2d\u4fdd\u6301\u4e0d\u53d8\uff0c\u6211\u4eec\u6709\uff1a \\[\\Delta x = a(x, t)~\\Delta t + b(x,t) \\epsilon \\sqrt{\\Delta t}\\]","title":"12.2.2 \u4f0a\u85e4\u8fc7\u7a0b"},{"location":"trading/option/Ito/#123","text":"\u5047\u8bbe\u6211\u4eec\u5bf9\u80a1\u7968\u7684\u671f\u671b\u6536\u76ca\u7387\u4e3a \\(\\mu\\) \uff0c\u5219\u7ecf\u8fc7\u4e00\u4e2a\u5f88\u77ed\u7684\u65f6\u95f4 \\(\\Delta t\\) \uff0c\u6211\u4eec\u671f\u671b\u7684\u80a1\u7968\u4ef7\u503c\u662f \\(\\mu S \\Delta t\\) \u3002\u5229\u7528\u4f0a\u85e4\u8fc7\u7a0b\u6765\u7406\u89e3\uff0c\u5219\u80a1\u7968\u4ef7\u683c\u7684\u6f02\u79fb\u901f\u5ea6 (drift rate) \u662f \\(\\mu S\\) \u3002 \u5982\u679c\u6211\u4eec\u4e0d\u8003\u8651\u4efb\u4f55\u6270\u52a8\uff0c\u5373\u80a1\u7968\u4ef7\u683c\u603b\u6309\u7167\u671f\u671b\u4e0a\u6da8\u3002\u5219\u53ef\u4ee5\u8ba1\u7b97\uff1a \\[\\frac{dS}{dt} = \\mu S\\] \u5c06 S \u4ece 0 \u81f3 T \u79ef\u5206\uff0c\u53ef\u4ee5\u5f97\u51fa\uff1a \\[S_T = S_0 e^{\\mu T}\\] \u73b0\u5b9e\u4e2d\u80af\u5b9a\u662f\u5b58\u5728\u6270\u52a8\u7684\uff0c\u6211\u4eec\u4e00\u822c\u5047\u8bbe\u6270\u52a8\u4e0e\u80a1\u7968\u4ef7\u683c\u6210\u6b63\u6bd4\uff0c\u5047\u8bbe\u6bd4\u4f8b\u662f \\(\\sigma\\) \uff0c\u5219\u6211\u4eec\u5f97\u5230\u4ee5\u4e0b\u4f0a\u85e4\u8fc7\u7a0b\uff1a \\[dS = \\mu S dt + \\sigma S dz \\] \u5373\uff1a \\[\\frac{ dS}{ S} = \\mu dt + \\sigma dz\\] \u5176\u79bb\u6563\u65f6\u95f4\u6a21\u578b\u4e3a\uff1a \\[\\frac{\\Delta S}{S} = \\mu \\Delta t + \\sigma \\epsilon \\sqrt{\\Delta t}\\] \u53ef\u4ee5\u53d1\u73b0 \\(\\frac{ \\Delta S }{ S }\\) \u670d\u4ece\u6b63\u6001\u5206\u5e03 \\(N(\\mu \\Delta t, \\sigma^2 \\Delta t)\\) \u3002 \u5176\u4e2d\uff1a - \\(\\mu\\) \uff1a\u80a1\u7968\u7684\u671f\u671b\u56de\u62a5\u7387\uff0c\u5728\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u4e0b\uff0c \\(\\mu\\) \u7b49\u4e8e\u65e0\u98ce\u9669\u5229\u7387 \\(r\\) - \\(\\sigma\\) : \u80a1\u7968\u4ef7\u683c\u7684\u6ce2\u52a8\u7387","title":"12.3 \u63cf\u8ff0\u80a1\u4ef7\u53d8\u5316\u7684\u8fc7\u7a0b"},{"location":"trading/option/Ito/#_4","text":"\u5206\u6790\u4ee5\u4e0a\u80a1\u7968\u4ef7\u683c\u53d8\u5316\u8fc7\u7a0b\u4e0e\u4e0b\u9762\u4e09\u4e2a\u8fc7\u7a0b\u7684\u533a\u522b\uff0c\u5e76\u89e3\u91ca\u4e3a\u4ec0\u4e48\u4e0a\u8ff0\u6a21\u578b\u66f4\u597d\u3002 \\(\\Delta S = \\mu \\Delta t + \\sigma \\epsilon \\sqrt{\\Delta t}\\) \\(\\Delta S = \\mu S \\Delta t + \\sigma \\epsilon \\sqrt{\\Delta t}\\) \\(\\Delta S = \\mu \\Delta t + \\sigma S \\epsilon \\sqrt{\\Delta t}\\) \u80a1\u7968\u4ef7\u683c\u7684\u9884\u671f\u589e\u957f\u91cf\u548c\u53d8\u5316\u91cf\u90fd\u5e94\u8be5\u4e0e\u80a1\u7968\u5f53\u65f6\u4ef7\u683c\u6210\u6b63\u6bd4\u3002\u56e0\u6b64\u4ee5\u4e0a\u8fc7\u7a0b\u90fd\u4e0d\u5982\u4e0b\u5f0f\u7684\u63cf\u8ff0\u51c6\u786e \\[\\frac{\\Delta S}{S} = \\mu \\Delta t + \\sigma \\epsilon \\sqrt{\\Delta t}\\]","title":"\u4f8b"},{"location":"trading/option/Ito/#126","text":"\u82e5\u53d8\u91cf x \u7b26\u5408\u4ee5\u4e0b\u4f0a\u85e4\u8fc7\u7a0b\uff1a \\[dx = a(x,t)~dt + b(x,t)~dz\\] \u90a3\u4e48\u5173\u4e8e \\(x\\) \u548c \\(t\\) \u7684\u53ef\u5fae\u51fd\u6570 \\(G(x,t)\\) \u9075\u5faa\u4ee5\u4e0b\u4f0a\u85e4\u8fc7\u7a0b\uff1a \\[dG = (\\frac{\\partial G}{\\partial x}a + \\frac{\\partial G}{\\partial t} + \\frac{1}{2} \\frac{\\partial^2 G}{\\partial x^2}b^2)~dt + \\frac{\\partial G}{\\partial x}b~dz\\]","title":"12.6 \u4f0a\u85e4\u5f15\u7406"},{"location":"trading/option/Ito/#_5","text":"\u6839\u636e\u591a\u5143\u6cf0\u52d2\u5c55\u5f00\u516c\u5f0f\uff0c\u5bf9 \\(G(x,t)\\) \u4f5c\u4e8c\u9636\u5c55\u5f00\uff0c\u5f97\uff1a \\[\\Delta G = \\frac{\\partial G}{\\partial x}\\Delta x + \\frac{\\partial G}{\\partial t}\\Delta t + \\frac{1}{2!}(\\frac{\\partial^2 G}{\\partial x^2}\\Delta x^2 + 2\\frac{\\partial^2 G}{\\partial x \\partial t}\\Delta x \\Delta t + \\frac{\\partial^2 G}{\\partial x^2}\\Delta t^2)\\] \u7531\u4e8e \\(\\Delta x\\) \u4e5f\u662f \\(\\Delta t\\) \u7684\u51fd\u6570\uff1a \\[\\Delta x = a(x,t)~\\Delta t + b(x,t) \\epsilon \\sqrt{\\Delta t}\\] \u5ffd\u7565 \\(\\Delta t\\) \u7684\u9ad8\u9636\u65e0\u7a77\u5c0f \\(o(\\Delta t)\\) \uff0c\u53ef\u5f97\uff1a \\[\\Delta x^2 = b^2(x,t) \\epsilon^2 \\Delta t \\] \u7531\u4e8e \\(\\epsilon\\) \u670d\u4ece \\(N(0,1)\\) \uff0c\u53ef\u77e5 \\(\\epsilon^2\\) \u670d\u4ece \\(\\chi^2_1\\) \uff0c\u5176\u4e2d \\(\\chi^2_n\\) \u662f\u5361\u65b9\u5206\u5e03\uff0c\u6ee1\u8db3 \\(E(\\chi^2_n) = n\\) \uff0c \\(D(\\chi^2_n) = 2n\\) \u3002 \u56e0\u6b64\uff0c\u5bf9\u4e8e \\(\\epsilon^2 \\Delta t\\) \uff0c\u5b83\u7684\u671f\u671b\u503c\u662f \\(\\Delta t\\) \uff0c\u65b9\u5dee\u662f \\(2\\Delta t^2\\) \u3002 \u5c31\u6574\u4e2a \\(\\Delta G\\) \u6765\u770b\uff1a \\[\\Delta G = \\frac{\\partial G}{\\partial x}\\Delta x + \\frac{\\partial G}{\\partial t}\\Delta t + \\frac{1}{2}\\frac{\\partial^2 G}{\\partial x^2}\\Delta x^2\\] \u7531\u4e8e \\(\\Delta x\\) \u90e8\u5206\u8fd8\u6709\u65b9\u5dee\u4e3a \\(\\Delta t\\) \u6270\u52a8\uff0c\u56e0\u6b64\u65b9\u5dee\u4e3a \\(\\Delta t^2\\) \u7684\u6270\u52a8\u4ece\u6570\u91cf\u7ea7\u4e0a\u5c31\u53ef\u4ee5\u5ffd\u7565\u3002\u6211\u4eec\u56e0\u6b64\u53ef\u4ee5\u76f4\u63a5\u628a \\(\\epsilon^2\\) \u8fd1\u4f3c\u4e3a\u5e38\u6570\uff0c\u4e5f\u5c31\u662f\u5b83\u7684\u671f\u671b\u503c 1\u3002\u5f97\u5230\uff1a \\[\\Delta G = \\frac{ \\partial G}{ \\partial x}(a\\Delta t + b \\epsilon \\sqrt{\\Delta t}) + \\frac{\\partial G}{\\partial t}\\Delta t + \\frac{1}{2}\\frac{\\partial^2 G}{\\partial x^2}b^2\\Delta t\\] \\[\\Delta G = (\\frac{\\partial G}{\\partial x}a + \\frac{\\partial G}{\\partial t} + \\frac{1}{2}\\frac{\\partial^2 G}{\\partial x^2}b^2)\\Delta t + \\frac{\\partial G}{\\partial x} b \\epsilon \\sqrt{\\Delta t}\\] \u4e5f\u5199\u4f5c\uff1a \\[ dG = (\\frac{\\partial G}{\\partial x}a + \\frac{\\partial G}{\\partial t} + \\frac{1}{2}\\frac{\\partial^2 G}{\\partial x^2}b^2)~dt + \\frac{\\partial G}{\\partial x} b~dz \\]","title":"\u8bc1\u660e"},{"location":"trading/option/Ito/#_6","text":"\u5bf9\u4e8e\u8fdc\u671f\u5408\u7ea6\uff0c\u5047\u8bbe\u5230\u671f\u65f6\u95f4\u4e3a \\(T\\) \uff0c\u65e0\u98ce\u9669\u5229\u7387\u4e3a \\(r\\) \uff0c\u5f53\u524d\u65f6\u95f4\u4e3a \\(t\\) \uff0c\u5f53\u524d\u73b0\u8d27\u4ef7\u683c\u4e3a \\(S\\) \uff0c\u5219\u8fdc\u671f\u5408\u7ea6\u7684\u6267\u884c\u4ef7\u683c\u5e94\u8be5\u4e3a \\(S\\) \u548c \\(t\\) \u7684\u51fd\u6570\uff08\u5426\u5219\u5b58\u5728\u5957\u5229\u673a\u4f1a\uff09\uff1a \\[F = Se^{r(T-t)}\\] \u5982\u6211\u4eec\u5728 12.3 \u4ecb\u7ecd\u7684\uff0c\u5047\u8bbe \\(S\\) \u6ee1\u8db3\u4f0a\u85e4\u8fc7\u7a0b\uff1a \\[dS = \\mu S dt + \\sigma S dz \\] \u5176\u4e2d\u671f\u671b\u6536\u76ca\u4e3a \\(\\mu\\) \uff0c\u6ce2\u52a8\u7387\u4e3a \\(\\sigma\\) \u3002\u5219 \\(F\\) \u7684\u4ef7\u683c\u53d8\u5316\u8fc7\u7a0b\u53ef\u4ee5\u5229\u7528\u4f0a\u85e4\u5f15\u7406\u786e\u5b9a\u3002 \\(\\frac{ \\partial F}{\\partial S} = e^{r(T-t)}\\) \uff0c \\(\\frac{\\partial^2 F}{\\partial S^2} = 0\\) \uff0c \\(\\frac{\\partial F}{\\partial t} = -r S e^{r(T-t)}\\) \uff0c\u5e26\u5165\u4f0a\u85e4\u5f15\u7406\u6709\uff1a \\[dF = (a - r S) e^{r(T-t)}~dt + e^{r(T-t)}b~dz \\] \u800c\uff0c \\(a\\) \u4e3a\u671f\u671b\u6536\u76ca \\(\\mu S\\) \uff0c \\(b\\) \u4e3a\u6ce2\u52a8\u7387 \\(\\sigma S\\) \uff0c\u5e26\u5165\u6709\uff1a \\[dF = (\\mu - r ) F~dt + \\sigma F~dz\\]","title":"\u5e94\u7528\uff1a\u8fdc\u671f\u5408\u7ea6"},{"location":"trading/option/Ito/#1","text":"\u5047\u8bbe \\(G(S, t)\\) \u662f\u5173\u4e8e\u80a1\u7968\u4ef7\u683c \\(S\\) \u548c\u65f6\u95f4 \\(t\\) \u7684\u51fd\u6570\uff0c \\(\\sigma_S\\) \u53ca \\(\\sigma_G\\) \u5206\u522b\u4e3a \\(S\\) \u548c \\(G\\) \u7684\u6ce2\u52a8\u7387\uff0c\u8bc1\u660e\u5f53 \\(S\\) \u7684\u671f\u671b\u56de\u62a5\u4e0a\u5347 \\(\\lambda \\sigma_S\\) \u65f6\uff0c \\(G\\) \u7684\u671f\u671b\u56de\u62a5\u4e0a\u5347 \\(\\lambda \\sigma_G\\) \uff0c\u5176\u4e2d \\(\\lambda\\) \u662f\u5e38\u6570\u3002 \u5047\u8bbe \\(S\\) \u7b26\u5408\u4f0a\u85e4\u8fc7\u7a0b\uff1a \\[ dS = a~dt + b~dz\\] \u7531\u4f0a\u85e4\u5f15\u7406\u53ef\u77e5\uff1a \\[ dG = (\\frac{\\partial G}{\\partial x}a + \\frac{\\partial G}{\\partial t} + \\frac{1}{2}\\frac{\\partial^2 G}{\\partial x^2}b^2)~dt + \\frac{\\partial G}{\\partial x} b~dz \\] \u56e0\u6b64\uff0c\u6ce2\u52a8\u7387\u6709\u5982\u4e0b\u5173\u7cfb\uff1a \\[ \\sigma_G = \\frac{ \\partial G }{ \\partial x } \\sigma_S \\] \u82e5 \\(S\\) \u7684\u671f\u671b\u6536\u76ca \\(a\\) \u4e0a\u5347\u4e86 \\(\\lambda \\sigma_S\\) \uff0c\u5219\u663e\u7136\u6709 \\(G\\) \u7684\u671f\u671b\u6536\u76ca\u4e0a\u5347\u4e86 \\(\\frac{ \\partial G }{\\partial x } \\lambda \\sigma_S = \\lambda \\sigma_G\\) \u3002","title":"\u4f8b1"},{"location":"trading/option/Ito/#2","text":"\u5047\u8bbe\u80a1\u7968\u4ef7\u683c \\(S\\) \u670d\u4ece\u51e0\u4f55\u5e03\u6717\u8fd0\u52a8\uff1a \\(dS = \\mu S~dt + \\sigma S~dz\\) \u5176\u4e2d\u671f\u671b\u56de\u62a5\u7387\u662f \\(\\mu\\) \uff0c\u6ce2\u52a8\u7387\u662f \\(\\sigma\\) \u3002\u8bc1\u660e \\(S^n\\) \u4e5f\u670d\u4ece\u51e0\u4f55\u5e03\u6717\u8fd0\u52a8\u3002 \u540c\u6837\u662f\u4f0a\u85e4\u5f15\u7406\u7684\u5e94\u7528\u3002\u4ee4 \\(G(S,t) = S^n\\) \u3002\u5219\u6709\uff1a \\[dG = (\\frac{\\partial G}{\\partial S} a + \\frac{\\partial G}{\\partial t} + \\frac{1}{2}\\frac{\\partial^2 G}{\\partial S^2}b^2)~dt + \\frac{\\partial G}{\\partial S} b~dz\\] \u5e26\u5165 \\(a = \\mu S\\) \uff0c \\(b = \\sigma S\\) \u53ef\u5f97\uff1a \\[dG = (n\\mu + \\frac{ 1}{ 2} n(n-1)\\sigma^2) G~dt + n \\sigma G~dz\\] \u56e0\u6b64 \\(S^n\\) \u4e0e \\(S\\) \u5177\u6709\u540c\u6837\u7684\u5f62\u5f0f\uff0c\u4e5f\u6ee1\u8db3\u51e0\u4f55\u5e03\u6717\u8fd0\u52a8\u3002\u5176\u671f\u671b\u7684\u6536\u76ca\u7387\u4e3a \\(n\\mu + \\frac{1}{2} n(n-1)\\sigma^2\\) \uff0c\u6ce2\u52a8\u7387\u4e3a \\(n \\sigma\\) \u3002","title":"\u4f8b2"},{"location":"trading/option/Risk/","text":"Option Volatility and Pricing - Risks \"Option Volatility and Pricing\", Sheldon Natenberg. This book helps readers to understand option from a trader's perspective. Other relevant reading materials: Option, Future and other Derivatives (John Hull) Best book to start with Stochastic Volatility Modeling (Lorenzo Bergomi) Advanced book if you are a developer or quant. Risk related Chapters: Chapter 7: Risk Measurement I Chapter 9: Risk Measurement II Chapter 10: Introduction to Spreading Chapter 13: Risk Consideration Chapter 7: Risk Measurement I 7.1 Difference between Gamma and Vega Gamma is a measurement of magnitude risk . Options have positive gamma. A negative gamma position is a good indication that a trader either wants the underlying market to sit still or move only very slowly. A positive gamma position indicates a desire for very large and swift moves in the underlying market. This seems to correspond to volatility. If we have a negative gamma, we want the market to remain relatively quiet. Isn't this the same as saying we want lower volatility? The gamma is a measure of whether we want higher or lower realized volatility (whether we want the underlying contract to be more volatile or less volatile). The vega is a measure of whether we want higher or lower implied volatility . Although the volatility of the underlying contract and changes in implied volatility are often correlated, this is not always the case. As the volatility of the underlying contract (realized volatility) changes, option demand rises and falls, and this demand is reflected in a corresponding rise or fall in the implied volatility. Chapter 9: Risk Measurement II 9.1 Implied delta many traders use the implied delta, the delta that results from using the implied volatility. Because the delta depends on the volatility, but volatility is an unknown factor, calculation of the delta can pose a major problem for a trader, especially for a large option position. 9.2 Theta the rate of decay slows for in-the-money and out-of-the-money options, whereas it accelerates for an at-the-money option This is because both OTM and ITM options have very little time value. 9.3 Vega Because vega is not a Greek letter, a common alternative in academic literature, where Greek letters are preferred, is kappa ( \\(\\kappa\\) ). The option price as volatility change is quite similar to theta one. In many situations, time and volatility will have a similar effect on options. More time, like higher volatility, increases the likelihood of large price changes. Less time, like lower volatility, reduces the likelihood of large price changes. vega of an at-the-money option is relatively constant with respect to changes in volatility. (the vega of an at-the-money option declines very slightly as we raise volatility. ) \\[\\nu = \\frac{ \\partial c}{ \\partial \\sigma} = \\frac{ \\partial p}{ \\partial \\sigma} = S_0 \\sqrt{T} \\Phi'(d_1)\\] where: \\[d_1 = \\frac{\\ln(S/K) + (r + 0.5\\sigma^2)T}{\\sigma \\sqrt{T}}\\] If the option is ATM, we have \\(S = K\\) , and if the interest rate is negligible (r = 0), we have: \\[d_1 = 0.5 \\sigma \\sqrt{T}\\] The sensitivity of vega to a change in volatility (volga): \\[\\begin{align} \\frac{ \\partial^2 c}{ \\partial \\sigma^2} = \\frac{ \\partial^2 p}{ \\partial \\sigma^2} &= S_0 \\sqrt{T} \\Phi''(d_1) \\frac{\\partial d_1}{\\partial \\sigma} \\\\ &= -\\frac{1}{4\\sqrt{2 \\pi}} e^{- \\frac{\\sigma^2 T}{8}} S_0 \\sigma T^{\\frac{3}{2}} \\end{align}\\] So it is negative, which means it is true that \"the vega of an at-the-money option declines as we raise volatility\". As for the magnitude of change, the book says it is \"very slight\", let's verify it with formula (if ATM): \\[\\frac{\\text{volga}}{\\text{vega}} = \\frac{d_1 d_2}{\\sigma} = - \\frac{1}{4} \\sigma T\\] It seems negligible if the time to expire is small enough. let's verify with an ATM option with: stock price \\(S=100\\) expire in one month \\(T=1/12\\) anual volatility \\(\\sigma = 25\\%\\) Its vega is 11.51, usually we use 1% change in volatility so it becomes 0.1151, which means +1% volatility change will +0.1151 to ATM option price. Its volga is 0.06, compared to 11.51 this is negligible. 9.4 Gamma \\[\\Gamma = \\frac{ \\partial \\Delta }{ \\partial S } = \\Phi'(d_1) \\frac{\\partial d_1}{\\partial S} = \\frac{\\Phi'(d_1)}{\\sigma S_0 \\sqrt{T}}\\] Gamma, Theta and Vega are greatest when an option is at the money. With less time to expiration or lower volatility, OTM and ITM options' time value will be lower because they will be less likely that a large price change will happen. Gamma will also be lower, the graph becomes \"thin\". More time to expiration, like higher volatility, will make OTM and ITM options behave like ATM ones. The graph becomes \"fat\". Chapter 10: Introduction to Spreading Scalping tries to make a market and make profit from liquidity. By observing the activity in a particular market, a scalper would try to determine an equilibrium price that reflected a balance between buyers and sellers. The scalper would then quote a bid-ask spread around this equilibrium price, attempting to buy at the bid price and sell at the offer price as often as possible without taking either a long or short position for any extended period of time. However, option markets are rarely sufficient liquid to support this type of trading. Most successful option traders are spread traders. A spread is a strategy that involves taking opposing positions in different but related instruments. When market condition changes, two legs of spread will gain and lose value respectively. Many common spreading strategies are based on arbitrage relationships. cash-and-carry strategy Given the current cash price, interest rate, and storage and insurance costs, a commodity trader can calculate the value of a forward contract. If the actual market price of the forward contract is higher than the calculated value, the trader will create a spread by purchasing the commodity, selling the overpriced forward contract, and carrying the position to maturity. Another type of spreading strategy involves buying and selling futures contracts of different maturities on the same underlying commodity. It is similar to the cash-and-carry strategy. Besides, we can also do this in different markets (intramarket spread v.s. intermarket spread). cash-and-carry strategy cancels the the directional risk, the trader does not need to tell which contract is mispriced, he only need to know if the spread is profitable. Note that the spread is not NECESSARILY a contract. We can't guarantee the entire spread will be executed at one time. Trade has to choose the best time to execute each leg. In this procedure, the portfolio is at risk. Most traders learn that it is usually best to execute the more difficult leg first . 10.1 Option Spreads Spreading strategies are widely employed in option markets, because: A trader might perceive a relative mispricing between contracts . Though it may not be possible to determine the exact value of either contract, the trade might be able to estimate the relative value of contracts. In option markets, the mispricing is often expressed in terms of volatility instead of price value A trader may want to construct a position that reflects a particular view of market conditions . e.g., long gamma but not not expose to directional risk. Spreading strategies help to control risk . spreading maintains profit potential but reduces short-term risk Chapter 13: Risk Considerations In option trading, assuming the theoretical price is correct, the immediate reward of a trade is the captured edge. Because there is no guarantee that our theoretical price will be right, the risk associated with the trade is also introduced. The risk is from multiple dimension: Delta risk (usually hedged) Gamma risk Theta risk (opposite side of Gamma risk) Vega risk Rho risk (usually ignored) So basically, in option trading, we only need to worry about two things: realized volatility (underlying price) change: gamma risk implied volatility change: vega risk In fact, they are both volatility risk . 13.1 Volatility risk For an option trader, volatility risk comes in two forms\u2014the risk that he has incorrectly estimated the realized volatility of the underlying contract over the life of a strategy and the risk that implied volatility in the option market will change. As we mentioned before, Gamma is related to realized volatility, and Vega is related to implied volatility. Any spread that has a nonzero gamma or vega has volatility risk. Steps to analysis risk for multiple kinds of spreads: calculate theoretical edge align theoretical edge (size up for spread with smaller edge) compare risks when underlying price move 13.1.1 Example Suppose that we find the implied volatility is higher than our theoretical value (18%). If we believe in our model, we conclude that they options are overpriced . To make a profit, trade chooses to short vega . There are multiple spreads to consider (excluding calendar spreads): Short straddles and strangles ( \\/ or \\_/ ) Call or put ratio spreads, sell more than buy ( __/-- or --\\__ ) Long butterflies ( --\\/-- ) Below is the greeks for each spread: Theoretical PnL of each spread when underlying price moves: Because we are shorting Gamma, large underlying price move will hurt our position . But different spreads have different exposure to the risk. Theoretical PnL of each spread when implied volatility moves: Because we are shorting Vega, increasing of volatility will also hurt the position . When deciding which spread to trade, we can analysis from 2 aspects. Risk . Considering only the gamma and vega risk, Spread 3 probably has the best risk characteristics. It has limited risk if there is a large move in either direction and performs better than either Spread 1 or Spread 2 if there is a dramatic change in volatility. But if there's only small move , Spread 2 outperforms Spread 1 and 3. Liquidity . Spread 3 requires a lot of quantity on the 3 options. It might be not possible to execute. If we can only choose from Spread 1 and 2, Spread 2 is the clear winner. straddles and strangles are the riskiest of all spreads This can be easily seen from their payoff graphs. 13.2 Dividends and Interest Risk For stock options, there are two additional risks: the risk of changing interest rates and the risk of changing dividends The interest-rate and dividend risk associated with volatility spreads is usually small compared with the volatility (gamma and vega) risk. Nonetheless, a trader ought to be aware of these risks, especially when a position is large and there is significant risk of a change in either interest rates or dividends. A good spread is not necessarily the one that shows the greatest profit when things go well; it may be the one that shows the least loss when things go badly. 13.3 Efficiency One method that traders sometimes use to compare the relative riskiness of potential strategies focuses on the risk-reward ratio, or efficiency , of the strategies For example, a trader is considering two possible spreads, both with a positive gamma and negative theta. The reward coms from the Gamma and the risk is mainly from Theta. Of course the trader want the reward (Gamma) to be as large as possible compared to the risk (Theta). The efficiency is a ratio of the absolute value: \\[\\text{efficiency} = |\\frac{\\text{Gamma}}{\\text{Theta}}|\\] We can calculate the efficiency for above 3 spreads: Gamma Theta Efficiency Spread 1 -406.0 +0.4235 958.68 Spread 2 -165.5 +0.1365 1208.79 Spread 3 -370.0 +0.4000 925.00 Because we are shorting Gamma, the reward is from Theta. So the smaller efficient is, the better. As a result, from a fast comparison, we find Spread3 is the best in risk term, which is consistent with our previous analysis of each spread. (Why the spread 2 is the worst? The book does not explain...) In cases that the Gamma and Theta are the primary risks to the position , Assuming that all strategies have approximately the same theoretical edge , the efficiency can be a reasonable method of quickly comparing strategies where all options expire at the same time . 13.4 Delta Adjustments Trader needs to adjust the position to remain delta-neutral. An adjustment to a trader\u2019s delta position may reduce his directional risk, but if he simultaneously increases his gamma, theta, or vega risk, he may inadvertently be exchanging one type of risk for another. Again, use above case as example. - underlying price goes down - since we are shorting Gamma, we will get positive delta - to hedge the delta position, we can: - sell underlying contracts. It does not affect other Greek Risks. - sell calls. This will help capturing more theoretical edge , but also accumulate more Greek Risks . And the trader will have to adjust position more frequently. Besides, If the market now makes a violent move in either direction, the adverse consequences will be greatly magnified. - buy puts. Trader can also reduce the Greek Risks . But, because we think the implied volatility is overpriced, when buying puts, the trader is actually doing trade with negative theoretical edge .","title":"Option Volatility and Pricing - Risks"},{"location":"trading/option/Risk/#option-volatility-and-pricing-risks","text":"\"Option Volatility and Pricing\", Sheldon Natenberg. This book helps readers to understand option from a trader's perspective. Other relevant reading materials: Option, Future and other Derivatives (John Hull) Best book to start with Stochastic Volatility Modeling (Lorenzo Bergomi) Advanced book if you are a developer or quant. Risk related Chapters: Chapter 7: Risk Measurement I Chapter 9: Risk Measurement II Chapter 10: Introduction to Spreading Chapter 13: Risk Consideration","title":"Option Volatility and Pricing - Risks"},{"location":"trading/option/Risk/#chapter-7-risk-measurement-i","text":"","title":"Chapter 7: Risk Measurement I"},{"location":"trading/option/Risk/#71-difference-between-gamma-and-vega","text":"Gamma is a measurement of magnitude risk . Options have positive gamma. A negative gamma position is a good indication that a trader either wants the underlying market to sit still or move only very slowly. A positive gamma position indicates a desire for very large and swift moves in the underlying market. This seems to correspond to volatility. If we have a negative gamma, we want the market to remain relatively quiet. Isn't this the same as saying we want lower volatility? The gamma is a measure of whether we want higher or lower realized volatility (whether we want the underlying contract to be more volatile or less volatile). The vega is a measure of whether we want higher or lower implied volatility . Although the volatility of the underlying contract and changes in implied volatility are often correlated, this is not always the case. As the volatility of the underlying contract (realized volatility) changes, option demand rises and falls, and this demand is reflected in a corresponding rise or fall in the implied volatility.","title":"7.1 Difference between Gamma and Vega"},{"location":"trading/option/Risk/#chapter-9-risk-measurement-ii","text":"","title":"Chapter 9: Risk Measurement II"},{"location":"trading/option/Risk/#91-implied-delta","text":"many traders use the implied delta, the delta that results from using the implied volatility. Because the delta depends on the volatility, but volatility is an unknown factor, calculation of the delta can pose a major problem for a trader, especially for a large option position.","title":"9.1 Implied delta"},{"location":"trading/option/Risk/#92-theta","text":"the rate of decay slows for in-the-money and out-of-the-money options, whereas it accelerates for an at-the-money option This is because both OTM and ITM options have very little time value.","title":"9.2 Theta"},{"location":"trading/option/Risk/#93-vega","text":"Because vega is not a Greek letter, a common alternative in academic literature, where Greek letters are preferred, is kappa ( \\(\\kappa\\) ). The option price as volatility change is quite similar to theta one. In many situations, time and volatility will have a similar effect on options. More time, like higher volatility, increases the likelihood of large price changes. Less time, like lower volatility, reduces the likelihood of large price changes. vega of an at-the-money option is relatively constant with respect to changes in volatility. (the vega of an at-the-money option declines very slightly as we raise volatility. ) \\[\\nu = \\frac{ \\partial c}{ \\partial \\sigma} = \\frac{ \\partial p}{ \\partial \\sigma} = S_0 \\sqrt{T} \\Phi'(d_1)\\] where: \\[d_1 = \\frac{\\ln(S/K) + (r + 0.5\\sigma^2)T}{\\sigma \\sqrt{T}}\\] If the option is ATM, we have \\(S = K\\) , and if the interest rate is negligible (r = 0), we have: \\[d_1 = 0.5 \\sigma \\sqrt{T}\\] The sensitivity of vega to a change in volatility (volga): \\[\\begin{align} \\frac{ \\partial^2 c}{ \\partial \\sigma^2} = \\frac{ \\partial^2 p}{ \\partial \\sigma^2} &= S_0 \\sqrt{T} \\Phi''(d_1) \\frac{\\partial d_1}{\\partial \\sigma} \\\\ &= -\\frac{1}{4\\sqrt{2 \\pi}} e^{- \\frac{\\sigma^2 T}{8}} S_0 \\sigma T^{\\frac{3}{2}} \\end{align}\\] So it is negative, which means it is true that \"the vega of an at-the-money option declines as we raise volatility\". As for the magnitude of change, the book says it is \"very slight\", let's verify it with formula (if ATM): \\[\\frac{\\text{volga}}{\\text{vega}} = \\frac{d_1 d_2}{\\sigma} = - \\frac{1}{4} \\sigma T\\] It seems negligible if the time to expire is small enough. let's verify with an ATM option with: stock price \\(S=100\\) expire in one month \\(T=1/12\\) anual volatility \\(\\sigma = 25\\%\\) Its vega is 11.51, usually we use 1% change in volatility so it becomes 0.1151, which means +1% volatility change will +0.1151 to ATM option price. Its volga is 0.06, compared to 11.51 this is negligible.","title":"9.3 Vega"},{"location":"trading/option/Risk/#94-gamma","text":"\\[\\Gamma = \\frac{ \\partial \\Delta }{ \\partial S } = \\Phi'(d_1) \\frac{\\partial d_1}{\\partial S} = \\frac{\\Phi'(d_1)}{\\sigma S_0 \\sqrt{T}}\\] Gamma, Theta and Vega are greatest when an option is at the money. With less time to expiration or lower volatility, OTM and ITM options' time value will be lower because they will be less likely that a large price change will happen. Gamma will also be lower, the graph becomes \"thin\". More time to expiration, like higher volatility, will make OTM and ITM options behave like ATM ones. The graph becomes \"fat\".","title":"9.4 Gamma"},{"location":"trading/option/Risk/#chapter-10-introduction-to-spreading","text":"Scalping tries to make a market and make profit from liquidity. By observing the activity in a particular market, a scalper would try to determine an equilibrium price that reflected a balance between buyers and sellers. The scalper would then quote a bid-ask spread around this equilibrium price, attempting to buy at the bid price and sell at the offer price as often as possible without taking either a long or short position for any extended period of time. However, option markets are rarely sufficient liquid to support this type of trading. Most successful option traders are spread traders. A spread is a strategy that involves taking opposing positions in different but related instruments. When market condition changes, two legs of spread will gain and lose value respectively. Many common spreading strategies are based on arbitrage relationships. cash-and-carry strategy Given the current cash price, interest rate, and storage and insurance costs, a commodity trader can calculate the value of a forward contract. If the actual market price of the forward contract is higher than the calculated value, the trader will create a spread by purchasing the commodity, selling the overpriced forward contract, and carrying the position to maturity. Another type of spreading strategy involves buying and selling futures contracts of different maturities on the same underlying commodity. It is similar to the cash-and-carry strategy. Besides, we can also do this in different markets (intramarket spread v.s. intermarket spread). cash-and-carry strategy cancels the the directional risk, the trader does not need to tell which contract is mispriced, he only need to know if the spread is profitable. Note that the spread is not NECESSARILY a contract. We can't guarantee the entire spread will be executed at one time. Trade has to choose the best time to execute each leg. In this procedure, the portfolio is at risk. Most traders learn that it is usually best to execute the more difficult leg first .","title":"Chapter 10: Introduction to Spreading"},{"location":"trading/option/Risk/#101-option-spreads","text":"Spreading strategies are widely employed in option markets, because: A trader might perceive a relative mispricing between contracts . Though it may not be possible to determine the exact value of either contract, the trade might be able to estimate the relative value of contracts. In option markets, the mispricing is often expressed in terms of volatility instead of price value A trader may want to construct a position that reflects a particular view of market conditions . e.g., long gamma but not not expose to directional risk. Spreading strategies help to control risk . spreading maintains profit potential but reduces short-term risk","title":"10.1 Option Spreads"},{"location":"trading/option/Risk/#chapter-13-risk-considerations","text":"In option trading, assuming the theoretical price is correct, the immediate reward of a trade is the captured edge. Because there is no guarantee that our theoretical price will be right, the risk associated with the trade is also introduced. The risk is from multiple dimension: Delta risk (usually hedged) Gamma risk Theta risk (opposite side of Gamma risk) Vega risk Rho risk (usually ignored) So basically, in option trading, we only need to worry about two things: realized volatility (underlying price) change: gamma risk implied volatility change: vega risk In fact, they are both volatility risk .","title":"Chapter 13: Risk Considerations"},{"location":"trading/option/Risk/#131-volatility-risk","text":"For an option trader, volatility risk comes in two forms\u2014the risk that he has incorrectly estimated the realized volatility of the underlying contract over the life of a strategy and the risk that implied volatility in the option market will change. As we mentioned before, Gamma is related to realized volatility, and Vega is related to implied volatility. Any spread that has a nonzero gamma or vega has volatility risk. Steps to analysis risk for multiple kinds of spreads: calculate theoretical edge align theoretical edge (size up for spread with smaller edge) compare risks when underlying price move","title":"13.1 Volatility risk"},{"location":"trading/option/Risk/#1311-example","text":"Suppose that we find the implied volatility is higher than our theoretical value (18%). If we believe in our model, we conclude that they options are overpriced . To make a profit, trade chooses to short vega . There are multiple spreads to consider (excluding calendar spreads): Short straddles and strangles ( \\/ or \\_/ ) Call or put ratio spreads, sell more than buy ( __/-- or --\\__ ) Long butterflies ( --\\/-- ) Below is the greeks for each spread: Theoretical PnL of each spread when underlying price moves: Because we are shorting Gamma, large underlying price move will hurt our position . But different spreads have different exposure to the risk. Theoretical PnL of each spread when implied volatility moves: Because we are shorting Vega, increasing of volatility will also hurt the position . When deciding which spread to trade, we can analysis from 2 aspects. Risk . Considering only the gamma and vega risk, Spread 3 probably has the best risk characteristics. It has limited risk if there is a large move in either direction and performs better than either Spread 1 or Spread 2 if there is a dramatic change in volatility. But if there's only small move , Spread 2 outperforms Spread 1 and 3. Liquidity . Spread 3 requires a lot of quantity on the 3 options. It might be not possible to execute. If we can only choose from Spread 1 and 2, Spread 2 is the clear winner. straddles and strangles are the riskiest of all spreads This can be easily seen from their payoff graphs.","title":"13.1.1 Example"},{"location":"trading/option/Risk/#132-dividends-and-interest-risk","text":"For stock options, there are two additional risks: the risk of changing interest rates and the risk of changing dividends The interest-rate and dividend risk associated with volatility spreads is usually small compared with the volatility (gamma and vega) risk. Nonetheless, a trader ought to be aware of these risks, especially when a position is large and there is significant risk of a change in either interest rates or dividends. A good spread is not necessarily the one that shows the greatest profit when things go well; it may be the one that shows the least loss when things go badly.","title":"13.2 Dividends and Interest Risk"},{"location":"trading/option/Risk/#133-efficiency","text":"One method that traders sometimes use to compare the relative riskiness of potential strategies focuses on the risk-reward ratio, or efficiency , of the strategies For example, a trader is considering two possible spreads, both with a positive gamma and negative theta. The reward coms from the Gamma and the risk is mainly from Theta. Of course the trader want the reward (Gamma) to be as large as possible compared to the risk (Theta). The efficiency is a ratio of the absolute value: \\[\\text{efficiency} = |\\frac{\\text{Gamma}}{\\text{Theta}}|\\] We can calculate the efficiency for above 3 spreads: Gamma Theta Efficiency Spread 1 -406.0 +0.4235 958.68 Spread 2 -165.5 +0.1365 1208.79 Spread 3 -370.0 +0.4000 925.00 Because we are shorting Gamma, the reward is from Theta. So the smaller efficient is, the better. As a result, from a fast comparison, we find Spread3 is the best in risk term, which is consistent with our previous analysis of each spread. (Why the spread 2 is the worst? The book does not explain...) In cases that the Gamma and Theta are the primary risks to the position , Assuming that all strategies have approximately the same theoretical edge , the efficiency can be a reasonable method of quickly comparing strategies where all options expire at the same time .","title":"13.3 Efficiency"},{"location":"trading/option/Risk/#134-delta-adjustments","text":"Trader needs to adjust the position to remain delta-neutral. An adjustment to a trader\u2019s delta position may reduce his directional risk, but if he simultaneously increases his gamma, theta, or vega risk, he may inadvertently be exchanging one type of risk for another. Again, use above case as example. - underlying price goes down - since we are shorting Gamma, we will get positive delta - to hedge the delta position, we can: - sell underlying contracts. It does not affect other Greek Risks. - sell calls. This will help capturing more theoretical edge , but also accumulate more Greek Risks . And the trader will have to adjust position more frequently. Besides, If the market now makes a violent move in either direction, the adverse consequences will be greatly magnified. - buy puts. Trader can also reduce the Greek Risks . But, because we think the implied volatility is overpriced, when buying puts, the trader is actually doing trade with negative theoretical edge .","title":"13.4 Delta Adjustments"},{"location":"trading/option/VolatilitySmile/","text":"Volatility Smile \u9690\u542b\u6ce2\u52a8\u7387\u4e0e\u671f\u6743\u6267\u884c\u4ef7\u683c\u7684\u51fd\u6570\u88ab\u79f0\u4e3a\u6ce2\u52a8\u7387\u5fae\u7b11(volatility smile)\u3002\u6240\u8c13\u9690\u542b\u6ce2\u52a8\u7387\uff0c\u662f\u6307\u9690\u542b\u5728\u671f\u6743 \u5e02\u573a\u4ef7\u683c \u4e2d\u7684\u6ce2\u52a8\u7387\uff0c\u800c\u975e\u6211\u4eec\u901a\u8fc7\u7edf\u8ba1\u65b9\u6cd5\u5f97\u51fa\u7684\u201c\u6ce2\u52a8\u7387\u201d\u3002 \u5728 B-S-M \u6a21\u578b\u4e2d\uff0c\u6211\u4eec\u5047\u8bbe\u6ce2\u52a8\u7387\u662f\u4e00\u4e2a\u5e38\u6570\uff0c\u5e76\u901a\u8fc7\u7edf\u8ba1\u65b9\u6cd5\u5229\u7528\u6807\u7684\u7269\u8d44\u4ea7\u7684\u5386\u53f2\u4ef7\u683c\u8ba1\u7b97\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u901a\u8fc7\u5e02\u573a\u4ef7\u683c\u5f97\u51fa\u7684\u9690\u542b\u6ce2\u52a8\u7387\u662f\u548c\u6211\u4eec\u6700\u521d\u7528\u7edf\u8ba1\u65b9\u6cd5\u7b97\u51fa\u7684\u76f8\u4f3c\u3002\u4f46\u662f\u5b9e\u9645\u4e0a\uff0c\u6211\u4eec\u53d1\u73b0\u8fd9\u4e24\u8005\u5e76\u4e0d\u4e00\u81f4\u3002 \u771f\u5b9e\u7684\u671f\u6743\u6ce2\u52a8\u7387\u5e76\u4e0d\u662f\u4e00\u4e2a\u5e38\u6570\uff0c\u800c\u662f\u4e00\u4e2a\u5173\u4e8e__\u5230\u671f\u65f6\u95f4__\u548c__\u6267\u884c\u4ef7\u683c__\u7684\u51fd\u6570\uff08\u5ffd\u7565\u968f\u673a\u56e0\u7d20\uff09\u3002 19.1 call \u548c put \u6709\u540c\u6837\u7684\u6ce2\u52a8\u7387\u5fae\u7b11 \u5f53\u6267\u884c\u4ef7\u683c\u548c\u5230\u671f\u65e5\u76f8\u540c\u65f6\uff0c\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u548c\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\u5177\u6709\u76f8\u540c\u7684\u9690\u542b\u6ce2\u52a8\u7387\u3002 \u56de\u5fc6\u4e00\u4e0b\u6211\u4eec\u4ee5\u524d\u5b66\u4e60\u7684 put-call parity \u516c\u5f0f\uff1a \\[p + S_0 e^{-qT} = c + K e^{-rT}\\] \u5176\u4e2d\uff0c \\(c\\) \u548c \\(p\\) \u5206\u522b\u4e3a\u6b27\u5f0f\u770b\u6da8\u548c\u770b\u8dcc\u671f\u6743\u7684\u4ef7\u683c\u3002\u4ed6\u4eec\u5177\u6709\u540c\u6837\u7684\u6267\u884c\u4ef7\u683c \\(K\\) \uff0c\u8ddd\u79bb\u5230\u671f\u65e5\u65f6\u95f4 \\(T\\) \u3002 \\(r\\) \u662f\u65e0\u98ce\u9669\u5229\u7387\uff0c \\(q\\) \u662f\u6807\u7684\u7269\u8d44\u4ea7\u7684\u6536\u76ca\uff08\u4f8b\u5982\u80a1\u606f\uff09\u3002 \\(S_0\\) \u662f\u6807\u7684\u7269\u8d44\u4ea7\u7684\u5373\u671f\u4ef7\u683c\u3002 put-call parity \u4ec5\u4ec5\u57fa\u4e8e\u65e0\u5957\u5229\u673a\u4f1a\u5047\u8bbe\u3002\u56e0\u6b64\u65e0\u8bba\u6807\u7684\u7269\u4ef7\u683c\u662f\u5426\u670d\u4ece\u5bf9\u6570\u6b63\u6001\u5206\u5e03\uff0c\u8fd9\u4e2a\u7ed3\u8bba\u90fd\u6210\u7acb\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u4f7f\u7528 B-S-M \u8ba1\u7b97\u51fa\u6765\u7684\u7406\u8bba\u4ef7\u683c\u6ee1\u8db3\uff1a \\[p_{\\mathrm{BS}} + S_0 e^{-qT} = c_{\\mathrm{BS}} + K e^{-rT}\\] \u540c\u65f6\uff0c\u5373\u4f7f\u4e0d\u7b26\u5408\u5bf9\u6570\u6b63\u6001\u5206\u5e03\uff0c\u671f\u6743\u7684\u5e02\u573a\u4ef7\u683c\u4e5f\u5e94\u8be5\u6ee1\u8db3\uff1a \\[p_{\\mathrm{mkt}} + S_0 e^{-qT} = c_{\\mathrm{mkt}} + K e^{-rT}\\] \u5047\u8bbe\u8fd9\u91cc\u7684\u770b\u6da8\u671f\u6743\u5e02\u573a\u4ef7\u683c \\(c_{\\mathrm{mkt}}\\) \u4ef7\u683c\u5df2\u77e5\uff0c\u4e14\u5df2\u7ecf\u901a\u8fc7 \\(c_{\\mathrm{mkt}}\\) \u5f97\u5230\u4e86\u5176\u9690\u542b\u6ce2\u52a8\u7387 \\(\\sigma_{\\mathrm{mkt}}\\) \u3002\u90a3\u4e48\uff0c\u5c06 \\(c_{\\mathrm{mkt}}\\) \u4ee3\u5165 put-call parity \u53ef\u4ee5\u8ba1\u7b97\u5f97\u51fa\u770b\u8dcc\u671f\u6743\u4ef7\u683c\uff1a \\[p_{\\mathrm{mkt}} = K e^{-rT}\\Phi(-d_2) - S_0 e^{-qT}\\Phi(-d_1) \\] \u8fd9\u4e0e\u5229\u7528 B-S-M \u6a21\u578b\u63a8\u5bfc\u7684\u770b\u8dcc\u671f\u6743\u8ba1\u7b97\u516c\u5f0f\u662f\u4e00\u81f4\u7684\u3002\u56e0\u6b64\uff0c\u5982\u679c\u6211\u4eec\u5229\u7528\u770b\u8dcc\u671f\u6743\u4ef7\u683c \\(p_{\\mathrm{mkt}}\\) \u6765\u518d\u6b21\u8ba1\u7b97\u9690\u542b\u6ce2\u52a8\u7387\uff0c\u7ed3\u679c\u4e5f\u662f \\(\\sigma_{\\mathrm{mkt}}\\) \u3002 \u53e6\u5916\uff0c\u901a\u8fc7 B-S-M \u8ba1\u7b97\u7684\u770b\u8dcc\u548c\u770b\u6da8\u671f\u6743\u4ef7\u683c \\(c_{\\mathrm{BS}}\\) \uff0c \\(p_{\\mathrm{BS}}\\) \u5728\u8ba1\u7b97\u4e2d\u90fd\u662f\u4f7f\u7528\u540c\u4e00\u4e2a\u6ce2\u52a8\u7387\uff0c\u56e0\u6b64\u5fc5\u7136\u76f8\u7b49\u3002\u5373\u65e0\u8bba\u662f\u7406\u8bba\u4ef7\u683c\u8fd8\u662f\u5e02\u573a\u4ef7\u683c\uff0c\u8be5\u7ed3\u8bba\u90fd\u6210\u7acb\u3002 \u6211\u4eec\u8fd8\u53ef\u4ee5\u5f97\u5230\uff1a \\[p_{\\mathrm{BS}} - p_{\\mathrm{mkt}} = c_{\\mathrm{BS}} - c_{\\mathrm{mkt}}\\] \u8be5\u5f0f\u8bf4\u660e\uff0cB-S-M \u6a21\u578b\u5b9a\u4ef7\u4e0e\u5b9e\u9645\u5e02\u573a\u4ef7\u683c\u7684__\u8bef\u5dee__\u5bf9\u4e8e call \u548cput \u5e94\u8be5\u662f\u4e00\u81f4\u7684\u3002 \u4f8b \u4e00\u4e2a\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u4e0e\u4e00\u4e2a\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\u5177\u6709\u540c\u6837\u7684\u6267\u884c\u4ef7\u683c\u4e0e\u671f\u9650\u3002\u770b\u6da8\u671f\u6743\u7684\u9690\u542b\u6ce2\u52a8\u7387\u4e3a 30%\uff0c\u770b\u8dcc\u671f\u6743\u7684\u9690\u542b\u6ce2\u52a8\u7387\u4e3a 25%\u3002\u5176\u4e2d\u5b58\u5728\u4ec0\u4e48\u6837\u7684\u5957\u5229\u673a\u4f1a\uff1f \u8fd9\u8bf4\u660e\u770b\u8dcc\u671f\u6743\u7684\u4ef7\u503c\u88ab\u5e02\u573a\u4f4e\u4f30\u4e86\uff08\u6216\u8005\u770b\u6da8\u671f\u6743\u7684\u4ef7\u503c\u88ab\u9ad8\u4f30\uff09\u3002\u6839\u636e put-call parity\uff0c\u53ef\u4ee5\u4e70\u5165\u770b\u8dcc\u671f\u6743\uff0c\u4e70\u5165\u80a1\u7968\uff0c\u5e76\u5356\u51fa\u770b\u6da8\u671f\u6743\u3002 19.2 \u5916\u6c47\u671f\u6743 \u4e00\u4e2a\u5178\u578b\u7684\u8d27\u5e01\u671f\u6743\u7684\u6ce2\u52a8\u7387\u5fae\u7b11\u5982\u4e0b\u56fe\uff1a \u53ef\u4ee5\u770b\u51fa\uff0c\u5728 ATM \u7684\u65f6\u5019\uff0c\u6ce2\u52a8\u7387\u6700\u4f4e\u3002\u968f\u7740\u6267\u884c\u4ef7\u683c\u4e0d\u540c\uff0c\u65e0\u8bba\u671d\u7740 ITM \u548c OTM \u53d8\u5316\uff0c\u6ce2\u52a8\u7387\u90fd\u6e10\u6e10\u589e\u5927\u3002 \u6211\u4eec\u53ef\u4ee5\u6839\u636e\u6ce2\u52a8\u7387\u5fae\u7b11\u63a8\u5bfc\u51fa\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u4e0b\u6807\u7684\u7269\u4ef7\u683c\u7684\u6982\u7387\u5206\u5e03\u3002 \u9996\u5148\u770b\u6da8\u671f\u6743\u7684\u4ef7\u683c\u53ef\u4ee5\u7531 payoff \u7684\u671f\u671b\u8d34\u73b0\u5f97\u51fa\uff1a \\[c = e^{-rT}\\int_{S_T = K}^{\\infty} (S_T - K)g(S_T)~dS_T\\] \u5176\u4e2d \\(g(S_T)\\) \u8868\u793a \\(T\\) \u65f6\u523b\u4ef7\u683c\u4e3a \\(S_T\\) \u7684\u6982\u7387\u3002\u5bf9 \\(K\\) \u6c42\u5bfc\u53ef\u5f97\uff1a \\[\\frac{\\partial c}{\\partial K} = -e^{-rT}\\int_{S_T = K}^{\\infty} g(S_T)~dS_T\\] \u518d\u5bf9 \\(K\\) \u6c42\u5bfc\u53ef\u4ee5\u5f97\u51fa\uff1a \\[\\frac{\\partial^2 c}{\\partial K^2} = e^{-rT} g(K)\\] \u4e8e\u662f\u53ef\u4ee5\u5f97\u51fa\uff1a \\[g(K) = e^{rT} \\frac{ \\partial^2 c}{ \\partial K^2}\\] \u5047\u8bbe\u6211\u4eec\u6709\u4e09\u4e2a\u671f\u6743\uff0c\u6267\u884c\u4ef7\u683c\u5206\u522b\u4e3a \\(K- \\delta\\) \uff0c \\(K\\) \uff0c \\(K+ \\delta\\) \uff0c \\(\\delta\\) \u662f\u4e00\u4e2a\u975e\u5e38\u5c0f\u7684\u6b63\u6570\u3002\u6211\u4eec\u53ef\u4ee5\u7528\u5dee\u5206\u8fd1\u4f3c\u5fae\u5206\uff0c\u5f97\u5230\uff1a \\[g(K) = e^{rT} \\frac{c_1 + c_3 - 2c_2} {\\delta^2}\\] \u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u9690\u542b\u6ce2\u52a8\u7387\u9996\u5148\u8ba1\u7b97\u51fa\u671f\u6743\u4ef7\u683c\uff0c\u518d\u8ba1\u7b97\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u4e0b\u6807\u7684\u7269\u4ef7\u683c\u7684\u6982\u7387 \\(g(K)\\) \u3002\u5176\u56fe\u50cf\u5982\u4e0b\u6240\u793a\uff1a \u6211\u4eec\u53ef\u4ee5\u770b\u51fa\uff0c\u5b9e\u9645\u7684\u66f2\u7ebf\u6bd4\u6211\u4eec\u5047\u8bbe\u7684\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u66f4\u201c\u5c16\u201d\uff0c\u56e0\u6b64\u5bf9\u4e8e deep OTM\uff08\u4f8b\u5982\u6267\u884c\u4ef7\u683c\u5927\u4e8e \\(K_2\\) \u7684call\uff0c\u4ee5\u53ca\u6267\u884c\u4ef7\u683c\u4f4e\u4e8e \\(K_1\\) \u7684put\uff09\uff0c\u5b9e\u9645\u4e0a B-S-M \u6a21\u578b\u4f4e\u4f30\u4e86\u4ed6\u4eec\u7684\u4ef7\u683c\u3002\u4e5f\u5c31\u662f\u4f4e\u4f30\u4e86\u4ed6\u4eec\u7684\u9690\u542b\u6ce2\u52a8\u7387\u3002 \u4ee5\u4e0a\u5206\u6790\u8868\u660e\uff0c\u6ce2\u52a8\u7387\u5fae\u7b11\u66f2\u7ebf\u548c\u5230\u671f\u65e5\u4ef7\u683c\u7684\u6982\u7387\u5206\u5e03\u66f2\u7ebf\u662f\u4e00\u81f4\u7684\u3002 \u4e1a\u754c\u6848\u4f8b \u60f3\u8c61\u4e00\u4e0b\uff0c\u5f53\u5927\u90e8\u5206\u5e02\u573a\u53c2\u4e0e\u8005\u90fd\u8ba4\u4e3a\u6c47\u7387\u670d\u4ece\u5bf9\u6570\u6b63\u6001\u5206\u5e03\uff0c\u800c\u4f7f\u7528\u540c\u4e00\u4e2a\u6ce2\u52a8\u7387\u5bf9\u67d0\u4e00\u4e2a\u6c47\u7387\u671f\u6743\u5b9a\u4ef7\u3002\u7136\u800c\u4f60\u901a\u8fc7\u5386\u53f2\u6570\u636e\u53d1\u73b0\u5bf9\u4e8e deep OTM \u5e76\u4e0d\u662f\u8fd9\u6837\u3002\u90a3\u5e94\u8be5\u600e\u4e48\u5229\u7528\u8fd9\u4e2a\u4fe1\u606f\u76c8\u5229\u5462\uff1f \u7b54\u6848\u662f\u4e70\u5165 deep OTM \u7684\u671f\u6743\uff0c\u7136\u540e\u7b49\u5f85\u3002\u5230\u671f\u65f6\u4f1a\u6709\u6bd4\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u9884\u6d4b\u7684\u66f4\u5927\u7684\u51e0\u7387\u6210\u4e3a ITM\u3002\u8fd9\u6837\u83b7\u53d6\u7684\u6536\u76ca\u671f\u671b\u8fdc\u5927\u4e8e\u6210\u672c\u3002 \u5728 1980 \u5e74\u4ee3\uff0c\u6709\u4e00\u4e9b\u4ea4\u6613\u5458\u5df2\u7ecf\u8ba4\u8bc6\u5230\u8fd9\u4e00\u70b9\u5e76\u5229\u7528\u8fd9\u4e2a\u7b80\u5355\u7684\u7b56\u7565\u83b7\u53d6\u4e86\u5de8\u5927\u7684\u6536\u76ca\u3002 \u4f8b 1 \u4e0b\u5217\u60c5\u51b5\u4e0b\uff0c\u53ef\u80fd\u89c2\u6d4b\u5230\u4ec0\u4e48\u6837\u7684\u6ce2\u52a8\u7387\u5fae\u7b11\uff1f a. \u80a1\u7968\u4ef7\u683c\u5206\u5e03\u4e24\u7aef\u7684\u5c3e\u90e8\u90fd\u6ca1\u6709\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u80a5\u5927 b. \u80a1\u7968\u4ef7\u683c\u5206\u5e03\u7684\u53f3\u5c3e\u6bd4\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u80a5\u5927\uff0c\u5de6\u5c3e\u4e0d\u5982\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u80a5\u5927\u3002 (a) \u8be5\u60c5\u51b5\u4e0b\uff0c \\(S_T < K1\\) \u4ee5\u53ca \\(S_T > K_2\\) \u7684\u6982\u7387\u90fd\u6bd4\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u4e0b\u7684\u6982\u7387\u4f4e\u3002\u56e0\u6b64 B-S-M \u6a21\u578b\u9ad8\u4f30\u4e86\u6267\u884c\u4ef7\u683c\u6781\u4f4e\u548c\u6781\u9ad8\u7684\u671f\u6743\u7684\u4ef7\u683c\u3002\u4e5f\u5c31\u662f\u8bf4 B-S-M \u6a21\u578b\u9ad8\u4f30\u4e86\u4ed6\u4eec\u7684\u9690\u542b\u6ce2\u52a8\u7387\u3002\u56e0\u6b64\u6ce2\u52a8\u7387\u5fae\u7b11\u5e94\u8be5\u662f\u7c7b\u4f3c\u4e8e\u201c\u76b1\u7709\u201d \u7684\u60c5\u51b5\u3002\u5373\u7c7b\u4f3c\u56fe 19.7 \u4e2d\u7684\u5f62\u72b6 (b) \u8be5\u60c5\u51b5\u4e0b\uff0c \\(S_T < K1\\) \u7684\u6982\u7387\u6bd4 B-S-M \u6a21\u578b\u4f30\u8ba1\u7684\u4f4e\uff0c\u800c \\(S_T > K_2\\) \u5219\u66f4\u9ad8\u3002\u8fd9\u8bf4\u660eB-S-M \u6a21\u578b\u9ad8\u4f30\u4e86\u4f4e\u6267\u884c\u4ef7\u683c\u7684\u9690\u542b\u6ce2\u52a8\u7387\uff0c\u4f4e\u4f30\u4e86\u9ad8\u6267\u884c\u4ef7\u683c\u7684\u9690\u542b\u6ce2\u52a8\u7387\u3002\u56e0\u6b64\u5176\u56fe\u5f62\u5e94\u8be5\u662f\u4e00\u4e2a\u5355\u8c03\u9012\u589e\u7684\u6ce2\u52a8\u7387\u5fae\u7b11\u3002 \u4f8b 2 \u5047\u5b9a\u592e\u884c\u7684\u653f\u7b56\u5141\u8bb8\u6c47\u7387\u5728 0.97 \u81f3 1.03 \u4e4b\u95f4\u53d8\u5316\u3002\u5219\u8be5\u5916\u6c47\u671f\u6743\u7684\u6ce2\u52a8\u7387\u5fae\u7b11\u6700\u53ef\u80fd\u662f\u4ec0\u4e48\u6837\u7684\uff1f \u7531\u4e8e\u653f\u7b56\u5f71\u54cd\uff0c\u6c47\u7387\u7684\u6982\u7387\u5206\u5e03\u4f1a\u51fa\u73b0\u201c\u7626\u5c3e\u201c\u7684\u7279\u5f81\uff08\u76f8\u5bf9\u4e8e\u5bf9\u6570\u6b63\u6001\u5206\u5e03\uff09\u3002\u4e5f\u5c31\u662f\u8bf4\u5f53\u6267\u884c\u4ef7\u683c\u975e\u5e38\u5c0f\u6216\u975e\u5e38\u5927\u65f6\uff0c B-S-M \u6a21\u578b\u4f1a\u9ad8\u4f30\u5176\u4ef7\u503c\uff0c\u4e5f\u5c31\u662f\u9ad8\u4f30\u5176\u6ce2\u52a8\u7387\u3002\u56e0\u6b64\u5b83\u7684\u6ce2\u52a8\u7387\u5fae\u7b11\u6700\u53ef\u80fd\u662f\u4e00\u4e2a\u201d\u76b1\u7709\u201c(frown)\u3002 19.2.1 \u5916\u6c47\u671f\u6743\u6ce2\u52a8\u7387\u5fae\u7b11\u7684\u539f\u56e0 \u67d0\u4e2a\u8d44\u4ea7\u4ef7\u683c\u670d\u4ece\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u6709\u4e24\u4e2a\u6761\u4ef6\uff1a 1. \u8be5\u8d44\u4ea7\u7684\u6ce2\u52a8\u7387\u662f\u5e38\u6570 2. \u8be5\u8d44\u4ea7\u4ef7\u683c\u53d8\u5316\u6ca1\u6709\u8df3\u53d8\uff08\u53ef\u5bfc\uff09 \u5b9e\u9645\u4e0a\uff0c\u5bf9\u4e8e\u5916\u6c47\u671f\u6743\u8fd9\u4e24\u4e2a\u6761\u4ef6\u90fd\u4e0d\u6210\u7acb\u3002\u6ce2\u52a8\u7387\u4e0d\u662f\u5e38\u6570\uff0c\u800c\u4e14\u7531\u4e8e\u56fd\u5bb6\u7684\u8d27\u5e01\u653f\u7b56\u8c03\u6574\u7ecf\u5e38\u51fa\u73b0\u8df3\u53d8\u3002\u7ed3\u679c\u5c31\u662f\u8ba9\u4ef7\u683c\u7684\u6781\u7aef\u60c5\u51b5\u66f4\u5bb9\u6613\u53d1\u751f\u3002 \u8df3\u53d8\u548c\u975e\u5e38\u6570\u7684\u6ce2\u52a8\u7387\u5bf9\u671f\u6743\u4ef7\u683c\u7684\u5f71\u54cd\u4e0e\u671f\u6743\u7684\u671f\u9650\u6709\u5173\u3002 \u5f53\u671f\u6743\u7684\u671f\u9650\u53d8\u957f\uff0c\u975e\u5e38\u6570\u7684\u6ce2\u52a8\u7387\u5bf9\u4ef7\u683c\u6982\u7387\u7684\u5f71\u54cd\u66f4\u4e3a\u663e\u8457\uff0c\u800c\u5bf9\u9690\u542b\u6ce2\u52a8\u7387\u7684\u5f71\u54cd\u7a0b\u5ea6\u5374\u53d8\u5c0f\u3002\u540c\u65f6\u8df3\u53d8\u5bf9\u8fd9\u4e24\u8005\u7684\u5f71\u54cd\u90fd\u8d8a\u6765\u8d8a\u5c0f\u3002\u7efc\u5408\u4f5c\u7528\u7684\u7ed3\u679c\u5c31\u662f\uff0c\u671f\u6743\u7684\u671f\u9650\u8d8a\u957f\uff0c\u6ce2\u52a8\u7387\u5fae\u7b11\u7684\u73b0\u8c61\u8d8a\u4e0d\u663e\u8457\u3002 19.3 \u80a1\u7968\u671f\u6743 \u4e0e\u5916\u6c47\u671f\u6743\u4e0d\u540c\uff0c\u5728 1987 \u5e74\u80a1\u707e\u4e4b\u524d\uff0c\u80a1\u7968\u671f\u6743\u5e76\u6ca1\u6709\u6ce2\u52a8\u7387\u5fae\u7b11\u7684\u73b0\u8c61\u3002\u81ea 1987 \u5e74\u4ee5\u6765\uff0c\u4ea4\u6613\u5458\u5728\u671f\u6743\u5b9a\u4ef7\u4e2d\u91c7\u7528\u7684\u6ce2\u52a8\u7387\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8fd9\u79cd\u5f62\u5f0f\u7684\u6ce2\u52a8\u7387\u5fae\u7b11\u4e5f\u88ab\u79f0\u4e3a\u6ce2\u52a8\u7387\u503e\u659c\uff08volatility skew\uff09\u3002\u968f\u7740\u6267\u884c\u4ef7\u683c\u53d8\u9ad8\uff0c\u9690\u542b\u6ce2\u52a8\u7387\u53d8\u5c0f\u3002\u5373\uff0cdeep OTM \u7684\u770b\u8dcc\u671f\u6743\u548c deep ITM \u7684\u770b\u6da8\u671f\u6743\u7684\u9690\u542b\u6ce2\u52a8\u7387\u660e\u663e\u9ad8\u4e8e\u9ad8\u6267\u884c\u4ef7\u683c\u7684\u671f\u6743\u3002 \u4e0b\u56fe\u7684\u5b9e\u7ebf\u5c55\u793a\u4e86\u80a1\u7968\u4ef7\u683c\u7684\u6982\u7387\u5206\u5e03\uff0c\u865a\u7ebf\u8868\u793a\u4e00\u4e2a\u5177\u6709\u76f8\u540c\u7684\u671f\u671b\u548c\u6807\u51c6\u5dee\u7684\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u3002\u6211\u4eec\u53ef\u4ee5\u770b\u51fa \\(S_T < K_1\\) \u7684\u6982\u7387\u8981\u5927\u4e8e\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u7684\u4f30\u7b97\uff0c\u8fd9\u4e5f\u5bfc\u81f4\u4e86\u6211\u4eec\u4f4e\u4f30\u4e86\u6267\u884c\u4ef7\u683c\u504f\u5c0f\u65f6\u7684\u6ce2\u52a8\u7387\u3002\u540c\u65f6\uff0c \\(S_T > K_2\\) \u7684\u6982\u7387\u8981\u5c0f\u4e8e\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u7684\u4f30\u8ba1\u3002 19.3.1 \u80a1\u7968\u671f\u6743\u6ce2\u52a8\u7387\u503e\u659c\u7684\u539f\u56e0 \u8fd9\u79cd\u73b0\u8c61\u7684\u539f\u56e0\u6709\u4e24\u79cd\u89e3\u91ca\uff1a \u4e0b\u8dcc\u7684\u80a1\u4ef7\u6697\u793a\u7740\u516c\u53f8\u7684\u8d22\u52a1\u6760\u6746\u63d0\u9ad8\u3002\u8fd9\u5bfc\u81f4\u80a1\u7968\u98ce\u9669\u589e\u5927\uff0c\u6ce2\u52a8\u7387\u589e\u52a0\u3002\u800c\u516c\u53f8\u80a1\u7968\u4e0a\u6da8\u65f6\u5219\u76f8\u53cd\u3002 \u7531\u4e8e\u80a1\u7968\u671f\u6743\u7684\u6ce2\u52a8\u7387\u503e\u659c\u5728 1987 \u5e74\u80a1\u7968\u5927\u8dcc\u540e\u624d\u51fa\u73b0\uff0c\u56e0\u6b64\u6709\u7684\u4eba\u8ba4\u4e3a\u8fd9\u662f\u66b4\u8dcc\u6050\u60e7\u75c7\uff08crashophobia\uff09\u7684\u4f53\u73b0\u3002\u4ea4\u6613\u5458\u5bb3\u6015\u5e02\u573a\u4f1a\u51fa\u73b0\u5927\u8dcc\u56e0\u6b64\u5bf9\u4e8e\u6df1\u5ea6\u865a\u503c\u7684\u770b\u8dcc\u671f\u6743\u8d4b\u4e88\u4e86\u8f83\u5927\u7684\u4ef7\u503c\u3002 19.4 \u6ce2\u52a8\u7387\u5fae\u7b11\u7684\u5176\u4ed6\u8868\u793a\u65b9\u6cd5 \u76ee\u524d\u4e3a\u6b62\u6211\u4eec\u628a\u6ce2\u52a8\u7387\u5fae\u7b11\u5b9a\u4e49\u4e3a\u9690\u542b\u6ce2\u52a8\u7387\u4e0e\u6267\u884c\u4ef7\u683c\u7684\u5173\u7cfb\u3002\u4ed6\u4eec\u7684\u5173\u7cfb\u4f9d\u8d56\u4e8e\u6807\u7684\u7269\u8d44\u4ea7\u7684\u5373\u671f\u4ef7\u683c \\(S_0\\) \u3002\u56e0\u6b64\uff0c\u82e5\u5373\u671f\u4ef7\u683c\u53d8\u5316\uff0c\u6ce2\u52a8\u7387\u5fae\u7b11\u4e5f\u4f1a\u76f8\u5e94\u53d8\u5316\u3002\u4e3a\u4e86\u8ba9\u66f2\u7ebf\u66f4\u52a0\u7a33\u5b9a\uff0c\u6211\u4eec\u6709\u65f6\u5019\u5c06\u6ce2\u52a8\u7387\u5fae\u7b11\u5b9a\u4e49\u4e3a\u9690\u542b\u6ce2\u52a8\u7387\u4e0e \\(\\frac{ K}{ S_0}\\) \u7684\u5173\u7cfb\u3002\u5f53\u6807\u7684\u8d44\u4ea7\u4ef7\u683c\u53d8\u5316\u65f6\uff0c\u9690\u542b\u6ce2\u52a8\u7387\u53cd\u5e94\u7684\u662f\u671f\u6743\u7684 moneyness\uff0c\u5373 ITM \u6216 OTM \u7684\u7a0b\u5ea6\u3002 \u6709\u4e00\u79cd\u6539\u8fdb\u65b9\u6cd5\u662f\u5c06\u6ce2\u52a8\u7387\u5b9a\u4e49\u4e3a\u9690\u542b\u6ce2\u52a8\u7387\u4e0e \\(\\frac{K}{F_0}\\) \u7684\u5173\u7cfb\uff0c\u5176\u4e2d \\(F_0\\) \u662f\u671f\u9650\u4e0e\u671f\u6743\u76f8\u540c\u7684\u8fdc\u671f\u4ef7\u683c\u3002\u4ea4\u6613\u5458\u4e5f\u7ecf\u5e38\u628a ATM \u7684\u671f\u6743\u5b9a\u4e49\u4e3a \\(K=F_0\\) \u7684\u671f\u6743\uff0c\u8fd9\u6837\u505a\u7684\u539f\u56e0\u662f \\(F_0\\) \uff08\u800c\u975e \\(S_0\\) \uff09\u662f\u5230\u671f\u65e5\u65f6\u6807\u7684\u8d44\u4ea7\u7684\u671f\u671b\u4ef7\u683c\u3002 \u53e6\u4e00\u79cd\u662f\u5c06\u5176\u5b9a\u4e49\u4e3a\u9690\u542b\u6ce2\u52a8\u7387\u4e0e\u671f\u6743 Delta \u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u8fd9\u79cd\u5b9a\u4e49\u53ef\u4ee5\u628a\u6ce2\u52a8\u7387\u5fae\u7b11\u6269\u5c55\u5230\u9664\u4e86\u6b27\u5f0f\u548c\u7f8e\u5f0f\u671f\u6743\u4ee5\u5916\u7684\u5e7f\u6cdb\u7684\u4ea7\u54c1\u7c7b\u578b\u4e0a\u3002\u6b64\u65f6 ATM \u7684\u671f\u6743\u88ab\u5b9a\u4e49\u4e3a Delta = 0.5 \u6216 Delta = -0.5 \u7684\u671f\u6743\u3002 19.6 \u6ce2\u52a8\u7387\u5fae\u7b11\u5bf9 Greeks \u7684\u5f71\u54cd \u5728\u4e4b\u524d\u7814\u7a76 Greeks \u65f6\u5019\u6211\u4eec\u4e00\u76f4\u5047\u8bbe\u9690\u542b\u6ce2\u52a8\u7387\u662f\u5e38\u6570\u3002\u7531\u4e8e\u5b58\u5728\u6ce2\u52a8\u7387\u5fae\u7b11\u7684\u73b0\u8c61\uff0c\u5b9e\u9645\u4e0a\u5f53\u6807\u7684\u7269\u4ef7\u683c\u53d8\u5316\u65f6\uff0c\u9690\u542b\u6ce2\u52a8\u7387\u4f1a\u968f\u4e4b\u53d8\u5316\u3002 \u4f8b\u5982\uff0c\u4e00\u4e2a\u80a1\u7968\u671f\u6743\u7684 Delta \u4f1a\u53d8\u4e3a\uff1a \\[\\Delta = \\frac{\\partial c_{\\mathrm{BS}}}{\\partial S} + \\frac{\\partial c_{\\mathrm{BS}}}{\\partial \\sigma_{\\mathrm{imp}}}\\frac{\\partial \\sigma_{\\mathrm{imp}}}{\\partial S}\\] \u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u5bf9\u4e8e\u80a1\u7968\u671f\u6743\uff0c\u6ce2\u52a8\u7387\u8d8a\u9ad8\uff0c\u4ef7\u683c\u8d8a\u9ad8\u3002 \\[ \\frac{\\partial c_{\\mathrm{BS}}}{\\partial \\sigma_{\\mathrm{imp}}} > 0\\] \u540c\u65f6\uff0c\u9690\u542b\u6ce2\u52a8\u7387\u662f \\(K/S\\) \u7684\u5355\u8c03\u51cf\u51fd\u6570\u3002\u8fd9\u8bf4\u660e\u5f53\u6807\u7684\u7269\u8d44\u4ea7\u4ef7\u683c\u5347\u9ad8\u65f6\uff0c\u6ce2\u52a8\u7387\u589e\u52a0\u3002\u56e0\u6b64\uff1a \\[\\frac{\\partial \\sigma_{\\mathrm{imp}}}{\\partial S} > 0\\] \u56e0\u6b64 \\(\\Delta\\) \u4f1a\u6bd4 B-S-M \u6a21\u578b\u4e0b\u7684\u7ed3\u679c\u66f4\u9ad8\u3002 18.7 \u5f53\u9884\u671f\u80a1\u4ef7\u6709\u5927\u7684\u8df3\u53d8\u65f6 \u5047\u8bbe\u67d0\u4e2a\u80a1\u7968\u73b0\u5728\u4ef7\u503c\u662f $50\uff0c\u9884\u671f\u672a\u6765\u6709\u4e2a\u91cd\u8981\u7684\u6d88\u606f\u4f1a\u4f7f\u80a1\u4ef7\u4e0a\u5347\u6216\u8005\u4e0b\u8dcc $8\u3002\u5219\u672a\u6765\u7684\u80a1\u4ef7\u53ef\u80fd\u7531\u4e24\u4e2a\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u53e0\u52a0\u5f62\u6210\uff0c\u5206\u522b\u5bf9\u5e94\u4e8e\u597d\u6d88\u606f\u548c\u574f\u6d88\u606f\u3002\u5982\u4e0b\u56fe\u6240\u793a\u3002\u865a\u7ebf\u662f\u5177\u6709\u76f8\u540c\u5747\u503c\u548c\u6807\u51c6\u5dee\u7684\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u3002 \u8fd9\u79cd\u60c5\u51b5\u4e0b\u7684\u9690\u542b\u6ce2\u52a8\u7387\u4e0e\u6267\u884c\u4ef7\u683c\u7684\u5173\u7cfb\u4e3a\uff1a \u53ef\u4ee5\u770b\u51fa\uff0cATM \u7684\u9690\u542b\u6ce2\u52a8\u7387\u6700\u9ad8\uff0c\u8d8a\u662f ITM/OTM\uff0c\u9690\u542b\u6ce2\u52a8\u7387\u8d8a\u4f4e\u3002\u5982\u679c\u6211\u4eec\u7528 ATM \u7684\u9690\u542b\u6ce2\u52a8\u7387\u8ba1\u7b97 ITM/OTM \u671f\u6743\uff0c\u4f1a\u9ad8\u4f30\u5176\u4ef7\u683c\u3002\u8fd9\u4e2a\u56fe\u5f62\u4e5f\u88ab\u79f0\u4e3a\u6ce2\u52a8\u7387\u201c\u76b1\u7709\u201d\u3002","title":"Volatility Smile"},{"location":"trading/option/VolatilitySmile/#volatility-smile","text":"\u9690\u542b\u6ce2\u52a8\u7387\u4e0e\u671f\u6743\u6267\u884c\u4ef7\u683c\u7684\u51fd\u6570\u88ab\u79f0\u4e3a\u6ce2\u52a8\u7387\u5fae\u7b11(volatility smile)\u3002\u6240\u8c13\u9690\u542b\u6ce2\u52a8\u7387\uff0c\u662f\u6307\u9690\u542b\u5728\u671f\u6743 \u5e02\u573a\u4ef7\u683c \u4e2d\u7684\u6ce2\u52a8\u7387\uff0c\u800c\u975e\u6211\u4eec\u901a\u8fc7\u7edf\u8ba1\u65b9\u6cd5\u5f97\u51fa\u7684\u201c\u6ce2\u52a8\u7387\u201d\u3002 \u5728 B-S-M \u6a21\u578b\u4e2d\uff0c\u6211\u4eec\u5047\u8bbe\u6ce2\u52a8\u7387\u662f\u4e00\u4e2a\u5e38\u6570\uff0c\u5e76\u901a\u8fc7\u7edf\u8ba1\u65b9\u6cd5\u5229\u7528\u6807\u7684\u7269\u8d44\u4ea7\u7684\u5386\u53f2\u4ef7\u683c\u8ba1\u7b97\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u901a\u8fc7\u5e02\u573a\u4ef7\u683c\u5f97\u51fa\u7684\u9690\u542b\u6ce2\u52a8\u7387\u662f\u548c\u6211\u4eec\u6700\u521d\u7528\u7edf\u8ba1\u65b9\u6cd5\u7b97\u51fa\u7684\u76f8\u4f3c\u3002\u4f46\u662f\u5b9e\u9645\u4e0a\uff0c\u6211\u4eec\u53d1\u73b0\u8fd9\u4e24\u8005\u5e76\u4e0d\u4e00\u81f4\u3002 \u771f\u5b9e\u7684\u671f\u6743\u6ce2\u52a8\u7387\u5e76\u4e0d\u662f\u4e00\u4e2a\u5e38\u6570\uff0c\u800c\u662f\u4e00\u4e2a\u5173\u4e8e__\u5230\u671f\u65f6\u95f4__\u548c__\u6267\u884c\u4ef7\u683c__\u7684\u51fd\u6570\uff08\u5ffd\u7565\u968f\u673a\u56e0\u7d20\uff09\u3002","title":"Volatility Smile"},{"location":"trading/option/VolatilitySmile/#191-call-put","text":"\u5f53\u6267\u884c\u4ef7\u683c\u548c\u5230\u671f\u65e5\u76f8\u540c\u65f6\uff0c\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u548c\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\u5177\u6709\u76f8\u540c\u7684\u9690\u542b\u6ce2\u52a8\u7387\u3002 \u56de\u5fc6\u4e00\u4e0b\u6211\u4eec\u4ee5\u524d\u5b66\u4e60\u7684 put-call parity \u516c\u5f0f\uff1a \\[p + S_0 e^{-qT} = c + K e^{-rT}\\] \u5176\u4e2d\uff0c \\(c\\) \u548c \\(p\\) \u5206\u522b\u4e3a\u6b27\u5f0f\u770b\u6da8\u548c\u770b\u8dcc\u671f\u6743\u7684\u4ef7\u683c\u3002\u4ed6\u4eec\u5177\u6709\u540c\u6837\u7684\u6267\u884c\u4ef7\u683c \\(K\\) \uff0c\u8ddd\u79bb\u5230\u671f\u65e5\u65f6\u95f4 \\(T\\) \u3002 \\(r\\) \u662f\u65e0\u98ce\u9669\u5229\u7387\uff0c \\(q\\) \u662f\u6807\u7684\u7269\u8d44\u4ea7\u7684\u6536\u76ca\uff08\u4f8b\u5982\u80a1\u606f\uff09\u3002 \\(S_0\\) \u662f\u6807\u7684\u7269\u8d44\u4ea7\u7684\u5373\u671f\u4ef7\u683c\u3002 put-call parity \u4ec5\u4ec5\u57fa\u4e8e\u65e0\u5957\u5229\u673a\u4f1a\u5047\u8bbe\u3002\u56e0\u6b64\u65e0\u8bba\u6807\u7684\u7269\u4ef7\u683c\u662f\u5426\u670d\u4ece\u5bf9\u6570\u6b63\u6001\u5206\u5e03\uff0c\u8fd9\u4e2a\u7ed3\u8bba\u90fd\u6210\u7acb\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u4f7f\u7528 B-S-M \u8ba1\u7b97\u51fa\u6765\u7684\u7406\u8bba\u4ef7\u683c\u6ee1\u8db3\uff1a \\[p_{\\mathrm{BS}} + S_0 e^{-qT} = c_{\\mathrm{BS}} + K e^{-rT}\\] \u540c\u65f6\uff0c\u5373\u4f7f\u4e0d\u7b26\u5408\u5bf9\u6570\u6b63\u6001\u5206\u5e03\uff0c\u671f\u6743\u7684\u5e02\u573a\u4ef7\u683c\u4e5f\u5e94\u8be5\u6ee1\u8db3\uff1a \\[p_{\\mathrm{mkt}} + S_0 e^{-qT} = c_{\\mathrm{mkt}} + K e^{-rT}\\] \u5047\u8bbe\u8fd9\u91cc\u7684\u770b\u6da8\u671f\u6743\u5e02\u573a\u4ef7\u683c \\(c_{\\mathrm{mkt}}\\) \u4ef7\u683c\u5df2\u77e5\uff0c\u4e14\u5df2\u7ecf\u901a\u8fc7 \\(c_{\\mathrm{mkt}}\\) \u5f97\u5230\u4e86\u5176\u9690\u542b\u6ce2\u52a8\u7387 \\(\\sigma_{\\mathrm{mkt}}\\) \u3002\u90a3\u4e48\uff0c\u5c06 \\(c_{\\mathrm{mkt}}\\) \u4ee3\u5165 put-call parity \u53ef\u4ee5\u8ba1\u7b97\u5f97\u51fa\u770b\u8dcc\u671f\u6743\u4ef7\u683c\uff1a \\[p_{\\mathrm{mkt}} = K e^{-rT}\\Phi(-d_2) - S_0 e^{-qT}\\Phi(-d_1) \\] \u8fd9\u4e0e\u5229\u7528 B-S-M \u6a21\u578b\u63a8\u5bfc\u7684\u770b\u8dcc\u671f\u6743\u8ba1\u7b97\u516c\u5f0f\u662f\u4e00\u81f4\u7684\u3002\u56e0\u6b64\uff0c\u5982\u679c\u6211\u4eec\u5229\u7528\u770b\u8dcc\u671f\u6743\u4ef7\u683c \\(p_{\\mathrm{mkt}}\\) \u6765\u518d\u6b21\u8ba1\u7b97\u9690\u542b\u6ce2\u52a8\u7387\uff0c\u7ed3\u679c\u4e5f\u662f \\(\\sigma_{\\mathrm{mkt}}\\) \u3002 \u53e6\u5916\uff0c\u901a\u8fc7 B-S-M \u8ba1\u7b97\u7684\u770b\u8dcc\u548c\u770b\u6da8\u671f\u6743\u4ef7\u683c \\(c_{\\mathrm{BS}}\\) \uff0c \\(p_{\\mathrm{BS}}\\) \u5728\u8ba1\u7b97\u4e2d\u90fd\u662f\u4f7f\u7528\u540c\u4e00\u4e2a\u6ce2\u52a8\u7387\uff0c\u56e0\u6b64\u5fc5\u7136\u76f8\u7b49\u3002\u5373\u65e0\u8bba\u662f\u7406\u8bba\u4ef7\u683c\u8fd8\u662f\u5e02\u573a\u4ef7\u683c\uff0c\u8be5\u7ed3\u8bba\u90fd\u6210\u7acb\u3002 \u6211\u4eec\u8fd8\u53ef\u4ee5\u5f97\u5230\uff1a \\[p_{\\mathrm{BS}} - p_{\\mathrm{mkt}} = c_{\\mathrm{BS}} - c_{\\mathrm{mkt}}\\] \u8be5\u5f0f\u8bf4\u660e\uff0cB-S-M \u6a21\u578b\u5b9a\u4ef7\u4e0e\u5b9e\u9645\u5e02\u573a\u4ef7\u683c\u7684__\u8bef\u5dee__\u5bf9\u4e8e call \u548cput \u5e94\u8be5\u662f\u4e00\u81f4\u7684\u3002","title":"19.1 call \u548c put \u6709\u540c\u6837\u7684\u6ce2\u52a8\u7387\u5fae\u7b11"},{"location":"trading/option/VolatilitySmile/#_1","text":"\u4e00\u4e2a\u6b27\u5f0f\u770b\u6da8\u671f\u6743\u4e0e\u4e00\u4e2a\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\u5177\u6709\u540c\u6837\u7684\u6267\u884c\u4ef7\u683c\u4e0e\u671f\u9650\u3002\u770b\u6da8\u671f\u6743\u7684\u9690\u542b\u6ce2\u52a8\u7387\u4e3a 30%\uff0c\u770b\u8dcc\u671f\u6743\u7684\u9690\u542b\u6ce2\u52a8\u7387\u4e3a 25%\u3002\u5176\u4e2d\u5b58\u5728\u4ec0\u4e48\u6837\u7684\u5957\u5229\u673a\u4f1a\uff1f \u8fd9\u8bf4\u660e\u770b\u8dcc\u671f\u6743\u7684\u4ef7\u503c\u88ab\u5e02\u573a\u4f4e\u4f30\u4e86\uff08\u6216\u8005\u770b\u6da8\u671f\u6743\u7684\u4ef7\u503c\u88ab\u9ad8\u4f30\uff09\u3002\u6839\u636e put-call parity\uff0c\u53ef\u4ee5\u4e70\u5165\u770b\u8dcc\u671f\u6743\uff0c\u4e70\u5165\u80a1\u7968\uff0c\u5e76\u5356\u51fa\u770b\u6da8\u671f\u6743\u3002","title":"\u4f8b"},{"location":"trading/option/VolatilitySmile/#192","text":"\u4e00\u4e2a\u5178\u578b\u7684\u8d27\u5e01\u671f\u6743\u7684\u6ce2\u52a8\u7387\u5fae\u7b11\u5982\u4e0b\u56fe\uff1a \u53ef\u4ee5\u770b\u51fa\uff0c\u5728 ATM \u7684\u65f6\u5019\uff0c\u6ce2\u52a8\u7387\u6700\u4f4e\u3002\u968f\u7740\u6267\u884c\u4ef7\u683c\u4e0d\u540c\uff0c\u65e0\u8bba\u671d\u7740 ITM \u548c OTM \u53d8\u5316\uff0c\u6ce2\u52a8\u7387\u90fd\u6e10\u6e10\u589e\u5927\u3002 \u6211\u4eec\u53ef\u4ee5\u6839\u636e\u6ce2\u52a8\u7387\u5fae\u7b11\u63a8\u5bfc\u51fa\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u4e0b\u6807\u7684\u7269\u4ef7\u683c\u7684\u6982\u7387\u5206\u5e03\u3002 \u9996\u5148\u770b\u6da8\u671f\u6743\u7684\u4ef7\u683c\u53ef\u4ee5\u7531 payoff \u7684\u671f\u671b\u8d34\u73b0\u5f97\u51fa\uff1a \\[c = e^{-rT}\\int_{S_T = K}^{\\infty} (S_T - K)g(S_T)~dS_T\\] \u5176\u4e2d \\(g(S_T)\\) \u8868\u793a \\(T\\) \u65f6\u523b\u4ef7\u683c\u4e3a \\(S_T\\) \u7684\u6982\u7387\u3002\u5bf9 \\(K\\) \u6c42\u5bfc\u53ef\u5f97\uff1a \\[\\frac{\\partial c}{\\partial K} = -e^{-rT}\\int_{S_T = K}^{\\infty} g(S_T)~dS_T\\] \u518d\u5bf9 \\(K\\) \u6c42\u5bfc\u53ef\u4ee5\u5f97\u51fa\uff1a \\[\\frac{\\partial^2 c}{\\partial K^2} = e^{-rT} g(K)\\] \u4e8e\u662f\u53ef\u4ee5\u5f97\u51fa\uff1a \\[g(K) = e^{rT} \\frac{ \\partial^2 c}{ \\partial K^2}\\] \u5047\u8bbe\u6211\u4eec\u6709\u4e09\u4e2a\u671f\u6743\uff0c\u6267\u884c\u4ef7\u683c\u5206\u522b\u4e3a \\(K- \\delta\\) \uff0c \\(K\\) \uff0c \\(K+ \\delta\\) \uff0c \\(\\delta\\) \u662f\u4e00\u4e2a\u975e\u5e38\u5c0f\u7684\u6b63\u6570\u3002\u6211\u4eec\u53ef\u4ee5\u7528\u5dee\u5206\u8fd1\u4f3c\u5fae\u5206\uff0c\u5f97\u5230\uff1a \\[g(K) = e^{rT} \\frac{c_1 + c_3 - 2c_2} {\\delta^2}\\] \u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u9690\u542b\u6ce2\u52a8\u7387\u9996\u5148\u8ba1\u7b97\u51fa\u671f\u6743\u4ef7\u683c\uff0c\u518d\u8ba1\u7b97\u98ce\u9669\u4e2d\u6027\u5047\u8bbe\u4e0b\u6807\u7684\u7269\u4ef7\u683c\u7684\u6982\u7387 \\(g(K)\\) \u3002\u5176\u56fe\u50cf\u5982\u4e0b\u6240\u793a\uff1a \u6211\u4eec\u53ef\u4ee5\u770b\u51fa\uff0c\u5b9e\u9645\u7684\u66f2\u7ebf\u6bd4\u6211\u4eec\u5047\u8bbe\u7684\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u66f4\u201c\u5c16\u201d\uff0c\u56e0\u6b64\u5bf9\u4e8e deep OTM\uff08\u4f8b\u5982\u6267\u884c\u4ef7\u683c\u5927\u4e8e \\(K_2\\) \u7684call\uff0c\u4ee5\u53ca\u6267\u884c\u4ef7\u683c\u4f4e\u4e8e \\(K_1\\) \u7684put\uff09\uff0c\u5b9e\u9645\u4e0a B-S-M \u6a21\u578b\u4f4e\u4f30\u4e86\u4ed6\u4eec\u7684\u4ef7\u683c\u3002\u4e5f\u5c31\u662f\u4f4e\u4f30\u4e86\u4ed6\u4eec\u7684\u9690\u542b\u6ce2\u52a8\u7387\u3002 \u4ee5\u4e0a\u5206\u6790\u8868\u660e\uff0c\u6ce2\u52a8\u7387\u5fae\u7b11\u66f2\u7ebf\u548c\u5230\u671f\u65e5\u4ef7\u683c\u7684\u6982\u7387\u5206\u5e03\u66f2\u7ebf\u662f\u4e00\u81f4\u7684\u3002","title":"19.2 \u5916\u6c47\u671f\u6743"},{"location":"trading/option/VolatilitySmile/#_2","text":"\u60f3\u8c61\u4e00\u4e0b\uff0c\u5f53\u5927\u90e8\u5206\u5e02\u573a\u53c2\u4e0e\u8005\u90fd\u8ba4\u4e3a\u6c47\u7387\u670d\u4ece\u5bf9\u6570\u6b63\u6001\u5206\u5e03\uff0c\u800c\u4f7f\u7528\u540c\u4e00\u4e2a\u6ce2\u52a8\u7387\u5bf9\u67d0\u4e00\u4e2a\u6c47\u7387\u671f\u6743\u5b9a\u4ef7\u3002\u7136\u800c\u4f60\u901a\u8fc7\u5386\u53f2\u6570\u636e\u53d1\u73b0\u5bf9\u4e8e deep OTM \u5e76\u4e0d\u662f\u8fd9\u6837\u3002\u90a3\u5e94\u8be5\u600e\u4e48\u5229\u7528\u8fd9\u4e2a\u4fe1\u606f\u76c8\u5229\u5462\uff1f \u7b54\u6848\u662f\u4e70\u5165 deep OTM \u7684\u671f\u6743\uff0c\u7136\u540e\u7b49\u5f85\u3002\u5230\u671f\u65f6\u4f1a\u6709\u6bd4\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u9884\u6d4b\u7684\u66f4\u5927\u7684\u51e0\u7387\u6210\u4e3a ITM\u3002\u8fd9\u6837\u83b7\u53d6\u7684\u6536\u76ca\u671f\u671b\u8fdc\u5927\u4e8e\u6210\u672c\u3002 \u5728 1980 \u5e74\u4ee3\uff0c\u6709\u4e00\u4e9b\u4ea4\u6613\u5458\u5df2\u7ecf\u8ba4\u8bc6\u5230\u8fd9\u4e00\u70b9\u5e76\u5229\u7528\u8fd9\u4e2a\u7b80\u5355\u7684\u7b56\u7565\u83b7\u53d6\u4e86\u5de8\u5927\u7684\u6536\u76ca\u3002","title":"\u4e1a\u754c\u6848\u4f8b"},{"location":"trading/option/VolatilitySmile/#1","text":"\u4e0b\u5217\u60c5\u51b5\u4e0b\uff0c\u53ef\u80fd\u89c2\u6d4b\u5230\u4ec0\u4e48\u6837\u7684\u6ce2\u52a8\u7387\u5fae\u7b11\uff1f a. \u80a1\u7968\u4ef7\u683c\u5206\u5e03\u4e24\u7aef\u7684\u5c3e\u90e8\u90fd\u6ca1\u6709\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u80a5\u5927 b. \u80a1\u7968\u4ef7\u683c\u5206\u5e03\u7684\u53f3\u5c3e\u6bd4\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u80a5\u5927\uff0c\u5de6\u5c3e\u4e0d\u5982\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u80a5\u5927\u3002 (a) \u8be5\u60c5\u51b5\u4e0b\uff0c \\(S_T < K1\\) \u4ee5\u53ca \\(S_T > K_2\\) \u7684\u6982\u7387\u90fd\u6bd4\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u4e0b\u7684\u6982\u7387\u4f4e\u3002\u56e0\u6b64 B-S-M \u6a21\u578b\u9ad8\u4f30\u4e86\u6267\u884c\u4ef7\u683c\u6781\u4f4e\u548c\u6781\u9ad8\u7684\u671f\u6743\u7684\u4ef7\u683c\u3002\u4e5f\u5c31\u662f\u8bf4 B-S-M \u6a21\u578b\u9ad8\u4f30\u4e86\u4ed6\u4eec\u7684\u9690\u542b\u6ce2\u52a8\u7387\u3002\u56e0\u6b64\u6ce2\u52a8\u7387\u5fae\u7b11\u5e94\u8be5\u662f\u7c7b\u4f3c\u4e8e\u201c\u76b1\u7709\u201d \u7684\u60c5\u51b5\u3002\u5373\u7c7b\u4f3c\u56fe 19.7 \u4e2d\u7684\u5f62\u72b6 (b) \u8be5\u60c5\u51b5\u4e0b\uff0c \\(S_T < K1\\) \u7684\u6982\u7387\u6bd4 B-S-M \u6a21\u578b\u4f30\u8ba1\u7684\u4f4e\uff0c\u800c \\(S_T > K_2\\) \u5219\u66f4\u9ad8\u3002\u8fd9\u8bf4\u660eB-S-M \u6a21\u578b\u9ad8\u4f30\u4e86\u4f4e\u6267\u884c\u4ef7\u683c\u7684\u9690\u542b\u6ce2\u52a8\u7387\uff0c\u4f4e\u4f30\u4e86\u9ad8\u6267\u884c\u4ef7\u683c\u7684\u9690\u542b\u6ce2\u52a8\u7387\u3002\u56e0\u6b64\u5176\u56fe\u5f62\u5e94\u8be5\u662f\u4e00\u4e2a\u5355\u8c03\u9012\u589e\u7684\u6ce2\u52a8\u7387\u5fae\u7b11\u3002","title":"\u4f8b 1"},{"location":"trading/option/VolatilitySmile/#2","text":"\u5047\u5b9a\u592e\u884c\u7684\u653f\u7b56\u5141\u8bb8\u6c47\u7387\u5728 0.97 \u81f3 1.03 \u4e4b\u95f4\u53d8\u5316\u3002\u5219\u8be5\u5916\u6c47\u671f\u6743\u7684\u6ce2\u52a8\u7387\u5fae\u7b11\u6700\u53ef\u80fd\u662f\u4ec0\u4e48\u6837\u7684\uff1f \u7531\u4e8e\u653f\u7b56\u5f71\u54cd\uff0c\u6c47\u7387\u7684\u6982\u7387\u5206\u5e03\u4f1a\u51fa\u73b0\u201c\u7626\u5c3e\u201c\u7684\u7279\u5f81\uff08\u76f8\u5bf9\u4e8e\u5bf9\u6570\u6b63\u6001\u5206\u5e03\uff09\u3002\u4e5f\u5c31\u662f\u8bf4\u5f53\u6267\u884c\u4ef7\u683c\u975e\u5e38\u5c0f\u6216\u975e\u5e38\u5927\u65f6\uff0c B-S-M \u6a21\u578b\u4f1a\u9ad8\u4f30\u5176\u4ef7\u503c\uff0c\u4e5f\u5c31\u662f\u9ad8\u4f30\u5176\u6ce2\u52a8\u7387\u3002\u56e0\u6b64\u5b83\u7684\u6ce2\u52a8\u7387\u5fae\u7b11\u6700\u53ef\u80fd\u662f\u4e00\u4e2a\u201d\u76b1\u7709\u201c(frown)\u3002","title":"\u4f8b 2"},{"location":"trading/option/VolatilitySmile/#1921","text":"\u67d0\u4e2a\u8d44\u4ea7\u4ef7\u683c\u670d\u4ece\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u6709\u4e24\u4e2a\u6761\u4ef6\uff1a 1. \u8be5\u8d44\u4ea7\u7684\u6ce2\u52a8\u7387\u662f\u5e38\u6570 2. \u8be5\u8d44\u4ea7\u4ef7\u683c\u53d8\u5316\u6ca1\u6709\u8df3\u53d8\uff08\u53ef\u5bfc\uff09 \u5b9e\u9645\u4e0a\uff0c\u5bf9\u4e8e\u5916\u6c47\u671f\u6743\u8fd9\u4e24\u4e2a\u6761\u4ef6\u90fd\u4e0d\u6210\u7acb\u3002\u6ce2\u52a8\u7387\u4e0d\u662f\u5e38\u6570\uff0c\u800c\u4e14\u7531\u4e8e\u56fd\u5bb6\u7684\u8d27\u5e01\u653f\u7b56\u8c03\u6574\u7ecf\u5e38\u51fa\u73b0\u8df3\u53d8\u3002\u7ed3\u679c\u5c31\u662f\u8ba9\u4ef7\u683c\u7684\u6781\u7aef\u60c5\u51b5\u66f4\u5bb9\u6613\u53d1\u751f\u3002 \u8df3\u53d8\u548c\u975e\u5e38\u6570\u7684\u6ce2\u52a8\u7387\u5bf9\u671f\u6743\u4ef7\u683c\u7684\u5f71\u54cd\u4e0e\u671f\u6743\u7684\u671f\u9650\u6709\u5173\u3002 \u5f53\u671f\u6743\u7684\u671f\u9650\u53d8\u957f\uff0c\u975e\u5e38\u6570\u7684\u6ce2\u52a8\u7387\u5bf9\u4ef7\u683c\u6982\u7387\u7684\u5f71\u54cd\u66f4\u4e3a\u663e\u8457\uff0c\u800c\u5bf9\u9690\u542b\u6ce2\u52a8\u7387\u7684\u5f71\u54cd\u7a0b\u5ea6\u5374\u53d8\u5c0f\u3002\u540c\u65f6\u8df3\u53d8\u5bf9\u8fd9\u4e24\u8005\u7684\u5f71\u54cd\u90fd\u8d8a\u6765\u8d8a\u5c0f\u3002\u7efc\u5408\u4f5c\u7528\u7684\u7ed3\u679c\u5c31\u662f\uff0c\u671f\u6743\u7684\u671f\u9650\u8d8a\u957f\uff0c\u6ce2\u52a8\u7387\u5fae\u7b11\u7684\u73b0\u8c61\u8d8a\u4e0d\u663e\u8457\u3002","title":"19.2.1 \u5916\u6c47\u671f\u6743\u6ce2\u52a8\u7387\u5fae\u7b11\u7684\u539f\u56e0"},{"location":"trading/option/VolatilitySmile/#193","text":"\u4e0e\u5916\u6c47\u671f\u6743\u4e0d\u540c\uff0c\u5728 1987 \u5e74\u80a1\u707e\u4e4b\u524d\uff0c\u80a1\u7968\u671f\u6743\u5e76\u6ca1\u6709\u6ce2\u52a8\u7387\u5fae\u7b11\u7684\u73b0\u8c61\u3002\u81ea 1987 \u5e74\u4ee5\u6765\uff0c\u4ea4\u6613\u5458\u5728\u671f\u6743\u5b9a\u4ef7\u4e2d\u91c7\u7528\u7684\u6ce2\u52a8\u7387\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8fd9\u79cd\u5f62\u5f0f\u7684\u6ce2\u52a8\u7387\u5fae\u7b11\u4e5f\u88ab\u79f0\u4e3a\u6ce2\u52a8\u7387\u503e\u659c\uff08volatility skew\uff09\u3002\u968f\u7740\u6267\u884c\u4ef7\u683c\u53d8\u9ad8\uff0c\u9690\u542b\u6ce2\u52a8\u7387\u53d8\u5c0f\u3002\u5373\uff0cdeep OTM \u7684\u770b\u8dcc\u671f\u6743\u548c deep ITM \u7684\u770b\u6da8\u671f\u6743\u7684\u9690\u542b\u6ce2\u52a8\u7387\u660e\u663e\u9ad8\u4e8e\u9ad8\u6267\u884c\u4ef7\u683c\u7684\u671f\u6743\u3002 \u4e0b\u56fe\u7684\u5b9e\u7ebf\u5c55\u793a\u4e86\u80a1\u7968\u4ef7\u683c\u7684\u6982\u7387\u5206\u5e03\uff0c\u865a\u7ebf\u8868\u793a\u4e00\u4e2a\u5177\u6709\u76f8\u540c\u7684\u671f\u671b\u548c\u6807\u51c6\u5dee\u7684\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u3002\u6211\u4eec\u53ef\u4ee5\u770b\u51fa \\(S_T < K_1\\) \u7684\u6982\u7387\u8981\u5927\u4e8e\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u7684\u4f30\u7b97\uff0c\u8fd9\u4e5f\u5bfc\u81f4\u4e86\u6211\u4eec\u4f4e\u4f30\u4e86\u6267\u884c\u4ef7\u683c\u504f\u5c0f\u65f6\u7684\u6ce2\u52a8\u7387\u3002\u540c\u65f6\uff0c \\(S_T > K_2\\) \u7684\u6982\u7387\u8981\u5c0f\u4e8e\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u7684\u4f30\u8ba1\u3002","title":"19.3 \u80a1\u7968\u671f\u6743"},{"location":"trading/option/VolatilitySmile/#1931","text":"\u8fd9\u79cd\u73b0\u8c61\u7684\u539f\u56e0\u6709\u4e24\u79cd\u89e3\u91ca\uff1a \u4e0b\u8dcc\u7684\u80a1\u4ef7\u6697\u793a\u7740\u516c\u53f8\u7684\u8d22\u52a1\u6760\u6746\u63d0\u9ad8\u3002\u8fd9\u5bfc\u81f4\u80a1\u7968\u98ce\u9669\u589e\u5927\uff0c\u6ce2\u52a8\u7387\u589e\u52a0\u3002\u800c\u516c\u53f8\u80a1\u7968\u4e0a\u6da8\u65f6\u5219\u76f8\u53cd\u3002 \u7531\u4e8e\u80a1\u7968\u671f\u6743\u7684\u6ce2\u52a8\u7387\u503e\u659c\u5728 1987 \u5e74\u80a1\u7968\u5927\u8dcc\u540e\u624d\u51fa\u73b0\uff0c\u56e0\u6b64\u6709\u7684\u4eba\u8ba4\u4e3a\u8fd9\u662f\u66b4\u8dcc\u6050\u60e7\u75c7\uff08crashophobia\uff09\u7684\u4f53\u73b0\u3002\u4ea4\u6613\u5458\u5bb3\u6015\u5e02\u573a\u4f1a\u51fa\u73b0\u5927\u8dcc\u56e0\u6b64\u5bf9\u4e8e\u6df1\u5ea6\u865a\u503c\u7684\u770b\u8dcc\u671f\u6743\u8d4b\u4e88\u4e86\u8f83\u5927\u7684\u4ef7\u503c\u3002","title":"19.3.1 \u80a1\u7968\u671f\u6743\u6ce2\u52a8\u7387\u503e\u659c\u7684\u539f\u56e0"},{"location":"trading/option/VolatilitySmile/#194","text":"\u76ee\u524d\u4e3a\u6b62\u6211\u4eec\u628a\u6ce2\u52a8\u7387\u5fae\u7b11\u5b9a\u4e49\u4e3a\u9690\u542b\u6ce2\u52a8\u7387\u4e0e\u6267\u884c\u4ef7\u683c\u7684\u5173\u7cfb\u3002\u4ed6\u4eec\u7684\u5173\u7cfb\u4f9d\u8d56\u4e8e\u6807\u7684\u7269\u8d44\u4ea7\u7684\u5373\u671f\u4ef7\u683c \\(S_0\\) \u3002\u56e0\u6b64\uff0c\u82e5\u5373\u671f\u4ef7\u683c\u53d8\u5316\uff0c\u6ce2\u52a8\u7387\u5fae\u7b11\u4e5f\u4f1a\u76f8\u5e94\u53d8\u5316\u3002\u4e3a\u4e86\u8ba9\u66f2\u7ebf\u66f4\u52a0\u7a33\u5b9a\uff0c\u6211\u4eec\u6709\u65f6\u5019\u5c06\u6ce2\u52a8\u7387\u5fae\u7b11\u5b9a\u4e49\u4e3a\u9690\u542b\u6ce2\u52a8\u7387\u4e0e \\(\\frac{ K}{ S_0}\\) \u7684\u5173\u7cfb\u3002\u5f53\u6807\u7684\u8d44\u4ea7\u4ef7\u683c\u53d8\u5316\u65f6\uff0c\u9690\u542b\u6ce2\u52a8\u7387\u53cd\u5e94\u7684\u662f\u671f\u6743\u7684 moneyness\uff0c\u5373 ITM \u6216 OTM \u7684\u7a0b\u5ea6\u3002 \u6709\u4e00\u79cd\u6539\u8fdb\u65b9\u6cd5\u662f\u5c06\u6ce2\u52a8\u7387\u5b9a\u4e49\u4e3a\u9690\u542b\u6ce2\u52a8\u7387\u4e0e \\(\\frac{K}{F_0}\\) \u7684\u5173\u7cfb\uff0c\u5176\u4e2d \\(F_0\\) \u662f\u671f\u9650\u4e0e\u671f\u6743\u76f8\u540c\u7684\u8fdc\u671f\u4ef7\u683c\u3002\u4ea4\u6613\u5458\u4e5f\u7ecf\u5e38\u628a ATM \u7684\u671f\u6743\u5b9a\u4e49\u4e3a \\(K=F_0\\) \u7684\u671f\u6743\uff0c\u8fd9\u6837\u505a\u7684\u539f\u56e0\u662f \\(F_0\\) \uff08\u800c\u975e \\(S_0\\) \uff09\u662f\u5230\u671f\u65e5\u65f6\u6807\u7684\u8d44\u4ea7\u7684\u671f\u671b\u4ef7\u683c\u3002 \u53e6\u4e00\u79cd\u662f\u5c06\u5176\u5b9a\u4e49\u4e3a\u9690\u542b\u6ce2\u52a8\u7387\u4e0e\u671f\u6743 Delta \u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u8fd9\u79cd\u5b9a\u4e49\u53ef\u4ee5\u628a\u6ce2\u52a8\u7387\u5fae\u7b11\u6269\u5c55\u5230\u9664\u4e86\u6b27\u5f0f\u548c\u7f8e\u5f0f\u671f\u6743\u4ee5\u5916\u7684\u5e7f\u6cdb\u7684\u4ea7\u54c1\u7c7b\u578b\u4e0a\u3002\u6b64\u65f6 ATM \u7684\u671f\u6743\u88ab\u5b9a\u4e49\u4e3a Delta = 0.5 \u6216 Delta = -0.5 \u7684\u671f\u6743\u3002","title":"19.4 \u6ce2\u52a8\u7387\u5fae\u7b11\u7684\u5176\u4ed6\u8868\u793a\u65b9\u6cd5"},{"location":"trading/option/VolatilitySmile/#196-greeks","text":"\u5728\u4e4b\u524d\u7814\u7a76 Greeks \u65f6\u5019\u6211\u4eec\u4e00\u76f4\u5047\u8bbe\u9690\u542b\u6ce2\u52a8\u7387\u662f\u5e38\u6570\u3002\u7531\u4e8e\u5b58\u5728\u6ce2\u52a8\u7387\u5fae\u7b11\u7684\u73b0\u8c61\uff0c\u5b9e\u9645\u4e0a\u5f53\u6807\u7684\u7269\u4ef7\u683c\u53d8\u5316\u65f6\uff0c\u9690\u542b\u6ce2\u52a8\u7387\u4f1a\u968f\u4e4b\u53d8\u5316\u3002 \u4f8b\u5982\uff0c\u4e00\u4e2a\u80a1\u7968\u671f\u6743\u7684 Delta \u4f1a\u53d8\u4e3a\uff1a \\[\\Delta = \\frac{\\partial c_{\\mathrm{BS}}}{\\partial S} + \\frac{\\partial c_{\\mathrm{BS}}}{\\partial \\sigma_{\\mathrm{imp}}}\\frac{\\partial \\sigma_{\\mathrm{imp}}}{\\partial S}\\] \u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u5bf9\u4e8e\u80a1\u7968\u671f\u6743\uff0c\u6ce2\u52a8\u7387\u8d8a\u9ad8\uff0c\u4ef7\u683c\u8d8a\u9ad8\u3002 \\[ \\frac{\\partial c_{\\mathrm{BS}}}{\\partial \\sigma_{\\mathrm{imp}}} > 0\\] \u540c\u65f6\uff0c\u9690\u542b\u6ce2\u52a8\u7387\u662f \\(K/S\\) \u7684\u5355\u8c03\u51cf\u51fd\u6570\u3002\u8fd9\u8bf4\u660e\u5f53\u6807\u7684\u7269\u8d44\u4ea7\u4ef7\u683c\u5347\u9ad8\u65f6\uff0c\u6ce2\u52a8\u7387\u589e\u52a0\u3002\u56e0\u6b64\uff1a \\[\\frac{\\partial \\sigma_{\\mathrm{imp}}}{\\partial S} > 0\\] \u56e0\u6b64 \\(\\Delta\\) \u4f1a\u6bd4 B-S-M \u6a21\u578b\u4e0b\u7684\u7ed3\u679c\u66f4\u9ad8\u3002","title":"19.6 \u6ce2\u52a8\u7387\u5fae\u7b11\u5bf9 Greeks \u7684\u5f71\u54cd"},{"location":"trading/option/VolatilitySmile/#187","text":"\u5047\u8bbe\u67d0\u4e2a\u80a1\u7968\u73b0\u5728\u4ef7\u503c\u662f $50\uff0c\u9884\u671f\u672a\u6765\u6709\u4e2a\u91cd\u8981\u7684\u6d88\u606f\u4f1a\u4f7f\u80a1\u4ef7\u4e0a\u5347\u6216\u8005\u4e0b\u8dcc $8\u3002\u5219\u672a\u6765\u7684\u80a1\u4ef7\u53ef\u80fd\u7531\u4e24\u4e2a\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u53e0\u52a0\u5f62\u6210\uff0c\u5206\u522b\u5bf9\u5e94\u4e8e\u597d\u6d88\u606f\u548c\u574f\u6d88\u606f\u3002\u5982\u4e0b\u56fe\u6240\u793a\u3002\u865a\u7ebf\u662f\u5177\u6709\u76f8\u540c\u5747\u503c\u548c\u6807\u51c6\u5dee\u7684\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u3002 \u8fd9\u79cd\u60c5\u51b5\u4e0b\u7684\u9690\u542b\u6ce2\u52a8\u7387\u4e0e\u6267\u884c\u4ef7\u683c\u7684\u5173\u7cfb\u4e3a\uff1a \u53ef\u4ee5\u770b\u51fa\uff0cATM \u7684\u9690\u542b\u6ce2\u52a8\u7387\u6700\u9ad8\uff0c\u8d8a\u662f ITM/OTM\uff0c\u9690\u542b\u6ce2\u52a8\u7387\u8d8a\u4f4e\u3002\u5982\u679c\u6211\u4eec\u7528 ATM \u7684\u9690\u542b\u6ce2\u52a8\u7387\u8ba1\u7b97 ITM/OTM \u671f\u6743\uff0c\u4f1a\u9ad8\u4f30\u5176\u4ef7\u683c\u3002\u8fd9\u4e2a\u56fe\u5f62\u4e5f\u88ab\u79f0\u4e3a\u6ce2\u52a8\u7387\u201c\u76b1\u7709\u201d\u3002","title":"18.7 \u5f53\u9884\u671f\u80a1\u4ef7\u6709\u5927\u7684\u8df3\u53d8\u65f6"},{"location":"trading/portfolio/MarkowitzPO/","text":"Portfolio Optimization with Known Parameters \u9996\u5148\u5f15\u5165\u4e00\u4e9b\u4e4b\u540e\u4f7f\u7528\u7684\u7b26\u53f7\u5b9a\u4e49\u3002 In practice, a portfolio deals with a whole universe of \\(N\\) assets. We denote the log-returns of the \\(N\\) assets at time index \\(t\\) with the vector \\(\\mathbf{r}_t \\in \\mathbb{R}\\) . The time index \\(t\\) can denote any arbitrary period such as minutes, days, weeks, etc. The historical data before \\(t\\) is denoted by \\(\\mathcal{F}_{t-1}\\) . \u5df2\u77e5\u5386\u53f2\u6570\u636e \\(\\mathcal{F}_{t-1}\\) \uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u56de\u62a5\u7387\u5206\u89e3\u4e3a \u671f\u671b\u56de\u62a5\u7387 \u548c \u566a\u58f0 \uff1a \\[ \\mathbf{r}_t = \\mathbf{\\mu}_t + \\mathbf{\\varepsilon}_t \\] \u5176\u4e2d\uff0c \\(\\mathbf{\\mu}_t\\) \u662f\u6839\u636e\u5386\u53f2\u6570\u636e \\(\\mathcal{F}_{t-1}\\) \u8ba1\u7b97\u5f97\u5230\u7684\u671f\u671b\u6536\u76ca\uff1a \\[\\mathbf{\\mu}_t = E(\\mathbf{r}_t|\\mathcal{F}_{t-1})\\] \\(\\mathbf{\\varepsilon}_t\\) \u662f\u5747\u503c\u4e3a 0 \u7684\u767d\u566a\u58f0\uff0c\u5176\u65b9\u5dee\u4e3a\uff1a \\[ \\mathbf{\\Sigma}_t = E[(\\mathbf{r}_t - \\mathbf{\\mu}_t)(\\mathbf{r}_t - \\mathbf{\\mu}_t)^T|\\mathcal{F}_{t-1}] \\] \u6211\u4eec\u901a\u8fc7\u5386\u53f2\u6570\u636e\u4e3b\u8981\u662f\u5e0c\u671b\u8ba1\u7b97\u51fa \\(\\mathbf{\\mu}_t\\) \u548c \\(\\mathbf{\\Sigma}_t\\) \u3002 \u5982\u679c\u6211\u4eec\u7b80\u5355\u5047\u8bbe \\(\\mathbf{\\mu}_t\\) \u548c \\(\\mathbf{\\Sigma}_t\\) \u4e0d\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u5373 \\(\\mathbf{r}_t\\) \u662f\u72ec\u7acb\u540c\u5206\u5e03\u7684\uff0c\u5219\u5229\u7528 \\(1, ..., t-1\\) \u65f6\u523b\u7684\u5386\u53f2\u6570\u636e\uff0c\u53ef\u4ee5\u7b80\u5355\u4f30\u8ba1\uff1a \\[ \\mathbf{\\mu}_t = \\mathbf{\\mu} = \\frac{1}{t-1}\\sum_{k=1}^{t-1} \\mathbf{r}_k \\] \\[ \\mathbf{\\Sigma}_t = \\mathbf{\\Sigma} = \\frac{1}{t-2} \\sum_{k=1}^{t-1} (\\mathbf{r}_k - \\mathbf{\\mu})(\\mathbf{r}_k - \\mathbf{\\mu})^T \\] \u5047\u8bbe\u6211\u4eec\u603b\u8d44\u91d1\u4e3a \\(B\\) \u7f8e\u5143\uff0c\u5047\u8bbe\u6bcf\u79cd\u8d44\u4ea7\u914d\u7f6e\u7684\u6743\u91cd\u4e3a \\(\\mathbf{w}\\) \uff0c\u6211\u4eec\u6709\uff1a \\(B \\mathbf{w}\\) \u8868\u793a\u5728\u6bcf\u79cd\u8d44\u4ea7\u6295\u5165\u7684\u8d44\u91d1\uff0c\u53ef\u4ee5\u4e3a\u8d1f\u6570\uff0c\u4ee3\u8868 short selling portfolio \u7684\u671f\u671b\u56de\u62a5\u7387\u662f \\(\\mathbf{w}^T \\mathbf{\\mu}\\) portfolio \u7684\u98ce\u9669\uff08\u5373\u6ce2\u52a8\u7387\uff09\u4e3a \\(\\sqrt{\\mathbf{w}^T \\mathbf{\\Sigma} \\mathbf{w}}\\) 1 Markowitz Mean-Variance Portfolio Optimization Markowitz mean-variance framework \u662f\u7ec4\u5408\u4f18\u5316\u7406\u8bba\u7684\u57fa\u77f3\u3002\u5b83\u7684\u76ee\u6807\u662f\u5bfb\u627e\u56de\u62a5\u548c\u98ce\u9669\u7684\u6700\u4f73 trade-off\u3002 1.1 Mean-Variance Trade-Off Optimization \u6211\u4eec\u53ef\u4ee5\u5c06\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u8868\u793a\u4e3a\uff1a \\[\\begin{align} \\mathop{\\arg \\max}_{\\mathbf{w}} & & \\mathbf{w}^T \\mathbf{\\mu} - \\lambda \\mathbf{w}^T\\mathbf{\\Sigma}\\mathbf{w} \\\\ \\text{s.t.} & &\\mathbf{w} \\mathbf{\\mu} >= \\mu_0, \\\\ & &\\mathbf{1}^T \\mathbf{w} = 1 \\end{align}\\] \u5176\u4e2d\uff0c \\(\\lambda\\) \u53c2\u6570\u53cd\u6620\u6295\u8d44\u8005\u7684\u98ce\u9669\u538c\u6076\u7a0b\u5ea6\u3002 \u8be5\u4f18\u5316\u95ee\u9898\u53ef\u4ee5\u7b80\u5355\u7528 Lagrange multiplier \u89e3\u51b3\uff0c\u4ee4\uff1a \\[ L(\\mathbf{w}, \\alpha) = \\mathbf{w}^T \\mathbf{\\mu} - \\lambda \\mathbf{w}^T\\mathbf{\\Sigma}\\mathbf{w} + \\alpha (\\mathbf{1}^T\\mathbf{w} - 1) \\] \u89e3\u65b9\u7a0b\u7ec4\uff1a \\[\\begin{cases} \\dfrac{\\partial L}{\\partial \\mathbf{w}} &= \\mathbf{\\mu} - 2\\lambda \\mathbf{\\Sigma}\\mathbf{w} + \\alpha\\mathbf{1} = 0 \\\\ \\dfrac{\\partial L}{\\partial \\alpha} &= \\mathbf{1}^T\\mathbf{w} - \\mathbf{1} = 0 \\end{cases}\\] \u4ece 1 \u5f0f\u5f97\u5230\uff1a \\[ \\mathbf{w} = \\frac{1}{2\\lambda} \\mathbf{\\Sigma}^{-1}(\\mathbf{\\mu} + \\alpha\\mathbf{1})\\] \u5c06 \\(\\mathbf{w}\\) \u5e26\u5165 2 \u5f0f\uff0c\u5f97\u5230\u4e0a\u5f0f\u7684 \\(\\alpha\\) \uff1a \\[ \\alpha = \\dfrac{2\\lambda - \\mathbf{1}^T\\mathbf{\\Sigma}^{-1}\\mathbf{\\mu} }{\\mathbf{1}^T\\mathbf{\\Sigma}^{-1}\\mathbf{1}}\\] \u81f3\u6b64\uff0c\u8be5\u4f18\u5316\u95ee\u9898\u7684\u6700\u4f18\u89e3\u786e\u5b9a\u3002 Efficient Frontier \u6709\u6548\u8fb9\u754c \u6240\u8c13 capital market line\uff0c\u662f\u6307\u5f53\u4e00\u4e2a\u4ea4\u6613\u8005\u53ef\u4ee5\u4ee5\u65e0\u98ce\u9669\u5229\u7387\u8d37\u6b3e\u548c\u501f\u6b3e\uff08\u7406\u60f3\u72b6\u51b5\uff09\u65f6\u7684\u6295\u8d44\u7ec4\u5408\u3002 1.2 Sharpe Ratio Optimization \u590f\u666e\u7387(Sharpe Ratio) \u8868\u793a\u6bcf\u5355\u4f4d\u98ce\u9669\uff08\u6ce2\u52a8\u7387\uff09\u7684\u8d85\u989d\u6536\u76ca\uff1a \\[ \\text{SR} = \\frac{\\mathbf{w}^T \\mathbf{\\mu} - r_f}{\\sqrt{\\mathbf{w}^T \\mathbf{\\Sigma} \\mathbf{w}}}\\] \u5982\u679c\u4ee5\u6700\u5927\u590f\u666e\u7387\u4e3a\u4f18\u5316\u76ee\u6807\uff0c\u5219\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\[\\begin{align} \\mathop{\\arg \\max}_{\\mathbf{w}} & & \\dfrac{\\mathbf{w}^T \\mathbf{\\mu} - r_f}{\\sqrt{\\mathbf{w}^T\\mathbf{\\Sigma}\\mathbf{w}}} \\\\ \\text{s.t.} & &\\mathbf{1}^T \\mathbf{w} = 1 \\end{align}\\] \u8be5\u95ee\u9898\u4e0d\u662f\u4e00\u4e2a\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u56e0\u6b64\u65e0\u6cd5\u76f4\u63a5\u6c42\u89e3\u3002\u6ce8\u610f\u5230 \\(\\mathbf{w}^T \\mathbf{1} = 1\\) \uff0c\u53ef\u4ee5\u6539\u5199\u4e3a\uff1a \\[\\begin{align} \\mathop{\\arg \\max}_{\\mathbf{w}} & & \\dfrac{\\mathbf{w}^T (\\mathbf{\\mu} - r_f \\mathbf{1})}{\\sqrt{\\mathbf{w}^T\\mathbf{\\Sigma}\\mathbf{w}}} \\\\ \\text{s.t.} & &\\mathbf{1}^T \\mathbf{w} = 1 \\end{align}\\] \u8fd9\u6837\u8f6c\u5316\u7684\u610f\u4e49\u662f\u8ba9\u76ee\u6807\u51fd\u6570\u4e0e \\(\\mathbf{w}\\) \u7684\u5c3a\u5ea6\u65e0\u5173\u3002\u8fd9\u662f\u663e\u7136\u7684\uff0c\u5047\u8bbe\u628a \\(\\mathbf{w}\\) \u653e\u5927\u4e3a \\(k \\mathbf{w}\\) \uff0c\u7531\u4e8e\u5206\u5b50\u548c\u5206\u6bcd\u62b5\u6d88\uff0c\u76ee\u6807\u51fd\u6570\u4e0d\u53d8\u3002 \u56e0\u6b64\uff0c\u6761\u4ef6 \\(\\mathbf{1}^T \\mathbf{w} = 1\\) \u53ef\u4ee5\u653e\u5bbd\u4e3a \\(\\mathbf{1}^T \\mathbf{w} > 0\\) \u3002\u56e0\u6b64\uff0c\u6211\u4eec\u603b\u80fd\u627e\u5230\u4e00\u7ec4 \\(\\mathbf{w}\\) \u4f7f\u5f97\uff1a \\[\\mathbf{w}^T (\\mathbf{\\mu} - r_f \\mathbf{1}) = 1\\] \u90a3\u4e48\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u56fa\u5b9a\u8fd9\u4e2a\u5206\u5b50\u4e3a 1\uff0c\u8f6c\u800c\u5bfb\u627e\u4f7f\u5206\u6bcd\u6700\u5c0f\u7684\u89e3\uff0c\u8f6c\u5316\u4e3a\u4e00\u4e2a\u51f8\u4f18\u5316\u95ee\u9898\uff1a \\[\\begin{align} \\mathop{\\arg \\min}_{\\mathbf{w}} & & \\mathbf{w}^T\\mathbf{\\Sigma}\\mathbf{w} \\\\ \\text{s.t.} & &\\mathbf{w}^T (\\mathbf{\\mu} - r_f \\mathbf{1}) = 1 \\\\ & & \\mathbf{1}^T \\mathbf{w} > 0 \\end{align}\\] \u5982\u679c\u5ffd\u7565 \\(\\mathbf{1}^T \\mathbf{w} > 0\\) \u8fd9\u4e2a\u6761\u4ef6\uff0c\u5219\u4e0a\u5f0f\u7684\u89e3\u4e3a\uff1a \\[\\mathbf{w}_{\\text{SR}} = \\dfrac{\\mathbf{\\Sigma}^{-1}(\\mathbf{\\mu} - r_f \\mathbf{1})}{(\\mathbf{\\mu} - r_f \\mathbf{1})^T \\mathbf{\\Sigma}^{-1} (\\mathbf{\\mu} - r_f \\mathbf{1})}\\] \u8fd9\u4e2a\u6700\u4f18\u89e3\u4e5f\u6709\u6548\u8fb9\u754c\u4e0a\uff08\u56fe\u4e2d\u84dd\u8272\u7684\u70b9\uff09\uff0c\u5b83\u662f capital market line \u4e0e effective frontier \u7684\u4ea4\u70b9\u3002 2 Drawbacks of Markowitz Framework \u867d\u7136 Markowitz \u7684\u65b9\u6cd5\u7b80\u5355\u6613\u61c2\uff0c\u4f46\u662f\u5b9e\u9645\u4e2d\u5374\u5e76\u4e0d\u5b9e\u7528\u3002\u56e0\u4e3a\u5b83\u6709\u4e24\u4e2a\u4e3b\u8981\u7f3a\u9677\uff1a \u6ce2\u52a8\u7387\u5e76\u4e0d\u662f\u4e00\u4e2a\u597d\u7684\u98ce\u9669\u8bc4\u4ef7\u6307\u6807 \u5bf9\u53c2\u6570\u53d8\u5316\u6781\u5176\u654f\u611f 2.1 Variance Is Not a Good Risk Measurement \u5728\u8bc4\u4ef7\u4e00\u4e2a\u6295\u8d44\u7ec4\u5408\u7684\u65f6\u5019\uff0c\u6211\u4eec\u66f4\u52a0\u5728\u610f\u662f\u5426\u51fa\u73b0\u5927\u7684\u4e8f\u635f\uff0c\u5c0f\u989d\u7684\u4e8f\u635f\u662f\u53ef\u63a5\u53d7\u7684\u6ce2\u52a8\uff0c\u540c\u65f6\uff0c\u6211\u4eec\u4e0d\u5e94\u8be5\u53bb\u60e9\u7f5a\u5927\u989d\u7684\u4e0a\u6da8\u3002 \u56e0\u6b64\uff0c\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u6211\u4eec\u53ef\u4ee5 \u53ea\u60e9\u7f5a\u5927\u989d\u4e8f\u635f \u7684\u60c5\u5f62\u3002\u6bd4\u8f83\u5e38\u7528\u7684\u98ce\u9669\u6d4b\u5ea6\u662f Conditional Value at Risk (CVaR)\u3002 2.1.1 CVaR Portfolio Optimization \u9996\u5148\u4ecb\u7ecd VaR (Value at Risk)\u3002\"p VaR\" \u8868\u793a\u635f\u5931\u9ad8\u4e8e VaR \u7684\u53ef\u80fd\u6027\u4e3a \\(1-p\\) \u3002\u6362\u8a00\u4e4b\uff0c\u635f\u5931\u4f4e\u4e8e VaR \u7684\u6982\u7387\u81f3\u591a\u4e3a \\(p\\) \u3002\u6570\u5b66\u4e0a\u5b9a\u4e49\uff0c\u5bf9\u4e8e\u968f\u673a\u53d8\u91cf \\(X\\) \uff0c \\(\\text{VaR}_{p}(X)\\) \u5c31\u662f \\(X\\) \u7684 \\(p-\\text{quantile}\\) \u3002 \u4e3e\u4f8b\u8bf4\u660e\uff0c\u5047\u8bbe\u67d0\u4e2a portfolio \u7684 95% VaR \u662f 100 \u4e07\u3002\u5219\u8868\u793a\u6709 5% \u7684\u51e0\u7387\u8fd9\u4e2a portfolio \u4f1a\u4e8f\u635f 100 \u4e07\u4ee5\u4e0a\u3002 CVaR \u662f VaR \u7684 \u6761\u4ef6\u671f\u671b\u503c \uff0c\u5373\u52a0\u6743\u5e73\u5747\u503c\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a VaR \u5e76\u4e0d\u662f\u4e00\u4e2a coherent risk measure\uff0c\u4f46\u662f CVaR \u662f\uff0c\u5e76\u4e14\u8fd8\u80fd\u8f6c\u5316\u4e3a\u51f8\u4f18\u5316\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u5f97\u76ca\u4e8e\u5176\u826f\u597d\u7684\u6570\u5b66\u7279\u6027\uff0cCVaR \u5f97\u5230\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9645\u5e94\u7528\u3002 \\[ \\text{CVaR}_{1 - \\varepsilon}(X) = E[X| X > \\text{VaR}_{1 - \\varepsilon} (X)] \\] \u5047\u8bbe \\(\\mathbf{r}\\) \u662f\u5404\u4e2a\u8d44\u4ea7\u7684\u56de\u62a5\u7387\uff0cportfolio \u4e8f\u635f\u662f \\(-\\mathbf{w}^T \\mathbf{r}\\) \uff0c\u5219\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e3a\uff1a \\[\\begin{align} \\mathop{\\arg \\min}_{\\mathbf{w}} & & \\text{CVaR}_{1 - \\varepsilon} (-\\mathbf{w}^T \\mathbf{r}) \\\\ \\text{s.t.} & & \\mathbf{1}^T \\mathbf{w} = 1 \\\\ \\end{align}\\] \u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u662f\u4e00\u4e2a\u975e\u51f8\u4f18\u5316\u3002Rockafellar \u548c Uryasev \u5f15\u5165\u4e86\u4e00\u4e2a\u8f85\u52a9\u51fd\u6570\u6765\u5c06\u5176\u8f6c\u5316\u4e3a\u51f8\u4f18\u5316\u95ee\u9898\uff1a \\[\\begin{align} F_{\\varepsilon}(\\mathbf{w}, \\gamma) &= \\gamma + \\frac{1}{\\varepsilon} E[\\mathbf{w}^T \\mathbf{r} - \\gamma]^{+}\\\\ &=\\gamma + \\frac{1}{\\varepsilon} \\int_{\\mathbf{w}^T \\mathbf{r} \\geq \\gamma}[\\mathbf{w}^T \\mathbf{r} - \\gamma]p(x) dx \\end{align}\\] \u5176\u4e2d\uff1a \\(\\gamma = \\text{VaR}_{1 - \\varepsilon} (X)\\) \uff0c\u663e\u7136\uff0c\u5b83\u4e0e \\(\\mathbf{w}\\) \u7684\u53d6\u503c\u6709\u5173\u3002 \\(p(x)\\) \u662f\u5bc6\u5ea6\u51fd\u6570\uff0c\u4ee3\u8868\u4f7f\u5f97 1 \u6210\u7acb\u7684 \\(x\\) \u7684\u6982\u7387 Rockafellar \u548c Uryasev \u8bc1\u660e\u4e86 \\(F_{\\alpha}(\\textbf{w}, \\gamma)\\) \u5bf9\u4e8e \\(\\gamma\\) \u662f\u51f8\u51fd\u6570\u3002\u5e76\u4e14\u6709\uff1a \\[ \\text{CVaR}_{1-\\varepsilon} (X) = \\mathop{\\arg \\min}_{\\gamma} ~ F_{\\varepsilon}(\\textbf{w}, \\gamma)\\] \u867d\u7136\u8f6c\u5316\u4e3a\u4e86\u4e00\u4e2a\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u4f46\u662f \\(E[\\mathbf{w} \\mathbf{r} - \\gamma]^{+}\\) \u540c\u6837\u4e0d\u662f\u5f88\u597d\u8ba1\u7b97\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u5386\u53f2\u56de\u62a5 \\(\\mathbf{r}_t\\) \u6765\u8fd1\u4f3c\uff1a \\[\\begin{align} \\mathop{\\arg \\min}_{\\mathbf{w}, \\mathbf{z}, \\gamma} & & \\gamma + \\frac{1}{\\varepsilon T} \\sum_{t=1}^T z_t \\\\ \\text{s.t.} & & \\mathbf{1}^T \\mathbf{w} = 1 \\\\ & & - \\mathbf{w}^T\\mathbf{r}_t - \\gamma \\leq z_t \\leq 0 \\end{align}\\] \u4e8e\u662f\uff0c\u8be5\u95ee\u9898\u8f6c\u5316\u4e3a\u4e86\u4e00\u4e2a\u7ebf\u6027\u89c4\u5212\u95ee\u9898\uff0c\u53ef\u4ee5\u7b80\u5355\u6c42\u89e3\u3002 2.2 Markowitz Framework Is Too Sensitive Markowitz \u65b9\u6cd5\u7684\u7b2c\u4e8c\u4e2a\u7f3a\u70b9\u662f\u5bf9\u53c2\u6570\u8fc7\u4e8e\u654f\u611f\u3002 \\(\\mathbf{\\mu}\\) \u548c \\(\\mathbf{\\Sigma}\\) \u7684\u5fae\u5c0f\u53d8\u5316\u90fd\u80fd\u5f15\u8d77 \\(\\mathbf{w}\\) \u7684\u5927\u5e45\u53d8\u5316\uff0c\u5bfc\u81f4\u5b83\u8981\u6c42\u9891\u7e41\u8c03\u6574\u4ed3\u4f4d\u3002 Reference Portfolio Optimization with Known Parameters Asset Allocation using Convex Portfolio Optimization","title":"Portfolio Optimization with Known Parameters"},{"location":"trading/portfolio/MarkowitzPO/#portfolio-optimization-with-known-parameters","text":"\u9996\u5148\u5f15\u5165\u4e00\u4e9b\u4e4b\u540e\u4f7f\u7528\u7684\u7b26\u53f7\u5b9a\u4e49\u3002 In practice, a portfolio deals with a whole universe of \\(N\\) assets. We denote the log-returns of the \\(N\\) assets at time index \\(t\\) with the vector \\(\\mathbf{r}_t \\in \\mathbb{R}\\) . The time index \\(t\\) can denote any arbitrary period such as minutes, days, weeks, etc. The historical data before \\(t\\) is denoted by \\(\\mathcal{F}_{t-1}\\) . \u5df2\u77e5\u5386\u53f2\u6570\u636e \\(\\mathcal{F}_{t-1}\\) \uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u56de\u62a5\u7387\u5206\u89e3\u4e3a \u671f\u671b\u56de\u62a5\u7387 \u548c \u566a\u58f0 \uff1a \\[ \\mathbf{r}_t = \\mathbf{\\mu}_t + \\mathbf{\\varepsilon}_t \\] \u5176\u4e2d\uff0c \\(\\mathbf{\\mu}_t\\) \u662f\u6839\u636e\u5386\u53f2\u6570\u636e \\(\\mathcal{F}_{t-1}\\) \u8ba1\u7b97\u5f97\u5230\u7684\u671f\u671b\u6536\u76ca\uff1a \\[\\mathbf{\\mu}_t = E(\\mathbf{r}_t|\\mathcal{F}_{t-1})\\] \\(\\mathbf{\\varepsilon}_t\\) \u662f\u5747\u503c\u4e3a 0 \u7684\u767d\u566a\u58f0\uff0c\u5176\u65b9\u5dee\u4e3a\uff1a \\[ \\mathbf{\\Sigma}_t = E[(\\mathbf{r}_t - \\mathbf{\\mu}_t)(\\mathbf{r}_t - \\mathbf{\\mu}_t)^T|\\mathcal{F}_{t-1}] \\] \u6211\u4eec\u901a\u8fc7\u5386\u53f2\u6570\u636e\u4e3b\u8981\u662f\u5e0c\u671b\u8ba1\u7b97\u51fa \\(\\mathbf{\\mu}_t\\) \u548c \\(\\mathbf{\\Sigma}_t\\) \u3002 \u5982\u679c\u6211\u4eec\u7b80\u5355\u5047\u8bbe \\(\\mathbf{\\mu}_t\\) \u548c \\(\\mathbf{\\Sigma}_t\\) \u4e0d\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u5373 \\(\\mathbf{r}_t\\) \u662f\u72ec\u7acb\u540c\u5206\u5e03\u7684\uff0c\u5219\u5229\u7528 \\(1, ..., t-1\\) \u65f6\u523b\u7684\u5386\u53f2\u6570\u636e\uff0c\u53ef\u4ee5\u7b80\u5355\u4f30\u8ba1\uff1a \\[ \\mathbf{\\mu}_t = \\mathbf{\\mu} = \\frac{1}{t-1}\\sum_{k=1}^{t-1} \\mathbf{r}_k \\] \\[ \\mathbf{\\Sigma}_t = \\mathbf{\\Sigma} = \\frac{1}{t-2} \\sum_{k=1}^{t-1} (\\mathbf{r}_k - \\mathbf{\\mu})(\\mathbf{r}_k - \\mathbf{\\mu})^T \\] \u5047\u8bbe\u6211\u4eec\u603b\u8d44\u91d1\u4e3a \\(B\\) \u7f8e\u5143\uff0c\u5047\u8bbe\u6bcf\u79cd\u8d44\u4ea7\u914d\u7f6e\u7684\u6743\u91cd\u4e3a \\(\\mathbf{w}\\) \uff0c\u6211\u4eec\u6709\uff1a \\(B \\mathbf{w}\\) \u8868\u793a\u5728\u6bcf\u79cd\u8d44\u4ea7\u6295\u5165\u7684\u8d44\u91d1\uff0c\u53ef\u4ee5\u4e3a\u8d1f\u6570\uff0c\u4ee3\u8868 short selling portfolio \u7684\u671f\u671b\u56de\u62a5\u7387\u662f \\(\\mathbf{w}^T \\mathbf{\\mu}\\) portfolio \u7684\u98ce\u9669\uff08\u5373\u6ce2\u52a8\u7387\uff09\u4e3a \\(\\sqrt{\\mathbf{w}^T \\mathbf{\\Sigma} \\mathbf{w}}\\)","title":"Portfolio Optimization with Known Parameters"},{"location":"trading/portfolio/MarkowitzPO/#1-markowitz-mean-variance-portfolio-optimization","text":"Markowitz mean-variance framework \u662f\u7ec4\u5408\u4f18\u5316\u7406\u8bba\u7684\u57fa\u77f3\u3002\u5b83\u7684\u76ee\u6807\u662f\u5bfb\u627e\u56de\u62a5\u548c\u98ce\u9669\u7684\u6700\u4f73 trade-off\u3002","title":"1 Markowitz Mean-Variance Portfolio Optimization"},{"location":"trading/portfolio/MarkowitzPO/#11-mean-variance-trade-off-optimization","text":"\u6211\u4eec\u53ef\u4ee5\u5c06\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u8868\u793a\u4e3a\uff1a \\[\\begin{align} \\mathop{\\arg \\max}_{\\mathbf{w}} & & \\mathbf{w}^T \\mathbf{\\mu} - \\lambda \\mathbf{w}^T\\mathbf{\\Sigma}\\mathbf{w} \\\\ \\text{s.t.} & &\\mathbf{w} \\mathbf{\\mu} >= \\mu_0, \\\\ & &\\mathbf{1}^T \\mathbf{w} = 1 \\end{align}\\] \u5176\u4e2d\uff0c \\(\\lambda\\) \u53c2\u6570\u53cd\u6620\u6295\u8d44\u8005\u7684\u98ce\u9669\u538c\u6076\u7a0b\u5ea6\u3002 \u8be5\u4f18\u5316\u95ee\u9898\u53ef\u4ee5\u7b80\u5355\u7528 Lagrange multiplier \u89e3\u51b3\uff0c\u4ee4\uff1a \\[ L(\\mathbf{w}, \\alpha) = \\mathbf{w}^T \\mathbf{\\mu} - \\lambda \\mathbf{w}^T\\mathbf{\\Sigma}\\mathbf{w} + \\alpha (\\mathbf{1}^T\\mathbf{w} - 1) \\] \u89e3\u65b9\u7a0b\u7ec4\uff1a \\[\\begin{cases} \\dfrac{\\partial L}{\\partial \\mathbf{w}} &= \\mathbf{\\mu} - 2\\lambda \\mathbf{\\Sigma}\\mathbf{w} + \\alpha\\mathbf{1} = 0 \\\\ \\dfrac{\\partial L}{\\partial \\alpha} &= \\mathbf{1}^T\\mathbf{w} - \\mathbf{1} = 0 \\end{cases}\\] \u4ece 1 \u5f0f\u5f97\u5230\uff1a \\[ \\mathbf{w} = \\frac{1}{2\\lambda} \\mathbf{\\Sigma}^{-1}(\\mathbf{\\mu} + \\alpha\\mathbf{1})\\] \u5c06 \\(\\mathbf{w}\\) \u5e26\u5165 2 \u5f0f\uff0c\u5f97\u5230\u4e0a\u5f0f\u7684 \\(\\alpha\\) \uff1a \\[ \\alpha = \\dfrac{2\\lambda - \\mathbf{1}^T\\mathbf{\\Sigma}^{-1}\\mathbf{\\mu} }{\\mathbf{1}^T\\mathbf{\\Sigma}^{-1}\\mathbf{1}}\\] \u81f3\u6b64\uff0c\u8be5\u4f18\u5316\u95ee\u9898\u7684\u6700\u4f18\u89e3\u786e\u5b9a\u3002","title":"1.1 Mean-Variance Trade-Off Optimization"},{"location":"trading/portfolio/MarkowitzPO/#efficient-frontier","text":"\u6709\u6548\u8fb9\u754c \u6240\u8c13 capital market line\uff0c\u662f\u6307\u5f53\u4e00\u4e2a\u4ea4\u6613\u8005\u53ef\u4ee5\u4ee5\u65e0\u98ce\u9669\u5229\u7387\u8d37\u6b3e\u548c\u501f\u6b3e\uff08\u7406\u60f3\u72b6\u51b5\uff09\u65f6\u7684\u6295\u8d44\u7ec4\u5408\u3002","title":"Efficient Frontier"},{"location":"trading/portfolio/MarkowitzPO/#12-sharpe-ratio-optimization","text":"\u590f\u666e\u7387(Sharpe Ratio) \u8868\u793a\u6bcf\u5355\u4f4d\u98ce\u9669\uff08\u6ce2\u52a8\u7387\uff09\u7684\u8d85\u989d\u6536\u76ca\uff1a \\[ \\text{SR} = \\frac{\\mathbf{w}^T \\mathbf{\\mu} - r_f}{\\sqrt{\\mathbf{w}^T \\mathbf{\\Sigma} \\mathbf{w}}}\\] \u5982\u679c\u4ee5\u6700\u5927\u590f\u666e\u7387\u4e3a\u4f18\u5316\u76ee\u6807\uff0c\u5219\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\[\\begin{align} \\mathop{\\arg \\max}_{\\mathbf{w}} & & \\dfrac{\\mathbf{w}^T \\mathbf{\\mu} - r_f}{\\sqrt{\\mathbf{w}^T\\mathbf{\\Sigma}\\mathbf{w}}} \\\\ \\text{s.t.} & &\\mathbf{1}^T \\mathbf{w} = 1 \\end{align}\\] \u8be5\u95ee\u9898\u4e0d\u662f\u4e00\u4e2a\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u56e0\u6b64\u65e0\u6cd5\u76f4\u63a5\u6c42\u89e3\u3002\u6ce8\u610f\u5230 \\(\\mathbf{w}^T \\mathbf{1} = 1\\) \uff0c\u53ef\u4ee5\u6539\u5199\u4e3a\uff1a \\[\\begin{align} \\mathop{\\arg \\max}_{\\mathbf{w}} & & \\dfrac{\\mathbf{w}^T (\\mathbf{\\mu} - r_f \\mathbf{1})}{\\sqrt{\\mathbf{w}^T\\mathbf{\\Sigma}\\mathbf{w}}} \\\\ \\text{s.t.} & &\\mathbf{1}^T \\mathbf{w} = 1 \\end{align}\\] \u8fd9\u6837\u8f6c\u5316\u7684\u610f\u4e49\u662f\u8ba9\u76ee\u6807\u51fd\u6570\u4e0e \\(\\mathbf{w}\\) \u7684\u5c3a\u5ea6\u65e0\u5173\u3002\u8fd9\u662f\u663e\u7136\u7684\uff0c\u5047\u8bbe\u628a \\(\\mathbf{w}\\) \u653e\u5927\u4e3a \\(k \\mathbf{w}\\) \uff0c\u7531\u4e8e\u5206\u5b50\u548c\u5206\u6bcd\u62b5\u6d88\uff0c\u76ee\u6807\u51fd\u6570\u4e0d\u53d8\u3002 \u56e0\u6b64\uff0c\u6761\u4ef6 \\(\\mathbf{1}^T \\mathbf{w} = 1\\) \u53ef\u4ee5\u653e\u5bbd\u4e3a \\(\\mathbf{1}^T \\mathbf{w} > 0\\) \u3002\u56e0\u6b64\uff0c\u6211\u4eec\u603b\u80fd\u627e\u5230\u4e00\u7ec4 \\(\\mathbf{w}\\) \u4f7f\u5f97\uff1a \\[\\mathbf{w}^T (\\mathbf{\\mu} - r_f \\mathbf{1}) = 1\\] \u90a3\u4e48\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u56fa\u5b9a\u8fd9\u4e2a\u5206\u5b50\u4e3a 1\uff0c\u8f6c\u800c\u5bfb\u627e\u4f7f\u5206\u6bcd\u6700\u5c0f\u7684\u89e3\uff0c\u8f6c\u5316\u4e3a\u4e00\u4e2a\u51f8\u4f18\u5316\u95ee\u9898\uff1a \\[\\begin{align} \\mathop{\\arg \\min}_{\\mathbf{w}} & & \\mathbf{w}^T\\mathbf{\\Sigma}\\mathbf{w} \\\\ \\text{s.t.} & &\\mathbf{w}^T (\\mathbf{\\mu} - r_f \\mathbf{1}) = 1 \\\\ & & \\mathbf{1}^T \\mathbf{w} > 0 \\end{align}\\] \u5982\u679c\u5ffd\u7565 \\(\\mathbf{1}^T \\mathbf{w} > 0\\) \u8fd9\u4e2a\u6761\u4ef6\uff0c\u5219\u4e0a\u5f0f\u7684\u89e3\u4e3a\uff1a \\[\\mathbf{w}_{\\text{SR}} = \\dfrac{\\mathbf{\\Sigma}^{-1}(\\mathbf{\\mu} - r_f \\mathbf{1})}{(\\mathbf{\\mu} - r_f \\mathbf{1})^T \\mathbf{\\Sigma}^{-1} (\\mathbf{\\mu} - r_f \\mathbf{1})}\\] \u8fd9\u4e2a\u6700\u4f18\u89e3\u4e5f\u6709\u6548\u8fb9\u754c\u4e0a\uff08\u56fe\u4e2d\u84dd\u8272\u7684\u70b9\uff09\uff0c\u5b83\u662f capital market line \u4e0e effective frontier \u7684\u4ea4\u70b9\u3002","title":"1.2 Sharpe Ratio Optimization"},{"location":"trading/portfolio/MarkowitzPO/#2-drawbacks-of-markowitz-framework","text":"\u867d\u7136 Markowitz \u7684\u65b9\u6cd5\u7b80\u5355\u6613\u61c2\uff0c\u4f46\u662f\u5b9e\u9645\u4e2d\u5374\u5e76\u4e0d\u5b9e\u7528\u3002\u56e0\u4e3a\u5b83\u6709\u4e24\u4e2a\u4e3b\u8981\u7f3a\u9677\uff1a \u6ce2\u52a8\u7387\u5e76\u4e0d\u662f\u4e00\u4e2a\u597d\u7684\u98ce\u9669\u8bc4\u4ef7\u6307\u6807 \u5bf9\u53c2\u6570\u53d8\u5316\u6781\u5176\u654f\u611f","title":"2 Drawbacks of Markowitz Framework"},{"location":"trading/portfolio/MarkowitzPO/#21-variance-is-not-a-good-risk-measurement","text":"\u5728\u8bc4\u4ef7\u4e00\u4e2a\u6295\u8d44\u7ec4\u5408\u7684\u65f6\u5019\uff0c\u6211\u4eec\u66f4\u52a0\u5728\u610f\u662f\u5426\u51fa\u73b0\u5927\u7684\u4e8f\u635f\uff0c\u5c0f\u989d\u7684\u4e8f\u635f\u662f\u53ef\u63a5\u53d7\u7684\u6ce2\u52a8\uff0c\u540c\u65f6\uff0c\u6211\u4eec\u4e0d\u5e94\u8be5\u53bb\u60e9\u7f5a\u5927\u989d\u7684\u4e0a\u6da8\u3002 \u56e0\u6b64\uff0c\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u6211\u4eec\u53ef\u4ee5 \u53ea\u60e9\u7f5a\u5927\u989d\u4e8f\u635f \u7684\u60c5\u5f62\u3002\u6bd4\u8f83\u5e38\u7528\u7684\u98ce\u9669\u6d4b\u5ea6\u662f Conditional Value at Risk (CVaR)\u3002","title":"2.1 Variance Is Not a Good Risk Measurement"},{"location":"trading/portfolio/MarkowitzPO/#211-cvar-portfolio-optimization","text":"\u9996\u5148\u4ecb\u7ecd VaR (Value at Risk)\u3002\"p VaR\" \u8868\u793a\u635f\u5931\u9ad8\u4e8e VaR \u7684\u53ef\u80fd\u6027\u4e3a \\(1-p\\) \u3002\u6362\u8a00\u4e4b\uff0c\u635f\u5931\u4f4e\u4e8e VaR \u7684\u6982\u7387\u81f3\u591a\u4e3a \\(p\\) \u3002\u6570\u5b66\u4e0a\u5b9a\u4e49\uff0c\u5bf9\u4e8e\u968f\u673a\u53d8\u91cf \\(X\\) \uff0c \\(\\text{VaR}_{p}(X)\\) \u5c31\u662f \\(X\\) \u7684 \\(p-\\text{quantile}\\) \u3002 \u4e3e\u4f8b\u8bf4\u660e\uff0c\u5047\u8bbe\u67d0\u4e2a portfolio \u7684 95% VaR \u662f 100 \u4e07\u3002\u5219\u8868\u793a\u6709 5% \u7684\u51e0\u7387\u8fd9\u4e2a portfolio \u4f1a\u4e8f\u635f 100 \u4e07\u4ee5\u4e0a\u3002 CVaR \u662f VaR \u7684 \u6761\u4ef6\u671f\u671b\u503c \uff0c\u5373\u52a0\u6743\u5e73\u5747\u503c\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a VaR \u5e76\u4e0d\u662f\u4e00\u4e2a coherent risk measure\uff0c\u4f46\u662f CVaR \u662f\uff0c\u5e76\u4e14\u8fd8\u80fd\u8f6c\u5316\u4e3a\u51f8\u4f18\u5316\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u5f97\u76ca\u4e8e\u5176\u826f\u597d\u7684\u6570\u5b66\u7279\u6027\uff0cCVaR \u5f97\u5230\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9645\u5e94\u7528\u3002 \\[ \\text{CVaR}_{1 - \\varepsilon}(X) = E[X| X > \\text{VaR}_{1 - \\varepsilon} (X)] \\] \u5047\u8bbe \\(\\mathbf{r}\\) \u662f\u5404\u4e2a\u8d44\u4ea7\u7684\u56de\u62a5\u7387\uff0cportfolio \u4e8f\u635f\u662f \\(-\\mathbf{w}^T \\mathbf{r}\\) \uff0c\u5219\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e3a\uff1a \\[\\begin{align} \\mathop{\\arg \\min}_{\\mathbf{w}} & & \\text{CVaR}_{1 - \\varepsilon} (-\\mathbf{w}^T \\mathbf{r}) \\\\ \\text{s.t.} & & \\mathbf{1}^T \\mathbf{w} = 1 \\\\ \\end{align}\\] \u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u662f\u4e00\u4e2a\u975e\u51f8\u4f18\u5316\u3002Rockafellar \u548c Uryasev \u5f15\u5165\u4e86\u4e00\u4e2a\u8f85\u52a9\u51fd\u6570\u6765\u5c06\u5176\u8f6c\u5316\u4e3a\u51f8\u4f18\u5316\u95ee\u9898\uff1a \\[\\begin{align} F_{\\varepsilon}(\\mathbf{w}, \\gamma) &= \\gamma + \\frac{1}{\\varepsilon} E[\\mathbf{w}^T \\mathbf{r} - \\gamma]^{+}\\\\ &=\\gamma + \\frac{1}{\\varepsilon} \\int_{\\mathbf{w}^T \\mathbf{r} \\geq \\gamma}[\\mathbf{w}^T \\mathbf{r} - \\gamma]p(x) dx \\end{align}\\] \u5176\u4e2d\uff1a \\(\\gamma = \\text{VaR}_{1 - \\varepsilon} (X)\\) \uff0c\u663e\u7136\uff0c\u5b83\u4e0e \\(\\mathbf{w}\\) \u7684\u53d6\u503c\u6709\u5173\u3002 \\(p(x)\\) \u662f\u5bc6\u5ea6\u51fd\u6570\uff0c\u4ee3\u8868\u4f7f\u5f97 1 \u6210\u7acb\u7684 \\(x\\) \u7684\u6982\u7387 Rockafellar \u548c Uryasev \u8bc1\u660e\u4e86 \\(F_{\\alpha}(\\textbf{w}, \\gamma)\\) \u5bf9\u4e8e \\(\\gamma\\) \u662f\u51f8\u51fd\u6570\u3002\u5e76\u4e14\u6709\uff1a \\[ \\text{CVaR}_{1-\\varepsilon} (X) = \\mathop{\\arg \\min}_{\\gamma} ~ F_{\\varepsilon}(\\textbf{w}, \\gamma)\\] \u867d\u7136\u8f6c\u5316\u4e3a\u4e86\u4e00\u4e2a\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u4f46\u662f \\(E[\\mathbf{w} \\mathbf{r} - \\gamma]^{+}\\) \u540c\u6837\u4e0d\u662f\u5f88\u597d\u8ba1\u7b97\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u5386\u53f2\u56de\u62a5 \\(\\mathbf{r}_t\\) \u6765\u8fd1\u4f3c\uff1a \\[\\begin{align} \\mathop{\\arg \\min}_{\\mathbf{w}, \\mathbf{z}, \\gamma} & & \\gamma + \\frac{1}{\\varepsilon T} \\sum_{t=1}^T z_t \\\\ \\text{s.t.} & & \\mathbf{1}^T \\mathbf{w} = 1 \\\\ & & - \\mathbf{w}^T\\mathbf{r}_t - \\gamma \\leq z_t \\leq 0 \\end{align}\\] \u4e8e\u662f\uff0c\u8be5\u95ee\u9898\u8f6c\u5316\u4e3a\u4e86\u4e00\u4e2a\u7ebf\u6027\u89c4\u5212\u95ee\u9898\uff0c\u53ef\u4ee5\u7b80\u5355\u6c42\u89e3\u3002","title":"2.1.1 CVaR Portfolio Optimization"},{"location":"trading/portfolio/MarkowitzPO/#22-markowitz-framework-is-too-sensitive","text":"Markowitz \u65b9\u6cd5\u7684\u7b2c\u4e8c\u4e2a\u7f3a\u70b9\u662f\u5bf9\u53c2\u6570\u8fc7\u4e8e\u654f\u611f\u3002 \\(\\mathbf{\\mu}\\) \u548c \\(\\mathbf{\\Sigma}\\) \u7684\u5fae\u5c0f\u53d8\u5316\u90fd\u80fd\u5f15\u8d77 \\(\\mathbf{w}\\) \u7684\u5927\u5e45\u53d8\u5316\uff0c\u5bfc\u81f4\u5b83\u8981\u6c42\u9891\u7e41\u8c03\u6574\u4ed3\u4f4d\u3002","title":"2.2 Markowitz Framework Is Too Sensitive"},{"location":"trading/portfolio/MarkowitzPO/#reference","text":"Portfolio Optimization with Known Parameters Asset Allocation using Convex Portfolio Optimization","title":"Reference"}]}